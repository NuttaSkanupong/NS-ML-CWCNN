{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb37bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from keras.layers import Input, Convolution2D, Convolution1D, MaxPooling2D, Dense, Dropout, \\\n",
    "                          Flatten, concatenate, Activation, Reshape, \\\n",
    "                          UpSampling2D,ZeroPadding2D\n",
    "from keras import layers\n",
    "\n",
    "import keras\n",
    "from pylab import plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import plot, figure\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cmocean # for perceptually uniform colormaps\n",
    "import cartopy as cr # for geographic mapping\n",
    "import cartopy.crs as ccrs # for map projections\n",
    "import matplotlib.pyplot as plt # plotting tool\n",
    "import cartopy.feature as cfeature # to add coastlines, land and ocean\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfea\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pylab as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import geocat.viz as gv\n",
    "import cmaps\n",
    "import geocat.datafiles as gdf\n",
    "import geocat.viz as gv\n",
    "import geocat.viz.util as gvutil\n",
    "from scipy import stats\n",
    "from mpl_toolkits.basemap import Basemap, cm, shiftgrid, addcyclic\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import math\n",
    "import iris\n",
    "from datetime import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import numpy.polynomial.polynomial as poly\n",
    "from netCDF4 import Dataset\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from eofs.standard import Eof\n",
    "import pint\n",
    "import pint_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689c7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saved path\n",
    "outdir='C:/Users/user/Research/Research Code/CNN/trainning/channelwise_Nonnormalised/running mean/train_1188/'\n",
    "ifile_data ='C:/Users/user/Research/Research Code/CNN/Data/'\n",
    "testsizepath='C:/Users/user/Research/Research Code/CNN/y_test/running_mean/'\n",
    "\n",
    "ifile ='C:/Users/user/Research/Research Code/CNN/trainning/channelwise_Nonnormalised/running mean/train_1428/'\n",
    "outdir_original_pred = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/original/pred/'\n",
    "outdir_original_test = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/original/test/'\n",
    "outdir_original_valid = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/original/validation/'\n",
    "outdir_smooth_pred = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/pred/'\n",
    "outdir_smooth_test= 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/test/'\n",
    "outdir_smooth_valid= 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/validation/'\n",
    "outdir_correlation = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/correlation/'\n",
    "outdir_smooth_pred_label = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/pred_label/'\n",
    "save_path = 'C:/Users/user/Research/Research Code/CNN/PDO/Heatmap/'\n",
    "outdir =  'C:/Users/user/Research/Research Code/CNN/PDO/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1899fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set up all functions\n",
    "def weighted_areamean(ds):\n",
    "    '''area mean weighted by cos of latitude'''\n",
    "    weights = xr.ufuncs.cos(np.deg2rad(ds.lat))\n",
    "    norm = np.sum(weights) * len(ds.lon)\n",
    "    amean = (ds*weights).sum(('lat','lon')) / norm\n",
    "\n",
    "    return amean\n",
    "\n",
    "\n",
    "def acc_score(x,y):\n",
    "    '''timestepwise anomaly correlation coefficient, averaged over time\n",
    "        (simple version without seasonal climatoloty)'''\n",
    "    assert(x.shape==y.shape)\n",
    "    return np.mean([np.corrcoef(x[i].flatten(),y[i].flatten())[0,1] for i in range(len(x))])\n",
    "\n",
    "\n",
    "def corr_over_time(x,y):\n",
    "    '''timestepwise anomaly correlation coefficient, averaged over time\n",
    "        (simple version without seasonal climatoloty)'''    \n",
    "    mx = x[0:i].mean()\n",
    "    my = y[0:i].mean()\n",
    "    xm, ym = x[0:i]-mx, y[0:i]-my\n",
    "    r_num = (xm*ym).mean()\n",
    "    r_den = xm.std() * ym.std()\n",
    "    r = r_num / r_den\n",
    "        \n",
    "    return r\n",
    "\n",
    "def mean(x):\n",
    "    avg = sum(x)/len(x)\n",
    "    return round(avg,2)\n",
    "\n",
    "\n",
    "def adjust(ds):\n",
    "    '''transform the data'''\n",
    "    z1 = np.array(ds)\n",
    "    df = pd.DataFrame (z1)\n",
    "    pred = df.iloc[:,0]\n",
    "    return pred \n",
    "\n",
    "def correlation(x,y,z):\n",
    "    corr_test = np.corrcoef(x [0:i],y [0:i])[0,1]\n",
    "    z.append(corr_test)\n",
    "    \n",
    "def lowpass_filter (x,y):\n",
    "    '''fraction of nyquist frequency, here  it is 10 years'''\n",
    "    fs=1/12/30/24/3600 \n",
    "\n",
    "    nyquist = fs / 2 # 0.5 times the sampling frequency\n",
    "    cutoff=x # fraction of nyquist frequency, here  it is 10 years\n",
    "    b, a = signal.butter(5, cutoff, btype='lowpass') #low pass filter\n",
    "\n",
    "\n",
    "    dUfilt = signal.filtfilt(b, a, y)\n",
    "    dUfilt=np.array(dUfilt)\n",
    "    dUfilt=dUfilt.transpose()\n",
    "    return dUfilt\n",
    "\n",
    "def avg(myArray, N=12):\n",
    "    '''average every 12 months'''\n",
    "    cum = np.cumsum(myArray,0)\n",
    "    result = cum[N-1::N]/float(N)\n",
    "    result[1:] = result[1:] - result[:-1]\n",
    "\n",
    "    remainder = myArray.shape[0] % N\n",
    "    if remainder != 0:\n",
    "        if remainder < myArray.shape[0]:\n",
    "            lastAvg = (cum[-1]-cum[-1-remainder])/float(remainder)\n",
    "        else:\n",
    "            lastAvg = cum[-1]/float(remainder)\n",
    "        result = np.vstack([result, lastAvg])\n",
    "\n",
    "    return result\n",
    "\n",
    "def detrend_dim(da,trend, dim, deg=1):\n",
    "    '''detrend along a single dimension'''\n",
    "    p = da.polyfit(dim=dim, deg=deg)\n",
    "    fit = xr.polyval(trend[dim], p.polyfit_coefficients)\n",
    "    return da - fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a8ab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open inputdata\n"
     ]
    }
   ],
   "source": [
    "os.system('mkdir -p '+outdir)\n",
    "N_gpu = 0\n",
    "print('open inputdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d653a130",
   "metadata": {},
   "source": [
    "# Start training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9375ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (time: 2028, lat: 32, lon: 64, lev: 1)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1854-01-01 1854-02-01 ... 2022-12-01\n",
       "  * lat      (lat) float32 64.0 62.0 60.0 58.0 56.0 ... 10.0 8.0 6.0 4.0 2.0\n",
       "  * lon      (lon) float32 122.0 124.0 126.0 128.0 ... 242.0 244.0 246.0 248.0\n",
       "  * lev      (lev) float64 0.0\n",
       "Data variables:\n",
       "    sst      (time, lat, lon, lev) float32 ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-9123389b-3d36-4ae4-ba44-141698708e67' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-9123389b-3d36-4ae4-ba44-141698708e67' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 2028</li><li><span class='xr-has-index'>lat</span>: 32</li><li><span class='xr-has-index'>lon</span>: 64</li><li><span class='xr-has-index'>lev</span>: 1</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-1caf7f45-4eca-4120-b039-60ee7fc2c273' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1caf7f45-4eca-4120-b039-60ee7fc2c273' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1854-01-01 ... 2022-12-01</div><input id='attrs-6dd88c9b-0d06-449a-be1f-00ba2992b16c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6dd88c9b-0d06-449a-be1f-00ba2992b16c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ec1916ff-a1e6-42b6-a5c3-1fa6779d2af5' class='xr-var-data-in' type='checkbox'><label for='data-ec1916ff-a1e6-42b6-a5c3-1fa6779d2af5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>delta_t :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>avg_period :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>prev_avg_period :</span></dt><dd>0000-00-07 00:00:00</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>actual_range :</span></dt><dd>[19723. 81418.]</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1854-01-01T00:00:00.000000000&#x27;, &#x27;1854-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;1854-03-01T00:00:00.000000000&#x27;, ..., &#x27;2022-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-11-01T00:00:00.000000000&#x27;, &#x27;2022-12-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>64.0 62.0 60.0 58.0 ... 6.0 4.0 2.0</div><input id='attrs-fcf9da8e-9a51-46aa-bcbe-9d7537f75131' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-fcf9da8e-9a51-46aa-bcbe-9d7537f75131' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-44b44602-6ad7-4571-9bab-3b29a529797e' class='xr-var-data-in' type='checkbox'><label for='data-44b44602-6ad7-4571-9bab-3b29a529797e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>actual_range :</span></dt><dd>[ 88. -88.]</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>coordinate_defines :</span></dt><dd>center</dd></dl></div><div class='xr-var-data'><pre>array([64., 62., 60., 58., 56., 54., 52., 50., 48., 46., 44., 42., 40., 38.,\n",
       "       36., 34., 32., 30., 28., 26., 24., 22., 20., 18., 16., 14., 12., 10.,\n",
       "        8.,  6.,  4.,  2.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>122.0 124.0 126.0 ... 246.0 248.0</div><input id='attrs-4779cb49-2208-4f5f-a7ce-9bb864be0359' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4779cb49-2208-4f5f-a7ce-9bb864be0359' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-49468817-3ff3-4f92-bbe2-9da53deccee2' class='xr-var-data-in' type='checkbox'><label for='data-49468817-3ff3-4f92-bbe2-9da53deccee2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>actual_range :</span></dt><dd>[  0. 358.]</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>coordinate_defines :</span></dt><dd>center</dd></dl></div><div class='xr-var-data'><pre>array([122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142., 144.,\n",
       "       146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166., 168.,\n",
       "       170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190., 192.,\n",
       "       194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214., 216.,\n",
       "       218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238., 240.,\n",
       "       242., 244., 246., 248.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lev</span></div><div class='xr-var-dims'>(lev)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0</div><input id='attrs-d5842747-7bb5-42b3-b1cb-61a2d825a19b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d5842747-7bb5-42b3-b1cb-61a2d825a19b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3f6b9c8e-ed88-4a90-9592-2b26d51d13d1' class='xr-var-data-in' type='checkbox'><label for='data-3f6b9c8e-ed88-4a90-9592-2b26d51d13d1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f64f5a6f-fe45-4452-a500-5ec6b01abef0' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f64f5a6f-fe45-4452-a500-5ec6b01abef0' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>sst</span></div><div class='xr-var-dims'>(time, lat, lon, lev)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a60ccbd5-b86f-41bb-89cc-04eca9e4d0b4' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a60ccbd5-b86f-41bb-89cc-04eca9e4d0b4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-be870f43-7c9d-4a60-af40-ca2dc29f7d47' class='xr-var-data-in' type='checkbox'><label for='data-be870f43-7c9d-4a60-af40-ca2dc29f7d47' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Monthly Means of Sea Surface Temperature</dd><dt><span>units :</span></dt><dd>degC</dd><dt><span>var_desc :</span></dt><dd>Sea Surface Temperature</dd><dt><span>level_desc :</span></dt><dd>Surface</dd><dt><span>statistic :</span></dt><dd>Mean</dd><dt><span>dataset :</span></dt><dd>NOAA Extended Reconstructed SST V5</dd><dt><span>parent_stat :</span></dt><dd>Individual Values</dd><dt><span>actual_range :</span></dt><dd>[-1.8     42.32636]</dd><dt><span>valid_range :</span></dt><dd>[-1.8 45. ]</dd></dl></div><div class='xr-var-data'><pre>[4153344 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-29f2a6fc-12b9-4066-9539-65896c3b47b1' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-29f2a6fc-12b9-4066-9539-65896c3b47b1' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 2028, lat: 32, lon: 64, lev: 1)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1854-01-01 1854-02-01 ... 2022-12-01\n",
       "  * lat      (lat) float32 64.0 62.0 60.0 58.0 56.0 ... 10.0 8.0 6.0 4.0 2.0\n",
       "  * lon      (lon) float32 122.0 124.0 126.0 128.0 ... 242.0 244.0 246.0 248.0\n",
       "  * lev      (lev) float64 0.0\n",
       "Data variables:\n",
       "    sst      (time, lat, lon, lev) float32 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imported data\n",
    "ds = xr.open_dataset(ifile_data+'nonnorm_Datapreprcess_ersst_1854_2022.nc')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d4d1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prepare data\n",
    "ds=ds['sst'].data \n",
    "ds[ds<0]=0 #treat nan values as 0\n",
    "np.nan_to_num(ds,copy=False)\n",
    "ds=ds/(np.nanmax(ds)) \n",
    "dates=pd.date_range(start='1854-01-01',periods=len(ds))\n",
    "label=np.array(dates.month)\n",
    "label=label-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf55701",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data separation\n",
    "## Different  models are trained for different target months \n",
    "## then All of the model output is put together to make the prediction of PDO index from 1983 to 2022.\n",
    "\n",
    "N_total = 2028\n",
    "N_train = 1428\n",
    "N_gab_1 = 0\n",
    "N_test = 1\n",
    "N_skip = N_total-N_train-N_gab_1-N_test-480\n",
    "\n",
    "x = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1e25c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Verify that we have sufficient information for the requirements.\n",
    "if N_skip+N_train+N_gab_1+N_test > x.shape[0]:\n",
    "    raise Exception('not enough timesteps in input file!')\n",
    "\n",
    "x = x.astype('float32')\n",
    "x = x[:N_skip+N_train+N_gab_1+N_test+480]\n",
    "\n",
    "lat,lon,lev=x.shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e72f3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(lead_time):\n",
    "    ''' split up data in predictor and predictant set by shifting\n",
    "     it according to the given lead time, and then split up\n",
    "     into train, developement and test set'''\n",
    "    if lead_time == 0:\n",
    "        X = x\n",
    "        y = X[:]\n",
    "\n",
    "    else:\n",
    "\n",
    "        X = x[:]\n",
    "        y = x[:]\n",
    "    \n",
    "\n",
    "    X_train = X[N_skip+i-lead_time:N_skip+N_train+i-lead_time]\n",
    "    y_train = y[N_skip+i-lead_time:N_skip+N_train+i-lead_time]\n",
    "    \n",
    "    \n",
    "    X_test = X[N_skip+N_train+N_gab_1+i:N_skip+N_train+N_gab_1+N_test+i]\n",
    "    y_test = y[N_skip+N_train+N_gab_1+i:N_skip+N_train+N_gab_1+N_test+i]\n",
    "    \n",
    "       \n",
    "    return X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fdb856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed (not-tuned params)\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "pool_size = 1\n",
    "drop_prob=0\n",
    "conv_activation='relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f517d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_score(x,y):\n",
    "    '''timestepwise anomaly correlation coefficient, averaged over time\n",
    "        (simple version without seasonal climatoloty)'''\n",
    "    assert(x.shape==y.shape)\n",
    "    return np.mean([np.corrcoef(x[i].flatten(),y[i].flatten())[0,1] for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7c0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(conv_depth, kernel_size, hidden_size, n_hidden_layers, lr):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "            \n",
    "            ## Convolution which involves dimensionality reduction (similar to Encoder in an autoencoder)\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation, input_shape=(lat,lon,lev)),\n",
    "            layers.MaxPooling2D(pool_size=pool_size),\n",
    "            Dropout(drop_prob),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.MaxPooling2D(pool_size=pool_size),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.MaxPooling2D(pool_size= 1),\n",
    "        \n",
    "        \n",
    "            # end \"encoder\"\n",
    "            \n",
    "            \n",
    "            # dense layers (Automatic flattening and reshaping occurs.)\n",
    "            ] + [layers.Dense(hidden_size, activation='sigmoid') for i in range(n_hidden_layers)] +\n",
    "             \n",
    "            [\n",
    "            \n",
    "            \n",
    "            # start \"Decoder\" (upsampling of the encoder above)\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.UpSampling2D(size=pool_size),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.UpSampling2D(size=pool_size),\n",
    "            layers.Convolution2D(lev, kernel_size, padding='same', activation=None)\n",
    "            ]\n",
    "            )\n",
    "    \n",
    "    \n",
    "    optimizer= keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    if N_gpu > 1:\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            # convert the model to a model that can be trained with N_GPU GPUs\n",
    "             model = keras.utils.multi_gpu_model(model, gpus=N_gpu)\n",
    "             \n",
    "    model.compile(loss='mean_squared_error', optimizer = optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea6ff2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2255\n",
      "Epoch 1: val_loss improved from inf to 0.10555, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.2255 - val_loss: 0.1055\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0748\n",
      "Epoch 2: val_loss improved from 0.10555 to 0.05288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0748 - val_loss: 0.0529\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0344\n",
      "Epoch 3: val_loss improved from 0.05288 to 0.02170, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0344 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02170 to 0.01072, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01072 to 0.00624, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0090 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00624 to 0.00421, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00421 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00311 to 0.00260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00260 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00230 to 0.00206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2322\n",
      "Epoch 1: val_loss improved from inf to 0.10880, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.2322 - val_loss: 0.1088\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0736\n",
      "Epoch 2: val_loss improved from 0.10880 to 0.04984, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0736 - val_loss: 0.0498\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0354\n",
      "Epoch 3: val_loss improved from 0.04984 to 0.02355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0354 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 4: val_loss improved from 0.02355 to 0.01346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0187 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01346 to 0.00647, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00647 to 0.00318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 7: val_loss improved from 0.00318 to 0.00240, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 8: val_loss improved from 0.00240 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 9: val_loss improved from 0.00211 to 0.00191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00191 to 0.00172, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2192\n",
      "Epoch 1: val_loss improved from inf to 0.08417, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.2192 - val_loss: 0.0842\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0510\n",
      "Epoch 2: val_loss improved from 0.08417 to 0.03150, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0510 - val_loss: 0.0315\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0242\n",
      "Epoch 3: val_loss improved from 0.03150 to 0.01665, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01665 to 0.00987, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.00987 to 0.00638, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00638 to 0.00449, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00449 to 0.00340, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00340 to 0.00267, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00267 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00225 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_8 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2999\n",
      "Epoch 1: val_loss improved from inf to 0.16628, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.2999 - val_loss: 0.1663\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0977\n",
      "Epoch 2: val_loss improved from 0.16628 to 0.04847, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0977 - val_loss: 0.0485\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0305\n",
      "Epoch 3: val_loss improved from 0.04847 to 0.01680, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0305 - val_loss: 0.0168\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01680 to 0.00825, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0133 - val_loss: 0.0082\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.00825 to 0.00533, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00533 to 0.00393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00393 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00312 to 0.00260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00260 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00229 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "finished training\n",
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AD0258C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1925\n",
      "Epoch 1: val_loss improved from inf to 0.07966, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.1925 - val_loss: 0.0797\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0573\n",
      "Epoch 2: val_loss improved from 0.07966 to 0.04128, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0573 - val_loss: 0.0413\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0293\n",
      "Epoch 3: val_loss improved from 0.04128 to 0.01911, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0293 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 4: val_loss improved from 0.01911 to 0.00988, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.00988 to 0.00599, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00599 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00447 to 0.00355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00355 to 0.00285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00285 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00237 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "finished training\n",
      "WARNING:tensorflow:6 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AD02871CF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2879\n",
      "Epoch 1: val_loss improved from inf to 0.19478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.2879 - val_loss: 0.1948\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1036\n",
      "Epoch 2: val_loss improved from 0.19478 to 0.05327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.1036 - val_loss: 0.0533\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0376\n",
      "Epoch 3: val_loss improved from 0.05327 to 0.02527, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0376 - val_loss: 0.0253\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 4: val_loss improved from 0.02527 to 0.01164, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01164 to 0.00690, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0090 - val_loss: 0.0069\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00690 to 0.00491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00491 to 0.00377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00377 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00311 to 0.00274, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00274 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_15 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2647\n",
      "Epoch 1: val_loss improved from inf to 0.16621, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.2647 - val_loss: 0.1662\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0794\n",
      "Epoch 2: val_loss improved from 0.16621 to 0.04875, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0794 - val_loss: 0.0488\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0347\n",
      "Epoch 3: val_loss improved from 0.04875 to 0.02696, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0347 - val_loss: 0.0270\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02696 to 0.01465, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 0.0191 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01465 to 0.00873, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00873 to 0.00598, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00598 to 0.00456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00456 to 0.00379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00379 to 0.00335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00335 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_17 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2691\n",
      "Epoch 1: val_loss improved from inf to 0.17150, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.2691 - val_loss: 0.1715\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0669\n",
      "Epoch 2: val_loss improved from 0.17150 to 0.04208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0669 - val_loss: 0.0421\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 3: val_loss improved from 0.04208 to 0.02291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0284 - val_loss: 0.0229\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.02291 to 0.01331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0141 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01331 to 0.00925, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00925 to 0.00708, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0055 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00708 to 0.00579, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00579 to 0.00494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00494 to 0.00434, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00434 to 0.00392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_18 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_19 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2486\n",
      "Epoch 1: val_loss improved from inf to 0.12575, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.2486 - val_loss: 0.1258\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0623\n",
      "Epoch 2: val_loss improved from 0.12575 to 0.05074, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0623 - val_loss: 0.0507\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0327\n",
      "Epoch 3: val_loss improved from 0.05074 to 0.03073, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0327 - val_loss: 0.0307\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.03073 to 0.02137, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0200 - val_loss: 0.0214\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.02137 to 0.01547, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.01547 to 0.01183, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0092 - val_loss: 0.0118\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.01183 to 0.00908, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00908 to 0.00728, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00728 to 0.00619, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00619 to 0.00557, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_20 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_21 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3058\n",
      "Epoch 1: val_loss improved from inf to 0.27391, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.3058 - val_loss: 0.2739\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1160\n",
      "Epoch 2: val_loss improved from 0.27391 to 0.05179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.1160 - val_loss: 0.0518\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0287\n",
      "Epoch 3: val_loss improved from 0.05179 to 0.02204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0287 - val_loss: 0.0220\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.02204 to 0.01546, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0142 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01546 to 0.01225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.01225 to 0.01000, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.01000 to 0.00824, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00824 to 0.00690, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00690 to 0.00599, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00599 to 0.00539, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0035 - val_loss: 0.0054\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_66 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_22 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_23 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3383\n",
      "Epoch 1: val_loss improved from inf to 0.29644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.3383 - val_loss: 0.2964\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1592\n",
      "Epoch 2: val_loss improved from 0.29644 to 0.07527, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.1592 - val_loss: 0.0753\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0565\n",
      "Epoch 3: val_loss improved from 0.07527 to 0.04083, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0565 - val_loss: 0.0408\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0265\n",
      "Epoch 4: val_loss improved from 0.04083 to 0.01846, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0265 - val_loss: 0.0185\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.01846 to 0.01175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01175 to 0.00822, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00822 to 0.00615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00615 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00474 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00397 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_72 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_24 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_25 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2126\n",
      "Epoch 1: val_loss improved from inf to 0.08451, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.2126 - val_loss: 0.0845\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0557\n",
      "Epoch 2: val_loss improved from 0.08451 to 0.03960, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0557 - val_loss: 0.0396\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0310\n",
      "Epoch 3: val_loss improved from 0.03960 to 0.02166, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0310 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02166 to 0.01056, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.0162 - val_loss: 0.0106\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01056 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0085 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.00629 to 0.00452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00452 to 0.00373, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00373 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00321 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00282 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_78 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_26 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_27 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2976\n",
      "Epoch 1: val_loss improved from inf to 0.16238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.2976 - val_loss: 0.1624\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0754\n",
      "Epoch 2: val_loss improved from 0.16238 to 0.03750, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.0754 - val_loss: 0.0375\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0306\n",
      "Epoch 3: val_loss improved from 0.03750 to 0.02069, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0306 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0185\n",
      "Epoch 4: val_loss improved from 0.02069 to 0.01297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0185 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01297 to 0.00759, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00759 to 0.00528, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00528 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00387 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00298 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00251 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_84 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_28 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_29 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3433\n",
      "Epoch 1: val_loss improved from inf to 0.21901, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.3433 - val_loss: 0.2190\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1182\n",
      "Epoch 2: val_loss improved from 0.21901 to 0.04644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.1182 - val_loss: 0.0464\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 3: val_loss improved from 0.04644 to 0.01570, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0315 - val_loss: 0.0157\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01570 to 0.00791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0133 - val_loss: 0.0079\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.00791 to 0.00519, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00519 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00381 to 0.00304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00304 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00256 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00222 to 0.00198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_90 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_30 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_31 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2762\n",
      "Epoch 1: val_loss improved from inf to 0.15005, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.2762 - val_loss: 0.1501\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0989\n",
      "Epoch 2: val_loss improved from 0.15005 to 0.06158, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0989 - val_loss: 0.0616\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0446\n",
      "Epoch 3: val_loss improved from 0.06158 to 0.02501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0446 - val_loss: 0.0250\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0204\n",
      "Epoch 4: val_loss improved from 0.02501 to 0.01250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0204 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01250 to 0.00644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00644 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00407 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00311 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00259 to 0.00226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00226 to 0.00205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_96 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_32 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_33 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2306\n",
      "Epoch 1: val_loss improved from inf to 0.08892, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.2306 - val_loss: 0.0889\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0458\n",
      "Epoch 2: val_loss improved from 0.08892 to 0.02521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0458 - val_loss: 0.0252\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 3: val_loss improved from 0.02521 to 0.01020, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.0188 - val_loss: 0.0102\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 4: val_loss improved from 0.01020 to 0.00623, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 5: val_loss improved from 0.00623 to 0.00427, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00427 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00324 to 0.00253, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00253 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00211 to 0.00182, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00182 to 0.00159, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_102 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_34 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_35 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3072\n",
      "Epoch 1: val_loss improved from inf to 0.19959, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.3072 - val_loss: 0.1996\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1168\n",
      "Epoch 2: val_loss improved from 0.19959 to 0.05035, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.1168 - val_loss: 0.0503\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0362\n",
      "Epoch 3: val_loss improved from 0.05035 to 0.02002, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0362 - val_loss: 0.0200\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.02002 to 0.00939, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0152 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.00939 to 0.00573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00573 to 0.00376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00376 to 0.00263, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00263 to 0.00213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00213 to 0.00181, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00181 to 0.00160, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_108 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_36 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_37 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1870\n",
      "Epoch 1: val_loss improved from inf to 0.06167, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.1870 - val_loss: 0.0617\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 2: val_loss improved from 0.06167 to 0.02897, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0441 - val_loss: 0.0290\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0212\n",
      "Epoch 3: val_loss improved from 0.02897 to 0.01551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0212 - val_loss: 0.0155\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 4: val_loss improved from 0.01551 to 0.01016, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01016 to 0.00698, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00698 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00499 to 0.00365, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00365 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00281 to 0.00235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00235 to 0.00203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_114 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_38 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_39 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2849\n",
      "Epoch 1: val_loss improved from inf to 0.19869, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.2849 - val_loss: 0.1987\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0840\n",
      "Epoch 2: val_loss improved from 0.19869 to 0.03337, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0840 - val_loss: 0.0334\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0230\n",
      "Epoch 3: val_loss improved from 0.03337 to 0.01568, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0230 - val_loss: 0.0157\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 4: val_loss improved from 0.01568 to 0.01018, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0120 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01018 to 0.00726, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00726 to 0.00554, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00554 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00447 to 0.00383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00383 to 0.00343, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00343 to 0.00313, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_120 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_40 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_41 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2450\n",
      "Epoch 1: val_loss improved from inf to 0.12263, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2450 - val_loss: 0.1226\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0533\n",
      "Epoch 2: val_loss improved from 0.12263 to 0.03508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0533 - val_loss: 0.0351\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 3: val_loss improved from 0.03508 to 0.01906, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0222 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 4: val_loss improved from 0.01906 to 0.01260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01260 to 0.00962, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00962 to 0.00797, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0059 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00797 to 0.00702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0048 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00702 to 0.00640, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00640 to 0.00592, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00592 to 0.00555, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0035 - val_loss: 0.0056\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_126 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11396\\2706725143.py:67: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_127 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_128 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_129 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_42 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_130 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_43 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_131 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2825\n",
      "Epoch 1: val_loss improved from inf to 0.24314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.2825 - val_loss: 0.2431\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0976\n",
      "Epoch 2: val_loss improved from 0.24314 to 0.05260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0976 - val_loss: 0.0526\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0306\n",
      "Epoch 3: val_loss improved from 0.05260 to 0.02455, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0306 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.02455 to 0.01633, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0151 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.01633 to 0.01155, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0092 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.01155 to 0.00910, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0063 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00910 to 0.00758, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00758 to 0.00669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00669 to 0.00614, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00614 to 0.00570, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0031 - val_loss: 0.0057\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_132 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_133 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_44 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_45 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3280\n",
      "Epoch 1: val_loss improved from inf to 0.33805, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.3280 - val_loss: 0.3380\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1520\n",
      "Epoch 2: val_loss improved from 0.33805 to 0.05836, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.1520 - val_loss: 0.0584\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0402\n",
      "Epoch 3: val_loss improved from 0.05836 to 0.03083, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0402 - val_loss: 0.0308\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 4: val_loss improved from 0.03083 to 0.01821, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0196 - val_loss: 0.0182\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01821 to 0.01306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01306 to 0.01003, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.01003 to 0.00788, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0062 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00788 to 0.00638, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00638 to 0.00538, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00538 to 0.00473, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_138 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_69 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_70 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_140 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_71 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_141 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_46 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_142 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_47 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_143 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2512\n",
      "Epoch 1: val_loss improved from inf to 0.12867, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.2512 - val_loss: 0.1287\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0570\n",
      "Epoch 2: val_loss improved from 0.12867 to 0.03889, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0570 - val_loss: 0.0389\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 3: val_loss improved from 0.03889 to 0.02203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0288 - val_loss: 0.0220\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 4: val_loss improved from 0.02203 to 0.01322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01322 to 0.00844, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00844 to 0.00623, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00623 to 0.00497, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00497 to 0.00414, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00414 to 0.00368, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00368 to 0.00334, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_144 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_145 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_146 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_147 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_48 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_49 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1921\n",
      "Epoch 1: val_loss improved from inf to 0.07320, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.1921 - val_loss: 0.0732\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0583\n",
      "Epoch 2: val_loss improved from 0.07320 to 0.04039, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0583 - val_loss: 0.0404\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.04039 to 0.01799, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0294 - val_loss: 0.0180\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01799 to 0.00797, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0133 - val_loss: 0.0080\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 5: val_loss improved from 0.00797 to 0.00475, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 6: val_loss improved from 0.00475 to 0.00363, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00363 to 0.00305, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00305 to 0.00267, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00267 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00239 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_150 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_151 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_152 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_77 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_153 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_50 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_154 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_51 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_155 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3302\n",
      "Epoch 1: val_loss improved from inf to 0.25318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.3302 - val_loss: 0.2532\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1755\n",
      "Epoch 2: val_loss improved from 0.25318 to 0.08310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.1755 - val_loss: 0.0831\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0634\n",
      "Epoch 3: val_loss improved from 0.08310 to 0.03759, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0634 - val_loss: 0.0376\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 4: val_loss improved from 0.03759 to 0.01828, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0296 - val_loss: 0.0183\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 5: val_loss improved from 0.01828 to 0.01032, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0162 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 6: val_loss improved from 0.01032 to 0.00662, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 7: val_loss improved from 0.00662 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00499 to 0.00380, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00380 to 0.00296, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00296 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_156 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_157 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_158 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_159 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_52 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_160 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_53 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_161 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3097\n",
      "Epoch 1: val_loss improved from inf to 0.20447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.3097 - val_loss: 0.2045\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1242\n",
      "Epoch 2: val_loss improved from 0.20447 to 0.05309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.1242 - val_loss: 0.0531\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 3: val_loss improved from 0.05309 to 0.01882, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0366 - val_loss: 0.0188\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.01882 to 0.00993, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0166 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.00993 to 0.00611, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00611 to 0.00403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00403 to 0.00285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00285 to 0.00236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00236 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00211 to 0.00191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_162 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_163 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_164 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_165 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_54 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_55 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2675\n",
      "Epoch 1: val_loss improved from inf to 0.11978, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.2675 - val_loss: 0.1198\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0588\n",
      "Epoch 2: val_loss improved from 0.11978 to 0.02813, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0588 - val_loss: 0.0281\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 3: val_loss improved from 0.02813 to 0.01419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0227 - val_loss: 0.0142\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 4: val_loss improved from 0.01419 to 0.00894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 0.0140 - val_loss: 0.0089\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.00894 to 0.00600, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00600 to 0.00414, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00414 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00303 to 0.00240, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00240 to 0.00203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00203 to 0.00179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_168 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_84 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_169 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_85 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_170 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_86 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_56 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_172 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_57 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_173 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3009\n",
      "Epoch 1: val_loss improved from inf to 0.18430, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.3009 - val_loss: 0.1843\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1172\n",
      "Epoch 2: val_loss improved from 0.18430 to 0.05787, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.1172 - val_loss: 0.0579\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0408\n",
      "Epoch 3: val_loss improved from 0.05787 to 0.01944, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0408 - val_loss: 0.0194\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.01944 to 0.00779, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0146 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.00779 to 0.00428, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00428 to 0.00296, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00296 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00250 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00220 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00196 to 0.00179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_174 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_175 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_177 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_58 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_178 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_59 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_179 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2857\n",
      "Epoch 1: val_loss improved from inf to 0.17539, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.2857 - val_loss: 0.1754\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1113\n",
      "Epoch 2: val_loss improved from 0.17539 to 0.06238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 0.1113 - val_loss: 0.0624\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Epoch 3: val_loss improved from 0.06238 to 0.02187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0432 - val_loss: 0.0219\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02187 to 0.00887, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0158 - val_loss: 0.0089\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.00887 to 0.00460, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00460 to 0.00328, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00328 to 0.00272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00272 to 0.00235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00235 to 0.00204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00204 to 0.00180, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_180 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_90 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_91 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_92 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_183 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_60 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_184 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_61 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_185 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2583\n",
      "Epoch 1: val_loss improved from inf to 0.12151, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2583 - val_loss: 0.1215\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0656\n",
      "Epoch 2: val_loss improved from 0.12151 to 0.04133, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0656 - val_loss: 0.0413\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 3: val_loss improved from 0.04133 to 0.01921, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 0.0299 - val_loss: 0.0192\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.01921 to 0.01185, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0158 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01185 to 0.00856, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.00856 to 0.00611, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00611 to 0.00465, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00465 to 0.00361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00361 to 0.00304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00304 to 0.00270, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_186 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_93 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_187 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_94 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_188 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_189 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_62 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_190 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_63 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2656\n",
      "Epoch 1: val_loss improved from inf to 0.14008, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.2656 - val_loss: 0.1401\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0670\n",
      "Epoch 2: val_loss improved from 0.14008 to 0.04392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0670 - val_loss: 0.0439\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0333\n",
      "Epoch 3: val_loss improved from 0.04392 to 0.02420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0333 - val_loss: 0.0242\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 4: val_loss improved from 0.02420 to 0.01398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0186 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01398 to 0.00854, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00854 to 0.00661, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00661 to 0.00552, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00552 to 0.00467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00467 to 0.00404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00404 to 0.00357, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_192 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_98 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_64 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_65 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3114\n",
      "Epoch 1: val_loss improved from inf to 0.27615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.3114 - val_loss: 0.2761\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1157\n",
      "Epoch 2: val_loss improved from 0.27615 to 0.04494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.1157 - val_loss: 0.0449\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.04494 to 0.02271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0291 - val_loss: 0.0227\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss improved from 0.02271 to 0.01509, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0159 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01509 to 0.01052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.01052 to 0.00783, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00783 to 0.00610, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00610 to 0.00507, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00507 to 0.00444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00444 to 0.00400, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_198 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_99 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_199 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_100 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_200 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_101 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_201 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_66 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_202 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_67 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_203 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2530\n",
      "Epoch 1: val_loss improved from inf to 0.15260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.2530 - val_loss: 0.1526\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0739\n",
      "Epoch 2: val_loss improved from 0.15260 to 0.05519, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0739 - val_loss: 0.0552\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0348\n",
      "Epoch 3: val_loss improved from 0.05519 to 0.02689, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0348 - val_loss: 0.0269\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02689 to 0.01670, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01670 to 0.01135, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01135 to 0.00858, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00858 to 0.00699, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0048 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00699 to 0.00615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00615 to 0.00564, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00564 to 0.00524, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0031 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_204 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_102 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_205 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_103 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_206 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_104 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_207 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_68 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_208 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_69 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_209 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3576\n",
      "Epoch 1: val_loss improved from inf to 0.37698, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.3576 - val_loss: 0.3770\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1972\n",
      "Epoch 2: val_loss improved from 0.37698 to 0.06642, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.1972 - val_loss: 0.0664\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0426\n",
      "Epoch 3: val_loss improved from 0.06642 to 0.02607, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0426 - val_loss: 0.0261\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02607 to 0.01473, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0162 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01473 to 0.01027, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.01027 to 0.00811, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0067 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00811 to 0.00666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0052 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00666 to 0.00569, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00569 to 0.00508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00508 to 0.00463, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_210 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_105 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_211 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_106 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_212 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_107 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_213 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_70 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_214 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_71 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_215 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3360\n",
      "Epoch 1: val_loss improved from inf to 0.24684, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.3360 - val_loss: 0.2468\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1195\n",
      "Epoch 2: val_loss improved from 0.24684 to 0.06425, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.1195 - val_loss: 0.0643\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0427\n",
      "Epoch 3: val_loss improved from 0.06425 to 0.02802, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0427 - val_loss: 0.0280\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 4: val_loss improved from 0.02802 to 0.01441, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0189 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01441 to 0.00869, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00869 to 0.00576, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00576 to 0.00439, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00439 to 0.00367, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00367 to 0.00326, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00326 to 0.00300, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_216 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_108 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_217 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_109 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_218 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_110 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_219 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_72 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_220 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_73 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_221 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2272\n",
      "Epoch 1: val_loss improved from inf to 0.13519, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.2272 - val_loss: 0.1352\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0861\n",
      "Epoch 2: val_loss improved from 0.13519 to 0.06354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0861 - val_loss: 0.0635\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0459\n",
      "Epoch 3: val_loss improved from 0.06354 to 0.02791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0459 - val_loss: 0.0279\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 4: val_loss improved from 0.02791 to 0.01258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0198 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01258 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0097 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00629 to 0.00451, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00451 to 0.00369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00369 to 0.00322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00322 to 0.00291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00291 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_222 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_111 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_223 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_112 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_224 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_113 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_225 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_74 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_226 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_75 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_227 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1778\n",
      "Epoch 1: val_loss improved from inf to 0.05861, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.1778 - val_loss: 0.0586\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0447\n",
      "Epoch 2: val_loss improved from 0.05861 to 0.02614, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0447 - val_loss: 0.0261\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 3: val_loss improved from 0.02614 to 0.01129, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0195 - val_loss: 0.0113\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 4: val_loss improved from 0.01129 to 0.00635, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0104 - val_loss: 0.0064\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 5: val_loss improved from 0.00635 to 0.00413, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00413 to 0.00309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00309 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00259 to 0.00228, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00228 to 0.00204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00204 to 0.00183, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_228 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_114 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_229 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_115 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_230 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_116 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_231 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_76 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_232 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_77 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_233 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2706\n",
      "Epoch 1: val_loss improved from inf to 0.14139, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.2706 - val_loss: 0.1414\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0822\n",
      "Epoch 2: val_loss improved from 0.14139 to 0.04635, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0822 - val_loss: 0.0463\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 3: val_loss improved from 0.04635 to 0.01920, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0342 - val_loss: 0.0192\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 4: val_loss improved from 0.01920 to 0.01033, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0169 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01033 to 0.00582, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00582 to 0.00361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00361 to 0.00263, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00263 to 0.00217, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00217 to 0.00190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00190 to 0.00166, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_234 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_117 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_235 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_118 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_236 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_119 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_237 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_78 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_238 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_79 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2581\n",
      "Epoch 1: val_loss improved from inf to 0.11040, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.2581 - val_loss: 0.1104\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0577\n",
      "Epoch 2: val_loss improved from 0.11040 to 0.03150, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0577 - val_loss: 0.0315\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 3: val_loss improved from 0.03150 to 0.01275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0239 - val_loss: 0.0127\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 4: val_loss improved from 0.01275 to 0.00739, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.00739 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0083 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00501 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00344 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0047 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00259 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00215 to 0.00190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00190 to 0.00174, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_240 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_120 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_121 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_122 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_80 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_81 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_245 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3046\n",
      "Epoch 1: val_loss improved from inf to 0.20412, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.3046 - val_loss: 0.2041\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1277\n",
      "Epoch 2: val_loss improved from 0.20412 to 0.06052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.1277 - val_loss: 0.0605\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 3: val_loss improved from 0.06052 to 0.02459, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0436 - val_loss: 0.0246\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0197\n",
      "Epoch 4: val_loss improved from 0.02459 to 0.01284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0197 - val_loss: 0.0128\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01284 to 0.00742, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0119 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00742 to 0.00451, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00451 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00311 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00252 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00220 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_246 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_123 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_247 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_124 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_248 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_125 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_249 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_82 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_250 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_83 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_251 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2305\n",
      "Epoch 1: val_loss improved from inf to 0.08114, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 380ms/step - loss: 0.2305 - val_loss: 0.0811\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0524\n",
      "Epoch 2: val_loss improved from 0.08114 to 0.03417, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0524 - val_loss: 0.0342\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0265\n",
      "Epoch 3: val_loss improved from 0.03417 to 0.01820, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0265 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.01820 to 0.01077, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01077 to 0.00669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00669 to 0.00502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00502 to 0.00392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00392 to 0.00307, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00307 to 0.00255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00255 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_252 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_126 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_253 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_127 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_254 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_128 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_255 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_84 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_256 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_85 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_257 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2807\n",
      "Epoch 1: val_loss improved from inf to 0.13717, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.2807 - val_loss: 0.1372\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0610\n",
      "Epoch 2: val_loss improved from 0.13717 to 0.03604, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0610 - val_loss: 0.0360\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0290\n",
      "Epoch 3: val_loss improved from 0.03604 to 0.02145, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0290 - val_loss: 0.0215\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02145 to 0.01212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0168 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01212 to 0.00701, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00701 to 0.00420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00420 to 0.00304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00304 to 0.00258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00258 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00230 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0027 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_258 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_129 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_259 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_130 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_260 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_131 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_261 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_86 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_262 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_87 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_263 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1: val_loss improved from inf to 0.11921, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.2416 - val_loss: 0.1192\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0567\n",
      "Epoch 2: val_loss improved from 0.11921 to 0.03433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0567 - val_loss: 0.0343\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Epoch 3: val_loss improved from 0.03433 to 0.01911, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0247 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.01911 to 0.01181, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01181 to 0.00788, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0093 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00788 to 0.00546, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00546 to 0.00425, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00425 to 0.00369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 365ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00369 to 0.00338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00338 to 0.00316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_264 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_132 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_265 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_133 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_266 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_134 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_267 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_88 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_268 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_89 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_269 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3057\n",
      "Epoch 1: val_loss improved from inf to 0.25473, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.3057 - val_loss: 0.2547\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1037\n",
      "Epoch 2: val_loss improved from 0.25473 to 0.04316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.1037 - val_loss: 0.0432\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0261\n",
      "Epoch 3: val_loss improved from 0.04316 to 0.02085, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.0261 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 4: val_loss improved from 0.02085 to 0.01362, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01362 to 0.01008, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.01008 to 0.00789, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00789 to 0.00642, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0054 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00642 to 0.00540, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00540 to 0.00476, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00476 to 0.00432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_270 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_135 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_271 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_136 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_272 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_137 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_273 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_90 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_274 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_91 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_275 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3223\n",
      "Epoch 1: val_loss improved from inf to 0.30893, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.3223 - val_loss: 0.3089\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1255\n",
      "Epoch 2: val_loss improved from 0.30893 to 0.05924, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 367ms/step - loss: 0.1255 - val_loss: 0.0592\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0373\n",
      "Epoch 3: val_loss improved from 0.05924 to 0.02956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0373 - val_loss: 0.0296\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 4: val_loss improved from 0.02956 to 0.01649, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0169 - val_loss: 0.0165\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01649 to 0.01193, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.01193 to 0.00985, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0070 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00985 to 0.00857, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00857 to 0.00754, saving model to best_weights.h5\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00754 to 0.00673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0042 - val_loss: 0.0067\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00673 to 0.00609, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0037 - val_loss: 0.0061\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_276 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_138 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_277 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_139 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_278 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_140 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_279 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_92 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_280 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_93 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_281 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3357\n",
      "Epoch 1: val_loss improved from inf to 0.34916, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.3357 - val_loss: 0.3492\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1589\n",
      "Epoch 2: val_loss improved from 0.34916 to 0.05803, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.1589 - val_loss: 0.0580\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0355\n",
      "Epoch 3: val_loss improved from 0.05803 to 0.02397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0355 - val_loss: 0.0240\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.02397 to 0.01588, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0157 - val_loss: 0.0159\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01588 to 0.01259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01259 to 0.01034, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 7: val_loss improved from 0.01034 to 0.00829, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0069 - val_loss: 0.0083\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00829 to 0.00690, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00690 to 0.00594, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00594 to 0.00532, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_282 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_141 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_283 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_142 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_284 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_143 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_285 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_94 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_286 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_95 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_287 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2780\n",
      "Epoch 1: val_loss improved from inf to 0.20691, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 380ms/step - loss: 0.2780 - val_loss: 0.2069\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1024\n",
      "Epoch 2: val_loss improved from 0.20691 to 0.06813, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.1024 - val_loss: 0.0681\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0485\n",
      "Epoch 3: val_loss improved from 0.06813 to 0.03508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0485 - val_loss: 0.0351\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 4: val_loss improved from 0.03508 to 0.01477, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0211 - val_loss: 0.0148\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01477 to 0.00935, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00935 to 0.00697, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00697 to 0.00554, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00554 to 0.00459, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00459 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00397 to 0.00353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_288 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_144 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_289 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_145 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_290 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_146 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_291 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_96 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_292 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_97 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_293 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2466\n",
      "Epoch 1: val_loss improved from inf to 0.09593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2466 - val_loss: 0.0959\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0537\n",
      "Epoch 2: val_loss improved from 0.09593 to 0.03858, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0537 - val_loss: 0.0386\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 3: val_loss improved from 0.03858 to 0.02184, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0288 - val_loss: 0.0218\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02184 to 0.01396, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0177 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 5: val_loss improved from 0.01396 to 0.00894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.00894 to 0.00634, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00634 to 0.00485, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00485 to 0.00399, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00399 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00346 to 0.00307, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_294 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_147 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_295 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_148 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_296 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_149 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_297 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_98 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_298 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_99 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_299 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3197\n",
      "Epoch 1: val_loss improved from inf to 0.25312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.3197 - val_loss: 0.2531\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 2: val_loss improved from 0.25312 to 0.04788, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.1460 - val_loss: 0.0479\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0365\n",
      "Epoch 3: val_loss improved from 0.04788 to 0.02393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0365 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02393 to 0.01005, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01005 to 0.00567, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00567 to 0.00388, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00388 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00303 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00259 to 0.00231, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00231 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_300 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_150 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_301 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_151 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_302 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_152 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_303 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_100 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_304 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_101 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_305 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2739\n",
      "Epoch 1: val_loss improved from inf to 0.15857, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.2739 - val_loss: 0.1586\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0953\n",
      "Epoch 2: val_loss improved from 0.15857 to 0.05537, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0953 - val_loss: 0.0554\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0389\n",
      "Epoch 3: val_loss improved from 0.05537 to 0.02312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0389 - val_loss: 0.0231\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 4: val_loss improved from 0.02312 to 0.01146, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01146 to 0.00614, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00614 to 0.00389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00389 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00282 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00220 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00187 to 0.00164, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_306 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_153 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_307 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_154 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_308 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_155 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_309 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_102 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_310 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_103 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_311 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2962\n",
      "Epoch 1: val_loss improved from inf to 0.16374, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2962 - val_loss: 0.1637\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0916\n",
      "Epoch 2: val_loss improved from 0.16374 to 0.04769, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0916 - val_loss: 0.0477\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 3: val_loss improved from 0.04769 to 0.02040, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0342 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 4: val_loss improved from 0.02040 to 0.01088, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01088 to 0.00697, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0105 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00697 to 0.00486, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00486 to 0.00371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00371 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00298 to 0.00255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00255 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_312 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_156 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_313 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_157 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_314 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_158 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_315 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_104 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_316 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_105 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_317 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3537\n",
      "Epoch 1: val_loss improved from inf to 0.24153, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 380ms/step - loss: 0.3537 - val_loss: 0.2415\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2035\n",
      "Epoch 2: val_loss improved from 0.24153 to 0.09736, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.2035 - val_loss: 0.0974\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0664\n",
      "Epoch 3: val_loss improved from 0.09736 to 0.04373, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0664 - val_loss: 0.0437\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0327\n",
      "Epoch 4: val_loss improved from 0.04373 to 0.02120, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0327 - val_loss: 0.0212\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 5: val_loss improved from 0.02120 to 0.01184, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0178 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 6: val_loss improved from 0.01184 to 0.00724, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00724 to 0.00503, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00503 to 0.00377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00377 to 0.00302, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00302 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_318 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_159 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_319 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_160 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_320 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_161 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_321 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_106 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_322 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_107 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_323 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2433\n",
      "Epoch 1: val_loss improved from inf to 0.09286, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.2433 - val_loss: 0.0929\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0653\n",
      "Epoch 2: val_loss improved from 0.09286 to 0.04375, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0653 - val_loss: 0.0437\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0309\n",
      "Epoch 3: val_loss improved from 0.04375 to 0.02211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0309 - val_loss: 0.0221\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02211 to 0.01274, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0177 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01274 to 0.00821, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00821 to 0.00566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00566 to 0.00425, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00425 to 0.00342, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00342 to 0.00284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00284 to 0.00241, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_324 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_162 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_325 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_163 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_326 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_164 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_327 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_108 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_328 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_109 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_329 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3299\n",
      "Epoch 1: val_loss improved from inf to 0.25870, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.3299 - val_loss: 0.2587\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1513\n",
      "Epoch 2: val_loss improved from 0.25870 to 0.06483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.1513 - val_loss: 0.0648\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0478\n",
      "Epoch 3: val_loss improved from 0.06483 to 0.03440, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0478 - val_loss: 0.0344\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0231\n",
      "Epoch 4: val_loss improved from 0.03440 to 0.01618, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0231 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss improved from 0.01618 to 0.01011, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0130 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01011 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00663 to 0.00477, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00477 to 0.00369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00369 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00310 to 0.00275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_330 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_165 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_331 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_166 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_332 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_167 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_333 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_110 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_334 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_111 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_335 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3235\n",
      "Epoch 1: val_loss improved from inf to 0.26611, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.3235 - val_loss: 0.2661\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1166\n",
      "Epoch 2: val_loss improved from 0.26611 to 0.04717, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.1166 - val_loss: 0.0472\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0301\n",
      "Epoch 3: val_loss improved from 0.04717 to 0.02133, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0301 - val_loss: 0.0213\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02133 to 0.01355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0161 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01355 to 0.00873, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0105 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00873 to 0.00641, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00641 to 0.00535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00535 to 0.00462, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00462 to 0.00413, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00413 to 0.00379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_336 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_168 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_337 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_169 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_338 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_170 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_339 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_112 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_340 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_113 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_341 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3479\n",
      "Epoch 1: val_loss improved from inf to 0.33681, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 380ms/step - loss: 0.3479 - val_loss: 0.3368\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1867\n",
      "Epoch 2: val_loss improved from 0.33681 to 0.07178, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.1867 - val_loss: 0.0718\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0494\n",
      "Epoch 3: val_loss improved from 0.07178 to 0.03605, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0494 - val_loss: 0.0360\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0223\n",
      "Epoch 4: val_loss improved from 0.03605 to 0.01846, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0223 - val_loss: 0.0185\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 5: val_loss improved from 0.01846 to 0.01216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01216 to 0.00973, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0083 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00973 to 0.00809, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0067 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00809 to 0.00679, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0055 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00679 to 0.00577, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00577 to 0.00498, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_342 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_171 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_343 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_172 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_344 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_173 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_345 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_114 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_346 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_115 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_347 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2403\n",
      "Epoch 1: val_loss improved from inf to 0.12166, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2403 - val_loss: 0.1217\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0630\n",
      "Epoch 2: val_loss improved from 0.12166 to 0.04510, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0630 - val_loss: 0.0451\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 3: val_loss improved from 0.04510 to 0.02451, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0273 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 4: val_loss improved from 0.02451 to 0.01430, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01430 to 0.00968, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0080 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00968 to 0.00759, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00759 to 0.00644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00644 to 0.00568, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00568 to 0.00515, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00515 to 0.00473, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0030 - val_loss: 0.0047\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_348 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_174 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_349 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_175 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_350 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_176 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_351 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_116 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_352 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_117 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_353 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2144\n",
      "Epoch 1: val_loss improved from inf to 0.10162, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 380ms/step - loss: 0.2144 - val_loss: 0.1016\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0589\n",
      "Epoch 2: val_loss improved from 0.10162 to 0.04956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0589 - val_loss: 0.0496\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0325\n",
      "Epoch 3: val_loss improved from 0.04956 to 0.02656, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0325 - val_loss: 0.0266\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.02656 to 0.01449, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0163 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01449 to 0.00907, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00907 to 0.00630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss improved from 0.00630 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 8: val_loss improved from 0.00501 to 0.00434, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 9: val_loss improved from 0.00434 to 0.00390, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 10: val_loss improved from 0.00390 to 0.00351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_354 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_177 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_355 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_178 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_356 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_179 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_357 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_118 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_358 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_119 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_359 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2047\n",
      "Epoch 1: val_loss improved from inf to 0.07091, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.2047 - val_loss: 0.0709\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 2: val_loss improved from 0.07091 to 0.02014, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0296 - val_loss: 0.0201\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 3: val_loss improved from 0.02014 to 0.01292, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 4: val_loss improved from 0.01292 to 0.00881, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 5: val_loss improved from 0.00881 to 0.00633, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 6: val_loss improved from 0.00633 to 0.00508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00508 to 0.00431, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00431 to 0.00374, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00374 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00331 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_360 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_180 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_361 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_181 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_362 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_182 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_363 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_120 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_364 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_121 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_365 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2856\n",
      "Epoch 1: val_loss improved from inf to 0.18785, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2856 - val_loss: 0.1878\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0757\n",
      "Epoch 2: val_loss improved from 0.18785 to 0.03631, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0757 - val_loss: 0.0363\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 3: val_loss improved from 0.03631 to 0.01719, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0237 - val_loss: 0.0172\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 4: val_loss improved from 0.01719 to 0.01123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01123 to 0.00832, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00832 to 0.00643, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0075 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00643 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00499 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00407 to 0.00350, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00350 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_366 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_183 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_367 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_184 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_368 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_185 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_369 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_122 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_370 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_123 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_371 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3143\n",
      "Epoch 1: val_loss improved from inf to 0.22383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.3143 - val_loss: 0.2238\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1123\n",
      "Epoch 2: val_loss improved from 0.22383 to 0.05509, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.1123 - val_loss: 0.0551\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0356\n",
      "Epoch 3: val_loss improved from 0.05509 to 0.02125, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0356 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.02125 to 0.00973, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0154 - val_loss: 0.0097\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.00973 to 0.00579, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00579 to 0.00415, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00415 to 0.00323, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00323 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00269 to 0.00235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00235 to 0.00213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_372 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_186 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_373 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_187 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_374 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_188 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_375 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_124 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_376 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_125 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_377 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1981\n",
      "Epoch 1: val_loss improved from inf to 0.09022, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.1981 - val_loss: 0.0902\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0583\n",
      "Epoch 2: val_loss improved from 0.09022 to 0.02875, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0583 - val_loss: 0.0287\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 3: val_loss improved from 0.02875 to 0.00817, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0167 - val_loss: 0.0082\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 4: val_loss improved from 0.00817 to 0.00440, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 5: val_loss improved from 0.00440 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 6: val_loss improved from 0.00345 to 0.00290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00290 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00252 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00224 to 0.00198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00198 to 0.00175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_378 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_189 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_379 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_190 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_380 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_191 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_381 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_126 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_382 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_127 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_383 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2569\n",
      "Epoch 1: val_loss improved from inf to 0.11471, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2569 - val_loss: 0.1147\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0655\n",
      "Epoch 2: val_loss improved from 0.11471 to 0.04093, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0655 - val_loss: 0.0409\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 3: val_loss improved from 0.04093 to 0.01685, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0303 - val_loss: 0.0169\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.01685 to 0.00993, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0148 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.00993 to 0.00642, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00642 to 0.00435, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00435 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00344 to 0.00293, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00293 to 0.00255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00255 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_384 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_192 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_385 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_193 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_386 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_194 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_387 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_128 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_388 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_129 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_389 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3283\n",
      "Epoch 1: val_loss improved from inf to 0.22337, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.3283 - val_loss: 0.2234\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1270\n",
      "Epoch 2: val_loss improved from 0.22337 to 0.05347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.1270 - val_loss: 0.0535\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 3: val_loss improved from 0.05347 to 0.02168, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0366 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 4: val_loss improved from 0.02168 to 0.01243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0183 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01243 to 0.00786, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0115 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00786 to 0.00529, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00529 to 0.00390, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00390 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00321 to 0.00273, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00273 to 0.00235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_390 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_195 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_391 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_196 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_392 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_197 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_393 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_130 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_394 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_131 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_395 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2724\n",
      "Epoch 1: val_loss improved from inf to 0.15526, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2724 - val_loss: 0.1553\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0789\n",
      "Epoch 2: val_loss improved from 0.15526 to 0.03799, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0789 - val_loss: 0.0380\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 3: val_loss improved from 0.03799 to 0.01406, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0251 - val_loss: 0.0141\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 4: val_loss improved from 0.01406 to 0.00786, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.00786 to 0.00551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00551 to 0.00432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00432 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00324 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00252 to 0.00214, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00214 to 0.00189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_396 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_198 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_397 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_199 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_398 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_200 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_399 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_132 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_400 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_133 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_401 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2199\n",
      "Epoch 1: val_loss improved from inf to 0.10085, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2199 - val_loss: 0.1009\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0618\n",
      "Epoch 2: val_loss improved from 0.10085 to 0.04141, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0618 - val_loss: 0.0414\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 3: val_loss improved from 0.04141 to 0.01921, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0297 - val_loss: 0.0192\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 4: val_loss improved from 0.01921 to 0.00945, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.00945 to 0.00555, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0080 - val_loss: 0.0056\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00555 to 0.00393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00393 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00321 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00277 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00248 to 0.00226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_402 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_201 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_403 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_202 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_404 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_203 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_405 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_134 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_406 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_135 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_407 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3275\n",
      "Epoch 1: val_loss improved from inf to 0.26908, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.3275 - val_loss: 0.2691\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1355\n",
      "Epoch 2: val_loss improved from 0.26908 to 0.06388, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.1355 - val_loss: 0.0639\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0418\n",
      "Epoch 3: val_loss improved from 0.06388 to 0.02674, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0418 - val_loss: 0.0267\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 4: val_loss improved from 0.02674 to 0.01510, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0199 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 5: val_loss improved from 0.01510 to 0.00969, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00969 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00663 to 0.00511, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00511 to 0.00439, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00439 to 0.00393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00393 to 0.00356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_408 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_204 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_409 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_205 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_410 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_206 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_411 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_136 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_412 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_137 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_413 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3599\n",
      "Epoch 1: val_loss improved from inf to 0.29587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.3599 - val_loss: 0.2959\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1290\n",
      "Epoch 2: val_loss improved from 0.29587 to 0.05753, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.1290 - val_loss: 0.0575\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0405\n",
      "Epoch 3: val_loss improved from 0.05753 to 0.03130, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0405 - val_loss: 0.0313\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0212\n",
      "Epoch 4: val_loss improved from 0.03130 to 0.01913, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0212 - val_loss: 0.0191\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 5: val_loss improved from 0.01913 to 0.01393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01393 to 0.01046, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.01046 to 0.00812, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00812 to 0.00645, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00645 to 0.00511, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00511 to 0.00446, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0032 - val_loss: 0.0045\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_414 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_207 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_415 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_208 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_416 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_209 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_417 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_138 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_418 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_139 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_419 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2483\n",
      "Epoch 1: val_loss improved from inf to 0.15114, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2483 - val_loss: 0.1511\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0682\n",
      "Epoch 2: val_loss improved from 0.15114 to 0.05175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0682 - val_loss: 0.0517\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 3: val_loss improved from 0.05175 to 0.03143, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0366 - val_loss: 0.0314\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 4: val_loss improved from 0.03143 to 0.01958, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0211 - val_loss: 0.0196\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01958 to 0.01234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.01234 to 0.00938, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00938 to 0.00803, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0052 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00803 to 0.00701, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00701 to 0.00630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00630 to 0.00578, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0033 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_420 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_210 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_421 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_211 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_422 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_212 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_423 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_140 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_424 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_141 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_425 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2513\n",
      "Epoch 1: val_loss improved from inf to 0.14375, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.2513 - val_loss: 0.1438\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0552\n",
      "Epoch 2: val_loss improved from 0.14375 to 0.03411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0552 - val_loss: 0.0341\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 3: val_loss improved from 0.03411 to 0.02054, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0228 - val_loss: 0.0205\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.02054 to 0.01401, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.01401 to 0.01000, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.01000 to 0.00779, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00779 to 0.00632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00632 to 0.00544, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00544 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00493 to 0.00454, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_426 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_213 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_427 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_214 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_428 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_215 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_429 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_142 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_430 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_143 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_431 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2854\n",
      "Epoch 1: val_loss improved from inf to 0.19309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2854 - val_loss: 0.1931\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0944\n",
      "Epoch 2: val_loss improved from 0.19309 to 0.05778, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0944 - val_loss: 0.0578\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0378\n",
      "Epoch 3: val_loss improved from 0.05778 to 0.02424, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0378 - val_loss: 0.0242\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 4: val_loss improved from 0.02424 to 0.01465, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0180 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 5: val_loss improved from 0.01465 to 0.01055, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01055 to 0.00822, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00822 to 0.00653, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00653 to 0.00538, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00538 to 0.00462, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00462 to 0.00408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_432 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_216 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_433 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_217 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_434 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_218 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_435 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_144 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_436 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_145 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_437 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3284\n",
      "Epoch 1: val_loss improved from inf to 0.26597, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.3284 - val_loss: 0.2660\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1230\n",
      "Epoch 2: val_loss improved from 0.26597 to 0.03995, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.1230 - val_loss: 0.0399\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 3: val_loss improved from 0.03995 to 0.01604, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0257 - val_loss: 0.0160\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.01604 to 0.01013, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01013 to 0.00700, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00700 to 0.00524, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00524 to 0.00419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00419 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00354 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00310 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_438 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_219 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_439 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_220 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_440 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_221 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_441 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_146 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_442 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_147 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_443 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2480\n",
      "Epoch 1: val_loss improved from inf to 0.12213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2480 - val_loss: 0.1221\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0709\n",
      "Epoch 2: val_loss improved from 0.12213 to 0.03820, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0709 - val_loss: 0.0382\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.03820 to 0.01775, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0291 - val_loss: 0.0177\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.01775 to 0.00957, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0162 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.00957 to 0.00554, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00554 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00407 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00311 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00247 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00202 to 0.00169, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_444 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_222 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_445 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_223 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_446 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_224 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_447 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_148 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_448 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_149 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_449 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3205\n",
      "Epoch 1: val_loss improved from inf to 0.24272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 385ms/step - loss: 0.3205 - val_loss: 0.2427\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1728\n",
      "Epoch 2: val_loss improved from 0.24272 to 0.04598, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.1728 - val_loss: 0.0460\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0397\n",
      "Epoch 3: val_loss improved from 0.04598 to 0.02518, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0397 - val_loss: 0.0252\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 4: val_loss improved from 0.02518 to 0.01335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0226 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01335 to 0.00701, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00701 to 0.00425, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0076 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00425 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00312 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00239 to 0.00200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00200 to 0.00178, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_450 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_225 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_451 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_226 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_452 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_227 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_453 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_150 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_454 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_151 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_455 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2099\n",
      "Epoch 1: val_loss improved from inf to 0.07874, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2099 - val_loss: 0.0787\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0471\n",
      "Epoch 2: val_loss improved from 0.07874 to 0.02432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0471 - val_loss: 0.0243\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0197\n",
      "Epoch 3: val_loss improved from 0.02432 to 0.01108, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0197 - val_loss: 0.0111\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 4: val_loss improved from 0.01108 to 0.00701, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0120 - val_loss: 0.0070\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.00701 to 0.00469, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00469 to 0.00360, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00360 to 0.00285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00285 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00230 to 0.00195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00195 to 0.00171, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_456 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_228 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_457 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_229 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_458 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_230 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_459 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_152 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_460 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_153 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_461 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2592\n",
      "Epoch 1: val_loss improved from inf to 0.13277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2592 - val_loss: 0.1328\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0830\n",
      "Epoch 2: val_loss improved from 0.13277 to 0.04893, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0830 - val_loss: 0.0489\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0381\n",
      "Epoch 3: val_loss improved from 0.04893 to 0.02405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0381 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0223\n",
      "Epoch 4: val_loss improved from 0.02405 to 0.01513, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0223 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01513 to 0.00839, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0140 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.00839 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00478 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00324 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00257 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00222 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_462 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_231 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_463 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_232 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_464 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_233 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_465 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_154 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_466 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_155 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_467 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2510\n",
      "Epoch 1: val_loss improved from inf to 0.11489, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2510 - val_loss: 0.1149\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0732\n",
      "Epoch 2: val_loss improved from 0.11489 to 0.04262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0732 - val_loss: 0.0426\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0281\n",
      "Epoch 3: val_loss improved from 0.04262 to 0.01712, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0281 - val_loss: 0.0171\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.01712 to 0.01022, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01022 to 0.00703, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0100 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00703 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00493 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00387 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00312 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00262 to 0.00227, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_468 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_234 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_469 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_235 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_470 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_236 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_471 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_156 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_472 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_157 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_473 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2898\n",
      "Epoch 1: val_loss improved from inf to 0.17392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2898 - val_loss: 0.1739\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0857\n",
      "Epoch 2: val_loss improved from 0.17392 to 0.04194, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0857 - val_loss: 0.0419\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0287\n",
      "Epoch 3: val_loss improved from 0.04194 to 0.01670, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0287 - val_loss: 0.0167\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 4: val_loss improved from 0.01670 to 0.01009, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01009 to 0.00702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00702 to 0.00497, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00497 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00387 to 0.00327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00327 to 0.00284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00284 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0031 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_474 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_237 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_475 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_238 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_476 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_239 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_477 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_158 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_478 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_159 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_479 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2497\n",
      "Epoch 1: val_loss improved from inf to 0.13587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.2497 - val_loss: 0.1359\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0668\n",
      "Epoch 2: val_loss improved from 0.13587 to 0.04340, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0668 - val_loss: 0.0434\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 3: val_loss improved from 0.04340 to 0.01886, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0299 - val_loss: 0.0189\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 4: val_loss improved from 0.01886 to 0.00980, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00980 to 0.00646, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00646 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00501 to 0.00408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00408 to 0.00353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00353 to 0.00319, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00319 to 0.00297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_480 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_240 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_481 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_241 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_482 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_242 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_483 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_160 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_484 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_161 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_485 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1984\n",
      "Epoch 1: val_loss improved from inf to 0.08348, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.1984 - val_loss: 0.0835\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0560\n",
      "Epoch 2: val_loss improved from 0.08348 to 0.03877, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0560 - val_loss: 0.0388\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 3: val_loss improved from 0.03877 to 0.02067, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0251 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.02067 to 0.01195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 5: val_loss improved from 0.01195 to 0.00775, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 6: val_loss improved from 0.00775 to 0.00603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss improved from 0.00603 to 0.00529, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00529 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00478 to 0.00437, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00437 to 0.00401, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_486 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_243 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_487 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_244 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_488 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_245 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_489 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_162 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_490 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_163 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_491 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1884\n",
      "Epoch 1: val_loss improved from inf to 0.05133, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.1884 - val_loss: 0.0513\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0361\n",
      "Epoch 2: val_loss improved from 0.05133 to 0.03109, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0361 - val_loss: 0.0311\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 3: val_loss improved from 0.03109 to 0.01883, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 4: val_loss improved from 0.01883 to 0.01388, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.01388 to 0.01073, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0077 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.01073 to 0.00859, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00859 to 0.00729, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0042 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00729 to 0.00647, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00647 to 0.00593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00593 to 0.00554, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0028 - val_loss: 0.0055\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_492 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_246 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_493 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_247 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_494 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_248 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_495 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_164 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_496 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_165 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_497 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1927\n",
      "Epoch 1: val_loss improved from inf to 0.07912, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.1927 - val_loss: 0.0791\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0387\n",
      "Epoch 2: val_loss improved from 0.07912 to 0.02928, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0387 - val_loss: 0.0293\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 3: val_loss improved from 0.02928 to 0.01757, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0186 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 4: val_loss improved from 0.01757 to 0.01136, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 5: val_loss improved from 0.01136 to 0.00847, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 6: val_loss improved from 0.00847 to 0.00708, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0048 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00708 to 0.00633, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00633 to 0.00583, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00583 to 0.00540, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00540 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_498 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_249 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_499 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_250 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_500 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_251 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_501 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_166 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_502 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_167 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_503 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1: val_loss improved from inf to 0.14383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2502 - val_loss: 0.1438\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0552\n",
      "Epoch 2: val_loss improved from 0.14383 to 0.03175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0552 - val_loss: 0.0318\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 3: val_loss improved from 0.03175 to 0.01744, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0208 - val_loss: 0.0174\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 4: val_loss improved from 0.01744 to 0.01193, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01193 to 0.00867, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00867 to 0.00653, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00653 to 0.00523, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00523 to 0.00446, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00446 to 0.00395, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00395 to 0.00355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_504 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_252 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_505 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_253 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_506 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_254 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_507 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_168 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_508 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_169 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_509 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2419\n",
      "Epoch 1: val_loss improved from inf to 0.12651, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2419 - val_loss: 0.1265\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0712\n",
      "Epoch 2: val_loss improved from 0.12651 to 0.05032, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0712 - val_loss: 0.0503\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.05032 to 0.02472, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0359 - val_loss: 0.0247\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.02472 to 0.01508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0200 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01508 to 0.00987, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.00987 to 0.00690, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00690 to 0.00490, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00490 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00364 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00295 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_510 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_255 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_511 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_256 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_512 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_257 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_513 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_170 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_514 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_171 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_515 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2895\n",
      "Epoch 1: val_loss improved from inf to 0.18371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2895 - val_loss: 0.1837\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0971\n",
      "Epoch 2: val_loss improved from 0.18371 to 0.05530, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0971 - val_loss: 0.0553\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0399\n",
      "Epoch 3: val_loss improved from 0.05530 to 0.02487, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0399 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0192\n",
      "Epoch 4: val_loss improved from 0.02487 to 0.01235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0192 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 5: val_loss improved from 0.01235 to 0.00734, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00734 to 0.00483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00483 to 0.00336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00336 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00264 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00229 to 0.00206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_516 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_258 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_517 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_259 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_518 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_260 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_519 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_172 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_520 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_173 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_521 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2304\n",
      "Epoch 1: val_loss improved from inf to 0.09279, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2304 - val_loss: 0.0928\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0545\n",
      "Epoch 2: val_loss improved from 0.09279 to 0.03552, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0545 - val_loss: 0.0355\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.03552 to 0.01845, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0291 - val_loss: 0.0185\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.01845 to 0.01044, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0162 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01044 to 0.00593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00593 to 0.00367, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00367 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00280 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00237 to 0.00206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00206 to 0.00184, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_522 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_261 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_523 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_262 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_524 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_263 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_525 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_174 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_526 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_175 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_527 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2554\n",
      "Epoch 1: val_loss improved from inf to 0.11636, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2554 - val_loss: 0.1164\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0696\n",
      "Epoch 2: val_loss improved from 0.11636 to 0.04084, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0696 - val_loss: 0.0408\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0298\n",
      "Epoch 3: val_loss improved from 0.04084 to 0.01806, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0298 - val_loss: 0.0181\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.01806 to 0.01022, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0161 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01022 to 0.00615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00615 to 0.00417, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00417 to 0.00313, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 368ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00313 to 0.00261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00261 to 0.00227, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00227 to 0.00201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_528 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_264 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_529 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_265 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_530 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_266 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_531 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_176 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_532 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_177 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_533 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3348\n",
      "Epoch 1: val_loss improved from inf to 0.22852, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.3348 - val_loss: 0.2285\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1417\n",
      "Epoch 2: val_loss improved from 0.22852 to 0.07587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.1417 - val_loss: 0.0759\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0574\n",
      "Epoch 3: val_loss improved from 0.07587 to 0.03704, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0574 - val_loss: 0.0370\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0279\n",
      "Epoch 4: val_loss improved from 0.03704 to 0.01708, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0279 - val_loss: 0.0171\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 5: val_loss improved from 0.01708 to 0.00712, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00712 to 0.00369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00369 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00282 to 0.00246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00246 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00221 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_534 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_267 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_535 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_268 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_536 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_269 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_537 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_178 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_538 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_179 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_539 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1982\n",
      "Epoch 1: val_loss improved from inf to 0.07134, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.1982 - val_loss: 0.0713\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0523\n",
      "Epoch 2: val_loss improved from 0.07134 to 0.03411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0523 - val_loss: 0.0341\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Epoch 3: val_loss improved from 0.03411 to 0.01428, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0233 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 4: val_loss improved from 0.01428 to 0.00808, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.00808 to 0.00556, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00556 to 0.00422, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00422 to 0.00333, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00333 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00282 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00250 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_540 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_270 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_541 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_271 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_542 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_272 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_543 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_180 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_544 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_181 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_545 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2982\n",
      "Epoch 1: val_loss improved from inf to 0.17603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2982 - val_loss: 0.1760\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0965\n",
      "Epoch 2: val_loss improved from 0.17603 to 0.06459, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0965 - val_loss: 0.0646\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0486\n",
      "Epoch 3: val_loss improved from 0.06459 to 0.03572, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0486 - val_loss: 0.0357\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 4: val_loss improved from 0.03572 to 0.02079, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0276 - val_loss: 0.0208\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 5: val_loss improved from 0.02079 to 0.01197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 6: val_loss improved from 0.01197 to 0.00781, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 7: val_loss improved from 0.00781 to 0.00595, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 8: val_loss improved from 0.00595 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00493 to 0.00417, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00417 to 0.00357, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_546 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_273 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_547 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_274 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_548 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_275 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_549 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_182 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_550 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_183 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_551 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2808\n",
      "Epoch 1: val_loss improved from inf to 0.18252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2808 - val_loss: 0.1825\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0860\n",
      "Epoch 2: val_loss improved from 0.18252 to 0.05131, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0860 - val_loss: 0.0513\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0370\n",
      "Epoch 3: val_loss improved from 0.05131 to 0.02771, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0370 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.02771 to 0.01601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0200 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 5: val_loss improved from 0.01601 to 0.00991, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00991 to 0.00673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00673 to 0.00507, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00507 to 0.00425, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00425 to 0.00377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00377 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_552 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_276 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_553 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_277 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_554 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_278 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_555 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_184 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_556 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_185 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_557 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2183\n",
      "Epoch 1: val_loss improved from inf to 0.08851, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2183 - val_loss: 0.0885\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0559\n",
      "Epoch 2: val_loss improved from 0.08851 to 0.04351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0559 - val_loss: 0.0435\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0274\n",
      "Epoch 3: val_loss improved from 0.04351 to 0.02437, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0274 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 4: val_loss improved from 0.02437 to 0.01442, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01442 to 0.00974, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00974 to 0.00762, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0058 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00762 to 0.00667, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00667 to 0.00599, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00599 to 0.00550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00550 to 0.00512, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_558 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_279 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_559 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_280 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_560 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_281 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_561 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_186 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_562 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_187 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_563 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2057\n",
      "Epoch 1: val_loss improved from inf to 0.10950, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2057 - val_loss: 0.1095\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0484\n",
      "Epoch 2: val_loss improved from 0.10950 to 0.03990, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0484 - val_loss: 0.0399\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0230\n",
      "Epoch 3: val_loss improved from 0.03990 to 0.02073, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 4: val_loss improved from 0.02073 to 0.01344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0117 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 5: val_loss improved from 0.01344 to 0.01004, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.01004 to 0.00805, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0052 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00805 to 0.00692, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0040 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00692 to 0.00626, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00626 to 0.00566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00566 to 0.00520, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0028 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_564 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_282 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_565 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_283 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_566 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_284 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_567 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_188 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_568 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_189 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_569 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2614\n",
      "Epoch 1: val_loss improved from inf to 0.18761, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2614 - val_loss: 0.1876\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0728\n",
      "Epoch 2: val_loss improved from 0.18761 to 0.04218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0728 - val_loss: 0.0422\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0256\n",
      "Epoch 3: val_loss improved from 0.04218 to 0.02242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0256 - val_loss: 0.0224\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 4: val_loss improved from 0.02242 to 0.01330, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.01330 to 0.00980, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0079 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.00980 to 0.00769, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00769 to 0.00644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00644 to 0.00558, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00558 to 0.00494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00494 to 0.00442, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0027 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_570 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_285 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_571 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_286 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_572 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_287 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_573 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_190 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_574 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_191 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_575 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2439\n",
      "Epoch 1: val_loss improved from inf to 0.15896, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2439 - val_loss: 0.1590\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0818\n",
      "Epoch 2: val_loss improved from 0.15896 to 0.05815, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0818 - val_loss: 0.0582\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0384\n",
      "Epoch 3: val_loss improved from 0.05815 to 0.02667, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0384 - val_loss: 0.0267\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02667 to 0.01402, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0177 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01402 to 0.00886, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00886 to 0.00627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00627 to 0.00504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00504 to 0.00430, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00430 to 0.00375, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00375 to 0.00329, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_576 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_288 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_577 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_289 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_578 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_290 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_579 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_192 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_580 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_193 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_581 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2901\n",
      "Epoch 1: val_loss improved from inf to 0.19491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2901 - val_loss: 0.1949\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0838\n",
      "Epoch 2: val_loss improved from 0.19491 to 0.04341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0838 - val_loss: 0.0434\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 3: val_loss improved from 0.04341 to 0.01896, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0300 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.01896 to 0.01162, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01162 to 0.00819, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00819 to 0.00570, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00570 to 0.00412, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00412 to 0.00322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00322 to 0.00272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00272 to 0.00240, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_582 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_291 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_583 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_292 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_584 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_293 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_585 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_194 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_586 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_195 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_587 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2586\n",
      "Epoch 1: val_loss improved from inf to 0.13603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2586 - val_loss: 0.1360\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0636\n",
      "Epoch 2: val_loss improved from 0.13603 to 0.03423, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0636 - val_loss: 0.0342\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 3: val_loss improved from 0.03423 to 0.01710, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0254 - val_loss: 0.0171\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.01710 to 0.00956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0144 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.00956 to 0.00562, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00562 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00387 to 0.00304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00304 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00256 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00225 to 0.00204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_588 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_294 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_589 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_295 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_590 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_296 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_591 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_196 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_592 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_197 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_593 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1: val_loss improved from inf to 0.10877, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2460 - val_loss: 0.1088\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0548\n",
      "Epoch 2: val_loss improved from 0.10877 to 0.02749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0548 - val_loss: 0.0275\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 3: val_loss improved from 0.02749 to 0.01304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0210 - val_loss: 0.0130\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 4: val_loss improved from 0.01304 to 0.00637, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0112 - val_loss: 0.0064\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 5: val_loss improved from 0.00637 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 6: val_loss improved from 0.00381 to 0.00285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00285 to 0.00236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00236 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00209 to 0.00188, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00188 to 0.00171, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_594 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_297 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_595 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_298 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_596 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_299 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_597 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_198 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_598 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_199 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_599 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2819\n",
      "Epoch 1: val_loss improved from inf to 0.17567, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2819 - val_loss: 0.1757\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1053\n",
      "Epoch 2: val_loss improved from 0.17567 to 0.04433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.1053 - val_loss: 0.0443\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0307\n",
      "Epoch 3: val_loss improved from 0.04433 to 0.01697, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0307 - val_loss: 0.0170\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 4: val_loss improved from 0.01697 to 0.00853, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0143 - val_loss: 0.0085\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.00853 to 0.00518, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00518 to 0.00375, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00375 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00288 to 0.00236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00236 to 0.00205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00205 to 0.00182, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_600 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_300 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_601 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_301 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_602 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_302 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_603 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_200 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_604 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_201 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_605 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2730\n",
      "Epoch 1: val_loss improved from inf to 0.14837, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2730 - val_loss: 0.1484\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0835\n",
      "Epoch 2: val_loss improved from 0.14837 to 0.04477, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0835 - val_loss: 0.0448\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0287\n",
      "Epoch 3: val_loss improved from 0.04477 to 0.01591, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0287 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 4: val_loss improved from 0.01591 to 0.00731, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0129 - val_loss: 0.0073\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 5: val_loss improved from 0.00731 to 0.00432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00432 to 0.00338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00338 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00280 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00238 to 0.00207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00207 to 0.00183, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_606 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_303 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_607 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_304 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_608 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_305 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_609 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_202 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_610 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_203 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_611 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2860\n",
      "Epoch 1: val_loss improved from inf to 0.14605, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.2860 - val_loss: 0.1460\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0668\n",
      "Epoch 2: val_loss improved from 0.14605 to 0.03426, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0668 - val_loss: 0.0343\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 3: val_loss improved from 0.03426 to 0.01518, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0244 - val_loss: 0.0152\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 4: val_loss improved from 0.01518 to 0.00801, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0126 - val_loss: 0.0080\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00801 to 0.00514, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0078 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00514 to 0.00372, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00372 to 0.00292, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00292 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00251 to 0.00226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00226 to 0.00207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_612 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_306 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_613 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_307 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_614 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_308 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_615 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_204 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_616 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_205 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_617 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3116\n",
      "Epoch 1: val_loss improved from inf to 0.21718, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.3116 - val_loss: 0.2172\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1161\n",
      "Epoch 2: val_loss improved from 0.21718 to 0.05752, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.1161 - val_loss: 0.0575\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0380\n",
      "Epoch 3: val_loss improved from 0.05752 to 0.02509, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0380 - val_loss: 0.0251\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 4: val_loss improved from 0.02509 to 0.01300, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0188 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01300 to 0.00733, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00733 to 0.00482, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00482 to 0.00356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00356 to 0.00291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00291 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00256 to 0.00232, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_618 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_309 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_619 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_310 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_620 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_311 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_621 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_206 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_622 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_207 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_623 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2289\n",
      "Epoch 1: val_loss improved from inf to 0.09431, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2289 - val_loss: 0.0943\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0429\n",
      "Epoch 2: val_loss improved from 0.09431 to 0.02825, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0429 - val_loss: 0.0283\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 3: val_loss improved from 0.02825 to 0.01490, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0194 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 4: val_loss improved from 0.01490 to 0.00864, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0107 - val_loss: 0.0086\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 5: val_loss improved from 0.00864 to 0.00538, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 6: val_loss improved from 0.00538 to 0.00412, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 7: val_loss improved from 0.00412 to 0.00351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 8: val_loss improved from 0.00351 to 0.00307, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 9: val_loss improved from 0.00307 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 10: val_loss improved from 0.00277 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_624 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_312 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_625 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_313 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_626 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_314 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_627 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_208 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_628 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_209 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_629 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2387\n",
      "Epoch 1: val_loss improved from inf to 0.15302, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2387 - val_loss: 0.1530\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0774\n",
      "Epoch 2: val_loss improved from 0.15302 to 0.05320, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0774 - val_loss: 0.0532\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0321\n",
      "Epoch 3: val_loss improved from 0.05320 to 0.02440, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0321 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02440 to 0.01567, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0161 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01567 to 0.01090, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.01090 to 0.00819, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00819 to 0.00648, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00648 to 0.00547, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00547 to 0.00483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00483 to 0.00435, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0030 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_630 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_315 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_631 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_316 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_632 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_317 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_633 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_210 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_634 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_211 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_635 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2196\n",
      "Epoch 1: val_loss improved from inf to 0.09917, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2196 - val_loss: 0.0992\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0521\n",
      "Epoch 2: val_loss improved from 0.09917 to 0.04118, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0521 - val_loss: 0.0412\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0261\n",
      "Epoch 3: val_loss improved from 0.04118 to 0.02452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0261 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02452 to 0.01659, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0158 - val_loss: 0.0166\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01659 to 0.01182, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01182 to 0.00909, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00909 to 0.00746, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0048 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00746 to 0.00646, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00646 to 0.00585, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00585 to 0.00544, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_636 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_318 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_637 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_319 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_638 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_320 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_639 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_212 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_640 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_213 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_641 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2606\n",
      "Epoch 1: val_loss improved from inf to 0.15597, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2606 - val_loss: 0.1560\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0760\n",
      "Epoch 2: val_loss improved from 0.15597 to 0.05387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0760 - val_loss: 0.0539\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0320\n",
      "Epoch 3: val_loss improved from 0.05387 to 0.02553, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0320 - val_loss: 0.0255\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 4: val_loss improved from 0.02553 to 0.01610, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0169 - val_loss: 0.0161\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01610 to 0.01072, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01072 to 0.00831, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00831 to 0.00681, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00681 to 0.00582, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00582 to 0.00522, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00522 to 0.00481, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_642 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_321 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_643 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_322 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_644 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_323 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_645 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_214 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_646 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_215 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_647 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1865\n",
      "Epoch 1: val_loss improved from inf to 0.08560, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 382ms/step - loss: 0.1865 - val_loss: 0.0856\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0518\n",
      "Epoch 2: val_loss improved from 0.08560 to 0.03467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0518 - val_loss: 0.0347\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 3: val_loss improved from 0.03467 to 0.01684, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0215 - val_loss: 0.0168\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 4: val_loss improved from 0.01684 to 0.01026, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 5: val_loss improved from 0.01026 to 0.00691, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00691 to 0.00518, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00518 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00433 to 0.00388, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00388 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00354 to 0.00325, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_648 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_324 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_649 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_325 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_650 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_326 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_651 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_216 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_652 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_217 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_653 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1: val_loss improved from inf to 0.12938, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2472 - val_loss: 0.1294\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0709\n",
      "Epoch 2: val_loss improved from 0.12938 to 0.05008, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0709 - val_loss: 0.0501\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0343\n",
      "Epoch 3: val_loss improved from 0.05008 to 0.02510, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0343 - val_loss: 0.0251\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 4: val_loss improved from 0.02510 to 0.01382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0186 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01382 to 0.00778, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00778 to 0.00465, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00465 to 0.00340, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00340 to 0.00284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00284 to 0.00254, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00254 to 0.00232, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_654 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_327 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_655 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_328 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_656 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_329 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_657 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_218 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_658 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_219 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_659 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2351\n",
      "Epoch 1: val_loss improved from inf to 0.10747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2351 - val_loss: 0.1075\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0732\n",
      "Epoch 2: val_loss improved from 0.10747 to 0.05277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0732 - val_loss: 0.0528\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0367\n",
      "Epoch 3: val_loss improved from 0.05277 to 0.02324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0367 - val_loss: 0.0232\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0184\n",
      "Epoch 4: val_loss improved from 0.02324 to 0.01360, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0184 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01360 to 0.00910, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0120 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.00910 to 0.00615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00615 to 0.00382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00382 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00262 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00215 to 0.00195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_660 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_330 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_661 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_331 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_662 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_332 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_663 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_220 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_664 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_221 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_665 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2936\n",
      "Epoch 1: val_loss improved from inf to 0.16900, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2936 - val_loss: 0.1690\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1048\n",
      "Epoch 2: val_loss improved from 0.16900 to 0.06772, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.1048 - val_loss: 0.0677\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0512\n",
      "Epoch 3: val_loss improved from 0.06772 to 0.03172, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0512 - val_loss: 0.0317\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 4: val_loss improved from 0.03172 to 0.01606, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0241 - val_loss: 0.0161\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01606 to 0.00760, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00760 to 0.00441, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00441 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00310 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00256 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00229 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_666 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_333 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_667 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_334 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_668 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_335 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_669 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_222 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_670 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_223 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_671 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2847\n",
      "Epoch 1: val_loss improved from inf to 0.16064, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.2847 - val_loss: 0.1606\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0899\n",
      "Epoch 2: val_loss improved from 0.16064 to 0.05246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0899 - val_loss: 0.0525\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 3: val_loss improved from 0.05246 to 0.03069, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0419 - val_loss: 0.0307\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 4: val_loss improved from 0.03069 to 0.01687, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0239 - val_loss: 0.0169\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 5: val_loss improved from 0.01687 to 0.01016, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.01016 to 0.00634, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00634 to 0.00426, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00426 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00314 to 0.00245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00245 to 0.00206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_672 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_336 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_673 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_337 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_674 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_338 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_675 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_224 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_676 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_225 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_677 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2175\n",
      "Epoch 1: val_loss improved from inf to 0.09317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2175 - val_loss: 0.0932\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0609\n",
      "Epoch 2: val_loss improved from 0.09317 to 0.04339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0609 - val_loss: 0.0434\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0337\n",
      "Epoch 3: val_loss improved from 0.04339 to 0.02350, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0337 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 4: val_loss improved from 0.02350 to 0.01500, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 370ms/step - loss: 0.0198 - val_loss: 0.0150\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01500 to 0.00944, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 6: val_loss improved from 0.00944 to 0.00573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00573 to 0.00370, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00370 to 0.00278, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00278 to 0.00234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00234 to 0.00208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_678 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_339 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_679 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_340 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_680 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_341 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_681 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_226 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_682 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_227 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_683 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3164\n",
      "Epoch 1: val_loss improved from inf to 0.20160, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 387ms/step - loss: 0.3164 - val_loss: 0.2016\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1146\n",
      "Epoch 2: val_loss improved from 0.20160 to 0.06124, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.1146 - val_loss: 0.0612\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0460\n",
      "Epoch 3: val_loss improved from 0.06124 to 0.03409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0460 - val_loss: 0.0341\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 4: val_loss improved from 0.03409 to 0.01311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0228 - val_loss: 0.0131\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01311 to 0.00623, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0098 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00623 to 0.00434, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00434 to 0.00341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00341 to 0.00289, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00289 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00256 to 0.00231, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_684 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_342 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_685 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_343 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_686 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_344 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_687 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_228 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_688 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_229 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_689 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2651\n",
      "Epoch 1: val_loss improved from inf to 0.16612, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2651 - val_loss: 0.1661\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0897\n",
      "Epoch 2: val_loss improved from 0.16612 to 0.05287, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0897 - val_loss: 0.0529\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0351\n",
      "Epoch 3: val_loss improved from 0.05287 to 0.02150, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0351 - val_loss: 0.0215\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.02150 to 0.01021, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01021 to 0.00653, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0084 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00653 to 0.00464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00464 to 0.00368, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00368 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00321 to 0.00294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00294 to 0.00273, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_690 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_345 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_691 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_346 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_692 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_347 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_693 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_230 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_694 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_231 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_695 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2354\n",
      "Epoch 1: val_loss improved from inf to 0.11268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 383ms/step - loss: 0.2354 - val_loss: 0.1127\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0723\n",
      "Epoch 2: val_loss improved from 0.11268 to 0.05128, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 369ms/step - loss: 0.0723 - val_loss: 0.0513\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0321\n",
      "Epoch 3: val_loss improved from 0.05128 to 0.02175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0321 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.02175 to 0.01092, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0142 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.01092 to 0.00669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00669 to 0.00484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00484 to 0.00402, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00402 to 0.00357, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00357 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00324 to 0.00299, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_696 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_348 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_697 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_349 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_698 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_350 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_699 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_232 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_700 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_233 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_701 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2929\n",
      "Epoch 1: val_loss improved from inf to 0.19657, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 381ms/step - loss: 0.2929 - val_loss: 0.1966\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0762\n",
      "Epoch 2: val_loss improved from 0.19657 to 0.04284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0762 - val_loss: 0.0428\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 3: val_loss improved from 0.04284 to 0.02043, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0255 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 4: val_loss improved from 0.02043 to 0.01397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0135 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01397 to 0.01024, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01024 to 0.00806, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00806 to 0.00662, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00662 to 0.00563, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00563 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00499 to 0.00454, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0032 - val_loss: 0.0045\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_702 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_351 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_703 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_352 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_704 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_353 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_705 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_234 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_706 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_235 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_707 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1589\n",
      "Epoch 1: val_loss improved from inf to 0.08322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.1589 - val_loss: 0.0832\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0536\n",
      "Epoch 2: val_loss improved from 0.08322 to 0.03834, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0536 - val_loss: 0.0383\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 3: val_loss improved from 0.03834 to 0.02067, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0225 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 4: val_loss improved from 0.02067 to 0.01378, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.01378 to 0.01005, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.01005 to 0.00797, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00797 to 0.00685, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0045 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00685 to 0.00615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00615 to 0.00566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00566 to 0.00527, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_708 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_354 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_709 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_355 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_710 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_356 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_711 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_236 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_712 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_237 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_713 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3330\n",
      "Epoch 1: val_loss improved from inf to 0.32148, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.3330 - val_loss: 0.3215\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1564\n",
      "Epoch 2: val_loss improved from 0.32148 to 0.07650, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.1564 - val_loss: 0.0765\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0508\n",
      "Epoch 3: val_loss improved from 0.07650 to 0.03559, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0508 - val_loss: 0.0356\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 4: val_loss improved from 0.03559 to 0.01736, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0209 - val_loss: 0.0174\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01736 to 0.01091, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.01091 to 0.00869, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0071 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00869 to 0.00723, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00723 to 0.00589, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00589 to 0.00494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00494 to 0.00441, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_714 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_357 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_715 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_358 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_716 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_359 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_717 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_238 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_718 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_239 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_719 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2900\n",
      "Epoch 1: val_loss improved from inf to 0.22331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 385ms/step - loss: 0.2900 - val_loss: 0.2233\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0858\n",
      "Epoch 2: val_loss improved from 0.22331 to 0.03907, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0858 - val_loss: 0.0391\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0235\n",
      "Epoch 3: val_loss improved from 0.03907 to 0.01560, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0235 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 4: val_loss improved from 0.01560 to 0.01014, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.01014 to 0.00722, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00722 to 0.00540, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00540 to 0.00443, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00443 to 0.00386, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00386 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00346 to 0.00316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_720 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_360 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_721 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_361 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_722 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_362 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_723 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_240 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_724 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_241 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_725 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3185\n",
      "Epoch 1: val_loss improved from inf to 0.26794, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.3185 - val_loss: 0.2679\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1542\n",
      "Epoch 2: val_loss improved from 0.26794 to 0.07552, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.1542 - val_loss: 0.0755\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0493\n",
      "Epoch 3: val_loss improved from 0.07552 to 0.03230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0493 - val_loss: 0.0323\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 4: val_loss improved from 0.03230 to 0.01685, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0241 - val_loss: 0.0169\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 5: val_loss improved from 0.01685 to 0.00867, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00867 to 0.00584, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00584 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00429 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00347 to 0.00304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00304 to 0.00275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_726 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_363 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_727 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_364 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_728 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_365 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_729 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_242 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_730 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_243 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_731 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2044\n",
      "Epoch 1: val_loss improved from inf to 0.07431, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 385ms/step - loss: 0.2044 - val_loss: 0.0743\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0523\n",
      "Epoch 2: val_loss improved from 0.07431 to 0.03621, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0523 - val_loss: 0.0362\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 3: val_loss improved from 0.03621 to 0.01381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0251 - val_loss: 0.0138\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 4: val_loss improved from 0.01381 to 0.00692, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 5: val_loss improved from 0.00692 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00433 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00345 to 0.00286, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00286 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00247 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00221 to 0.00199, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_732 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_366 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_733 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_367 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_734 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_368 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_735 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_244 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_736 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_245 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_737 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3323\n",
      "Epoch 1: val_loss improved from inf to 0.24317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 387ms/step - loss: 0.3323 - val_loss: 0.2432\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 2: val_loss improved from 0.24317 to 0.06530, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.1489 - val_loss: 0.0653\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0483\n",
      "Epoch 3: val_loss improved from 0.06530 to 0.02964, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0483 - val_loss: 0.0296\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 4: val_loss improved from 0.02964 to 0.01408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0226 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01408 to 0.00683, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0119 - val_loss: 0.0068\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00683 to 0.00466, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00466 to 0.00342, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00342 to 0.00273, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00273 to 0.00234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00234 to 0.00206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_738 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_369 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_739 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_370 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_740 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_371 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_741 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_246 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_742 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_247 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_743 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2499\n",
      "Epoch 1: val_loss improved from inf to 0.12567, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2499 - val_loss: 0.1257\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0677\n",
      "Epoch 2: val_loss improved from 0.12567 to 0.03716, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0677 - val_loss: 0.0372\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 3: val_loss improved from 0.03716 to 0.01941, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0299 - val_loss: 0.0194\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.01941 to 0.01070, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0166 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01070 to 0.00598, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00598 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00354 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00262 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00221 to 0.00193, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00193 to 0.00168, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_744 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_372 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_745 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_373 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_746 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_374 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_747 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_248 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_748 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_249 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_749 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2616\n",
      "Epoch 1: val_loss improved from inf to 0.13967, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 385ms/step - loss: 0.2616 - val_loss: 0.1397\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0865\n",
      "Epoch 2: val_loss improved from 0.13967 to 0.03998, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0865 - val_loss: 0.0400\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 3: val_loss improved from 0.03998 to 0.01900, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0286 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.01900 to 0.01037, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01037 to 0.00607, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00607 to 0.00378, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00378 to 0.00272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00272 to 0.00233, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00233 to 0.00208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00208 to 0.00188, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_750 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_375 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_751 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_376 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_752 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_377 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_753 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_250 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_754 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_251 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_755 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2575\n",
      "Epoch 1: val_loss improved from inf to 0.11342, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2575 - val_loss: 0.1134\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0783\n",
      "Epoch 2: val_loss improved from 0.11342 to 0.05280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0783 - val_loss: 0.0528\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 3: val_loss improved from 0.05280 to 0.02786, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0386 - val_loss: 0.0279\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0217\n",
      "Epoch 4: val_loss improved from 0.02786 to 0.01557, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0217 - val_loss: 0.0156\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01557 to 0.00841, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00841 to 0.00503, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00503 to 0.00371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00371 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00311 to 0.00272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00272 to 0.00240, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_756 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_378 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_757 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_379 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_758 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_380 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_759 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_252 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_760 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_253 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_761 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2671\n",
      "Epoch 1: val_loss improved from inf to 0.14591, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2671 - val_loss: 0.1459\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0709\n",
      "Epoch 2: val_loss improved from 0.14591 to 0.04186, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0709 - val_loss: 0.0419\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0279\n",
      "Epoch 3: val_loss improved from 0.04186 to 0.01898, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0279 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.01898 to 0.01174, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01174 to 0.00772, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0098 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00772 to 0.00564, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00564 to 0.00440, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00440 to 0.00358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00358 to 0.00301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00301 to 0.00260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_762 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_381 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_763 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_382 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_764 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_383 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_765 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_254 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_766 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_255 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_767 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2664\n",
      "Epoch 1: val_loss improved from inf to 0.15669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.2664 - val_loss: 0.1567\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0899\n",
      "Epoch 2: val_loss improved from 0.15669 to 0.06406, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0899 - val_loss: 0.0641\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0448\n",
      "Epoch 3: val_loss improved from 0.06406 to 0.03402, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0448 - val_loss: 0.0340\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 4: val_loss improved from 0.03402 to 0.01870, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0241 - val_loss: 0.0187\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01870 to 0.01122, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0132 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01122 to 0.00758, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00758 to 0.00561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00561 to 0.00444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00444 to 0.00374, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00374 to 0.00338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_768 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_384 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_769 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_385 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_770 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_386 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_771 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_256 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_772 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_257 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_773 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2819\n",
      "Epoch 1: val_loss improved from inf to 0.20521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2819 - val_loss: 0.2052\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0925\n",
      "Epoch 2: val_loss improved from 0.20521 to 0.06033, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0925 - val_loss: 0.0603\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0393\n",
      "Epoch 3: val_loss improved from 0.06033 to 0.02906, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0393 - val_loss: 0.0291\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 4: val_loss improved from 0.02906 to 0.01735, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0195 - val_loss: 0.0174\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01735 to 0.01032, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.01032 to 0.00750, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00750 to 0.00603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00603 to 0.00525, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00525 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 372ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00478 to 0.00441, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0030 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_774 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_387 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_775 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_388 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_776 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_389 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_777 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_258 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_778 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_259 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_779 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2637\n",
      "Epoch 1: val_loss improved from inf to 0.14215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2637 - val_loss: 0.1421\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0641\n",
      "Epoch 2: val_loss improved from 0.14215 to 0.04938, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0641 - val_loss: 0.0494\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0321\n",
      "Epoch 3: val_loss improved from 0.04938 to 0.02690, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0321 - val_loss: 0.0269\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02690 to 0.01894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01894 to 0.01448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 6: val_loss improved from 0.01448 to 0.01113, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.01113 to 0.00866, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00866 to 0.00698, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0048 - val_loss: 0.0070\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00698 to 0.00598, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00598 to 0.00536, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 371ms/step - loss: 0.0032 - val_loss: 0.0054\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_780 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_390 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_781 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_391 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_782 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_392 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_783 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_260 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_784 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_261 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_785 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2964\n",
      "Epoch 1: val_loss improved from inf to 0.24086, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2964 - val_loss: 0.2409\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0977\n",
      "Epoch 2: val_loss improved from 0.24086 to 0.05814, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0977 - val_loss: 0.0581\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0394\n",
      "Epoch 3: val_loss improved from 0.05814 to 0.03094, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0394 - val_loss: 0.0309\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 4: val_loss improved from 0.03094 to 0.01543, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0189 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01543 to 0.00894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0090 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00894 to 0.00648, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00648 to 0.00546, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00546 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00478 to 0.00431, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00431 to 0.00396, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_786 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_393 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_787 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_394 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_788 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_395 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_789 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_262 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_790 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_263 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_791 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1478\n",
      "Epoch 1: val_loss improved from inf to 0.05964, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 387ms/step - loss: 0.1478 - val_loss: 0.0596\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0433\n",
      "Epoch 2: val_loss improved from 0.05964 to 0.03204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0433 - val_loss: 0.0320\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 3: val_loss improved from 0.03204 to 0.02062, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0239 - val_loss: 0.0206\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.02062 to 0.01369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0157 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01369 to 0.00922, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00922 to 0.00633, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00633 to 0.00496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00496 to 0.00413, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00413 to 0.00350, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00350 to 0.00301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_792 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_396 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_793 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_397 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_794 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_398 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_795 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_264 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_796 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_265 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_797 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2510\n",
      "Epoch 1: val_loss improved from inf to 0.11895, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 385ms/step - loss: 0.2510 - val_loss: 0.1190\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0470\n",
      "Epoch 2: val_loss improved from 0.11895 to 0.02409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0470 - val_loss: 0.0241\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 3: val_loss improved from 0.02409 to 0.01166, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 4: val_loss improved from 0.01166 to 0.00785, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 5: val_loss improved from 0.00785 to 0.00580, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00580 to 0.00456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00456 to 0.00371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00371 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00314 to 0.00278, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00278 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_798 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_399 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_799 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_400 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_800 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_401 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_801 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_266 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_802 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_267 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_803 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2634\n",
      "Epoch 1: val_loss improved from inf to 0.13148, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2634 - val_loss: 0.1315\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0767\n",
      "Epoch 2: val_loss improved from 0.13148 to 0.05075, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0767 - val_loss: 0.0507\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0367\n",
      "Epoch 3: val_loss improved from 0.05075 to 0.02176, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0367 - val_loss: 0.0218\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 4: val_loss improved from 0.02176 to 0.01029, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0164 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01029 to 0.00533, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00533 to 0.00361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00361 to 0.00300, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00300 to 0.00265, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00265 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00238 to 0.00216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_804 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_402 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_805 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_403 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_806 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_404 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_807 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_268 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_808 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_269 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_809 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2346\n",
      "Epoch 1: val_loss improved from inf to 0.10696, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 385ms/step - loss: 0.2346 - val_loss: 0.1070\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0614\n",
      "Epoch 2: val_loss improved from 0.10696 to 0.03402, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0614 - val_loss: 0.0340\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 3: val_loss improved from 0.03402 to 0.01462, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0241 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 4: val_loss improved from 0.01462 to 0.00772, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0126 - val_loss: 0.0077\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.00772 to 0.00450, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00450 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00311 to 0.00246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00246 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00211 to 0.00190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00190 to 0.00173, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_810 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_405 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_811 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_406 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_812 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_407 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_813 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_270 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_814 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_271 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_815 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2496\n",
      "Epoch 1: val_loss improved from inf to 0.11583, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.2496 - val_loss: 0.1158\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0564\n",
      "Epoch 2: val_loss improved from 0.11583 to 0.02442, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0564 - val_loss: 0.0244\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0190\n",
      "Epoch 3: val_loss improved from 0.02442 to 0.01123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0190 - val_loss: 0.0112\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 4: val_loss improved from 0.01123 to 0.00636, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 5: val_loss improved from 0.00636 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00433 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00310 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00243 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00209 to 0.00186, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 373ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00186 to 0.00168, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_816 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_408 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_817 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_409 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_818 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_410 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_819 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_272 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_820 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_273 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_821 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2121\n",
      "Epoch 1: val_loss improved from inf to 0.07918, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 384ms/step - loss: 0.2121 - val_loss: 0.0792\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0502\n",
      "Epoch 2: val_loss improved from 0.07918 to 0.03216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0502 - val_loss: 0.0322\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0250\n",
      "Epoch 3: val_loss improved from 0.03216 to 0.01616, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0250 - val_loss: 0.0162\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.01616 to 0.00964, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0144 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.00964 to 0.00640, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00640 to 0.00453, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00453 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00324 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00259 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00218 to 0.00188, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_822 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_411 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_823 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_412 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_824 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_413 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_825 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_274 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_826 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_275 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_827 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1887\n",
      "Epoch 1: val_loss improved from inf to 0.06924, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 386ms/step - loss: 0.1887 - val_loss: 0.0692\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0534\n",
      "Epoch 2: val_loss improved from 0.06924 to 0.03939, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0534 - val_loss: 0.0394\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 3: val_loss improved from 0.03939 to 0.01881, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0288 - val_loss: 0.0188\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.01881 to 0.01035, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 374ms/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.01035 to 0.00613, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00613 to 0.00408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00408 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00298 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00242 to 0.00212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00212 to 0.00191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_828 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_414 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_829 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_415 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_830 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_416 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_831 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_276 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_832 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_277 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_833 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2097\n",
      "Epoch 1: val_loss improved from inf to 0.07337, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 388ms/step - loss: 0.2097 - val_loss: 0.0734\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0444\n",
      "Epoch 2: val_loss improved from 0.07337 to 0.02835, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0444 - val_loss: 0.0283\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 3: val_loss improved from 0.02835 to 0.01513, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0208 - val_loss: 0.0151\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 4: val_loss improved from 0.01513 to 0.00875, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 375ms/step - loss: 0.0119 - val_loss: 0.0087\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.00875 to 0.00601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00601 to 0.00467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00467 to 0.00375, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00375 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 377ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00324 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00288 to 0.00260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 376ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_834 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_417 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_835 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_418 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_836 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_419 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_837 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_278 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_838 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_279 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_839 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2308\n",
      "Epoch 1: val_loss improved from inf to 0.11123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 387ms/step - loss: 0.2308 - val_loss: 0.1112\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0755\n",
      "Epoch 2: val_loss improved from 0.11123 to 0.06124, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0755 - val_loss: 0.0612\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 3: val_loss improved from 0.06124 to 0.02942, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0419 - val_loss: 0.0294\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02942 to 0.01469, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 379ms/step - loss: 0.0191 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01469 to 0.00909, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00909 to 0.00679, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00679 to 0.00557, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00557 to 0.00472, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00472 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00407 to 0.00362, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_840 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_420 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_841 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_421 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_842 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_422 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_843 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_280 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_844 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_281 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_845 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2849\n",
      "Epoch 1: val_loss improved from inf to 0.19248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.2849 - val_loss: 0.1925\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0889\n",
      "Epoch 2: val_loss improved from 0.19248 to 0.06499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0889 - val_loss: 0.0650\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0430\n",
      "Epoch 3: val_loss improved from 0.06499 to 0.03353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0430 - val_loss: 0.0335\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 4: val_loss improved from 0.03353 to 0.02100, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0220 - val_loss: 0.0210\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 5: val_loss improved from 0.02100 to 0.01411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0137 - val_loss: 0.0141\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01411 to 0.01006, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.01006 to 0.00815, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00815 to 0.00717, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0051 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00717 to 0.00653, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00653 to 0.00604, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_846 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_423 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_847 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_424 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_848 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_425 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_849 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_282 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_850 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_283 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_851 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2792\n",
      "Epoch 1: val_loss improved from inf to 0.20297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 387ms/step - loss: 0.2792 - val_loss: 0.2030\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0729\n",
      "Epoch 2: val_loss improved from 0.20297 to 0.04837, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0729 - val_loss: 0.0484\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 3: val_loss improved from 0.04837 to 0.02604, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0284 - val_loss: 0.0260\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.02604 to 0.01614, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.01614 to 0.01189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 380ms/step - loss: 0.0086 - val_loss: 0.0119\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.01189 to 0.00970, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0060 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00970 to 0.00808, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0045 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00808 to 0.00715, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0037 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00715 to 0.00651, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00651 to 0.00590, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0030 - val_loss: 0.0059\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_852 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_426 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_853 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_427 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_854 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_428 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_855 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_284 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_856 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_285 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_857 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2025\n",
      "Epoch 1: val_loss improved from inf to 0.09612, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.2025 - val_loss: 0.0961\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0618\n",
      "Epoch 2: val_loss improved from 0.09612 to 0.05089, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0618 - val_loss: 0.0509\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0349\n",
      "Epoch 3: val_loss improved from 0.05089 to 0.03101, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0349 - val_loss: 0.0310\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 4: val_loss improved from 0.03101 to 0.01807, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0199 - val_loss: 0.0181\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01807 to 0.01057, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.01057 to 0.00754, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00754 to 0.00636, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00636 to 0.00560, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00560 to 0.00504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00504 to 0.00459, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_858 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_429 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_859 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_430 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_860 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_431 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_861 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_286 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_862 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_287 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_863 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2187\n",
      "Epoch 1: val_loss improved from inf to 0.10428, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 452ms/step - loss: 0.2187 - val_loss: 0.1043\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0705\n",
      "Epoch 2: val_loss improved from 0.10428 to 0.05544, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0705 - val_loss: 0.0554\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0364\n",
      "Epoch 3: val_loss improved from 0.05544 to 0.02681, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0364 - val_loss: 0.0268\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02681 to 0.01412, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0176 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01412 to 0.00806, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00806 to 0.00551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00551 to 0.00430, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00430 to 0.00369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00369 to 0.00327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00327 to 0.00294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 478ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_864 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_432 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_865 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_433 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_866 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_434 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_867 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_288 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_868 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_289 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_869 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2729\n",
      "Epoch 1: val_loss improved from inf to 0.17496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.2729 - val_loss: 0.1750\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0888\n",
      "Epoch 2: val_loss improved from 0.17496 to 0.05643, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 530ms/step - loss: 0.0888 - val_loss: 0.0564\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0371   \n",
      "Epoch 3: val_loss improved from 0.05643 to 0.02533, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28828s 655s/step - loss: 0.0371 - val_loss: 0.0253\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02533 to 0.01460, saving model to best_weights.h5\n",
      "45/45 [==============================] - 30s 659ms/step - loss: 0.0194 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01460 to 0.00869, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0115 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00869 to 0.00521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00521 to 0.00361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00361 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00295 to 0.00265, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00265 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0029 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_870 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_435 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_871 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_436 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_872 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_437 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_873 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_290 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_874 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_291 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_875 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2276\n",
      "Epoch 1: val_loss improved from inf to 0.08321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.2276 - val_loss: 0.0832\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 2: val_loss improved from 0.08321 to 0.02502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0403 - val_loss: 0.0250\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 3: val_loss improved from 0.02502 to 0.01323, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0196 - val_loss: 0.0132\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 4: val_loss improved from 0.01323 to 0.00747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00747 to 0.00495, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00495 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00354 to 0.00284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00284 to 0.00246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00246 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00218 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_876 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_438 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_877 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_439 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_878 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_440 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_879 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_292 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_880 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_293 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_881 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2370\n",
      "Epoch 1: val_loss improved from inf to 0.09539, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.2370 - val_loss: 0.0954\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0665\n",
      "Epoch 2: val_loss improved from 0.09539 to 0.04389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0665 - val_loss: 0.0439\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0327\n",
      "Epoch 3: val_loss improved from 0.04389 to 0.02082, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0327 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 4: val_loss improved from 0.02082 to 0.01190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0178 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01190 to 0.00626, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00626 to 0.00380, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 501ms/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00380 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00264 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00215 to 0.00192, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00192 to 0.00175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_882 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_441 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_883 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_442 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_884 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_443 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_885 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_294 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_886 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_295 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_887 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2584\n",
      "Epoch 1: val_loss improved from inf to 0.11071, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.2584 - val_loss: 0.1107\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0720\n",
      "Epoch 2: val_loss improved from 0.11071 to 0.04416, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0720 - val_loss: 0.0442\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0307\n",
      "Epoch 3: val_loss improved from 0.04416 to 0.01842, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0307 - val_loss: 0.0184\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.01842 to 0.00853, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0149 - val_loss: 0.0085\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.00853 to 0.00525, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00525 to 0.00388, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00388 to 0.00294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00294 to 0.00241, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00241 to 0.00208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00208 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 477ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_888 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_444 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_889 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_445 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_890 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_446 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_891 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_296 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_892 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_297 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_893 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1151\n",
      "Epoch 1: val_loss improved from inf to 0.05294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 516ms/step - loss: 0.1151 - val_loss: 0.0529\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0392\n",
      "Epoch 2: val_loss improved from 0.05294 to 0.02513, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0392 - val_loss: 0.0251\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0213\n",
      "Epoch 3: val_loss improved from 0.02513 to 0.01592, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0213 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.01592 to 0.01060, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01060 to 0.00690, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0099 - val_loss: 0.0069\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00690 to 0.00458, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00458 to 0.00328, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00328 to 0.00258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00258 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00222 to 0.00200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 501ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_894 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_447 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_895 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_448 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_896 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_449 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_897 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_298 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_898 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_299 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_899 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1969\n",
      "Epoch 1: val_loss improved from inf to 0.08122, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.1969 - val_loss: 0.0812\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0602\n",
      "Epoch 2: val_loss improved from 0.08122 to 0.04261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0602 - val_loss: 0.0426\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0306\n",
      "Epoch 3: val_loss improved from 0.04261 to 0.02078, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0306 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02078 to 0.01236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01236 to 0.00789, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00789 to 0.00500, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0076 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00500 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00347 to 0.00276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00276 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00239 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_900 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_450 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_901 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_451 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_902 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_452 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_903 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_300 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_904 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_301 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_905 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2621\n",
      "Epoch 1: val_loss improved from inf to 0.14336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.2621 - val_loss: 0.1434\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0718\n",
      "Epoch 2: val_loss improved from 0.14336 to 0.03971, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0718 - val_loss: 0.0397\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0242\n",
      "Epoch 3: val_loss improved from 0.03971 to 0.01456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0242 - val_loss: 0.0146\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 4: val_loss improved from 0.01456 to 0.00842, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.00842 to 0.00596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00596 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00474 to 0.00393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00393 to 0.00336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00336 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00295 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_906 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_453 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_907 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_454 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_908 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_455 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_909 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_302 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_910 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_303 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_911 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3120\n",
      "Epoch 1: val_loss improved from inf to 0.22592, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.3120 - val_loss: 0.2259\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1038\n",
      "Epoch 2: val_loss improved from 0.22592 to 0.04489, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.1038 - val_loss: 0.0449\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0314\n",
      "Epoch 3: val_loss improved from 0.04489 to 0.02338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0314 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.02338 to 0.01335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0163 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01335 to 0.00901, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00901 to 0.00678, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00678 to 0.00537, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00537 to 0.00452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00452 to 0.00395, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00395 to 0.00350, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_912 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_456 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_913 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_457 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_914 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_458 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_915 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_304 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_916 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_305 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_917 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2922\n",
      "Epoch 1: val_loss improved from inf to 0.24397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.2922 - val_loss: 0.2440\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0937\n",
      "Epoch 2: val_loss improved from 0.24397 to 0.04223, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0937 - val_loss: 0.0422\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 3: val_loss improved from 0.04223 to 0.02113, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0257 - val_loss: 0.0211\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 4: val_loss improved from 0.02113 to 0.01443, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0140 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01443 to 0.01030, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.01030 to 0.00803, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00803 to 0.00676, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00676 to 0.00597, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00597 to 0.00539, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00539 to 0.00497, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_918 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_459 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_919 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_460 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_920 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_461 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_921 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_306 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_922 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_307 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_923 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2892\n",
      "Epoch 1: val_loss improved from inf to 0.24145, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.2892 - val_loss: 0.2415\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1008\n",
      "Epoch 2: val_loss improved from 0.24145 to 0.05775, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.1008 - val_loss: 0.0577\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0357\n",
      "Epoch 3: val_loss improved from 0.05775 to 0.02871, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0357 - val_loss: 0.0287\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02871 to 0.01796, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0177 - val_loss: 0.0180\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01796 to 0.01336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0110 - val_loss: 0.0134\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.01336 to 0.01107, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0082 - val_loss: 0.0111\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.01107 to 0.00911, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00911 to 0.00747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0050 - val_loss: 0.0075\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00747 to 0.00650, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00650 to 0.00582, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0034 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_924 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_462 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_925 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_463 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_926 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_464 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_927 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_308 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_928 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_309 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_929 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2904\n",
      "Epoch 1: val_loss improved from inf to 0.22747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.2904 - val_loss: 0.2275\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0801\n",
      "Epoch 2: val_loss improved from 0.22747 to 0.04787, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0801 - val_loss: 0.0479\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.04787 to 0.02293, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0291 - val_loss: 0.0229\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.02293 to 0.01504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01504 to 0.01022, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.01022 to 0.00814, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0060 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00814 to 0.00688, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00688 to 0.00588, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00588 to 0.00532, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00532 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_930 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_465 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_931 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_466 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_932 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_467 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_933 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_310 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_934 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_311 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_935 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3246\n",
      "Epoch 1: val_loss improved from inf to 0.29782, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.3246 - val_loss: 0.2978\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1448\n",
      "Epoch 2: val_loss improved from 0.29782 to 0.07298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.1448 - val_loss: 0.0730\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0481\n",
      "Epoch 3: val_loss improved from 0.07298 to 0.03036, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0481 - val_loss: 0.0304\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0190\n",
      "Epoch 4: val_loss improved from 0.03036 to 0.01376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0190 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01376 to 0.00908, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00908 to 0.00679, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00679 to 0.00552, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00552 to 0.00477, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00477 to 0.00424, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00424 to 0.00384, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_936 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_468 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_937 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_469 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_938 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_470 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_939 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_312 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_940 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_313 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_941 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3158\n",
      "Epoch 1: val_loss improved from inf to 0.27147, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.3158 - val_loss: 0.2715\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1460\n",
      "Epoch 2: val_loss improved from 0.27147 to 0.05618, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.1460 - val_loss: 0.0562\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0400\n",
      "Epoch 3: val_loss improved from 0.05618 to 0.02412, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0400 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.02412 to 0.01076, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01076 to 0.00654, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0090 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00654 to 0.00471, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00471 to 0.00380, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00380 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00324 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00288 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_942 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_471 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_943 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_472 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_944 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_473 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_945 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_314 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_946 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_315 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_947 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2457\n",
      "Epoch 1: val_loss improved from inf to 0.09640, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.2457 - val_loss: 0.0964\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0400\n",
      "Epoch 2: val_loss improved from 0.09640 to 0.02011, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0400 - val_loss: 0.0201\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 3: val_loss improved from 0.02011 to 0.00980, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0154 - val_loss: 0.0098\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 4: val_loss improved from 0.00980 to 0.00591, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 5: val_loss improved from 0.00591 to 0.00403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 6: val_loss improved from 0.00403 to 0.00301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 7: val_loss improved from 0.00301 to 0.00246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 8: val_loss improved from 0.00246 to 0.00212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 9: val_loss improved from 0.00212 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 10: val_loss improved from 0.00187 to 0.00166, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_948 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_474 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_949 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_475 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_950 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_476 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_951 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_316 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_952 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_317 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_953 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2953\n",
      "Epoch 1: val_loss improved from inf to 0.16747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.2953 - val_loss: 0.1675\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0854\n",
      "Epoch 2: val_loss improved from 0.16747 to 0.03920, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0854 - val_loss: 0.0392\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 3: val_loss improved from 0.03920 to 0.01768, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0292 - val_loss: 0.0177\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.01768 to 0.01031, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 457ms/step - loss: 0.0163 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01031 to 0.00632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00632 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00433 to 0.00329, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00329 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00268 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00230 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_954 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_477 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_955 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_478 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_956 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_479 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_957 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_318 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_958 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_319 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_959 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2318\n",
      "Epoch 1: val_loss improved from inf to 0.10723, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.2318 - val_loss: 0.1072\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0791\n",
      "Epoch 2: val_loss improved from 0.10723 to 0.05317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0791 - val_loss: 0.0532\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0373\n",
      "Epoch 3: val_loss improved from 0.05317 to 0.01821, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0373 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.01821 to 0.00795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0145 - val_loss: 0.0079\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.00795 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00474 to 0.00327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00327 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00247 to 0.00200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00200 to 0.00177, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00177 to 0.00158, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_960 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_480 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_961 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_481 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_962 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_482 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_963 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_320 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_964 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_321 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_965 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2959\n",
      "Epoch 1: val_loss improved from inf to 0.17339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 453ms/step - loss: 0.2959 - val_loss: 0.1734\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0872\n",
      "Epoch 2: val_loss improved from 0.17339 to 0.03603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0872 - val_loss: 0.0360\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 3: val_loss improved from 0.03603 to 0.01616, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0276 - val_loss: 0.0162\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 4: val_loss improved from 0.01616 to 0.00741, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0135 - val_loss: 0.0074\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.00741 to 0.00465, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.00465 to 0.00340, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00340 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00262 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00220 to 0.00198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00198 to 0.00179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_966 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_483 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_967 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_484 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_968 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_485 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_969 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_322 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_970 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_323 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_971 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2045\n",
      "Epoch 1: val_loss improved from inf to 0.06864, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 447ms/step - loss: 0.2045 - val_loss: 0.0686\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0473\n",
      "Epoch 2: val_loss improved from 0.06864 to 0.02952, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0473 - val_loss: 0.0295\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 3: val_loss improved from 0.02952 to 0.01544, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0228 - val_loss: 0.0154\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 4: val_loss improved from 0.01544 to 0.00969, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.00969 to 0.00657, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0093 - val_loss: 0.0066\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00657 to 0.00457, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00457 to 0.00336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00336 to 0.00263, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00263 to 0.00217, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00217 to 0.00189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_972 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_486 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_973 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_487 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_974 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_488 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_975 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_324 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_976 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_325 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_977 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2421\n",
      "Epoch 1: val_loss improved from inf to 0.12656, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 428ms/step - loss: 0.2421 - val_loss: 0.1266\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0787\n",
      "Epoch 2: val_loss improved from 0.12656 to 0.05615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0787 - val_loss: 0.0561\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0408\n",
      "Epoch 3: val_loss improved from 0.05615 to 0.02892, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0408 - val_loss: 0.0289\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 4: val_loss improved from 0.02892 to 0.01675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0226 - val_loss: 0.0168\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01675 to 0.00966, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00966 to 0.00587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00587 to 0.00411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00411 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00324 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00281 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0032 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_978 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_489 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_979 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_490 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_980 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_491 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_981 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_326 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_982 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_327 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_983 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3112\n",
      "Epoch 1: val_loss improved from inf to 0.21124, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.3112 - val_loss: 0.2112\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0989\n",
      "Epoch 2: val_loss improved from 0.21124 to 0.05557, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0989 - val_loss: 0.0556\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0384\n",
      "Epoch 3: val_loss improved from 0.05557 to 0.02644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0384 - val_loss: 0.0264\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02644 to 0.01499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0191 - val_loss: 0.0150\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01499 to 0.00891, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00891 to 0.00630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00630 to 0.00467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00467 to 0.00366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00366 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00311 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_984 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_492 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_985 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_493 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_986 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_494 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_987 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_328 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_988 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_329 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_989 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2927\n",
      "Epoch 1: val_loss improved from inf to 0.22140, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.2927 - val_loss: 0.2214\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0879\n",
      "Epoch 2: val_loss improved from 0.22140 to 0.05013, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0879 - val_loss: 0.0501\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0347\n",
      "Epoch 3: val_loss improved from 0.05013 to 0.02723, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0347 - val_loss: 0.0272\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 4: val_loss improved from 0.02723 to 0.01639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0180 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01639 to 0.01041, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.01041 to 0.00722, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0064 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00722 to 0.00573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00573 to 0.00490, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00490 to 0.00444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00444 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_990 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_495 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_991 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_496 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_992 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_497 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_993 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_330 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_994 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_331 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_995 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2889\n",
      "Epoch 1: val_loss improved from inf to 0.22470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.2889 - val_loss: 0.2247\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1086\n",
      "Epoch 2: val_loss improved from 0.22470 to 0.08421, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.1086 - val_loss: 0.0842\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0580\n",
      "Epoch 3: val_loss improved from 0.08421 to 0.04814, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0580 - val_loss: 0.0481\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0309\n",
      "Epoch 4: val_loss improved from 0.04814 to 0.02696, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0309 - val_loss: 0.0270\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 5: val_loss improved from 0.02696 to 0.01295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.01295 to 0.00863, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0064 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00863 to 0.00707, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00707 to 0.00612, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00612 to 0.00549, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00549 to 0.00496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "finished training\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_996 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_498 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_997 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_499 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_998 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_500 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_999 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_332 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1000 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_333 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1001 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2971\n",
      "Epoch 1: val_loss improved from inf to 0.25658, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.2971 - val_loss: 0.2566\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0976\n",
      "Epoch 2: val_loss improved from 0.25658 to 0.05001, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0976 - val_loss: 0.0500\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0320\n",
      "Epoch 3: val_loss improved from 0.05001 to 0.02603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0320 - val_loss: 0.0260\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 4: val_loss improved from 0.02603 to 0.01627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0167 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01627 to 0.01107, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.01107 to 0.00850, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00850 to 0.00719, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0052 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00719 to 0.00626, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00626 to 0.00558, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00558 to 0.00506, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1002 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_501 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1003 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_502 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1004 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_503 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1005 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_334 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1006 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_335 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1007 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2666\n",
      "Epoch 1: val_loss improved from inf to 0.16736, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.2666 - val_loss: 0.1674\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0772\n",
      "Epoch 2: val_loss improved from 0.16736 to 0.04909, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0772 - val_loss: 0.0491\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 3: val_loss improved from 0.04909 to 0.02245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0324 - val_loss: 0.0224\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02245 to 0.01356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0161 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01356 to 0.00900, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00900 to 0.00622, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00622 to 0.00483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00483 to 0.00419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00419 to 0.00382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00382 to 0.00352, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1008 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_504 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1009 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_505 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1010 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_506 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1011 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_336 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1012 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_337 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1013 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3207\n",
      "Epoch 1: val_loss improved from inf to 0.24324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.3207 - val_loss: 0.2432\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1153\n",
      "Epoch 2: val_loss improved from 0.24324 to 0.05443, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.1153 - val_loss: 0.0544\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0390\n",
      "Epoch 3: val_loss improved from 0.05443 to 0.02644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0390 - val_loss: 0.0264\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0206\n",
      "Epoch 4: val_loss improved from 0.02644 to 0.01551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0206 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 5: val_loss improved from 0.01551 to 0.01012, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 6: val_loss improved from 0.01012 to 0.00673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00673 to 0.00503, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00503 to 0.00403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00403 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00344 to 0.00304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1014 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_507 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1015 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_508 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1016 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_509 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1017 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_338 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1018 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_339 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1019 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2726\n",
      "Epoch 1: val_loss improved from inf to 0.11678, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 428ms/step - loss: 0.2726 - val_loss: 0.1168\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0616\n",
      "Epoch 2: val_loss improved from 0.11678 to 0.03751, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0616 - val_loss: 0.0375\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0278\n",
      "Epoch 3: val_loss improved from 0.03751 to 0.01788, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0278 - val_loss: 0.0179\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.01788 to 0.01052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01052 to 0.00649, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0098 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00649 to 0.00443, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00443 to 0.00336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00336 to 0.00279, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00279 to 0.00245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00245 to 0.00219, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1020 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_510 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1021 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_511 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1022 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_512 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1023 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_340 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1024 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_341 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1025 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3281\n",
      "Epoch 1: val_loss improved from inf to 0.22004, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.3281 - val_loss: 0.2200\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1487\n",
      "Epoch 2: val_loss improved from 0.22004 to 0.06964, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.1487 - val_loss: 0.0696\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0589\n",
      "Epoch 3: val_loss improved from 0.06964 to 0.04008, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0589 - val_loss: 0.0401\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0313\n",
      "Epoch 4: val_loss improved from 0.04008 to 0.01967, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0313 - val_loss: 0.0197\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 5: val_loss improved from 0.01967 to 0.01086, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0172 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 6: val_loss improved from 0.01086 to 0.00688, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 7: val_loss improved from 0.00688 to 0.00481, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00481 to 0.00358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00358 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00282 to 0.00235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1026 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_513 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1027 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_514 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1028 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_515 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1029 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_342 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1030 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_343 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1031 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2505\n",
      "Epoch 1: val_loss improved from inf to 0.10046, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.2505 - val_loss: 0.1005\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0621\n",
      "Epoch 2: val_loss improved from 0.10046 to 0.03436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0621 - val_loss: 0.0344\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0264\n",
      "Epoch 3: val_loss improved from 0.03436 to 0.01559, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0264 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 4: val_loss improved from 0.01559 to 0.00723, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0134 - val_loss: 0.0072\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.00723 to 0.00465, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00465 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00364 to 0.00290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00290 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00237 to 0.00204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00204 to 0.00184, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1032 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_516 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1033 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_517 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1034 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_518 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1035 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_344 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1036 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_345 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1037 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2983\n",
      "Epoch 1: val_loss improved from inf to 0.17948, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.2983 - val_loss: 0.1795\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1056\n",
      "Epoch 2: val_loss improved from 0.17948 to 0.04679, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.1056 - val_loss: 0.0468\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 3: val_loss improved from 0.04679 to 0.01675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0316 - val_loss: 0.0168\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.01675 to 0.00778, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0138 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00778 to 0.00414, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 6: val_loss improved from 0.00414 to 0.00279, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 7: val_loss improved from 0.00279 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 8: val_loss improved from 0.00222 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00197 to 0.00178, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00178 to 0.00162, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1038 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_519 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1039 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_520 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1040 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_521 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1041 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_346 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1042 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_347 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1043 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3152\n",
      "Epoch 1: val_loss improved from inf to 0.21931, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.3152 - val_loss: 0.2193\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1366\n",
      "Epoch 2: val_loss improved from 0.21931 to 0.06949, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.1366 - val_loss: 0.0695\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0456\n",
      "Epoch 3: val_loss improved from 0.06949 to 0.02576, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0456 - val_loss: 0.0258\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 4: val_loss improved from 0.02576 to 0.01028, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0183 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01028 to 0.00484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00484 to 0.00351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00351 to 0.00283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00283 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00242 to 0.00212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00212 to 0.00188, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1044 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_522 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1045 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_523 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1046 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_524 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1047 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_348 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1048 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_349 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1049 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1922\n",
      "Epoch 1: val_loss improved from inf to 0.05704, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.1922 - val_loss: 0.0570\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0428\n",
      "Epoch 2: val_loss improved from 0.05704 to 0.03301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0428 - val_loss: 0.0330\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 3: val_loss improved from 0.03301 to 0.02205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0260 - val_loss: 0.0220\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02205 to 0.01406, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0176 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01406 to 0.00758, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00758 to 0.00479, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00479 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00347 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00288 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00250 to 0.00216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1050 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_525 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1051 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_526 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1052 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_527 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1053 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_350 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1054 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_351 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1055 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1823\n",
      "Epoch 1: val_loss improved from inf to 0.06000, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.1823 - val_loss: 0.0600\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0451\n",
      "Epoch 2: val_loss improved from 0.06000 to 0.03534, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0451 - val_loss: 0.0353\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0230\n",
      "Epoch 3: val_loss improved from 0.03534 to 0.01846, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0230 - val_loss: 0.0185\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0128\n",
      "Epoch 4: val_loss improved from 0.01846 to 0.01159, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0128 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 5: val_loss improved from 0.01159 to 0.00774, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00774 to 0.00548, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00548 to 0.00451, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00451 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00397 to 0.00358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00358 to 0.00326, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1056 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_528 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1057 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_529 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1058 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_530 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1059 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_352 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1060 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_353 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1061 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2844\n",
      "Epoch 1: val_loss improved from inf to 0.22207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 449ms/step - loss: 0.2844 - val_loss: 0.2221\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0886\n",
      "Epoch 2: val_loss improved from 0.22207 to 0.04859, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0886 - val_loss: 0.0486\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 3: val_loss improved from 0.04859 to 0.01927, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0228 - val_loss: 0.0193\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 4: val_loss improved from 0.01927 to 0.01344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.01344 to 0.00984, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00984 to 0.00759, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00759 to 0.00602, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 8: val_loss improved from 0.00602 to 0.00513, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 9: val_loss improved from 0.00513 to 0.00464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00464 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0026 - val_loss: 0.0043\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1062 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_531 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1063 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_532 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1064 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_533 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1065 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_354 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1066 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_355 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1067 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2539\n",
      "Epoch 1: val_loss improved from inf to 0.18454, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.2539 - val_loss: 0.1845\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0661\n",
      "Epoch 2: val_loss improved from 0.18454 to 0.04267, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0661 - val_loss: 0.0427\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0258\n",
      "Epoch 3: val_loss improved from 0.04267 to 0.02499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0258 - val_loss: 0.0250\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.02499 to 0.01617, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0138 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.01617 to 0.01157, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.01157 to 0.00930, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00930 to 0.00780, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0045 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00780 to 0.00679, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0037 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00679 to 0.00612, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00612 to 0.00557, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0029 - val_loss: 0.0056\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1068 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_534 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1069 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_535 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1070 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_536 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1071 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_356 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1072 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_357 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1073 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2729\n",
      "Epoch 1: val_loss improved from inf to 0.17593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.2729 - val_loss: 0.1759\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0635\n",
      "Epoch 2: val_loss improved from 0.17593 to 0.04112, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0635 - val_loss: 0.0411\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0217\n",
      "Epoch 3: val_loss improved from 0.04112 to 0.01821, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0217 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 4: val_loss improved from 0.01821 to 0.01195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 5: val_loss improved from 0.01195 to 0.00924, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0065 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00924 to 0.00774, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0050 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00774 to 0.00673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00673 to 0.00609, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00609 to 0.00556, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00556 to 0.00514, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1074 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_537 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1075 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_538 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1076 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_539 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1077 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_358 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1078 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_359 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1079 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2024\n",
      "Epoch 1: val_loss improved from inf to 0.10433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.2024 - val_loss: 0.1043\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0672\n",
      "Epoch 2: val_loss improved from 0.10433 to 0.05214, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0672 - val_loss: 0.0521\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0313\n",
      "Epoch 3: val_loss improved from 0.05214 to 0.02366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0313 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.02366 to 0.01223, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0142 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.01223 to 0.00792, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00792 to 0.00596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00596 to 0.00484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00484 to 0.00418, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00418 to 0.00372, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00372 to 0.00334, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1080 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_540 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1081 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_541 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1082 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_542 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1083 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_360 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1084 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_361 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1085 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2116\n",
      "Epoch 1: val_loss improved from inf to 0.09791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.2116 - val_loss: 0.0979\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0576\n",
      "Epoch 2: val_loss improved from 0.09791 to 0.04141, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0576 - val_loss: 0.0414\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0274\n",
      "Epoch 3: val_loss improved from 0.04141 to 0.02018, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0274 - val_loss: 0.0202\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.02018 to 0.01090, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0138 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.01090 to 0.00738, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00738 to 0.00524, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00524 to 0.00391, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00391 to 0.00328, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00328 to 0.00294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00294 to 0.00270, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1086 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_543 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1087 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_544 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1088 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_545 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1089 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_362 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1090 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_363 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1091 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1923\n",
      "Epoch 1: val_loss improved from inf to 0.08251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.1923 - val_loss: 0.0825\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0583\n",
      "Epoch 2: val_loss improved from 0.08251 to 0.04448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0583 - val_loss: 0.0445\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0308\n",
      "Epoch 3: val_loss improved from 0.04448 to 0.02185, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0308 - val_loss: 0.0218\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.02185 to 0.01142, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01142 to 0.00683, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0089 - val_loss: 0.0068\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00683 to 0.00486, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00486 to 0.00380, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00380 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00312 to 0.00266, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00266 to 0.00231, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1092 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_546 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1093 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_547 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1094 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_548 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1095 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_364 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1096 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_365 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1097 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2735\n",
      "Epoch 1: val_loss improved from inf to 0.15782, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.2735 - val_loss: 0.1578\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0786\n",
      "Epoch 2: val_loss improved from 0.15782 to 0.04072, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0786 - val_loss: 0.0407\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.04072 to 0.01867, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0291 - val_loss: 0.0187\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.01867 to 0.01016, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.01016 to 0.00561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00561 to 0.00367, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00367 to 0.00289, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00289 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00243 to 0.00214, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00214 to 0.00191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1098 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_549 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1099 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_550 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1100 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_551 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1101 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_366 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1102 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_367 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1103 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2806\n",
      "Epoch 1: val_loss improved from inf to 0.14877, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.2806 - val_loss: 0.1488\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0820\n",
      "Epoch 2: val_loss improved from 0.14877 to 0.04623, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0820 - val_loss: 0.0462\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0344\n",
      "Epoch 3: val_loss improved from 0.04623 to 0.02247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0344 - val_loss: 0.0225\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02247 to 0.00960, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0161 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.00960 to 0.00617, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0090 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00617 to 0.00450, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00450 to 0.00313, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00313 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00250 to 0.00219, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00219 to 0.00195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1104 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_552 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1105 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_553 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1106 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_554 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1107 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_368 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1108 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_369 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1109 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3394\n",
      "Epoch 1: val_loss improved from inf to 0.24303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.3394 - val_loss: 0.2430\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1650\n",
      "Epoch 2: val_loss improved from 0.24303 to 0.05860, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.1650 - val_loss: 0.0586\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0439\n",
      "Epoch 3: val_loss improved from 0.05860 to 0.02696, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0439 - val_loss: 0.0270\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 4: val_loss improved from 0.02696 to 0.01303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0199 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 5: val_loss improved from 0.01303 to 0.00724, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00724 to 0.00496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00496 to 0.00361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00361 to 0.00275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00275 to 0.00226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00226 to 0.00199, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1110 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_555 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1111 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_556 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1112 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_557 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1113 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_370 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1114 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_371 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1115 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2445\n",
      "Epoch 1: val_loss improved from inf to 0.11584, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 443ms/step - loss: 0.2445 - val_loss: 0.1158\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0824\n",
      "Epoch 2: val_loss improved from 0.11584 to 0.06143, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0824 - val_loss: 0.0614\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 3: val_loss improved from 0.06143 to 0.02929, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0442 - val_loss: 0.0293\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0212\n",
      "Epoch 4: val_loss improved from 0.02929 to 0.01366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0212 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01366 to 0.00724, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0106 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00724 to 0.00432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00432 to 0.00309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00309 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00259 to 0.00228, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00228 to 0.00205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1116 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_558 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1117 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_559 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1118 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_560 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1119 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_372 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1120 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_373 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1121 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2727\n",
      "Epoch 1: val_loss improved from inf to 0.16982, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 446ms/step - loss: 0.2727 - val_loss: 0.1698\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0804\n",
      "Epoch 2: val_loss improved from 0.16982 to 0.03997, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 479ms/step - loss: 0.0804 - val_loss: 0.0400\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 3: val_loss improved from 0.03997 to 0.01866, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0273 - val_loss: 0.0187\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 4: val_loss improved from 0.01866 to 0.00993, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.00993 to 0.00603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00603 to 0.00435, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00435 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00345 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00288 to 0.00254, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00254 to 0.00228, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0026 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1122 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_561 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1123 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_562 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1124 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_563 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1125 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_374 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1126 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_375 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1127 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2736\n",
      "Epoch 1: val_loss improved from inf to 0.19569, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 406ms/step - loss: 0.2736 - val_loss: 0.1957\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0810\n",
      "Epoch 2: val_loss improved from 0.19569 to 0.03230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0810 - val_loss: 0.0323\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 3: val_loss improved from 0.03230 to 0.01627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0219 - val_loss: 0.0163\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 4: val_loss improved from 0.01627 to 0.01079, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0123 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.01079 to 0.00790, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00790 to 0.00601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00601 to 0.00487, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00487 to 0.00411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00411 to 0.00355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00355 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1128 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_564 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1129 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_565 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1130 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_566 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1131 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_376 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1132 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_377 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1133 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 1: val_loss improved from inf to 0.08144, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 403ms/step - loss: 0.1654 - val_loss: 0.0814\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0569\n",
      "Epoch 2: val_loss improved from 0.08144 to 0.04203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0569 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0250\n",
      "Epoch 3: val_loss improved from 0.04203 to 0.02023, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0250 - val_loss: 0.0202\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 4: val_loss improved from 0.02023 to 0.01275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.01275 to 0.00954, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00954 to 0.00769, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00769 to 0.00649, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00649 to 0.00563, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00563 to 0.00502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00502 to 0.00456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1134 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_567 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1135 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_568 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1136 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_569 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1137 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_378 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1138 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_379 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1139 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2875\n",
      "Epoch 1: val_loss improved from inf to 0.22979, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.2875 - val_loss: 0.2298\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0869\n",
      "Epoch 2: val_loss improved from 0.22979 to 0.05143, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 412ms/step - loss: 0.0869 - val_loss: 0.0514\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0322\n",
      "Epoch 3: val_loss improved from 0.05143 to 0.02573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0322 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.02573 to 0.01612, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01612 to 0.01220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.01220 to 0.01017, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0068 - val_loss: 0.0102\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.01017 to 0.00867, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0054 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00867 to 0.00750, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00750 to 0.00664, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00664 to 0.00606, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0033 - val_loss: 0.0061\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1140 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_570 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1141 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_571 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1142 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_572 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1143 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_380 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1144 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_381 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1145 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3132\n",
      "Epoch 1: val_loss improved from inf to 0.28452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.3132 - val_loss: 0.2845\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0934\n",
      "Epoch 2: val_loss improved from 0.28452 to 0.03419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0934 - val_loss: 0.0342\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0221\n",
      "Epoch 3: val_loss improved from 0.03419 to 0.02054, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0221 - val_loss: 0.0205\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.02054 to 0.01355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01355 to 0.00988, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00988 to 0.00768, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0059 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00768 to 0.00638, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00638 to 0.00571, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00571 to 0.00531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00531 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1146 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_573 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1147 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_574 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1148 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_575 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1149 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_382 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1150 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_383 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1151 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2837\n",
      "Epoch 1: val_loss improved from inf to 0.19770, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.2837 - val_loss: 0.1977\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0803\n",
      "Epoch 2: val_loss improved from 0.19770 to 0.04500, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0803 - val_loss: 0.0450\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0318\n",
      "Epoch 3: val_loss improved from 0.04500 to 0.02284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0318 - val_loss: 0.0228\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02284 to 0.01316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01316 to 0.00938, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00938 to 0.00709, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00709 to 0.00558, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00558 to 0.00470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00470 to 0.00414, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00414 to 0.00372, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1152 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_576 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1153 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_577 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1154 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_578 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1155 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_384 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1156 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_385 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1157 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2663\n",
      "Epoch 1: val_loss improved from inf to 0.16472, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.2663 - val_loss: 0.1647\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0865\n",
      "Epoch 2: val_loss improved from 0.16472 to 0.05358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0865 - val_loss: 0.0536\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0381\n",
      "Epoch 3: val_loss improved from 0.05358 to 0.02403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0381 - val_loss: 0.0240\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0185\n",
      "Epoch 4: val_loss improved from 0.02403 to 0.01271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0185 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01271 to 0.00798, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00798 to 0.00568, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00568 to 0.00448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00448 to 0.00379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00379 to 0.00335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00335 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1158 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_579 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1159 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_580 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1160 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_581 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1161 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_386 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1162 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_387 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1163 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1: val_loss improved from inf to 0.09735, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.2468 - val_loss: 0.0973\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0516\n",
      "Epoch 2: val_loss improved from 0.09735 to 0.02638, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0516 - val_loss: 0.0264\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 3: val_loss improved from 0.02638 to 0.01423, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0209 - val_loss: 0.0142\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.01423 to 0.00989, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.00989 to 0.00727, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0100 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00727 to 0.00550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00550 to 0.00408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00408 to 0.00322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00322 to 0.00276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00276 to 0.00244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1164 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_582 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1165 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_583 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1166 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_584 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1167 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_388 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1168 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_389 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1169 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3043\n",
      "Epoch 1: val_loss improved from inf to 0.17371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 404ms/step - loss: 0.3043 - val_loss: 0.1737\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0941\n",
      "Epoch 2: val_loss improved from 0.17371 to 0.04566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0941 - val_loss: 0.0457\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0317\n",
      "Epoch 3: val_loss improved from 0.04566 to 0.01669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0317 - val_loss: 0.0167\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.01669 to 0.01019, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01019 to 0.00645, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00645 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00410 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00312 to 0.00258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00258 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00229 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1170 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_585 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1171 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_586 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1172 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_587 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1173 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_390 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1174 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_391 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1175 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2674\n",
      "Epoch 1: val_loss improved from inf to 0.12169, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.2674 - val_loss: 0.1217\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0555\n",
      "Epoch 2: val_loss improved from 0.12169 to 0.02252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0555 - val_loss: 0.0225\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 3: val_loss improved from 0.02252 to 0.00839, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0172 - val_loss: 0.0084\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 4: val_loss improved from 0.00839 to 0.00539, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 5: val_loss improved from 0.00539 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00405 to 0.00322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00322 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00271 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00237 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00210 to 0.00190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1176 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_588 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1177 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_589 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1178 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_590 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1179 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_392 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1180 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_393 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1181 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2464\n",
      "Epoch 1: val_loss improved from inf to 0.11746, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.2464 - val_loss: 0.1175\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0723\n",
      "Epoch 2: val_loss improved from 0.11746 to 0.03980, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0723 - val_loss: 0.0398\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 3: val_loss improved from 0.03980 to 0.01964, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0311 - val_loss: 0.0196\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.01964 to 0.00962, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0166 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.00962 to 0.00473, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00473 to 0.00306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00306 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00247 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00215 to 0.00192, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00192 to 0.00174, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1182 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_591 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1183 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_592 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1184 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_593 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1185 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_394 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1186 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_395 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1187 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2938\n",
      "Epoch 1: val_loss improved from inf to 0.16093, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 473ms/step - loss: 0.2938 - val_loss: 0.1609\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0715\n",
      "Epoch 2: val_loss improved from 0.16093 to 0.03057, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0715 - val_loss: 0.0306\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0235\n",
      "Epoch 3: val_loss improved from 0.03057 to 0.01388, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0235 - val_loss: 0.0139\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 4: val_loss improved from 0.01388 to 0.00795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00795 to 0.00502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00502 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00347 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00268 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00230 to 0.00207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00207 to 0.00189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1188 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_594 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1189 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_595 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1190 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_596 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1191 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_396 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1192 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_397 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1193 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2761\n",
      "Epoch 1: val_loss improved from inf to 0.15657, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.2761 - val_loss: 0.1566\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0831\n",
      "Epoch 2: val_loss improved from 0.15657 to 0.05201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0831 - val_loss: 0.0520\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0383\n",
      "Epoch 3: val_loss improved from 0.05201 to 0.02353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0383 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 4: val_loss improved from 0.02353 to 0.01287, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0189 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 5: val_loss improved from 0.01287 to 0.00754, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0109 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00754 to 0.00505, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00505 to 0.00392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00392 to 0.00320, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00320 to 0.00274, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00274 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1194 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_597 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1195 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_598 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1196 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_599 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1197 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_398 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1198 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_399 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1199 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3064\n",
      "Epoch 1: val_loss improved from inf to 0.24120, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 451ms/step - loss: 0.3064 - val_loss: 0.2412\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1216\n",
      "Epoch 2: val_loss improved from 0.24120 to 0.05669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.1216 - val_loss: 0.0567\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0411\n",
      "Epoch 3: val_loss improved from 0.05669 to 0.02971, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0411 - val_loss: 0.0297\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0232\n",
      "Epoch 4: val_loss improved from 0.02971 to 0.01782, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0232 - val_loss: 0.0178\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 5: val_loss improved from 0.01782 to 0.01117, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0139 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01117 to 0.00735, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00735 to 0.00504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00504 to 0.00395, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00395 to 0.00341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00341 to 0.00309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1200 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_600 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1201 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_601 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1202 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_602 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1203 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_400 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1204 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_401 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1205 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2377\n",
      "Epoch 1: val_loss improved from inf to 0.12586, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 424ms/step - loss: 0.2377 - val_loss: 0.1259\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0597\n",
      "Epoch 2: val_loss improved from 0.12586 to 0.03694, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0597 - val_loss: 0.0369\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 3: val_loss improved from 0.03694 to 0.01591, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0215 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 4: val_loss improved from 0.01591 to 0.01030, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 5: val_loss improved from 0.01030 to 0.00732, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 6: val_loss improved from 0.00732 to 0.00577, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 7: val_loss improved from 0.00577 to 0.00498, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 8: val_loss improved from 0.00498 to 0.00444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00444 to 0.00403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00403 to 0.00366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0026 - val_loss: 0.0037\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1206 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_603 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1207 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_604 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1208 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_605 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1209 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_402 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1210 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_403 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1211 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2688\n",
      "Epoch 1: val_loss improved from inf to 0.17179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 424ms/step - loss: 0.2688 - val_loss: 0.1718\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0761\n",
      "Epoch 2: val_loss improved from 0.17179 to 0.05420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0761 - val_loss: 0.0542\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 3: val_loss improved from 0.05420 to 0.02805, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0342 - val_loss: 0.0280\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02805 to 0.01522, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0162 - val_loss: 0.0152\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01522 to 0.01026, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.01026 to 0.00853, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0057 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00853 to 0.00747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00747 to 0.00675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00675 to 0.00626, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 434ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00626 to 0.00585, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0034 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1212 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_606 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1213 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_607 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1214 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_608 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1215 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_404 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1216 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_405 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1217 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2782\n",
      "Epoch 1: val_loss improved from inf to 0.20264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.2782 - val_loss: 0.2026\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0884\n",
      "Epoch 2: val_loss improved from 0.20264 to 0.05484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0884 - val_loss: 0.0548\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0362\n",
      "Epoch 3: val_loss improved from 0.05484 to 0.02613, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0362 - val_loss: 0.0261\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02613 to 0.01611, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0172 - val_loss: 0.0161\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01611 to 0.01148, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.01148 to 0.00926, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0075 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00926 to 0.00784, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0060 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00784 to 0.00641, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00641 to 0.00526, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00526 to 0.00444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0030 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1218 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_609 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1219 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_610 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1220 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_611 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1221 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_406 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1222 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_407 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1223 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3127\n",
      "Epoch 1: val_loss improved from inf to 0.26337, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 406ms/step - loss: 0.3127 - val_loss: 0.2634\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1233\n",
      "Epoch 2: val_loss improved from 0.26337 to 0.06223, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.1233 - val_loss: 0.0622\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 3: val_loss improved from 0.06223 to 0.02593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 434ms/step - loss: 0.0422 - val_loss: 0.0259\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02593 to 0.01290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01290 to 0.00920, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00920 to 0.00714, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00714 to 0.00558, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00558 to 0.00446, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00446 to 0.00377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00377 to 0.00326, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1224 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_612 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1225 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_613 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1226 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_614 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1227 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_408 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1228 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_409 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1229 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3364\n",
      "Epoch 1: val_loss improved from inf to 0.27318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.3364 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1466\n",
      "Epoch 2: val_loss improved from 0.27318 to 0.06566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.1466 - val_loss: 0.0657\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0445\n",
      "Epoch 3: val_loss improved from 0.06566 to 0.02404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0445 - val_loss: 0.0240\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02404 to 0.01148, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0176 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01148 to 0.00742, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0101 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00742 to 0.00510, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00510 to 0.00384, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00384 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00314 to 0.00276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00276 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1230 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_615 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1231 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_616 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1232 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_617 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1233 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_410 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1234 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_411 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1235 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2548\n",
      "Epoch 1: val_loss improved from inf to 0.12643, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.2548 - val_loss: 0.1264\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0618\n",
      "Epoch 2: val_loss improved from 0.12643 to 0.03189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0618 - val_loss: 0.0319\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Epoch 3: val_loss improved from 0.03189 to 0.01547, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0247 - val_loss: 0.0155\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 4: val_loss improved from 0.01547 to 0.00909, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0143 - val_loss: 0.0091\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.00909 to 0.00601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00601 to 0.00442, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00442 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00346 to 0.00289, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00289 to 0.00253, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00253 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1236 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_618 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1237 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_619 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1238 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_620 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1239 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_412 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1240 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_413 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1241 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2894\n",
      "Epoch 1: val_loss improved from inf to 0.16976, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.2894 - val_loss: 0.1698\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1051\n",
      "Epoch 2: val_loss improved from 0.16976 to 0.05493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.1051 - val_loss: 0.0549\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0391\n",
      "Epoch 3: val_loss improved from 0.05493 to 0.01940, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0391 - val_loss: 0.0194\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 4: val_loss improved from 0.01940 to 0.00999, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0174 - val_loss: 0.0100\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.00999 to 0.00561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00561 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00381 to 0.00302, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00302 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00257 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00222 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1242 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_621 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1243 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_622 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1244 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_623 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1245 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_414 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1246 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_415 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1247 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3354\n",
      "Epoch 1: val_loss improved from inf to 0.23604, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.3354 - val_loss: 0.2360\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1483\n",
      "Epoch 2: val_loss improved from 0.23604 to 0.05290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.1483 - val_loss: 0.0529\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0408\n",
      "Epoch 3: val_loss improved from 0.05290 to 0.02326, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0408 - val_loss: 0.0233\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02326 to 0.01215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0203 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 5: val_loss improved from 0.01215 to 0.00666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0117 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00666 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00410 to 0.00300, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00300 to 0.00255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00255 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00225 to 0.00201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1248 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_624 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1249 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_625 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1250 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_626 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1251 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_416 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1252 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_417 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1253 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3336\n",
      "Epoch 1: val_loss improved from inf to 0.24617, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.3336 - val_loss: 0.2462\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1837\n",
      "Epoch 2: val_loss improved from 0.24617 to 0.05259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.1837 - val_loss: 0.0526\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0423\n",
      "Epoch 3: val_loss improved from 0.05259 to 0.02562, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0423 - val_loss: 0.0256\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 4: val_loss improved from 0.02562 to 0.01363, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0214 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 5: val_loss improved from 0.01363 to 0.00761, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00761 to 0.00484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00484 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00344 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00277 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00238 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1254 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_627 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1255 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_628 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1256 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_629 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1257 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_418 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1258 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_419 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1259 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2370\n",
      "Epoch 1: val_loss improved from inf to 0.08867, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.2370 - val_loss: 0.0887\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0491\n",
      "Epoch 2: val_loss improved from 0.08867 to 0.02841, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0491 - val_loss: 0.0284\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 3: val_loss improved from 0.02841 to 0.01408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0214 - val_loss: 0.0141\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 4: val_loss improved from 0.01408 to 0.00918, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.00918 to 0.00667, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00667 to 0.00480, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00480 to 0.00378, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00378 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00314 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00271 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1260 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_630 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1261 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_631 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1262 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_632 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1263 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_420 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1264 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_421 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1265 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2374\n",
      "Epoch 1: val_loss improved from inf to 0.09221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.2374 - val_loss: 0.0922\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0658\n",
      "Epoch 2: val_loss improved from 0.09221 to 0.04285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0658 - val_loss: 0.0429\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0322\n",
      "Epoch 3: val_loss improved from 0.04285 to 0.02256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0322 - val_loss: 0.0226\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 4: val_loss improved from 0.02256 to 0.01267, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0181 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01267 to 0.00819, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0108 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00819 to 0.00603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00603 to 0.00491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00491 to 0.00411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00411 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00347 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1266 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_633 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1267 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_634 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1268 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_635 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1269 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_422 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1270 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_423 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1271 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3124\n",
      "Epoch 1: val_loss improved from inf to 0.23852, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.3124 - val_loss: 0.2385\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1199\n",
      "Epoch 2: val_loss improved from 0.23852 to 0.06120, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.1199 - val_loss: 0.0612\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 3: val_loss improved from 0.06120 to 0.03202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0441 - val_loss: 0.0320\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 4: val_loss improved from 0.03202 to 0.02018, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0248 - val_loss: 0.0202\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 5: val_loss improved from 0.02018 to 0.01212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0149 - val_loss: 0.0121\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.01212 to 0.00800, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00800 to 0.00584, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00584 to 0.00468, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00468 to 0.00398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00398 to 0.00349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1272 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_636 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_212 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1273 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_637 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1274 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_638 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1275 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_424 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1276 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_425 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1277 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3219\n",
      "Epoch 1: val_loss improved from inf to 0.29898, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.3219 - val_loss: 0.2990\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1380\n",
      "Epoch 2: val_loss improved from 0.29898 to 0.05837, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.1380 - val_loss: 0.0584\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.05837 to 0.02404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0359 - val_loss: 0.0240\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02404 to 0.01495, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0158 - val_loss: 0.0150\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01495 to 0.01047, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0095 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01047 to 0.00825, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00825 to 0.00686, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00686 to 0.00596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00596 to 0.00545, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00545 to 0.00506, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1278 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_639 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_213 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1279 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_640 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1280 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_641 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1281 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_426 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1282 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_427 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1283 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2640\n",
      "Epoch 1: val_loss improved from inf to 0.15842, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2640 - val_loss: 0.1584\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0678\n",
      "Epoch 2: val_loss improved from 0.15842 to 0.05256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0678 - val_loss: 0.0526\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 3: val_loss improved from 0.05256 to 0.02419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0312 - val_loss: 0.0242\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 4: val_loss improved from 0.02419 to 0.01627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0140 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01627 to 0.01209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0093 - val_loss: 0.0121\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.01209 to 0.00963, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0068 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00963 to 0.00788, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00788 to 0.00681, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00681 to 0.00608, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00608 to 0.00553, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0032 - val_loss: 0.0055\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1284 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_642 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_214 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1285 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_643 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1286 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_644 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1287 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_428 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1288 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_429 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1289 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2148\n",
      "Epoch 1: val_loss improved from inf to 0.10373, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 426ms/step - loss: 0.2148 - val_loss: 0.1037\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0392\n",
      "Epoch 2: val_loss improved from 0.10373 to 0.02732, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0392 - val_loss: 0.0273\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 3: val_loss improved from 0.02732 to 0.01664, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0174 - val_loss: 0.0166\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 4: val_loss improved from 0.01664 to 0.01165, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 5: val_loss improved from 0.01165 to 0.00924, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0071 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00924 to 0.00796, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00796 to 0.00710, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0047 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00710 to 0.00638, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00638 to 0.00574, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00574 to 0.00516, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1290 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_645 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_215 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1291 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_646 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1292 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_647 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1293 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_430 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1294 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_431 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1295 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2065\n",
      "Epoch 1: val_loss improved from inf to 0.07928, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 424ms/step - loss: 0.2065 - val_loss: 0.0793\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0503\n",
      "Epoch 2: val_loss improved from 0.07928 to 0.03706, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0503 - val_loss: 0.0371\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 3: val_loss improved from 0.03706 to 0.01879, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0255 - val_loss: 0.0188\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 4: val_loss improved from 0.01879 to 0.01144, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01144 to 0.00811, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00811 to 0.00632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00632 to 0.00511, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00511 to 0.00435, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00435 to 0.00385, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00385 to 0.00352, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1296 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_648 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_216 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1297 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_649 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1298 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_650 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1299 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_432 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1300 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_433 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1301 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3200\n",
      "Epoch 1: val_loss improved from inf to 0.24703, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.3200 - val_loss: 0.2470\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1143\n",
      "Epoch 2: val_loss improved from 0.24703 to 0.05346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.1143 - val_loss: 0.0535\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0409\n",
      "Epoch 3: val_loss improved from 0.05346 to 0.02921, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0409 - val_loss: 0.0292\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0240\n",
      "Epoch 4: val_loss improved from 0.02921 to 0.01860, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0240 - val_loss: 0.0186\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 5: val_loss improved from 0.01860 to 0.01216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0161 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 6: val_loss improved from 0.01216 to 0.00811, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0107 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00811 to 0.00562, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00562 to 0.00423, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00423 to 0.00353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00353 to 0.00309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1302 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_651 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1303 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_652 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1304 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_653 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1305 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_434 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1306 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_435 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1307 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2822\n",
      "Epoch 1: val_loss improved from inf to 0.14523, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 474ms/step - loss: 0.2822 - val_loss: 0.1452\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0666\n",
      "Epoch 2: val_loss improved from 0.14523 to 0.03671, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0666 - val_loss: 0.0367\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0289\n",
      "Epoch 3: val_loss improved from 0.03671 to 0.01868, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0289 - val_loss: 0.0187\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.01868 to 0.01110, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01110 to 0.00693, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0105 - val_loss: 0.0069\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00693 to 0.00398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00398 to 0.00267, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00267 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00225 to 0.00200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00200 to 0.00181, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 434ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1308 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_654 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_218 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1309 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_655 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1310 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_656 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1311 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_436 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1312 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_437 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1313 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1494\n",
      "Epoch 1: val_loss improved from inf to 0.04244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 411ms/step - loss: 0.1494 - val_loss: 0.0424\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0355\n",
      "Epoch 2: val_loss improved from 0.04244 to 0.02082, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0355 - val_loss: 0.0208\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 3: val_loss improved from 0.02082 to 0.01031, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0171 - val_loss: 0.0103\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 4: val_loss improved from 0.01031 to 0.00675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0106 - val_loss: 0.0067\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00675 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00493 to 0.00376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00376 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00298 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00247 to 0.00214, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00214 to 0.00193, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1314 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_657 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_219 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1315 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_658 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1316 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_659 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1317 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_438 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1318 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_439 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1319 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2940\n",
      "Epoch 1: val_loss improved from inf to 0.17959, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 452ms/step - loss: 0.2940 - val_loss: 0.1796\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1120\n",
      "Epoch 2: val_loss improved from 0.17959 to 0.06310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.1120 - val_loss: 0.0631\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0521\n",
      "Epoch 3: val_loss improved from 0.06310 to 0.03353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0521 - val_loss: 0.0335\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0272\n",
      "Epoch 4: val_loss improved from 0.03353 to 0.01639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0272 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01639 to 0.00774, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0140 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00774 to 0.00431, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00431 to 0.00330, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00330 to 0.00274, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00274 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00230 to 0.00195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1320 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_660 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_220 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1321 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_661 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1322 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_662 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1323 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_440 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1324 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_441 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1325 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2173\n",
      "Epoch 1: val_loss improved from inf to 0.05268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.2173 - val_loss: 0.0527\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0391\n",
      "Epoch 2: val_loss improved from 0.05268 to 0.02598, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0391 - val_loss: 0.0260\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 3: val_loss improved from 0.02598 to 0.01531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0222 - val_loss: 0.0153\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.01531 to 0.00956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.00956 to 0.00569, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00569 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00364 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00271 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00230 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00202 to 0.00178, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1326 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_663 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_221 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1327 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_664 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1328 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_665 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1329 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_442 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1330 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_443 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1331 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3263\n",
      "Epoch 1: val_loss improved from inf to 0.23190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.3263 - val_loss: 0.2319\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1441\n",
      "Epoch 2: val_loss improved from 0.23190 to 0.05655, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.1441 - val_loss: 0.0565\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0411\n",
      "Epoch 3: val_loss improved from 0.05655 to 0.02407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0411 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0190\n",
      "Epoch 4: val_loss improved from 0.02407 to 0.01324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0190 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01324 to 0.00959, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0127 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 6: val_loss improved from 0.00959 to 0.00752, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0099 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 7: val_loss improved from 0.00752 to 0.00586, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 8: val_loss improved from 0.00586 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00447 to 0.00357, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00357 to 0.00297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1332 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_666 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_222 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1333 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_667 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1334 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_668 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1335 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_444 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1336 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_445 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1337 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3521\n",
      "Epoch 1: val_loss improved from inf to 0.30082, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.3521 - val_loss: 0.3008\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2008\n",
      "Epoch 2: val_loss improved from 0.30082 to 0.07795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.2008 - val_loss: 0.0780\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0587\n",
      "Epoch 3: val_loss improved from 0.07795 to 0.03957, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 454ms/step - loss: 0.0587 - val_loss: 0.0396\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 4: val_loss improved from 0.03957 to 0.01649, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0252 - val_loss: 0.0165\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01649 to 0.00955, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.00955 to 0.00575, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0081 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00575 to 0.00404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 521ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00404 to 0.00325, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00325 to 0.00283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00283 to 0.00253, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1338 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_669 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_223 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1339 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_670 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1340 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_671 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1341 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_446 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1342 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_447 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1343 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2807\n",
      "Epoch 1: val_loss improved from inf to 0.17657, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 448ms/step - loss: 0.2807 - val_loss: 0.1766\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0928\n",
      "Epoch 2: val_loss improved from 0.17657 to 0.06532, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0928 - val_loss: 0.0653\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0458\n",
      "Epoch 3: val_loss improved from 0.06532 to 0.03205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 526ms/step - loss: 0.0458 - val_loss: 0.0321\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 4: val_loss improved from 0.03205 to 0.01641, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0219 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 5: val_loss improved from 0.01641 to 0.00964, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 520ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00964 to 0.00691, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00691 to 0.00529, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00529 to 0.00437, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00437 to 0.00382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00382 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1344 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_672 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_224 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1345 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_673 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1346 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_674 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1347 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_448 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1348 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_449 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1349 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2679\n",
      "Epoch 1: val_loss improved from inf to 0.14351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.2679 - val_loss: 0.1435\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0596\n",
      "Epoch 2: val_loss improved from 0.14351 to 0.04201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0596 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0271\n",
      "Epoch 3: val_loss improved from 0.04201 to 0.02274, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0271 - val_loss: 0.0227\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.02274 to 0.01401, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0144 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01401 to 0.01034, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0090 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01034 to 0.00843, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0066 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00843 to 0.00708, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00708 to 0.00606, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00606 to 0.00539, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00539 to 0.00491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1350 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_675 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_225 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1351 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_676 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1352 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_677 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1353 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_450 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1354 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_451 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1355 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2648\n",
      "Epoch 1: val_loss improved from inf to 0.17351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.2648 - val_loss: 0.1735\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0720\n",
      "Epoch 2: val_loss improved from 0.17351 to 0.05343, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0720 - val_loss: 0.0534\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0329\n",
      "Epoch 3: val_loss improved from 0.05343 to 0.02521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0329 - val_loss: 0.0252\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.02521 to 0.01543, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01543 to 0.01072, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 537ms/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.01072 to 0.00845, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0061 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00845 to 0.00717, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00717 to 0.00626, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00626 to 0.00560, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00560 to 0.00516, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1356 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_678 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_226 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1357 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_679 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1358 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_680 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1359 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_452 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1360 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_453 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1361 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3057\n",
      "Epoch 1: val_loss improved from inf to 0.27290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 530ms/step - loss: 0.3057 - val_loss: 0.2729\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1124\n",
      "Epoch 2: val_loss improved from 0.27290 to 0.06552, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.1124 - val_loss: 0.0655\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0410\n",
      "Epoch 3: val_loss improved from 0.06552 to 0.03189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0410 - val_loss: 0.0319\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 4: val_loss improved from 0.03189 to 0.01957, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0214 - val_loss: 0.0196\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0128\n",
      "Epoch 5: val_loss improved from 0.01957 to 0.01305, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.01305 to 0.00952, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00952 to 0.00772, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00772 to 0.00660, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00660 to 0.00587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00587 to 0.00529, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "finished training\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1362 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_681 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1363 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_682 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1364 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_683 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1365 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_454 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1366 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_455 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1367 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2550\n",
      "Epoch 1: val_loss improved from inf to 0.16220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.2550 - val_loss: 0.1622\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0661\n",
      "Epoch 2: val_loss improved from 0.16220 to 0.03750, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0661 - val_loss: 0.0375\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 3: val_loss improved from 0.03750 to 0.01730, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0234 - val_loss: 0.0173\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 4: val_loss improved from 0.01730 to 0.01150, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01150 to 0.00864, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0089 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00864 to 0.00695, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00695 to 0.00574, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00574 to 0.00485, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00485 to 0.00422, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00422 to 0.00376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "finished training\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1368 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_684 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_228 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1369 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_685 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1370 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_686 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1371 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_456 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1372 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_457 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1373 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2314\n",
      "Epoch 1: val_loss improved from inf to 0.10714, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.2314 - val_loss: 0.1071\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0605\n",
      "Epoch 2: val_loss improved from 0.10714 to 0.03889, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0605 - val_loss: 0.0389\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 3: val_loss improved from 0.03889 to 0.01642, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0257 - val_loss: 0.0164\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 4: val_loss improved from 0.01642 to 0.00925, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0130 - val_loss: 0.0092\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.00925 to 0.00616, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00616 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 568ms/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00478 to 0.00389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00389 to 0.00328, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00328 to 0.00287, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00287 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1374 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_687 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_229 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1375 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_688 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1376 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_689 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1377 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_458 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1378 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_459 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1379 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1827\n",
      "Epoch 1: val_loss improved from inf to 0.06768, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 452ms/step - loss: 0.1827 - val_loss: 0.0677\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0548\n",
      "Epoch 2: val_loss improved from 0.06768 to 0.03791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0548 - val_loss: 0.0379\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 3: val_loss improved from 0.03791 to 0.01600, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0266 - val_loss: 0.0160\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 4: val_loss improved from 0.01600 to 0.00855, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0132 - val_loss: 0.0085\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.00855 to 0.00511, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00511 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00331 to 0.00270, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00270 to 0.00241, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00241 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00220 to 0.00201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 541ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1380 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_690 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_230 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1381 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_691 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1382 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_692 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1383 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_460 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1384 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_461 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1385 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2658\n",
      "Epoch 1: val_loss improved from inf to 0.13361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.2658 - val_loss: 0.1336\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0712\n",
      "Epoch 2: val_loss improved from 0.13361 to 0.03504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0712 - val_loss: 0.0350\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0245\n",
      "Epoch 3: val_loss improved from 0.03504 to 0.01431, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0245 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 4: val_loss improved from 0.01431 to 0.00825, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0131 - val_loss: 0.0082\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.00825 to 0.00516, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00516 to 0.00368, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00368 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00288 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00237 to 0.00204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00204 to 0.00179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1386 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_693 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_231 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1387 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_694 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1388 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_695 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1389 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_462 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1390 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_463 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1391 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3372\n",
      "Epoch 1: val_loss improved from inf to 0.24499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 452ms/step - loss: 0.3372 - val_loss: 0.2450\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1454\n",
      "Epoch 2: val_loss improved from 0.24499 to 0.04709, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.1454 - val_loss: 0.0471\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0327\n",
      "Epoch 3: val_loss improved from 0.04709 to 0.01812, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0327 - val_loss: 0.0181\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.01812 to 0.01029, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0161 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01029 to 0.00622, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00622 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00433 to 0.00332, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00332 to 0.00266, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00266 to 0.00223, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00223 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1392 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_696 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_232 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1393 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_697 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1394 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_698 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1395 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_464 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1396 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_465 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1397 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2258\n",
      "Epoch 1: val_loss improved from inf to 0.07484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.2258 - val_loss: 0.0748\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0497\n",
      "Epoch 2: val_loss improved from 0.07484 to 0.03061, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0497 - val_loss: 0.0306\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 3: val_loss improved from 0.03061 to 0.01517, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0239 - val_loss: 0.0152\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.01517 to 0.00915, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0138 - val_loss: 0.0091\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.00915 to 0.00608, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00608 to 0.00430, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0067 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00430 to 0.00320, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00320 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00257 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00218 to 0.00186, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1398 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_699 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1399 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_700 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1400 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_701 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1401 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_466 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1402 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_467 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1403 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3390\n",
      "Epoch 1: val_loss improved from inf to 0.23880, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 469ms/step - loss: 0.3390 - val_loss: 0.2388\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1393\n",
      "Epoch 2: val_loss improved from 0.23880 to 0.06526, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.1393 - val_loss: 0.0653\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0465\n",
      "Epoch 3: val_loss improved from 0.06526 to 0.02880, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0465 - val_loss: 0.0288\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 4: val_loss improved from 0.02880 to 0.01615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0220 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01615 to 0.00973, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 6: val_loss improved from 0.00973 to 0.00619, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0090 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00619 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00433 to 0.00328, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00328 to 0.00278, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00278 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1404 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_702 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1405 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_703 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1406 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_704 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1407 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_468 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1408 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_469 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1409 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2437\n",
      "Epoch 1: val_loss improved from inf to 0.10005, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 402ms/step - loss: 0.2437 - val_loss: 0.1001\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0551\n",
      "Epoch 2: val_loss improved from 0.10005 to 0.03639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0551 - val_loss: 0.0364\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0259\n",
      "Epoch 3: val_loss improved from 0.03639 to 0.01838, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0259 - val_loss: 0.0184\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.01838 to 0.01020, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01020 to 0.00666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0089 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00666 to 0.00464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00464 to 0.00353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00353 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00295 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00262 to 0.00241, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0030 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1410 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_705 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1411 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_706 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1412 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_707 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1413 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_470 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1414 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_471 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1415 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3186\n",
      "Epoch 1: val_loss improved from inf to 0.23013, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.3186 - val_loss: 0.2301\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1009\n",
      "Epoch 2: val_loss improved from 0.23013 to 0.05651, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.1009 - val_loss: 0.0565\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0378\n",
      "Epoch 3: val_loss improved from 0.05651 to 0.02981, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0378 - val_loss: 0.0298\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 4: val_loss improved from 0.02981 to 0.02070, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 5: val_loss improved from 0.02070 to 0.01404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0155 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 6: val_loss improved from 0.01404 to 0.00981, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00981 to 0.00716, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0074 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00716 to 0.00547, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00547 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00447 to 0.00385, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1416 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_708 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1417 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_709 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1418 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_710 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1419 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_472 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1420 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_473 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1421 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3504\n",
      "Epoch 1: val_loss improved from inf to 0.35411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.3504 - val_loss: 0.3541\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 2: val_loss improved from 0.35411 to 0.08562, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.1945 - val_loss: 0.0856\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0580\n",
      "Epoch 3: val_loss improved from 0.08562 to 0.04204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0580 - val_loss: 0.0420\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0263\n",
      "Epoch 4: val_loss improved from 0.04204 to 0.02306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0263 - val_loss: 0.0231\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 5: val_loss improved from 0.02306 to 0.01534, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 6: val_loss improved from 0.01534 to 0.01129, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 7: val_loss improved from 0.01129 to 0.00913, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0075 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 8: val_loss improved from 0.00913 to 0.00769, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00769 to 0.00667, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00667 to 0.00585, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1422 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_711 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_237 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1423 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_712 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1424 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_713 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1425 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_474 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1426 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_475 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1427 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2557\n",
      "Epoch 1: val_loss improved from inf to 0.14498, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.2557 - val_loss: 0.1450\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0642\n",
      "Epoch 2: val_loss improved from 0.14498 to 0.04704, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0642 - val_loss: 0.0470\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0267\n",
      "Epoch 3: val_loss improved from 0.04704 to 0.02318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0267 - val_loss: 0.0232\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 4: val_loss improved from 0.02318 to 0.01466, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01466 to 0.01024, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.01024 to 0.00856, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00856 to 0.00738, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0047 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00738 to 0.00664, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00664 to 0.00614, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00614 to 0.00580, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0033 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1428 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_714 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_238 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1429 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_715 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1430 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_716 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1431 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_476 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1432 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_477 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1433 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2521\n",
      "Epoch 1: val_loss improved from inf to 0.15575, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 403ms/step - loss: 0.2521 - val_loss: 0.1557\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0560\n",
      "Epoch 2: val_loss improved from 0.15575 to 0.03956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0560 - val_loss: 0.0396\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 3: val_loss improved from 0.03956 to 0.02298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0257 - val_loss: 0.0230\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.02298 to 0.01405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0145 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.01405 to 0.00897, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0078 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00897 to 0.00728, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00728 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00629 to 0.00551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00551 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00493 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1434 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_717 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_239 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1435 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_718 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1436 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_719 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1437 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_478 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1438 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_479 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1439 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3095\n",
      "Epoch 1: val_loss improved from inf to 0.28972, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 403ms/step - loss: 0.3095 - val_loss: 0.2897\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 2: val_loss improved from 0.28972 to 0.07718, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.1591 - val_loss: 0.0772\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0510\n",
      "Epoch 3: val_loss improved from 0.07718 to 0.03448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0510 - val_loss: 0.0345\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 4: val_loss improved from 0.03448 to 0.01771, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0222 - val_loss: 0.0177\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01771 to 0.01040, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.01040 to 0.00674, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00674 to 0.00490, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00490 to 0.00409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00409 to 0.00362, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00362 to 0.00330, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1440 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_720 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_240 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1441 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_721 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1442 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_722 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1443 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_480 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1444 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_481 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1445 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3035\n",
      "Epoch 1: val_loss improved from inf to 0.22684, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.3035 - val_loss: 0.2268\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1162\n",
      "Epoch 2: val_loss improved from 0.22684 to 0.06697, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.1162 - val_loss: 0.0670\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 3: val_loss improved from 0.06697 to 0.02514, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0421 - val_loss: 0.0251\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02514 to 0.01188, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01188 to 0.00730, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0094 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00730 to 0.00518, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00518 to 0.00417, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00417 to 0.00352, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00352 to 0.00305, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00305 to 0.00270, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1446 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_723 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_241 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1447 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_724 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1448 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_725 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1449 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_482 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1450 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_483 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1451 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2455\n",
      "Epoch 1: val_loss improved from inf to 0.12706, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.2455 - val_loss: 0.1271\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0558\n",
      "Epoch 2: val_loss improved from 0.12706 to 0.02982, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0558 - val_loss: 0.0298\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0231\n",
      "Epoch 3: val_loss improved from 0.02982 to 0.01633, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0231 - val_loss: 0.0163\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.01633 to 0.01030, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01030 to 0.00694, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00694 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00478 to 0.00353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00353 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00282 to 0.00235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00235 to 0.00205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1452 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_726 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_242 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1453 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_727 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1454 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_728 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1455 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_484 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1456 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_485 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1457 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2546\n",
      "Epoch 1: val_loss improved from inf to 0.12927, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.2546 - val_loss: 0.1293\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0862\n",
      "Epoch 2: val_loss improved from 0.12927 to 0.06038, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0862 - val_loss: 0.0604\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0462\n",
      "Epoch 3: val_loss improved from 0.06038 to 0.03076, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0462 - val_loss: 0.0308\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 4: val_loss improved from 0.03076 to 0.01515, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0241 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01515 to 0.00675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0119 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00675 to 0.00404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00404 to 0.00296, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00296 to 0.00244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00244 to 0.00212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00212 to 0.00192, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1458 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_729 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_243 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1459 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_730 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1460 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_731 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1461 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_486 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1462 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_487 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1463 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2045\n",
      "Epoch 1: val_loss improved from inf to 0.06178, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.2045 - val_loss: 0.0618\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 2: val_loss improved from 0.06178 to 0.02695, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0422 - val_loss: 0.0269\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0206\n",
      "Epoch 3: val_loss improved from 0.02695 to 0.01332, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0206 - val_loss: 0.0133\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 4: val_loss improved from 0.01332 to 0.00746, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.00746 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00499 to 0.00373, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00373 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00295 to 0.00245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00245 to 0.00216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00216 to 0.00194, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1464 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_732 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_244 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1465 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_733 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1466 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_734 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1467 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_488 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1468 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_489 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1469 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2217\n",
      "Epoch 1: val_loss improved from inf to 0.08549, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.2217 - val_loss: 0.0855\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0485\n",
      "Epoch 2: val_loss improved from 0.08549 to 0.03052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0485 - val_loss: 0.0305\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0238\n",
      "Epoch 3: val_loss improved from 0.03052 to 0.01587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0238 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.01587 to 0.01046, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01046 to 0.00705, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0104 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00705 to 0.00479, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0074 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00479 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00347 to 0.00266, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00266 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00224 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1470 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_735 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_245 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1471 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_736 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1472 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_737 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1473 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_490 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1474 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_491 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1475 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3215\n",
      "Epoch 1: val_loss improved from inf to 0.22936, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.3215 - val_loss: 0.2294\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1355\n",
      "Epoch 2: val_loss improved from 0.22936 to 0.06404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.1355 - val_loss: 0.0640\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0447\n",
      "Epoch 3: val_loss improved from 0.06404 to 0.02950, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0447 - val_loss: 0.0295\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 4: val_loss improved from 0.02950 to 0.01722, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0237 - val_loss: 0.0172\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 5: val_loss improved from 0.01722 to 0.01022, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.01022 to 0.00630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00630 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00410 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00303 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00257 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1476 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_738 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_246 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1477 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_739 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1478 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_740 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1479 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_492 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1480 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_493 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1481 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2840\n",
      "Epoch 1: val_loss improved from inf to 0.17194, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.2840 - val_loss: 0.1719\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0783\n",
      "Epoch 2: val_loss improved from 0.17194 to 0.03830, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0783 - val_loss: 0.0383\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 3: val_loss improved from 0.03830 to 0.01543, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0255 - val_loss: 0.0154\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 4: val_loss improved from 0.01543 to 0.00799, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00799 to 0.00586, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00586 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00447 to 0.00351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00351 to 0.00286, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00286 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00248 to 0.00223, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1482 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_741 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_247 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1483 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_742 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1484 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_743 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1485 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_494 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1486 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_495 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1487 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2761\n",
      "Epoch 1: val_loss improved from inf to 0.16111, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.2761 - val_loss: 0.1611\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0735\n",
      "Epoch 2: val_loss improved from 0.16111 to 0.04315, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0735 - val_loss: 0.0432\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 3: val_loss improved from 0.04315 to 0.02081, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0286 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 4: val_loss improved from 0.02081 to 0.01294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0156 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01294 to 0.00862, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00862 to 0.00621, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00621 to 0.00476, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00476 to 0.00399, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00399 to 0.00353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00353 to 0.00323, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1488 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_744 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_248 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1489 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_745 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1490 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_746 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1491 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_496 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1492 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_497 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1493 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2625\n",
      "Epoch 1: val_loss improved from inf to 0.19007, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.2625 - val_loss: 0.1901\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0782\n",
      "Epoch 2: val_loss improved from 0.19007 to 0.04914, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0782 - val_loss: 0.0491\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0322\n",
      "Epoch 3: val_loss improved from 0.04914 to 0.02537, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0322 - val_loss: 0.0254\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 4: val_loss improved from 0.02537 to 0.01600, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0165 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01600 to 0.01055, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.01055 to 0.00780, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00780 to 0.00655, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00655 to 0.00577, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00577 to 0.00521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00521 to 0.00479, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1494 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_747 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_249 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1495 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_748 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1496 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_749 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1497 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_498 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1498 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_499 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1499 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2760\n",
      "Epoch 1: val_loss improved from inf to 0.23324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.2760 - val_loss: 0.2332\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0818\n",
      "Epoch 2: val_loss improved from 0.23324 to 0.04326, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0818 - val_loss: 0.0433\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0285\n",
      "Epoch 3: val_loss improved from 0.04326 to 0.02663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0285 - val_loss: 0.0266\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 4: val_loss improved from 0.02663 to 0.01842, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0169 - val_loss: 0.0184\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01842 to 0.01268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.01268 to 0.00927, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00927 to 0.00766, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00766 to 0.00686, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0039 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00686 to 0.00635, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00635 to 0.00596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0033 - val_loss: 0.0060\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1500 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_750 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_250 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1501 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_751 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1502 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_752 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1503 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_500 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1504 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_501 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1505 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2491\n",
      "Epoch 1: val_loss improved from inf to 0.11992, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.2491 - val_loss: 0.1199\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0705\n",
      "Epoch 2: val_loss improved from 0.11992 to 0.05504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0705 - val_loss: 0.0550\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 3: val_loss improved from 0.05504 to 0.02459, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0316 - val_loss: 0.0246\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.02459 to 0.01467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01467 to 0.00938, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00938 to 0.00689, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00689 to 0.00574, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00574 to 0.00513, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00513 to 0.00470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00470 to 0.00435, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0027 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1506 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_753 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_251 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1507 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_754 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1508 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_755 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1509 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_502 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1510 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_503 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1511 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2815\n",
      "Epoch 1: val_loss improved from inf to 0.21290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.2815 - val_loss: 0.2129\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0942\n",
      "Epoch 2: val_loss improved from 0.21290 to 0.05484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0942 - val_loss: 0.0548\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0319\n",
      "Epoch 3: val_loss improved from 0.05484 to 0.02243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0319 - val_loss: 0.0224\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.02243 to 0.01353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0151 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01353 to 0.00966, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00966 to 0.00718, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00718 to 0.00557, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00557 to 0.00458, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00458 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00405 to 0.00370, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1512 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_756 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_252 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1513 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_757 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1514 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_758 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1515 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_504 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1516 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_505 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1517 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3093\n",
      "Epoch 1: val_loss improved from inf to 0.24184, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.3093 - val_loss: 0.2418\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1260\n",
      "Epoch 2: val_loss improved from 0.24184 to 0.07752, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.1260 - val_loss: 0.0775\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0529\n",
      "Epoch 3: val_loss improved from 0.07752 to 0.03438, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0529 - val_loss: 0.0344\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 4: val_loss improved from 0.03438 to 0.01487, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0225 - val_loss: 0.0149\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01487 to 0.00710, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00710 to 0.00468, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00468 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00387 to 0.00343, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00343 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00310 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1518 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_759 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_253 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1519 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_760 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1520 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_761 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1521 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_506 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1522 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_507 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1523 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1949\n",
      "Epoch 1: val_loss improved from inf to 0.07432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.1949 - val_loss: 0.0743\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0534\n",
      "Epoch 2: val_loss improved from 0.07432 to 0.03535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0534 - val_loss: 0.0354\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0250\n",
      "Epoch 3: val_loss improved from 0.03535 to 0.01702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0250 - val_loss: 0.0170\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01702 to 0.00924, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0141 - val_loss: 0.0092\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.00924 to 0.00502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0081 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00502 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00346 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00280 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00242 to 0.00212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00212 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1524 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_762 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_254 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1525 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_763 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1526 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_764 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1527 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_508 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1528 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_509 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1529 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2946\n",
      "Epoch 1: val_loss improved from inf to 0.15052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 403ms/step - loss: 0.2946 - val_loss: 0.1505\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0864\n",
      "Epoch 2: val_loss improved from 0.15052 to 0.04973, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0864 - val_loss: 0.0497\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0373\n",
      "Epoch 3: val_loss improved from 0.04973 to 0.02317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0373 - val_loss: 0.0232\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02317 to 0.01324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0194 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01324 to 0.00782, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00782 to 0.00488, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00488 to 0.00351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00351 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00281 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00239 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1530 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_765 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_255 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1531 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_766 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1532 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_767 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1533 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_510 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1534 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_511 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1535 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3091\n",
      "Epoch 1: val_loss improved from inf to 0.20281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.3091 - val_loss: 0.2028\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1344\n",
      "Epoch 2: val_loss improved from 0.20281 to 0.06859, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.1344 - val_loss: 0.0686\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0510\n",
      "Epoch 3: val_loss improved from 0.06859 to 0.03179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0510 - val_loss: 0.0318\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 4: val_loss improved from 0.03179 to 0.01901, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0266 - val_loss: 0.0190\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 5: val_loss improved from 0.01901 to 0.01138, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 6: val_loss improved from 0.01138 to 0.00632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0105 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00632 to 0.00359, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00359 to 0.00286, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00286 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00250 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1536 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_768 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_256 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1537 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_769 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1538 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_770 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1539 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_512 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1540 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_513 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1541 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3203\n",
      "Epoch 1: val_loss improved from inf to 0.21627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.3203 - val_loss: 0.2163\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1277\n",
      "Epoch 2: val_loss improved from 0.21627 to 0.05278, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.1277 - val_loss: 0.0528\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0365\n",
      "Epoch 3: val_loss improved from 0.05278 to 0.02073, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0365 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 4: val_loss improved from 0.02073 to 0.00943, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.00943 to 0.00531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00531 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00364 to 0.00291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00291 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00242 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00211 to 0.00189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1542 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_771 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_257 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1543 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_772 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1544 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_773 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1545 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_514 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1546 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_515 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1547 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2755\n",
      "Epoch 1: val_loss improved from inf to 0.13515, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.2755 - val_loss: 0.1352\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0652\n",
      "Epoch 2: val_loss improved from 0.13515 to 0.03466, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0652 - val_loss: 0.0347\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 3: val_loss improved from 0.03466 to 0.01450, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0237 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 4: val_loss improved from 0.01450 to 0.00831, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.00831 to 0.00528, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00528 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00387 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00311 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00259 to 0.00216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00216 to 0.00190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1548 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_774 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_258 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1549 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_775 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1550 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_776 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1551 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_516 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1552 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_517 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1553 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2805\n",
      "Epoch 1: val_loss improved from inf to 0.19206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.2805 - val_loss: 0.1921\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0997\n",
      "Epoch 2: val_loss improved from 0.19206 to 0.05408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0997 - val_loss: 0.0541\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0348\n",
      "Epoch 3: val_loss improved from 0.05408 to 0.02217, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0348 - val_loss: 0.0222\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.02217 to 0.01065, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 5: val_loss improved from 0.01065 to 0.00617, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00617 to 0.00425, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00425 to 0.00351, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00351 to 0.00313, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00313 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00288 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1554 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_777 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_259 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1555 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_778 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1556 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_779 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1557 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_518 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1558 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_519 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1559 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2992\n",
      "Epoch 1: val_loss improved from inf to 0.19733, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.2992 - val_loss: 0.1973\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0820\n",
      "Epoch 2: val_loss improved from 0.19733 to 0.04056, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0820 - val_loss: 0.0406\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0267\n",
      "Epoch 3: val_loss improved from 0.04056 to 0.02145, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0267 - val_loss: 0.0215\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.02145 to 0.01335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0149 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01335 to 0.00871, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00871 to 0.00664, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00664 to 0.00558, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00558 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00493 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00447 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "finished training\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1560 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_780 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_260 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1561 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_781 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1562 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_782 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1563 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_520 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1564 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_521 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1565 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2279\n",
      "Epoch 1: val_loss improved from inf to 0.11423, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.2279 - val_loss: 0.1142\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0584\n",
      "Epoch 2: val_loss improved from 0.11423 to 0.04165, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0584 - val_loss: 0.0416\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0229\n",
      "Epoch 3: val_loss improved from 0.04165 to 0.01902, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0229 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 4: val_loss improved from 0.01902 to 0.01263, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.01263 to 0.00954, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00954 to 0.00748, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00748 to 0.00625, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00625 to 0.00555, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00555 to 0.00500, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00500 to 0.00453, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1566 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_783 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_261 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1567 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_784 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1568 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_785 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1569 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_522 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1570 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_523 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1571 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2863\n",
      "Epoch 1: val_loss improved from inf to 0.27475, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 402ms/step - loss: 0.2863 - val_loss: 0.2747\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1066\n",
      "Epoch 2: val_loss improved from 0.27475 to 0.04794, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.1066 - val_loss: 0.0479\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 3: val_loss improved from 0.04794 to 0.02702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0283 - val_loss: 0.0270\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.02702 to 0.01666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.01666 to 0.01171, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0086 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.01171 to 0.00936, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0059 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00936 to 0.00793, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00793 to 0.00698, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00698 to 0.00628, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00628 to 0.00572, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0030 - val_loss: 0.0057\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1572 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_786 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_262 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1573 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_787 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1574 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_788 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1575 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_524 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1576 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_525 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1577 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2737\n",
      "Epoch 1: val_loss improved from inf to 0.19129, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.2737 - val_loss: 0.1913\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0862\n",
      "Epoch 2: val_loss improved from 0.19129 to 0.05868, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0862 - val_loss: 0.0587\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0353\n",
      "Epoch 3: val_loss improved from 0.05868 to 0.02910, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0353 - val_loss: 0.0291\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 4: val_loss improved from 0.02910 to 0.01866, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0187 - val_loss: 0.0187\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01866 to 0.01239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.01239 to 0.00914, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0072 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00914 to 0.00744, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00744 to 0.00639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00639 to 0.00563, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00563 to 0.00505, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_263\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1578 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_789 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_263 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1579 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_790 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1580 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_791 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1581 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_526 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1582 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_527 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1583 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3450\n",
      "Epoch 1: val_loss improved from inf to 0.29326, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.3450 - val_loss: 0.2933\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1178\n",
      "Epoch 2: val_loss improved from 0.29326 to 0.04161, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.1178 - val_loss: 0.0416\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 3: val_loss improved from 0.04161 to 0.02222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0268 - val_loss: 0.0222\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 4: val_loss improved from 0.02222 to 0.01345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0156 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01345 to 0.00880, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 387ms/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00880 to 0.00673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00673 to 0.00545, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00545 to 0.00469, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00469 to 0.00416, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00416 to 0.00380, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1584 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_792 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_264 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1585 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_793 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1586 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_794 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1587 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_528 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1588 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_529 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1589 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2994\n",
      "Epoch 1: val_loss improved from inf to 0.23345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.2994 - val_loss: 0.2334\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1186\n",
      "Epoch 2: val_loss improved from 0.23345 to 0.06814, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.1186 - val_loss: 0.0681\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 3: val_loss improved from 0.06814 to 0.02812, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0436 - val_loss: 0.0281\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0218\n",
      "Epoch 4: val_loss improved from 0.02812 to 0.01754, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0218 - val_loss: 0.0175\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01754 to 0.01093, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0140 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01093 to 0.00681, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00681 to 0.00464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00464 to 0.00366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00366 to 0.00319, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00319 to 0.00290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_265\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1590 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_795 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1591 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_796 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1592 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_797 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1593 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_530 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1594 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_531 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1595 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2701\n",
      "Epoch 1: val_loss improved from inf to 0.15383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 498ms/step - loss: 0.2701 - val_loss: 0.1538\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0880\n",
      "Epoch 2: val_loss improved from 0.15383 to 0.05894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0880 - val_loss: 0.0589\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0417\n",
      "Epoch 3: val_loss improved from 0.05894 to 0.02675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0417 - val_loss: 0.0268\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 4: val_loss improved from 0.02675 to 0.01055, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 390ms/step - loss: 0.0187 - val_loss: 0.0106\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01055 to 0.00550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00550 to 0.00390, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00390 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00321 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00280 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 384ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00252 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_266\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1596 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_798 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_266 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1597 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_799 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1598 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_800 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1599 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_532 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1600 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_533 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1601 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1928\n",
      "Epoch 1: val_loss improved from inf to 0.05872, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.1928 - val_loss: 0.0587\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 2: val_loss improved from 0.05872 to 0.02696, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0435 - val_loss: 0.0270\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 3: val_loss improved from 0.02696 to 0.01433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0216 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 4: val_loss improved from 0.01433 to 0.00820, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0130 - val_loss: 0.0082\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.00820 to 0.00513, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00513 to 0.00352, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00352 to 0.00265, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00265 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00221 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00196 to 0.00179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_267\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1602 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_801 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_267 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1603 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_802 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1604 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_803 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1605 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_534 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1606 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_535 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1607 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3359\n",
      "Epoch 1: val_loss improved from inf to 0.23014, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.3359 - val_loss: 0.2301\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1328\n",
      "Epoch 2: val_loss improved from 0.23014 to 0.05956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.1328 - val_loss: 0.0596\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0440\n",
      "Epoch 3: val_loss improved from 0.05956 to 0.02735, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0440 - val_loss: 0.0274\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0221\n",
      "Epoch 4: val_loss improved from 0.02735 to 0.01463, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0221 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01463 to 0.00857, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.00857 to 0.00563, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00563 to 0.00401, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00401 to 0.00306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00306 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00248 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_268\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1608 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_804 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_268 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1609 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_805 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1610 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_806 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1611 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_536 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1612 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_537 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1613 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3239\n",
      "Epoch 1: val_loss improved from inf to 0.21406, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.3239 - val_loss: 0.2141\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1275\n",
      "Epoch 2: val_loss improved from 0.21406 to 0.04672, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 0.1275 - val_loss: 0.0467\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0325\n",
      "Epoch 3: val_loss improved from 0.04672 to 0.01661, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0325 - val_loss: 0.0166\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 4: val_loss improved from 0.01661 to 0.00926, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 499ms/step - loss: 0.0139 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.00926 to 0.00557, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00557 to 0.00378, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00378 to 0.00283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00283 to 0.00232, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 478ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00232 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00197 to 0.00175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_269\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1614 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_807 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_269 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1615 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_808 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1616 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_809 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1617 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_538 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1618 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_539 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1619 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1683\n",
      "Epoch 1: val_loss improved from inf to 0.07531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 468ms/step - loss: 0.1683 - val_loss: 0.0753\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0575\n",
      "Epoch 2: val_loss improved from 0.07531 to 0.03953, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0575 - val_loss: 0.0395\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.03953 to 0.02030, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0294 - val_loss: 0.0203\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 4: val_loss improved from 0.02030 to 0.00883, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0150 - val_loss: 0.0088\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 5: val_loss improved from 0.00883 to 0.00577, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00577 to 0.00452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00452 to 0.00356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00356 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00288 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00242 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_270\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1620 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_810 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_270 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1621 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_811 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1622 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_812 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1623 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_540 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1624 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_541 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1625 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3058\n",
      "Epoch 1: val_loss improved from inf to 0.19924, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.3058 - val_loss: 0.1992\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1014\n",
      "Epoch 2: val_loss improved from 0.19924 to 0.05248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.1014 - val_loss: 0.0525\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0350\n",
      "Epoch 3: val_loss improved from 0.05248 to 0.02361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0350 - val_loss: 0.0236\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 4: val_loss improved from 0.02361 to 0.01369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0178 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01369 to 0.00798, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00798 to 0.00489, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00489 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00364 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00310 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00277 to 0.00249, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_271\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1626 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_813 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_271 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1627 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_814 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1628 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_815 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1629 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_542 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1630 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_543 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1631 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3019\n",
      "Epoch 1: val_loss improved from inf to 0.23799, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 492ms/step - loss: 0.3019 - val_loss: 0.2380\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1077\n",
      "Epoch 2: val_loss improved from 0.23799 to 0.05174, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.1077 - val_loss: 0.0517\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.05174 to 0.01758, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 478ms/step - loss: 0.0294 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 4: val_loss improved from 0.01758 to 0.00992, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 475ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 5: val_loss improved from 0.00992 to 0.00728, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00728 to 0.00580, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00580 to 0.00494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00494 to 0.00440, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00440 to 0.00400, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00400 to 0.00372, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_272\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1632 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_816 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_272 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1633 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_817 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1634 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_818 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1635 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_544 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1636 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_545 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1637 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2909\n",
      "Epoch 1: val_loss improved from inf to 0.19952, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 424ms/step - loss: 0.2909 - val_loss: 0.1995\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0948\n",
      "Epoch 2: val_loss improved from 0.19952 to 0.06786, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0948 - val_loss: 0.0679\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 3: val_loss improved from 0.06786 to 0.03284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0436 - val_loss: 0.0328\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.03284 to 0.01856, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0203 - val_loss: 0.0186\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01856 to 0.01202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.01202 to 0.00889, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0067 - val_loss: 0.0089\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00889 to 0.00742, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00742 to 0.00672, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00672 to 0.00627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00627 to 0.00590, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0034 - val_loss: 0.0059\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_273\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1638 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_819 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_273 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1639 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_820 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1640 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_821 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1641 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_546 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1642 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_547 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1643 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2131\n",
      "Epoch 1: val_loss improved from inf to 0.10905, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 426ms/step - loss: 0.2131 - val_loss: 0.1090\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0538\n",
      "Epoch 2: val_loss improved from 0.10905 to 0.04392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0538 - val_loss: 0.0439\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 3: val_loss improved from 0.04392 to 0.02489, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0273 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.02489 to 0.01563, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01563 to 0.01060, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.01060 to 0.00838, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0051 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00838 to 0.00727, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 520ms/step - loss: 0.0040 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00727 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0035 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00663 to 0.00615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00615 to 0.00576, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0029 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_274\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1644 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_822 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_274 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1645 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_823 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1646 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_824 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1647 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_548 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1648 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_549 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1649 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3112\n",
      "Epoch 1: val_loss improved from inf to 0.22026, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 490ms/step - loss: 0.3112 - val_loss: 0.2203\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0793\n",
      "Epoch 2: val_loss improved from 0.22026 to 0.04933, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0793 - val_loss: 0.0493\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0319\n",
      "Epoch 3: val_loss improved from 0.04933 to 0.02835, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0319 - val_loss: 0.0283\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 4: val_loss improved from 0.02835 to 0.01941, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0188 - val_loss: 0.0194\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01941 to 0.01403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 6: val_loss improved from 0.01403 to 0.01077, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.01077 to 0.00847, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00847 to 0.00685, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00685 to 0.00590, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00590 to 0.00534, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "finished training\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_275\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1650 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_825 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_275 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1651 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_826 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1652 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_827 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1653 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_550 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1654 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_551 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1655 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2754\n",
      "Epoch 1: val_loss improved from inf to 0.17541, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.2754 - val_loss: 0.1754\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0796\n",
      "Epoch 2: val_loss improved from 0.17541 to 0.05483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0796 - val_loss: 0.0548\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0371\n",
      "Epoch 3: val_loss improved from 0.05483 to 0.02708, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0371 - val_loss: 0.0271\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 4: val_loss improved from 0.02708 to 0.01573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0187 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01573 to 0.01070, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.01070 to 0.00825, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00825 to 0.00680, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00680 to 0.00574, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00574 to 0.00496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00496 to 0.00444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_276\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1656 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_828 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_276 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1657 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_829 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1658 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_830 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1659 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_552 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1660 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_553 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1661 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2198\n",
      "Epoch 1: val_loss improved from inf to 0.09676, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.2198 - val_loss: 0.0968\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0558\n",
      "Epoch 2: val_loss improved from 0.09676 to 0.03722, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0558 - val_loss: 0.0372\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0253\n",
      "Epoch 3: val_loss improved from 0.03722 to 0.01565, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0253 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 4: val_loss improved from 0.01565 to 0.00782, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 5: val_loss improved from 0.00782 to 0.00456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 6: val_loss improved from 0.00456 to 0.00338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 7: val_loss improved from 0.00338 to 0.00291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 8: val_loss improved from 0.00291 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 9: val_loss improved from 0.00262 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00238 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_277\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1662 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_831 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_277 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1663 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_832 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1664 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_833 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1665 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_554 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1666 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_555 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1667 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2520\n",
      "Epoch 1: val_loss improved from inf to 0.14062, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.2520 - val_loss: 0.1406\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0770\n",
      "Epoch 2: val_loss improved from 0.14062 to 0.04209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0770 - val_loss: 0.0421\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0301\n",
      "Epoch 3: val_loss improved from 0.04209 to 0.01740, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0301 - val_loss: 0.0174\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 4: val_loss improved from 0.01740 to 0.00926, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0150 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.00926 to 0.00554, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00554 to 0.00391, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00391 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00303 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 538ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00252 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00220 to 0.00198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 543ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_278\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1668 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_834 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_278 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1669 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_835 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1670 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_836 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1671 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_556 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1672 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_557 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1673 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2983\n",
      "Epoch 1: val_loss improved from inf to 0.18339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 541ms/step - loss: 0.2983 - val_loss: 0.1834\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1067\n",
      "Epoch 2: val_loss improved from 0.18339 to 0.05390, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 526ms/step - loss: 0.1067 - val_loss: 0.0539\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0434\n",
      "Epoch 3: val_loss improved from 0.05390 to 0.02783, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0434 - val_loss: 0.0278\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0230\n",
      "Epoch 4: val_loss improved from 0.02783 to 0.01317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0230 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01317 to 0.00683, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 538ms/step - loss: 0.0119 - val_loss: 0.0068\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00683 to 0.00481, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 538ms/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00481 to 0.00355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00355 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 537ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00277 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00230 to 0.00208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_279\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1674 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_837 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_279 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1675 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_838 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1676 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_839 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1677 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_558 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1678 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_559 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1679 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3456\n",
      "Epoch 1: val_loss improved from inf to 0.26123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 428ms/step - loss: 0.3456 - val_loss: 0.2612\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1988\n",
      "Epoch 2: val_loss improved from 0.26123 to 0.05373, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.1988 - val_loss: 0.0537\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0427\n",
      "Epoch 3: val_loss improved from 0.05373 to 0.02381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0427 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 4: val_loss improved from 0.02381 to 0.01091, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0186 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01091 to 0.00638, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00638 to 0.00461, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 478ms/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00461 to 0.00348, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00348 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00268 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00222 to 0.00191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_280\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1680 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_840 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_280 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1681 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_841 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1682 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_842 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1683 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_560 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1684 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_561 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1685 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2083\n",
      "Epoch 1: val_loss improved from inf to 0.06894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.2083 - val_loss: 0.0689\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0464\n",
      "Epoch 2: val_loss improved from 0.06894 to 0.02827, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0464 - val_loss: 0.0283\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 3: val_loss improved from 0.02827 to 0.01222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0208 - val_loss: 0.0122\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 4: val_loss improved from 0.01222 to 0.00705, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0116 - val_loss: 0.0071\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00705 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00474 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00347 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00271 to 0.00226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00226 to 0.00195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 427ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00195 to 0.00174, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_281\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1686 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_843 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_281 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1687 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_844 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1688 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_845 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1689 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_562 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1690 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_563 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1691 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2659\n",
      "Epoch 1: val_loss improved from inf to 0.13177, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.2659 - val_loss: 0.1318\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0799\n",
      "Epoch 2: val_loss improved from 0.13177 to 0.05316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0799 - val_loss: 0.0532\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 3: val_loss improved from 0.05316 to 0.02214, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0377 - val_loss: 0.0221\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 4: val_loss improved from 0.02214 to 0.01157, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0181 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01157 to 0.00660, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0103 - val_loss: 0.0066\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00660 to 0.00458, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00458 to 0.00337, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00337 to 0.00272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 477ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00272 to 0.00236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00236 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_282\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1692 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_846 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_282 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1693 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_847 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1694 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_848 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1695 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_564 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1696 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_565 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1697 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3202\n",
      "Epoch 1: val_loss improved from inf to 0.23874, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 512ms/step - loss: 0.3202 - val_loss: 0.2387\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1312\n",
      "Epoch 2: val_loss improved from 0.23874 to 0.05759, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.1312 - val_loss: 0.0576\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0401\n",
      "Epoch 3: val_loss improved from 0.05759 to 0.02718, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0401 - val_loss: 0.0272\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 4: val_loss improved from 0.02718 to 0.01446, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0198 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01446 to 0.00923, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.00923 to 0.00630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0082 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00630 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00474 to 0.00383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00383 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00324 to 0.00284, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_283\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1698 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_849 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_283 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1699 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_850 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1700 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_851 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1701 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_566 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1702 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_567 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1703 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2882\n",
      "Epoch 1: val_loss improved from inf to 0.21180, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.2882 - val_loss: 0.2118\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1087\n",
      "Epoch 2: val_loss improved from 0.21180 to 0.06971, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.1087 - val_loss: 0.0697\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0519\n",
      "Epoch 3: val_loss improved from 0.06971 to 0.03830, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0519 - val_loss: 0.0383\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0259\n",
      "Epoch 4: val_loss improved from 0.03830 to 0.01950, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0259 - val_loss: 0.0195\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 5: val_loss improved from 0.01950 to 0.01155, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01155 to 0.00809, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00809 to 0.00628, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00628 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00501 to 0.00418, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00418 to 0.00377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 477ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_284\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1704 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_852 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_284 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1705 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_853 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1706 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_854 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1707 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_568 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1708 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_569 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1709 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2721\n",
      "Epoch 1: val_loss improved from inf to 0.18109, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.2721 - val_loss: 0.1811\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0759\n",
      "Epoch 2: val_loss improved from 0.18109 to 0.04946, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0759 - val_loss: 0.0495\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 3: val_loss improved from 0.04946 to 0.02766, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0324 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 4: val_loss improved from 0.02766 to 0.01818, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 499ms/step - loss: 0.0187 - val_loss: 0.0182\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 5: val_loss improved from 0.01818 to 0.01180, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.01180 to 0.00848, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00848 to 0.00664, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00664 to 0.00554, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00554 to 0.00491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00491 to 0.00453, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0028 - val_loss: 0.0045\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_285\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1710 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_855 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_285 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1711 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_856 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1712 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_857 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1713 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_570 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1714 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_571 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1715 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3275\n",
      "Epoch 1: val_loss improved from inf to 0.31023, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.3275 - val_loss: 0.3102\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1306\n",
      "Epoch 2: val_loss improved from 0.31023 to 0.06122, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.1306 - val_loss: 0.0612\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.06122 to 0.03024, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0359 - val_loss: 0.0302\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 4: val_loss improved from 0.03024 to 0.02056, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0188 - val_loss: 0.0206\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.02056 to 0.01524, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0120 - val_loss: 0.0152\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01524 to 0.01224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0083 - val_loss: 0.0122\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.01224 to 0.01044, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 0.0063 - val_loss: 0.0104\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.01044 to 0.00904, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0052 - val_loss: 0.0090\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00904 to 0.00793, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 498ms/step - loss: 0.0044 - val_loss: 0.0079\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00793 to 0.00713, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0037 - val_loss: 0.0071\n",
      "finished training\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_286\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1716 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_858 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_286 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1717 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_859 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1718 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_860 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1719 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_572 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1720 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_573 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1721 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2468\n",
      "Epoch 1: val_loss improved from inf to 0.16160, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 494ms/step - loss: 0.2468 - val_loss: 0.1616\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0705\n",
      "Epoch 2: val_loss improved from 0.16160 to 0.05346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0705 - val_loss: 0.0535\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0338\n",
      "Epoch 3: val_loss improved from 0.05346 to 0.03029, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0338 - val_loss: 0.0303\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.03029 to 0.01992, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0194 - val_loss: 0.0199\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01992 to 0.01395, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.0122 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 6: val_loss improved from 0.01395 to 0.01084, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0085 - val_loss: 0.0108\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.01084 to 0.00836, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00836 to 0.00690, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0047 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00690 to 0.00610, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00610 to 0.00551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0034 - val_loss: 0.0055\n",
      "finished training\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_287\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1722 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_861 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_287 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1723 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_862 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1724 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_863 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1725 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_574 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1726 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_575 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1727 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1877\n",
      "Epoch 1: val_loss improved from inf to 0.06951, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.1877 - val_loss: 0.0695\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0416\n",
      "Epoch 2: val_loss improved from 0.06951 to 0.03066, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0416 - val_loss: 0.0307\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 3: val_loss improved from 0.03066 to 0.01648, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0195 - val_loss: 0.0165\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 4: val_loss improved from 0.01648 to 0.01131, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01131 to 0.00857, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00857 to 0.00672, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00672 to 0.00541, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00541 to 0.00448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00448 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00387 to 0.00347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_288\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1728 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_864 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_288 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1729 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_865 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1730 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_866 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1731 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_576 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1732 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_577 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1733 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2168\n",
      "Epoch 1: val_loss improved from inf to 0.09036, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.2168 - val_loss: 0.0904\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0536\n",
      "Epoch 2: val_loss improved from 0.09036 to 0.03668, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0536 - val_loss: 0.0367\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 3: val_loss improved from 0.03668 to 0.01675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0239 - val_loss: 0.0167\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 4: val_loss improved from 0.01675 to 0.01058, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0132 - val_loss: 0.0106\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01058 to 0.00702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00702 to 0.00494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00494 to 0.00378, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00378 to 0.00317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00317 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00280 to 0.00258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_289\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1734 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_867 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_289 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1735 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_868 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1736 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_869 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1737 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_578 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1738 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_579 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1739 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2717\n",
      "Epoch 1: val_loss improved from inf to 0.16786, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 444ms/step - loss: 0.2717 - val_loss: 0.1679\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0757\n",
      "Epoch 2: val_loss improved from 0.16786 to 0.03823, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0757 - val_loss: 0.0382\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 3: val_loss improved from 0.03823 to 0.01935, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0284 - val_loss: 0.0194\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.01935 to 0.01082, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01082 to 0.00595, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00595 to 0.00382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00382 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00288 to 0.00245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00245 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00218 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_290\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1740 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_870 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_290 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1741 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_871 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1742 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_872 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1743 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_580 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1744 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_581 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1745 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2110\n",
      "Epoch 1: val_loss improved from inf to 0.07467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 431ms/step - loss: 0.2110 - val_loss: 0.0747\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0574\n",
      "Epoch 2: val_loss improved from 0.07467 to 0.03728, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0574 - val_loss: 0.0373\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 3: val_loss improved from 0.03728 to 0.01370, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0244 - val_loss: 0.0137\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 4: val_loss improved from 0.01370 to 0.00775, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.00775 to 0.00503, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0080 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00503 to 0.00362, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00362 to 0.00283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00283 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00237 to 0.00207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00207 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 539ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_291\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1746 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_873 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_291 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1747 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_874 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1748 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_875 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1749 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_582 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1750 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_583 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1751 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2749\n",
      "Epoch 1: val_loss improved from inf to 0.14458, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.2749 - val_loss: 0.1446\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0831\n",
      "Epoch 2: val_loss improved from 0.14458 to 0.04255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0831 - val_loss: 0.0425\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.04255 to 0.01691, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0294 - val_loss: 0.0169\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01691 to 0.00843, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0141 - val_loss: 0.0084\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 5: val_loss improved from 0.00843 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00499 to 0.00355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00355 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00277 to 0.00228, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00228 to 0.00203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00203 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_292\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1752 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_876 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_292 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1753 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_877 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1754 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_878 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1755 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_584 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1756 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_585 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1757 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2846\n",
      "Epoch 1: val_loss improved from inf to 0.16341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.2846 - val_loss: 0.1634\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0856\n",
      "Epoch 2: val_loss improved from 0.16341 to 0.03783, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0856 - val_loss: 0.0378\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 3: val_loss improved from 0.03783 to 0.01888, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0284 - val_loss: 0.0189\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.01888 to 0.00943, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0157 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.00943 to 0.00498, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00498 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00321 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00257 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00224 to 0.00201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00201 to 0.00183, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_293\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1758 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_879 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_293 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1759 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_880 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1760 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_881 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1761 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_586 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1762 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_587 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1763 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2988\n",
      "Epoch 1: val_loss improved from inf to 0.15189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.2988 - val_loss: 0.1519\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0780\n",
      "Epoch 2: val_loss improved from 0.15189 to 0.03928, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0780 - val_loss: 0.0393\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 3: val_loss improved from 0.03928 to 0.02003, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0302 - val_loss: 0.0200\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02003 to 0.01078, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01078 to 0.00711, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00711 to 0.00518, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00518 to 0.00389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00389 to 0.00309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00309 to 0.00261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00261 to 0.00228, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_294\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1764 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_882 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_294 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1765 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_883 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1766 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_884 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1767 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_588 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1768 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_589 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1769 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3182\n",
      "Epoch 1: val_loss improved from inf to 0.24012, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 403ms/step - loss: 0.3182 - val_loss: 0.2401\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1353\n",
      "Epoch 2: val_loss improved from 0.24012 to 0.05474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.1353 - val_loss: 0.0547\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0372\n",
      "Epoch 3: val_loss improved from 0.05474 to 0.02239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0372 - val_loss: 0.0224\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02239 to 0.01067, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0162 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01067 to 0.00551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00551 to 0.00379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00379 to 0.00304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00304 to 0.00267, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00267 to 0.00244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00244 to 0.00227, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_295\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1770 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_885 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_295 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1771 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_886 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1772 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_887 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1773 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_590 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1774 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_591 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1775 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3361\n",
      "Epoch 1: val_loss improved from inf to 0.28481, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.3361 - val_loss: 0.2848\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1331\n",
      "Epoch 2: val_loss improved from 0.28481 to 0.04237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.1331 - val_loss: 0.0424\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.04237 to 0.02123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0291 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.02123 to 0.01280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0149 - val_loss: 0.0128\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01280 to 0.00910, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00910 to 0.00760, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00760 to 0.00651, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00651 to 0.00563, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00563 to 0.00494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00494 to 0.00441, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_296\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1776 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_888 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_296 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1777 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_889 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1778 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_890 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1779 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_592 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1780 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_593 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1781 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3259\n",
      "Epoch 1: val_loss improved from inf to 0.29762, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.3259 - val_loss: 0.2976\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1373\n",
      "Epoch 2: val_loss improved from 0.29762 to 0.05739, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.1373 - val_loss: 0.0574\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0401\n",
      "Epoch 3: val_loss improved from 0.05739 to 0.03221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0401 - val_loss: 0.0322\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 4: val_loss improved from 0.03221 to 0.01928, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0210 - val_loss: 0.0193\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 5: val_loss improved from 0.01928 to 0.01244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.01244 to 0.00874, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00874 to 0.00688, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00688 to 0.00587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00587 to 0.00521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00521 to 0.00475, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_297\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1782 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_891 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_297 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1783 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_892 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1784 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_893 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1785 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_594 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1786 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_595 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1787 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2847\n",
      "Epoch 1: val_loss improved from inf to 0.21458, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.2847 - val_loss: 0.2146\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1005\n",
      "Epoch 2: val_loss improved from 0.21458 to 0.07520, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.1005 - val_loss: 0.0752\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0549\n",
      "Epoch 3: val_loss improved from 0.07520 to 0.04700, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0549 - val_loss: 0.0470\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 4: val_loss improved from 0.04700 to 0.02941, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0315 - val_loss: 0.0294\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0201\n",
      "Epoch 5: val_loss improved from 0.02941 to 0.02097, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0201 - val_loss: 0.0210\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 6: val_loss improved from 0.02097 to 0.01542, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0135 - val_loss: 0.0154\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 7: val_loss improved from 0.01542 to 0.01191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 8: val_loss improved from 0.01191 to 0.00933, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00933 to 0.00761, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0049 - val_loss: 0.0076\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00761 to 0.00665, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0040 - val_loss: 0.0067\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_298\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1788 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_894 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_298 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1789 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_895 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1790 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_896 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1791 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_596 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1792 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_597 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1793 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2887\n",
      "Epoch 1: val_loss improved from inf to 0.22465, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 404ms/step - loss: 0.2887 - val_loss: 0.2247\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0811\n",
      "Epoch 2: val_loss improved from 0.22465 to 0.04320, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0811 - val_loss: 0.0432\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 3: val_loss improved from 0.04320 to 0.02336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0273 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 4: val_loss improved from 0.02336 to 0.01622, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01622 to 0.01244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.01244 to 0.01035, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.01035 to 0.00907, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0064 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00907 to 0.00811, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00811 to 0.00724, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0048 - val_loss: 0.0072\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00724 to 0.00651, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0042 - val_loss: 0.0065\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_299\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1794 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_897 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_299 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1795 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_898 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1796 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_899 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1797 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_598 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1798 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_599 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1799 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1917\n",
      "Epoch 1: val_loss improved from inf to 0.06867, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.1917 - val_loss: 0.0687\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0495\n",
      "Epoch 2: val_loss improved from 0.06867 to 0.03880, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0495 - val_loss: 0.0388\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0281\n",
      "Epoch 3: val_loss improved from 0.03880 to 0.02117, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0281 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.02117 to 0.01171, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01171 to 0.00783, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00783 to 0.00596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0058 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00596 to 0.00476, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00476 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00410 to 0.00370, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00370 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_300\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1800 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_900 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_300 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1801 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_901 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1802 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_902 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1803 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_600 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1804 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_601 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1805 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2001\n",
      "Epoch 1: val_loss improved from inf to 0.05679, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.2001 - val_loss: 0.0568\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0396\n",
      "Epoch 2: val_loss improved from 0.05679 to 0.02409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0396 - val_loss: 0.0241\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 3: val_loss improved from 0.02409 to 0.01278, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0191 - val_loss: 0.0128\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 4: val_loss improved from 0.01278 to 0.00811, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 5: val_loss improved from 0.00811 to 0.00568, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00568 to 0.00421, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00421 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00344 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00298 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00269 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_301\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1806 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_903 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_301 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1807 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_904 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1808 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_905 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1809 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_602 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1810 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_603 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1811 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2738\n",
      "Epoch 1: val_loss improved from inf to 0.13930, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 404ms/step - loss: 0.2738 - val_loss: 0.1393\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0568\n",
      "Epoch 2: val_loss improved from 0.13930 to 0.02234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0568 - val_loss: 0.0223\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 3: val_loss improved from 0.02234 to 0.01151, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0187 - val_loss: 0.0115\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 4: val_loss improved from 0.01151 to 0.00732, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.00732 to 0.00515, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00515 to 0.00393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00393 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00312 to 0.00255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00255 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00221 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_302\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1812 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_906 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_302 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1813 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_907 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1814 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_908 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1815 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_604 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1816 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_605 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1817 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2834\n",
      "Epoch 1: val_loss improved from inf to 0.16548, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.2834 - val_loss: 0.1655\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0905\n",
      "Epoch 2: val_loss improved from 0.16548 to 0.03934, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0905 - val_loss: 0.0393\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.03934 to 0.01479, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0291 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 4: val_loss improved from 0.01479 to 0.00754, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0137 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.00754 to 0.00447, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00447 to 0.00297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00297 to 0.00228, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00228 to 0.00198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00198 to 0.00175, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00175 to 0.00157, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_303\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1818 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_909 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_303 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1819 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_910 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1820 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_911 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1821 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_606 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1822 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_607 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1823 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3472\n",
      "Epoch 1: val_loss improved from inf to 0.23760, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.3472 - val_loss: 0.2376\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1526\n",
      "Epoch 2: val_loss improved from 0.23760 to 0.05357, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.1526 - val_loss: 0.0536\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0357\n",
      "Epoch 3: val_loss improved from 0.05357 to 0.01831, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0357 - val_loss: 0.0183\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.01831 to 0.01026, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0176 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01026 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0107 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00629 to 0.00440, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00440 to 0.00336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00336 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00269 to 0.00228, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00228 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_304\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1824 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_912 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_304 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1825 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_913 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1826 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_914 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1827 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_608 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1828 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_609 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1829 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2199\n",
      "Epoch 1: val_loss improved from inf to 0.09024, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2199 - val_loss: 0.0902\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0578\n",
      "Epoch 2: val_loss improved from 0.09024 to 0.03255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0578 - val_loss: 0.0325\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 3: val_loss improved from 0.03255 to 0.01534, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0257 - val_loss: 0.0153\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 4: val_loss improved from 0.01534 to 0.00749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00749 to 0.00403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 6: val_loss improved from 0.00403 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss improved from 0.00280 to 0.00235, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00235 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00209 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00187 to 0.00168, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_305\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1830 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_915 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_305 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1831 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_916 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1832 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_917 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1833 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_610 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1834 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_611 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1835 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3406\n",
      "Epoch 1: val_loss improved from inf to 0.25755, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.3406 - val_loss: 0.2575\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1870\n",
      "Epoch 2: val_loss improved from 0.25755 to 0.07226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.1870 - val_loss: 0.0723\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0544\n",
      "Epoch 3: val_loss improved from 0.07226 to 0.02890, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0544 - val_loss: 0.0289\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.02890 to 0.01074, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0200 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01074 to 0.00573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00573 to 0.00414, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00414 to 0.00333, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00333 to 0.00283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00283 to 0.00249, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00249 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_306\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1836 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_918 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_306 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1837 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_919 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1838 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_920 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1839 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_612 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1840 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_613 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1841 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2655\n",
      "Epoch 1: val_loss improved from inf to 0.12040, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 403ms/step - loss: 0.2655 - val_loss: 0.1204\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0519\n",
      "Epoch 2: val_loss improved from 0.12040 to 0.02750, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0519 - val_loss: 0.0275\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 3: val_loss improved from 0.02750 to 0.01706, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0226 - val_loss: 0.0171\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.01706 to 0.01093, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0149 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01093 to 0.00736, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00736 to 0.00550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00550 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00429 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00345 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00295 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_307\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1842 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_921 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_307 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1843 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_922 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1844 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_923 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1845 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_614 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1846 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_615 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1847 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2776\n",
      "Epoch 1: val_loss improved from inf to 0.17864, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.2776 - val_loss: 0.1786\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0742\n",
      "Epoch 2: val_loss improved from 0.17864 to 0.03596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0742 - val_loss: 0.0360\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 3: val_loss improved from 0.03596 to 0.01792, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0252 - val_loss: 0.0179\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01792 to 0.01032, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01032 to 0.00711, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00711 to 0.00560, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00560 to 0.00468, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00468 to 0.00404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00404 to 0.00358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00358 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_308\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1848 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_924 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_308 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1849 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_925 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1850 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_926 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1851 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_616 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1852 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_617 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1853 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2327\n",
      "Epoch 1: val_loss improved from inf to 0.12399, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.2327 - val_loss: 0.1240\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0604\n",
      "Epoch 2: val_loss improved from 0.12399 to 0.04515, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0604 - val_loss: 0.0452\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 3: val_loss improved from 0.04515 to 0.02531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0312 - val_loss: 0.0253\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss improved from 0.02531 to 0.01399, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0159 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01399 to 0.00930, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0085 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.00930 to 0.00731, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00731 to 0.00634, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00634 to 0.00570, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00570 to 0.00521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00521 to 0.00477, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_309\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1854 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_927 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_309 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1855 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_928 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1856 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_929 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1857 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_618 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1858 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_619 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1859 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2377\n",
      "Epoch 1: val_loss improved from inf to 0.11951, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 406ms/step - loss: 0.2377 - val_loss: 0.1195\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0431\n",
      "Epoch 2: val_loss improved from 0.11951 to 0.03246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0431 - val_loss: 0.0325\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0204\n",
      "Epoch 3: val_loss improved from 0.03246 to 0.02068, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0204 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 4: val_loss improved from 0.02068 to 0.01487, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0127 - val_loss: 0.0149\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01487 to 0.01157, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.01157 to 0.00960, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00960 to 0.00806, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0051 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00806 to 0.00709, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0041 - val_loss: 0.0071\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00709 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00629 to 0.00569, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0031 - val_loss: 0.0057\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_310\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1860 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_930 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_310 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1861 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_931 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1862 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_932 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1863 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_620 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1864 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_621 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1865 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1487\n",
      "Epoch 1: val_loss improved from inf to 0.06729, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.1487 - val_loss: 0.0673\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0460\n",
      "Epoch 2: val_loss improved from 0.06729 to 0.03596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0460 - val_loss: 0.0360\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 3: val_loss improved from 0.03596 to 0.02034, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 392ms/step - loss: 0.0216 - val_loss: 0.0203\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 4: val_loss improved from 0.02034 to 0.01370, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0125 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01370 to 0.01012, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0080 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.01012 to 0.00801, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00801 to 0.00689, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00689 to 0.00619, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00619 to 0.00577, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00577 to 0.00542, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "finished training\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_311\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1866 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_933 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_311 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1867 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_934 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1868 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_935 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1869 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_622 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1870 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_623 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1871 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2883\n",
      "Epoch 1: val_loss improved from inf to 0.19797, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.2883 - val_loss: 0.1980\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0800\n",
      "Epoch 2: val_loss improved from 0.19797 to 0.04398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0800 - val_loss: 0.0440\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Epoch 3: val_loss improved from 0.04398 to 0.02140, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0295 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.02140 to 0.01189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.01189 to 0.00706, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00706 to 0.00535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00535 to 0.00451, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00451 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00405 to 0.00372, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00372 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_312\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1872 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_936 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_312 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1873 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_937 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1874 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_938 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1875 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_624 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1876 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_625 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1877 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2745\n",
      "Epoch 1: val_loss improved from inf to 0.15389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 406ms/step - loss: 0.2745 - val_loss: 0.1539\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0692\n",
      "Epoch 2: val_loss improved from 0.15389 to 0.04213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0692 - val_loss: 0.0421\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 3: val_loss improved from 0.04213 to 0.02038, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0302 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02038 to 0.01182, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01182 to 0.00824, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0100 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00824 to 0.00619, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 393ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00619 to 0.00492, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00492 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00410 to 0.00353, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00353 to 0.00311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_313\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1878 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_939 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_313 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1879 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_940 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1880 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_941 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1881 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_626 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1882 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_627 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1883 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3072\n",
      "Epoch 1: val_loss improved from inf to 0.22725, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.3072 - val_loss: 0.2273\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1274\n",
      "Epoch 2: val_loss improved from 0.22725 to 0.06268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.1274 - val_loss: 0.0627\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0458\n",
      "Epoch 3: val_loss improved from 0.06268 to 0.02992, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0458 - val_loss: 0.0299\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.02992 to 0.01566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0234 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 5: val_loss improved from 0.01566 to 0.00953, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0139 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 6: val_loss improved from 0.00953 to 0.00659, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 7: val_loss improved from 0.00659 to 0.00484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00484 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00364 to 0.00300, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 398ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00300 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_314\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1884 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_942 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_314 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1885 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_943 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1886 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_944 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1887 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_628 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1888 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_629 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1889 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2268\n",
      "Epoch 1: val_loss improved from inf to 0.09450, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 405ms/step - loss: 0.2268 - val_loss: 0.0945\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0498\n",
      "Epoch 2: val_loss improved from 0.09450 to 0.02641, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0498 - val_loss: 0.0264\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 3: val_loss improved from 0.02641 to 0.01233, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0210 - val_loss: 0.0123\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 4: val_loss improved from 0.01233 to 0.00749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.00749 to 0.00490, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00490 to 0.00338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 399ms/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00338 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00248 to 0.00203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00203 to 0.00177, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00177 to 0.00158, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_315\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1890 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_945 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_315 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1891 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_946 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1892 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_947 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1893 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_630 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1894 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_631 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1895 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2028\n",
      "Epoch 1: val_loss improved from inf to 0.09052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 408ms/step - loss: 0.2028 - val_loss: 0.0905\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0717\n",
      "Epoch 2: val_loss improved from 0.09052 to 0.04275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0717 - val_loss: 0.0428\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 3: val_loss improved from 0.04275 to 0.01585, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0292 - val_loss: 0.0158\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.01585 to 0.00927, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 394ms/step - loss: 0.0145 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.00927 to 0.00611, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0096 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00611 to 0.00434, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00434 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00314 to 0.00241, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00241 to 0.00199, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00199 to 0.00173, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_316\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1896 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_948 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_316 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1897 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_949 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1898 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_950 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1899 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_632 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1900 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_633 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1901 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2021\n",
      "Epoch 1: val_loss improved from inf to 0.06848, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 410ms/step - loss: 0.2021 - val_loss: 0.0685\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0526\n",
      "Epoch 2: val_loss improved from 0.06848 to 0.03534, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0526 - val_loss: 0.0353\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 3: val_loss improved from 0.03534 to 0.01849, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0284 - val_loss: 0.0185\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 4: val_loss improved from 0.01849 to 0.00964, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0160 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.00964 to 0.00568, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00568 to 0.00392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00392 to 0.00301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00301 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00252 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00220 to 0.00195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 395ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_317\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1902 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_951 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_317 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1903 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_952 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1904 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_953 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1905 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_634 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1906 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_635 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1907 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3391\n",
      "Epoch 1: val_loss improved from inf to 0.25673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 409ms/step - loss: 0.3391 - val_loss: 0.2567\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1720\n",
      "Epoch 2: val_loss improved from 0.25673 to 0.05398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.1720 - val_loss: 0.0540\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 3: val_loss improved from 0.05398 to 0.02773, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0424 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0223\n",
      "Epoch 4: val_loss improved from 0.02773 to 0.01601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0223 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 5: val_loss improved from 0.01601 to 0.00981, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.00981 to 0.00622, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00622 to 0.00411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00411 to 0.00292, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00292 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00243 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_318\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1908 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_954 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_318 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1909 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_955 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1910 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_956 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1911 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_636 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1912 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_637 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1913 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2506\n",
      "Epoch 1: val_loss improved from inf to 0.11456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 407ms/step - loss: 0.2506 - val_loss: 0.1146\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0524\n",
      "Epoch 2: val_loss improved from 0.11456 to 0.02993, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0524 - val_loss: 0.0299\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0217\n",
      "Epoch 3: val_loss improved from 0.02993 to 0.01528, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0217 - val_loss: 0.0153\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 4: val_loss improved from 0.01528 to 0.00845, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00845 to 0.00541, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0074 - val_loss: 0.0054\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00541 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00405 to 0.00328, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00328 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00281 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00248 to 0.00226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_319\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1914 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_957 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_319 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1915 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_958 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1916 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_959 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1917 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_638 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1918 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_639 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1919 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2773\n",
      "Epoch 1: val_loss improved from inf to 0.19230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 427ms/step - loss: 0.2773 - val_loss: 0.1923\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0967\n",
      "Epoch 2: val_loss improved from 0.19230 to 0.06091, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0967 - val_loss: 0.0609\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0387\n",
      "Epoch 3: val_loss improved from 0.06091 to 0.02621, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0387 - val_loss: 0.0262\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02621 to 0.01394, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0179 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01394 to 0.00889, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00889 to 0.00659, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00659 to 0.00504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00504 to 0.00413, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00413 to 0.00360, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00360 to 0.00327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_320\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1920 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_960 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_320 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1921 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_961 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1922 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_962 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1923 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_640 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1924 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_641 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1925 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3095\n",
      "Epoch 1: val_loss improved from inf to 0.26864, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 448ms/step - loss: 0.3095 - val_loss: 0.2686\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1134\n",
      "Epoch 2: val_loss improved from 0.26864 to 0.06761, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.1134 - val_loss: 0.0676\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0464\n",
      "Epoch 3: val_loss improved from 0.06761 to 0.03728, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0464 - val_loss: 0.0373\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 4: val_loss improved from 0.03728 to 0.02303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0248 - val_loss: 0.0230\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 5: val_loss improved from 0.02303 to 0.01526, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01526 to 0.01049, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 525ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.01049 to 0.00780, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00780 to 0.00622, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00622 to 0.00529, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00529 to 0.00471, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "finished training\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_321\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1926 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_963 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_321 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1927 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_964 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1928 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_965 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1929 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_642 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1930 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_643 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1931 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2370\n",
      "Epoch 1: val_loss improved from inf to 0.13098, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 525ms/step - loss: 0.2370 - val_loss: 0.1310\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0633\n",
      "Epoch 2: val_loss improved from 0.13098 to 0.05161, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0633 - val_loss: 0.0516\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 3: val_loss improved from 0.05161 to 0.03082, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0328 - val_loss: 0.0308\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 4: val_loss improved from 0.03082 to 0.01923, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.0188 - val_loss: 0.0192\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01923 to 0.01276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.01276 to 0.00968, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0069 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00968 to 0.00811, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0052 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00811 to 0.00721, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0043 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00721 to 0.00650, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00650 to 0.00593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.0034 - val_loss: 0.0059\n",
      "finished training\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_322\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1932 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_966 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_322 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1933 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_967 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1934 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_968 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1935 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_644 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1936 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_645 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1937 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3301\n",
      "Epoch 1: val_loss improved from inf to 0.33037, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.3301 - val_loss: 0.3304\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1292\n",
      "Epoch 2: val_loss improved from 0.33037 to 0.05330, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 519ms/step - loss: 0.1292 - val_loss: 0.0533\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0325\n",
      "Epoch 3: val_loss improved from 0.05330 to 0.03017, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0325 - val_loss: 0.0302\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.03017 to 0.02079, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0200 - val_loss: 0.0208\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss improved from 0.02079 to 0.01437, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 526ms/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01437 to 0.01049, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 520ms/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.01049 to 0.00815, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00815 to 0.00661, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00661 to 0.00569, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00569 to 0.00511, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0034 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_323\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1938 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_969 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_323 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1939 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_970 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1940 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_971 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1941 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_646 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1942 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_647 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1943 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2823\n",
      "Epoch 1: val_loss improved from inf to 0.22297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 520ms/step - loss: 0.2823 - val_loss: 0.2230\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0946\n",
      "Epoch 2: val_loss improved from 0.22297 to 0.05508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0946 - val_loss: 0.0551\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0358\n",
      "Epoch 3: val_loss improved from 0.05508 to 0.02563, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0358 - val_loss: 0.0256\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.02563 to 0.01409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0163 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01409 to 0.00966, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 522ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00966 to 0.00705, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00705 to 0.00534, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00534 to 0.00423, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00423 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00364 to 0.00325, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_324\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1944 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_972 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_324 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1945 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_973 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1946 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_974 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1947 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_648 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1948 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_649 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1949 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2545\n",
      "Epoch 1: val_loss improved from inf to 0.13114, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 516ms/step - loss: 0.2545 - val_loss: 0.1311\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0688\n",
      "Epoch 2: val_loss improved from 0.13114 to 0.05042, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0688 - val_loss: 0.0504\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 3: val_loss improved from 0.05042 to 0.02989, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0369 - val_loss: 0.0299\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.02989 to 0.02002, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0233 - val_loss: 0.0200\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 5: val_loss improved from 0.02002 to 0.01281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0155 - val_loss: 0.0128\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 6: val_loss improved from 0.01281 to 0.00781, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00781 to 0.00503, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00503 to 0.00395, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00395 to 0.00338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00338 to 0.00297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_325\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1950 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_975 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_325 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1951 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_976 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1952 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_977 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1953 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_650 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1954 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_651 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1955 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1534\n",
      "Epoch 1: val_loss improved from inf to 0.05629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 430ms/step - loss: 0.1534 - val_loss: 0.0563\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 2: val_loss improved from 0.05629 to 0.02881, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0422 - val_loss: 0.0288\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 3: val_loss improved from 0.02881 to 0.01586, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0214 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 4: val_loss improved from 0.01586 to 0.00975, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.00975 to 0.00589, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00589 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00397 to 0.00308, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00308 to 0.00265, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00265 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00239 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_326\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1956 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_978 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_326 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1957 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_979 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1958 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_980 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1959 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_652 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1960 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_653 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1961 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2659\n",
      "Epoch 1: val_loss improved from inf to 0.13436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.2659 - val_loss: 0.1344\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0691\n",
      "Epoch 2: val_loss improved from 0.13436 to 0.03894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0691 - val_loss: 0.0389\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0277\n",
      "Epoch 3: val_loss improved from 0.03894 to 0.01579, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0277 - val_loss: 0.0158\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 4: val_loss improved from 0.01579 to 0.00786, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 403ms/step - loss: 0.0129 - val_loss: 0.0079\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.00786 to 0.00479, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00479 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00354 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00288 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00243 to 0.00213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00213 to 0.00191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_327\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1962 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_981 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_327 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1963 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_982 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1964 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_983 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1965 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_654 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1966 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_655 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1967 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2951\n",
      "Epoch 1: val_loss improved from inf to 0.17639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 518ms/step - loss: 0.2951 - val_loss: 0.1764\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1105\n",
      "Epoch 2: val_loss improved from 0.17639 to 0.06427, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.1105 - val_loss: 0.0643\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0477\n",
      "Epoch 3: val_loss improved from 0.06427 to 0.03162, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0477 - val_loss: 0.0316\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 4: val_loss improved from 0.03162 to 0.01411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0228 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 5: val_loss improved from 0.01411 to 0.00707, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00707 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00397 to 0.00289, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00289 to 0.00244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00244 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00215 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_328\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1968 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_984 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_328 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1969 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_985 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1970 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_986 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1971 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_656 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1972 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_657 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1973 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3084\n",
      "Epoch 1: val_loss improved from inf to 0.19121, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 473ms/step - loss: 0.3084 - val_loss: 0.1912\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1186\n",
      "Epoch 2: val_loss improved from 0.19121 to 0.06429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.1186 - val_loss: 0.0643\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 3: val_loss improved from 0.06429 to 0.02028, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0415 - val_loss: 0.0203\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.02028 to 0.00912, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.0145 - val_loss: 0.0091\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.00912 to 0.00519, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00519 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00346 to 0.00272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00272 to 0.00232, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00232 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 433ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00210 to 0.00193, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_329\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1974 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_987 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_329 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1975 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_988 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1976 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_989 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1977 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_658 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1978 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_659 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1979 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2617\n",
      "Epoch 1: val_loss improved from inf to 0.11661, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 438ms/step - loss: 0.2617 - val_loss: 0.1166\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0515\n",
      "Epoch 2: val_loss improved from 0.11661 to 0.02771, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0515 - val_loss: 0.0277\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0212\n",
      "Epoch 3: val_loss improved from 0.02771 to 0.01448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 430ms/step - loss: 0.0212 - val_loss: 0.0145\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 4: val_loss improved from 0.01448 to 0.00748, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 5: val_loss improved from 0.00748 to 0.00424, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0068 - val_loss: 0.0042\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 6: val_loss improved from 0.00424 to 0.00319, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00319 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00268 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 442ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00237 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00215 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_330\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1980 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_990 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_330 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1981 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_991 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1982 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_992 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1983 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_660 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1984 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_661 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1985 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2869\n",
      "Epoch 1: val_loss improved from inf to 0.17960, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 498ms/step - loss: 0.2869 - val_loss: 0.1796\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0890\n",
      "Epoch 2: val_loss improved from 0.17960 to 0.04724, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0890 - val_loss: 0.0472\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0333\n",
      "Epoch 3: val_loss improved from 0.04724 to 0.02226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0333 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02226 to 0.01052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0162 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01052 to 0.00662, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 443ms/step - loss: 0.0087 - val_loss: 0.0066\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00662 to 0.00511, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00511 to 0.00413, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00413 to 0.00350, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00350 to 0.00307, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00307 to 0.00276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_331\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1986 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_993 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_331 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1987 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_994 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1988 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_995 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1989 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_662 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1990 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_663 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1991 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2852\n",
      "Epoch 1: val_loss improved from inf to 0.19635, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 497ms/step - loss: 0.2852 - val_loss: 0.1964\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1071\n",
      "Epoch 2: val_loss improved from 0.19635 to 0.07491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.1071 - val_loss: 0.0749\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0548\n",
      "Epoch 3: val_loss improved from 0.07491 to 0.03874, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0548 - val_loss: 0.0387\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 4: val_loss improved from 0.03874 to 0.02010, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0268 - val_loss: 0.0201\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 5: val_loss improved from 0.02010 to 0.01170, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0143 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01170 to 0.00749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00749 to 0.00562, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00562 to 0.00468, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00468 to 0.00409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00409 to 0.00367, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 491ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_332\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1992 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_996 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_332 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1993 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_997 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1994 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_998 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1995 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_664 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1996 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_665 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1997 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2956\n",
      "Epoch 1: val_loss improved from inf to 0.24766, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.2956 - val_loss: 0.2477\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1072\n",
      "Epoch 2: val_loss improved from 0.24766 to 0.06245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.1072 - val_loss: 0.0624\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0400\n",
      "Epoch 3: val_loss improved from 0.06245 to 0.02894, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 426ms/step - loss: 0.0400 - val_loss: 0.0289\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 4: val_loss improved from 0.02894 to 0.01590, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0174 - val_loss: 0.0159\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01590 to 0.01123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.01123 to 0.00898, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0071 - val_loss: 0.0090\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00898 to 0.00747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00747 to 0.00643, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00643 to 0.00573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00573 to 0.00527, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_333\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1998 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_999 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_333 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1999 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1000 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2000 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1001 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2001 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_666 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2002 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_667 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2003 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2612\n",
      "Epoch 1: val_loss improved from inf to 0.17016, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.2612 - val_loss: 0.1702\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0756\n",
      "Epoch 2: val_loss improved from 0.17016 to 0.05762, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0756 - val_loss: 0.0576\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0383\n",
      "Epoch 3: val_loss improved from 0.05762 to 0.03123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0383 - val_loss: 0.0312\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0192\n",
      "Epoch 4: val_loss improved from 0.03123 to 0.01887, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 439ms/step - loss: 0.0192 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01887 to 0.01319, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 436ms/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.01319 to 0.01031, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0072 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.01031 to 0.00853, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 0.0054 - val_loss: 0.0085\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00853 to 0.00725, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0043 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00725 to 0.00630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00630 to 0.00567, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0031 - val_loss: 0.0057\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_334\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2004 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1002 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_334 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2005 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1003 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2006 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1004 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2007 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_668 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2008 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_669 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2009 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2211\n",
      "Epoch 1: val_loss improved from inf to 0.07461, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.2211 - val_loss: 0.0746\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0459\n",
      "Epoch 2: val_loss improved from 0.07461 to 0.03430, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0459 - val_loss: 0.0343\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 3: val_loss improved from 0.03430 to 0.01749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0209 - val_loss: 0.0175\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 4: val_loss improved from 0.01749 to 0.01177, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 5: val_loss improved from 0.01177 to 0.00904, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0071 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00904 to 0.00757, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00757 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0044 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00663 to 0.00593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00593 to 0.00540, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00540 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_335\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2010 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1005 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_335 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2011 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1006 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2012 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1007 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2013 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_670 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2014 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_671 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2015 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2959\n",
      "Epoch 1: val_loss improved from inf to 0.21649, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.2959 - val_loss: 0.2165\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0942\n",
      "Epoch 2: val_loss improved from 0.21649 to 0.05245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0942 - val_loss: 0.0524\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0378\n",
      "Epoch 3: val_loss improved from 0.05245 to 0.02630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0378 - val_loss: 0.0263\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 4: val_loss improved from 0.02630 to 0.01367, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0180 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01367 to 0.00851, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00851 to 0.00587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00587 to 0.00475, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00475 to 0.00420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00420 to 0.00384, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00384 to 0.00355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_336\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2016 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1008 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_336 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2017 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1009 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2018 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1010 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2019 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_672 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2020 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_673 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2021 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2649\n",
      "Epoch 1: val_loss improved from inf to 0.14142, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 451ms/step - loss: 0.2649 - val_loss: 0.1414\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0565\n",
      "Epoch 2: val_loss improved from 0.14142 to 0.02624, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0565 - val_loss: 0.0262\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 3: val_loss improved from 0.02624 to 0.01199, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0187 - val_loss: 0.0120\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 4: val_loss improved from 0.01199 to 0.00733, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0102 - val_loss: 0.0073\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 5: val_loss improved from 0.00733 to 0.00511, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00511 to 0.00399, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00399 to 0.00335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00335 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00298 to 0.00274, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00274 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_337\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2022 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1011 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_337 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2023 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1012 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2024 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1013 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2025 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_674 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2026 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_675 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2027 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3302\n",
      "Epoch 1: val_loss improved from inf to 0.24538, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.3302 - val_loss: 0.2454\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1429\n",
      "Epoch 2: val_loss improved from 0.24538 to 0.05591, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.1429 - val_loss: 0.0559\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 3: val_loss improved from 0.05591 to 0.02281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0403 - val_loss: 0.0228\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 4: val_loss improved from 0.02281 to 0.01288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0199 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01288 to 0.00791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.00791 to 0.00536, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00536 to 0.00406, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00406 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00324 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00269 to 0.00231, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_338\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2028 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1014 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_338 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2029 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1015 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2030 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1016 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2031 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_676 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2032 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_677 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2033 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2613\n",
      "Epoch 1: val_loss improved from inf to 0.11156, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 470ms/step - loss: 0.2613 - val_loss: 0.1116\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0588\n",
      "Epoch 2: val_loss improved from 0.11156 to 0.03301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0588 - val_loss: 0.0330\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 3: val_loss improved from 0.03301 to 0.01842, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0288 - val_loss: 0.0184\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 4: val_loss improved from 0.01842 to 0.01195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 5: val_loss improved from 0.01195 to 0.00747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.00747 to 0.00464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00464 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00295 to 0.00216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00216 to 0.00178, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 10: val_loss improved from 0.00178 to 0.00155, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_339\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2034 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1017 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_339 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2035 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1018 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2036 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1019 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2037 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_678 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2038 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_679 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2039 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2848\n",
      "Epoch 1: val_loss improved from inf to 0.16226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 471ms/step - loss: 0.2848 - val_loss: 0.1623\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0840\n",
      "Epoch 2: val_loss improved from 0.16226 to 0.03398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0840 - val_loss: 0.0340\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 3: val_loss improved from 0.03398 to 0.01927, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0302 - val_loss: 0.0193\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0184\n",
      "Epoch 4: val_loss improved from 0.01927 to 0.01142, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 405ms/step - loss: 0.0184 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01142 to 0.00730, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 6: val_loss improved from 0.00730 to 0.00509, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00509 to 0.00375, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00375 to 0.00279, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00279 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00224 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0034 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_340\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2040 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1020 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_340 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2041 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1021 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2042 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1022 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2043 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_680 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2044 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_681 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2045 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1987\n",
      "Epoch 1: val_loss improved from inf to 0.06633, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.1987 - val_loss: 0.0663\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0487\n",
      "Epoch 2: val_loss improved from 0.06633 to 0.02680, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0487 - val_loss: 0.0268\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 3: val_loss improved from 0.02680 to 0.01087, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0195 - val_loss: 0.0109\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 4: val_loss improved from 0.01087 to 0.00645, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.00645 to 0.00448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.00448 to 0.00334, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00334 to 0.00259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 478ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00259 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00211 to 0.00180, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00180 to 0.00160, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 496ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_341\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2046 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1023 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_341 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2047 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1024 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2048 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1025 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2049 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_682 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2050 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_683 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2051 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2352\n",
      "Epoch 1: val_loss improved from inf to 0.10220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 519ms/step - loss: 0.2352 - val_loss: 0.1022\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0573\n",
      "Epoch 2: val_loss improved from 0.10220 to 0.03601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0573 - val_loss: 0.0360\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 3: val_loss improved from 0.03601 to 0.01901, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.0283 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 4: val_loss improved from 0.01901 to 0.01195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0170 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 5: val_loss improved from 0.01195 to 0.00734, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00734 to 0.00489, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00489 to 0.00356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00356 to 0.00287, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00287 to 0.00244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00244 to 0.00210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_342\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2052 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1026 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_342 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2053 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1027 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2054 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1028 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2055 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_684 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2056 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_685 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2057 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2639\n",
      "Epoch 1: val_loss improved from inf to 0.13725, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 453ms/step - loss: 0.2639 - val_loss: 0.1373\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0697\n",
      "Epoch 2: val_loss improved from 0.13725 to 0.04260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0697 - val_loss: 0.0426\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0318\n",
      "Epoch 3: val_loss improved from 0.04260 to 0.02242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 477ms/step - loss: 0.0318 - val_loss: 0.0224\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 4: val_loss improved from 0.02242 to 0.01420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0183 - val_loss: 0.0142\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01420 to 0.00960, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 6: val_loss improved from 0.00960 to 0.00669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 475ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00669 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00501 to 0.00396, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00396 to 0.00336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00336 to 0.00297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_343\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2058 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1029 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_343 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2059 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1030 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2060 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1031 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2061 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_686 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2062 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_687 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2063 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2594\n",
      "Epoch 1: val_loss improved from inf to 0.13143, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.2594 - val_loss: 0.1314\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0654\n",
      "Epoch 2: val_loss improved from 0.13143 to 0.04152, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0654 - val_loss: 0.0415\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0262\n",
      "Epoch 3: val_loss improved from 0.04152 to 0.01864, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0262 - val_loss: 0.0186\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 4: val_loss improved from 0.01864 to 0.01163, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01163 to 0.00822, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0088 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00822 to 0.00599, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 456ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00599 to 0.00470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00470 to 0.00394, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00394 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00345 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_344\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2064 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1032 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_344 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2065 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1033 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2066 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1034 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2067 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_688 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2068 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_689 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2069 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3235\n",
      "Epoch 1: val_loss improved from inf to 0.28488, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 516ms/step - loss: 0.3235 - val_loss: 0.2849\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1379\n",
      "Epoch 2: val_loss improved from 0.28488 to 0.08216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.1379 - val_loss: 0.0822\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0560\n",
      "Epoch 3: val_loss improved from 0.08216 to 0.03907, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0560 - val_loss: 0.0391\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0230\n",
      "Epoch 4: val_loss improved from 0.03907 to 0.01796, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0230 - val_loss: 0.0180\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 5: val_loss improved from 0.01796 to 0.01144, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.01144 to 0.00882, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0071 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00882 to 0.00743, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00743 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00663 to 0.00610, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00610 to 0.00567, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 541ms/step - loss: 0.0036 - val_loss: 0.0057\n",
      "finished training\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_345\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2070 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1035 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_345 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2071 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1036 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2072 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1037 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2073 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_690 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2074 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_691 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2075 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2698\n",
      "Epoch 1: val_loss improved from inf to 0.11921, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.2698 - val_loss: 0.1192\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0681\n",
      "Epoch 2: val_loss improved from 0.11921 to 0.05531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0681 - val_loss: 0.0553\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.05531 to 0.03057, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 0.0359 - val_loss: 0.0306\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.03057 to 0.01913, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01913 to 0.01207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 524ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01207 to 0.00899, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0066 - val_loss: 0.0090\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00899 to 0.00749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 519ms/step - loss: 0.0048 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00749 to 0.00664, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00664 to 0.00607, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00607 to 0.00565, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.0032 - val_loss: 0.0056\n",
      "finished training\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_346\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2076 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1038 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_346 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2077 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1039 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2078 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1040 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2079 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_692 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2080 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_693 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2081 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2563\n",
      "Epoch 1: val_loss improved from inf to 0.15414, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.2563 - val_loss: 0.1541\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0658\n",
      "Epoch 2: val_loss improved from 0.15414 to 0.04976, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 528ms/step - loss: 0.0658 - val_loss: 0.0498\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0351\n",
      "Epoch 3: val_loss improved from 0.04976 to 0.03148, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.0351 - val_loss: 0.0315\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0217\n",
      "Epoch 4: val_loss improved from 0.03148 to 0.01980, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0217 - val_loss: 0.0198\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01980 to 0.01248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.01248 to 0.00857, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0071 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00857 to 0.00712, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 0.0050 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00712 to 0.00625, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00625 to 0.00564, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00564 to 0.00519, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_347\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2082 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1041 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_347 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2083 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1042 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2084 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1043 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2085 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_694 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2086 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_695 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2087 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3128\n",
      "Epoch 1: val_loss improved from inf to 0.26449, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 514ms/step - loss: 0.3128 - val_loss: 0.2645\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1380\n",
      "Epoch 2: val_loss improved from 0.26449 to 0.08329, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.1380 - val_loss: 0.0833\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0601\n",
      "Epoch 3: val_loss improved from 0.08329 to 0.04163, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0601 - val_loss: 0.0416\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 4: val_loss improved from 0.04163 to 0.01979, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0284 - val_loss: 0.0198\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.01979 to 0.01060, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 521ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.01060 to 0.00706, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00706 to 0.00533, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00533 to 0.00436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00436 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00381 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 450ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_348\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2088 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1044 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_348 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2089 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1045 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2090 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1046 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2091 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_696 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2092 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_697 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2093 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3170\n",
      "Epoch 1: val_loss improved from inf to 0.24696, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.3170 - val_loss: 0.2470\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1410\n",
      "Epoch 2: val_loss improved from 0.24696 to 0.07657, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.1410 - val_loss: 0.0766\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0576\n",
      "Epoch 3: val_loss improved from 0.07657 to 0.03746, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 449ms/step - loss: 0.0576 - val_loss: 0.0375\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0256\n",
      "Epoch 4: val_loss improved from 0.03746 to 0.01667, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0256 - val_loss: 0.0167\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 5: val_loss improved from 0.01667 to 0.00908, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0133 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00908 to 0.00532, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00532 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00381 to 0.00307, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00307 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00269 to 0.00245, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_349\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2094 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1047 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_349 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2095 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1048 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2096 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1049 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2097 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_698 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2098 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_699 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2099 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2534\n",
      "Epoch 1: val_loss improved from inf to 0.12648, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.2534 - val_loss: 0.1265\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0774\n",
      "Epoch 2: val_loss improved from 0.12648 to 0.04421, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0774 - val_loss: 0.0442\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0326\n",
      "Epoch 3: val_loss improved from 0.04421 to 0.02185, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0326 - val_loss: 0.0219\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0190\n",
      "Epoch 4: val_loss improved from 0.02185 to 0.01195, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0190 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01195 to 0.00632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0105 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00632 to 0.00421, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00421 to 0.00333, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00333 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00288 to 0.00261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00261 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_350\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2100 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1050 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_350 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2101 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1051 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2102 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1052 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2103 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_700 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2104 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_701 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2105 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2922\n",
      "Epoch 1: val_loss improved from inf to 0.17464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.2922 - val_loss: 0.1746\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0929\n",
      "Epoch 2: val_loss improved from 0.17464 to 0.04533, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0929 - val_loss: 0.0453\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0334\n",
      "Epoch 3: val_loss improved from 0.04533 to 0.01729, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0334 - val_loss: 0.0173\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 4: val_loss improved from 0.01729 to 0.00869, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0147 - val_loss: 0.0087\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.00869 to 0.00522, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00522 to 0.00376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00376 to 0.00302, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00302 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00256 to 0.00224, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00224 to 0.00200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_351\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2106 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1053 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_351 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2107 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1054 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2108 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1055 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2109 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_702 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2110 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_703 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2111 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3059\n",
      "Epoch 1: val_loss improved from inf to 0.16155, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.3059 - val_loss: 0.1616\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0917\n",
      "Epoch 2: val_loss improved from 0.16155 to 0.04832, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0917 - val_loss: 0.0483\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0401\n",
      "Epoch 3: val_loss improved from 0.04832 to 0.02537, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0401 - val_loss: 0.0254\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 4: val_loss improved from 0.02537 to 0.01385, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0220 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 5: val_loss improved from 0.01385 to 0.00694, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00694 to 0.00436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00436 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00331 to 0.00275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00275 to 0.00236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00236 to 0.00207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_352\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2112 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1056 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_352 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2113 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1057 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2114 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1058 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2115 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_704 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2116 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_705 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2117 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2429\n",
      "Epoch 1: val_loss improved from inf to 0.10942, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.2429 - val_loss: 0.1094\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0705\n",
      "Epoch 2: val_loss improved from 0.10942 to 0.04726, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0705 - val_loss: 0.0473\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 3: val_loss improved from 0.04726 to 0.02283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0377 - val_loss: 0.0228\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02283 to 0.01067, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0179 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01067 to 0.00601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00601 to 0.00423, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00423 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00344 to 0.00299, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00299 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00268 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_353\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2118 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1059 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_353 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2119 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1060 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2120 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1061 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2121 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_706 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2122 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_707 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2123 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2269\n",
      "Epoch 1: val_loss improved from inf to 0.07571, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.2269 - val_loss: 0.0757\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0389\n",
      "Epoch 2: val_loss improved from 0.07571 to 0.01995, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0389 - val_loss: 0.0199\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 3: val_loss improved from 0.01995 to 0.01081, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0162 - val_loss: 0.0108\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 4: val_loss improved from 0.01081 to 0.00730, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0107 - val_loss: 0.0073\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.00730 to 0.00525, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00525 to 0.00393, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00393 to 0.00312, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00312 to 0.00258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00258 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00221 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 523ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_354\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2124 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1062 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_354 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2125 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1063 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2126 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1064 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2127 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_708 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2128 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_709 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2129 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2302\n",
      "Epoch 1: val_loss improved from inf to 0.10666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 500ms/step - loss: 0.2302 - val_loss: 0.1067\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0701\n",
      "Epoch 2: val_loss improved from 0.10666 to 0.04507, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 510ms/step - loss: 0.0701 - val_loss: 0.0451\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 3: val_loss improved from 0.04507 to 0.01938, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0296 - val_loss: 0.0194\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 4: val_loss improved from 0.01938 to 0.01199, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0156 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01199 to 0.00839, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00839 to 0.00602, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00602 to 0.00435, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00435 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00344 to 0.00301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00301 to 0.00274, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_355\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2130 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1065 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_355 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2131 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1066 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2132 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1067 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2133 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_710 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2134 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_711 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2135 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2629\n",
      "Epoch 1: val_loss improved from inf to 0.11966, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.2629 - val_loss: 0.1197\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0459\n",
      "Epoch 2: val_loss improved from 0.11966 to 0.02470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0459 - val_loss: 0.0247\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0175\n",
      "Epoch 3: val_loss improved from 0.02470 to 0.01514, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0175 - val_loss: 0.0151\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 4: val_loss improved from 0.01514 to 0.01131, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01131 to 0.00893, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00893 to 0.00725, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00725 to 0.00582, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00582 to 0.00468, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00468 to 0.00392, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 471ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00392 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_356\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2136 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1068 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_356 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2137 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1069 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2138 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1070 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2139 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_712 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2140 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_713 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2141 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2643\n",
      "Epoch 1: val_loss improved from inf to 0.15727, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 468ms/step - loss: 0.2643 - val_loss: 0.1573\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0666\n",
      "Epoch 2: val_loss improved from 0.15727 to 0.04338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0666 - val_loss: 0.0434\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0281\n",
      "Epoch 3: val_loss improved from 0.04338 to 0.02502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0281 - val_loss: 0.0250\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02502 to 0.01779, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0176 - val_loss: 0.0178\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 5: val_loss improved from 0.01779 to 0.01239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 499ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.01239 to 0.00871, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00871 to 0.00661, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 480ms/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00661 to 0.00559, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00559 to 0.00504, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00504 to 0.00462, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_357\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2142 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1071 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_357 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2143 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1072 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2144 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1073 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2145 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_714 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2146 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_715 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2147 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2510\n",
      "Epoch 1: val_loss improved from inf to 0.14810, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 468ms/step - loss: 0.2510 - val_loss: 0.1481\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0587\n",
      "Epoch 2: val_loss improved from 0.14810 to 0.03997, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0587 - val_loss: 0.0400\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Epoch 3: val_loss improved from 0.03997 to 0.02118, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0233 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 4: val_loss improved from 0.02118 to 0.01327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0117 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 5: val_loss improved from 0.01327 to 0.00984, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 0.0068 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00984 to 0.00822, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0050 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00822 to 0.00713, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0041 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00713 to 0.00638, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00638 to 0.00588, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00588 to 0.00547, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0029 - val_loss: 0.0055\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_358\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2148 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1074 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_358 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2149 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1075 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2150 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1076 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2151 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_716 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2152 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_717 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2153 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2555\n",
      "Epoch 1: val_loss improved from inf to 0.15135, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 478ms/step - loss: 0.2555 - val_loss: 0.1514\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0613\n",
      "Epoch 2: val_loss improved from 0.15135 to 0.04398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 455ms/step - loss: 0.0613 - val_loss: 0.0440\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 3: val_loss improved from 0.04398 to 0.02126, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0266 - val_loss: 0.0213\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 4: val_loss improved from 0.02126 to 0.01256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.01256 to 0.00912, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0074 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00912 to 0.00727, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00727 to 0.00628, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00628 to 0.00561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00561 to 0.00510, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00510 to 0.00463, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_359\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2154 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1077 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_359 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2155 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1078 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2156 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1079 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2157 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_718 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2158 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_719 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2159 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2637\n",
      "Epoch 1: val_loss improved from inf to 0.17677, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.2637 - val_loss: 0.1768\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0804\n",
      "Epoch 2: val_loss improved from 0.17677 to 0.05280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0804 - val_loss: 0.0528\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0314\n",
      "Epoch 3: val_loss improved from 0.05280 to 0.01916, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0314 - val_loss: 0.0192\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 4: val_loss improved from 0.01916 to 0.01130, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0126 - val_loss: 0.0113\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.01130 to 0.00771, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00771 to 0.00555, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00555 to 0.00457, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 455ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00457 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 459ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00407 to 0.00369, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00369 to 0.00337, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "finished training\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_360\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2160 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1080 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_360 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2161 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1081 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2162 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1082 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2163 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_720 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2164 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_721 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2165 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2301\n",
      "Epoch 1: val_loss improved from inf to 0.11068, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 470ms/step - loss: 0.2301 - val_loss: 0.1107\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0630\n",
      "Epoch 2: val_loss improved from 0.11068 to 0.03987, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0630 - val_loss: 0.0399\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 3: val_loss improved from 0.03987 to 0.01829, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0260 - val_loss: 0.0183\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.01829 to 0.01260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01260 to 0.00930, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.00930 to 0.00703, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00703 to 0.00530, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00530 to 0.00412, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00412 to 0.00339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 519ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00339 to 0.00285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_361\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2166 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1083 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_361 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2167 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1084 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2168 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1085 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2169 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_722 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2170 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_723 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2171 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3763\n",
      "Epoch 1: val_loss improved from inf to 0.31000, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 514ms/step - loss: 0.3763 - val_loss: 0.3100\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2425\n",
      "Epoch 2: val_loss improved from 0.31000 to 0.11726, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.2425 - val_loss: 0.1173\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0732\n",
      "Epoch 3: val_loss improved from 0.11726 to 0.04738, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.0732 - val_loss: 0.0474\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0326\n",
      "Epoch 4: val_loss improved from 0.04738 to 0.02007, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 500ms/step - loss: 0.0326 - val_loss: 0.0201\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 5: val_loss improved from 0.02007 to 0.01038, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 0.0162 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.01038 to 0.00565, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00565 to 0.00366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00366 to 0.00294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00294 to 0.00258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 541ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00258 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_362\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2172 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1086 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_362 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2173 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1087 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2174 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1088 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2175 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_724 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2176 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_725 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2177 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2984\n",
      "Epoch 1: val_loss improved from inf to 0.17281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 536ms/step - loss: 0.2984 - val_loss: 0.1728\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0813\n",
      "Epoch 2: val_loss improved from 0.17281 to 0.03288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 539ms/step - loss: 0.0813 - val_loss: 0.0329\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0243\n",
      "Epoch 3: val_loss improved from 0.03288 to 0.01387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0243 - val_loss: 0.0139\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 4: val_loss improved from 0.01387 to 0.00859, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 476ms/step - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.00859 to 0.00608, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00608 to 0.00470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00470 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00381 to 0.00316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00316 to 0.00261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00261 to 0.00213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_363\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2178 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1089 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_363 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2179 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1090 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2180 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1091 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2181 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_726 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2182 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_727 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2183 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2179\n",
      "Epoch 1: val_loss improved from inf to 0.07589, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 472ms/step - loss: 0.2179 - val_loss: 0.0759\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0500\n",
      "Epoch 2: val_loss improved from 0.07589 to 0.02734, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.0500 - val_loss: 0.0273\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 3: val_loss improved from 0.02734 to 0.01186, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 458ms/step - loss: 0.0211 - val_loss: 0.0119\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 4: val_loss improved from 0.01186 to 0.00634, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 454ms/step - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 5: val_loss improved from 0.00634 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0070 - val_loss: 0.0040\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00397 to 0.00277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00277 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 464ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00218 to 0.00189, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00189 to 0.00171, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00171 to 0.00157, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 468ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_364\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2184 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1092 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_364 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2185 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1093 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2186 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1094 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2187 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_728 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2188 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_729 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2189 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2293\n",
      "Epoch 1: val_loss improved from inf to 0.09459, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 469ms/step - loss: 0.2293 - val_loss: 0.0946\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0541\n",
      "Epoch 2: val_loss improved from 0.09459 to 0.03085, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0541 - val_loss: 0.0308\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 3: val_loss improved from 0.03085 to 0.01434, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 538ms/step - loss: 0.0234 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01434 to 0.00871, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 547ms/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.00871 to 0.00581, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00581 to 0.00403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00403 to 0.00306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00306 to 0.00253, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00253 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00218 to 0.00193, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_365\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2190 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1095 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_365 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2191 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1096 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2192 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1097 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2193 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_730 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2194 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_731 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2195 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3363\n",
      "Epoch 1: val_loss improved from inf to 0.23666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.3363 - val_loss: 0.2367\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1482\n",
      "Epoch 2: val_loss improved from 0.23666 to 0.07792, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.1482 - val_loss: 0.0779\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0548\n",
      "Epoch 3: val_loss improved from 0.07792 to 0.03327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0548 - val_loss: 0.0333\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0243\n",
      "Epoch 4: val_loss improved from 0.03327 to 0.01681, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0243 - val_loss: 0.0168\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 5: val_loss improved from 0.01681 to 0.00922, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0137 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.00922 to 0.00535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00535 to 0.00363, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00363 to 0.00291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00291 to 0.00252, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00252 to 0.00226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_366\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2196 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1098 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_366 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2197 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1099 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2198 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1100 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2199 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_732 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2200 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_733 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2201 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3439\n",
      "Epoch 1: val_loss improved from inf to 0.29060, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.3439 - val_loss: 0.2906\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1880\n",
      "Epoch 2: val_loss improved from 0.29060 to 0.05674, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.1880 - val_loss: 0.0567\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 3: val_loss improved from 0.05674 to 0.02727, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0419 - val_loss: 0.0273\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 4: val_loss improved from 0.02727 to 0.01566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0208 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 5: val_loss improved from 0.01566 to 0.00913, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 409ms/step - loss: 0.0129 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00913 to 0.00581, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00581 to 0.00453, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00453 to 0.00374, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00374 to 0.00319, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00319 to 0.00280, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_367\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2202 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1101 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_367 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2203 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1102 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2204 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1103 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2205 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_734 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2206 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_735 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2207 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2643\n",
      "Epoch 1: val_loss improved from inf to 0.15023, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 426ms/step - loss: 0.2643 - val_loss: 0.1502\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0770\n",
      "Epoch 2: val_loss improved from 0.15023 to 0.05075, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0770 - val_loss: 0.0507\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0305\n",
      "Epoch 3: val_loss improved from 0.05075 to 0.01980, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0305 - val_loss: 0.0198\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.01980 to 0.01210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0144 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01210 to 0.00783, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00783 to 0.00579, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00579 to 0.00480, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00480 to 0.00420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00420 to 0.00376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00376 to 0.00344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_368\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2208 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1104 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_368 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2209 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1105 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2210 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1106 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2211 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_736 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2212 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_737 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2213 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2501\n",
      "Epoch 1: val_loss improved from inf to 0.13861, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.2501 - val_loss: 0.1386\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0676\n",
      "Epoch 2: val_loss improved from 0.13861 to 0.05109, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0676 - val_loss: 0.0511\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 3: val_loss improved from 0.05109 to 0.02436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0316 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 4: val_loss improved from 0.02436 to 0.01468, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 451ms/step - loss: 0.0147 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01468 to 0.01036, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0085 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.01036 to 0.00836, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00836 to 0.00712, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 446ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00712 to 0.00635, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 444ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00635 to 0.00588, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00588 to 0.00550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 448ms/step - loss: 0.0032 - val_loss: 0.0055\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_369\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2214 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1107 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_369 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2215 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1108 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2216 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1109 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2217 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_738 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2218 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_739 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2219 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2039\n",
      "Epoch 1: val_loss improved from inf to 0.09570, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 497ms/step - loss: 0.2039 - val_loss: 0.0957\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0467\n",
      "Epoch 2: val_loss improved from 0.09570 to 0.04024, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 499ms/step - loss: 0.0467 - val_loss: 0.0402\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 3: val_loss improved from 0.04024 to 0.02524, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 510ms/step - loss: 0.0241 - val_loss: 0.0252\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.02524 to 0.01673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 0.0141 - val_loss: 0.0167\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01673 to 0.01269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.01269 to 0.01025, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.0066 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.01025 to 0.00863, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00863 to 0.00762, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 520ms/step - loss: 0.0043 - val_loss: 0.0076\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00762 to 0.00689, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0038 - val_loss: 0.0069\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00689 to 0.00636, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 0.0034 - val_loss: 0.0064\n",
      "finished training\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_370\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2220 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1110 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_370 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2221 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1111 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2222 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1112 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2223 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_740 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2224 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_741 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2225 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2298\n",
      "Epoch 1: val_loss improved from inf to 0.12984, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.2298 - val_loss: 0.1298\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0689\n",
      "Epoch 2: val_loss improved from 0.12984 to 0.05325, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0689 - val_loss: 0.0532\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0340\n",
      "Epoch 3: val_loss improved from 0.05325 to 0.02709, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0340 - val_loss: 0.0271\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02709 to 0.01656, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0172 - val_loss: 0.0166\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01656 to 0.01131, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.01131 to 0.00920, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00920 to 0.00759, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 519ms/step - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00759 to 0.00641, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 0.0043 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00641 to 0.00552, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00552 to 0.00490, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_371\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2226 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1113 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_371 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2227 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1114 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2228 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1115 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2229 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_742 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2230 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_743 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2231 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2394\n",
      "Epoch 1: val_loss improved from inf to 0.09913, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.2394 - val_loss: 0.0991\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0483\n",
      "Epoch 2: val_loss improved from 0.09913 to 0.03054, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0483 - val_loss: 0.0305\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 3: val_loss improved from 0.03054 to 0.01593, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.0196 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 4: val_loss improved from 0.01593 to 0.01104, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.01104 to 0.00864, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 499ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00864 to 0.00698, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00698 to 0.00573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00573 to 0.00481, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00481 to 0.00421, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00421 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 494ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "finished training\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_372\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2232 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1116 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_372 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2233 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1117 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2234 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1118 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2235 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_744 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2236 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_745 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2237 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1800\n",
      "Epoch 1: val_loss improved from inf to 0.07311, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.1800 - val_loss: 0.0731\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0469\n",
      "Epoch 2: val_loss improved from 0.07311 to 0.03379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 0.0469 - val_loss: 0.0338\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0264\n",
      "Epoch 3: val_loss improved from 0.03379 to 0.02092, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 489ms/step - loss: 0.0264 - val_loss: 0.0209\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02092 to 0.01262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0168 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01262 to 0.00738, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 485ms/step - loss: 0.0099 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00738 to 0.00508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0064 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00508 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 469ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00381 to 0.00315, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 500ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00315 to 0.00275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00275 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_373\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2238 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1119 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_373 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2239 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1120 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2240 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1121 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2241 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_746 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2242 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_747 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2243 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2558\n",
      "Epoch 1: val_loss improved from inf to 0.16226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 517ms/step - loss: 0.2558 - val_loss: 0.1623\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1074\n",
      "Epoch 2: val_loss improved from 0.16226 to 0.07146, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 486ms/step - loss: 0.1074 - val_loss: 0.0715\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 3: val_loss improved from 0.07146 to 0.03545, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 497ms/step - loss: 0.0525 - val_loss: 0.0354\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0278\n",
      "Epoch 4: val_loss improved from 0.03545 to 0.01855, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0278 - val_loss: 0.0186\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 5: val_loss improved from 0.01855 to 0.00877, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 476ms/step - loss: 0.0145 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00877 to 0.00452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00452 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 492ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00331 to 0.00276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 487ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00276 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 470ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00239 to 0.00212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 447ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_374\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2244 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1122 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_374 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2245 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1123 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2246 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1124 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2247 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_748 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2248 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_749 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2249 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2525\n",
      "Epoch 1: val_loss improved from inf to 0.11451, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 456ms/step - loss: 0.2525 - val_loss: 0.1145\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0704\n",
      "Epoch 2: val_loss improved from 0.11451 to 0.04339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.0704 - val_loss: 0.0434\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 3: val_loss improved from 0.04339 to 0.01697, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 0.0311 - val_loss: 0.0170\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01697 to 0.00821, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0141 - val_loss: 0.0082\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.00821 to 0.00497, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 499ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00497 to 0.00358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00358 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00282 to 0.00234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00234 to 0.00204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 527ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00204 to 0.00183, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_375\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2250 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1125 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_375 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2251 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1126 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2252 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1127 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2253 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_750 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2254 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_751 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2255 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2422\n",
      "Epoch 1: val_loss improved from inf to 0.10168, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 512ms/step - loss: 0.2422 - val_loss: 0.1017\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0565\n",
      "Epoch 2: val_loss improved from 0.10168 to 0.03344, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 501ms/step - loss: 0.0565 - val_loss: 0.0334\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0261\n",
      "Epoch 3: val_loss improved from 0.03344 to 0.01550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 493ms/step - loss: 0.0261 - val_loss: 0.0155\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 4: val_loss improved from 0.01550 to 0.00681, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 524ms/step - loss: 0.0129 - val_loss: 0.0068\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 5: val_loss improved from 0.00681 to 0.00349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0066 - val_loss: 0.0035\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 6: val_loss improved from 0.00349 to 0.00249, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 7: val_loss improved from 0.00249 to 0.00207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 509ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 8: val_loss improved from 0.00207 to 0.00184, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 519ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00184 to 0.00165, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00165 to 0.00150, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "finished training\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_376\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2256 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1128 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_376 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2257 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1129 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2258 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1130 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2259 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_752 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2260 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_753 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2261 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2199\n",
      "Epoch 1: val_loss improved from inf to 0.10053, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 522ms/step - loss: 0.2199 - val_loss: 0.1005\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0661\n",
      "Epoch 2: val_loss improved from 0.10053 to 0.03182, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 520ms/step - loss: 0.0661 - val_loss: 0.0318\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 3: val_loss improved from 0.03182 to 0.01047, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0202 - val_loss: 0.0105\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 4: val_loss improved from 0.01047 to 0.00587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 5: val_loss improved from 0.00587 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00433 to 0.00339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00339 to 0.00279, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00279 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00243 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00220 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_377\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2262 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1131 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_377 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2263 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1132 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2264 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1133 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2265 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_754 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2266 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_755 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2267 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2836\n",
      "Epoch 1: val_loss improved from inf to 0.16230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 496ms/step - loss: 0.2836 - val_loss: 0.1623\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0883\n",
      "Epoch 2: val_loss improved from 0.16230 to 0.04787, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0883 - val_loss: 0.0479\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0345\n",
      "Epoch 3: val_loss improved from 0.04787 to 0.02449, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0345 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02449 to 0.01334, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0194 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 5: val_loss improved from 0.01334 to 0.00730, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 500ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00730 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 495ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00493 to 0.00370, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 525ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00370 to 0.00305, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 498ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00305 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 505ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00264 to 0.00236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_378\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2268 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1134 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_378 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2269 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1135 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2270 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1136 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2271 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_756 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2272 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_757 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2273 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3022\n",
      "Epoch 1: val_loss improved from inf to 0.22883, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 511ms/step - loss: 0.3022 - val_loss: 0.2288\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1239\n",
      "Epoch 2: val_loss improved from 0.22883 to 0.06268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.1239 - val_loss: 0.0627\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0400\n",
      "Epoch 3: val_loss improved from 0.06268 to 0.02567, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0400 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 4: val_loss improved from 0.02567 to 0.01383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0183 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01383 to 0.00772, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 461ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00772 to 0.00524, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00524 to 0.00409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00409 to 0.00346, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 463ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00346 to 0.00308, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00308 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 457ms/step - loss: 0.0033 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_379\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2274 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1137 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_379 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2275 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1138 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2276 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1139 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2277 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_758 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2278 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_759 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2279 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2644\n",
      "Epoch 1: val_loss improved from inf to 0.15893, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 493ms/step - loss: 0.2644 - val_loss: 0.1589\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0800\n",
      "Epoch 2: val_loss improved from 0.15893 to 0.05895, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 467ms/step - loss: 0.0800 - val_loss: 0.0590\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0427\n",
      "Epoch 3: val_loss improved from 0.05895 to 0.03364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 472ms/step - loss: 0.0427 - val_loss: 0.0336\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0238\n",
      "Epoch 4: val_loss improved from 0.03364 to 0.02064, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0238 - val_loss: 0.0206\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 5: val_loss improved from 0.02064 to 0.01358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 462ms/step - loss: 0.0150 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 6: val_loss improved from 0.01358 to 0.00990, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00990 to 0.00787, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 466ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00787 to 0.00634, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 460ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00634 to 0.00522, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00522 to 0.00443, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_380\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2280 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1140 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_380 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2281 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1141 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2282 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1142 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2283 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_760 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2284 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_761 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2285 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1255\n",
      "Epoch 1: val_loss improved from inf to 0.05004, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.1255 - val_loss: 0.0500\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0341\n",
      "Epoch 2: val_loss improved from 0.05004 to 0.03133, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0341 - val_loss: 0.0313\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 3: val_loss improved from 0.03133 to 0.01904, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 4: val_loss improved from 0.01904 to 0.01123, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 525ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 5: val_loss improved from 0.01123 to 0.00823, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 504ms/step - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 6: val_loss improved from 0.00823 to 0.00705, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss improved from 0.00705 to 0.00631, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00631 to 0.00573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00573 to 0.00528, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 484ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00528 to 0.00488, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 503ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "finished training\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_381\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2286 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1143 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_381 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2287 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1144 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2288 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1145 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2289 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_762 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2290 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_763 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2291 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3106\n",
      "Epoch 1: val_loss improved from inf to 0.31742, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 0.3106 - val_loss: 0.3174\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 2: val_loss improved from 0.31742 to 0.06210, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.1368 - val_loss: 0.0621\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0394\n",
      "Epoch 3: val_loss improved from 0.06210 to 0.03438, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0394 - val_loss: 0.0344\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 4: val_loss improved from 0.03438 to 0.02336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0209 - val_loss: 0.0234\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.02336 to 0.01632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 31s 700ms/step - loss: 0.0132 - val_loss: 0.0163\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01632 to 0.01198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0084 - val_loss: 0.0120\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.01198 to 0.00975, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 507ms/step - loss: 0.0059 - val_loss: 0.0098\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00975 to 0.00833, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.0046 - val_loss: 0.0083\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00833 to 0.00746, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 525ms/step - loss: 0.0039 - val_loss: 0.0075\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00746 to 0.00679, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0035 - val_loss: 0.0068\n",
      "finished training\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_382\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2292 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1146 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_382 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2293 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1147 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2294 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1148 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2295 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_764 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2296 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_765 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2297 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2637\n",
      "Epoch 1: val_loss improved from inf to 0.19366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.2637 - val_loss: 0.1937\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0717\n",
      "Epoch 2: val_loss improved from 0.19366 to 0.04617, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0717 - val_loss: 0.0462\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 3: val_loss improved from 0.04617 to 0.02339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0284 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0128\n",
      "Epoch 4: val_loss improved from 0.02339 to 0.01306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0128 - val_loss: 0.0131\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 5: val_loss improved from 0.01306 to 0.00874, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 6: val_loss improved from 0.00874 to 0.00704, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 7: val_loss improved from 0.00704 to 0.00623, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00623 to 0.00568, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00568 to 0.00532, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00532 to 0.00496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0028 - val_loss: 0.0050\n",
      "finished training\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_383\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2298 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1149 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_383 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2299 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1150 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2300 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1151 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2301 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_766 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2302 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_767 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2303 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1304\n",
      "Epoch 1: val_loss improved from inf to 0.06644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.1304 - val_loss: 0.0664\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 2: val_loss improved from 0.06644 to 0.02823, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0421 - val_loss: 0.0282\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 3: val_loss improved from 0.02823 to 0.01559, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0173 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 4: val_loss improved from 0.01559 to 0.01077, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 5: val_loss improved from 0.01077 to 0.00762, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00762 to 0.00585, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00585 to 0.00492, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00492 to 0.00432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00432 to 0.00391, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00391 to 0.00359, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0027 - val_loss: 0.0036\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_384\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2304 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1152 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_384 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2305 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1153 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2306 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1154 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2307 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_768 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2308 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_769 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2309 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1818\n",
      "Epoch 1: val_loss improved from inf to 0.04630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 528ms/step - loss: 0.1818 - val_loss: 0.0463\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0323\n",
      "Epoch 2: val_loss improved from 0.04630 to 0.02391, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0323 - val_loss: 0.0239\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 3: val_loss improved from 0.02391 to 0.01561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0181 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 4: val_loss improved from 0.01561 to 0.01087, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 567ms/step - loss: 0.0124 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01087 to 0.00805, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00805 to 0.00639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00639 to 0.00526, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00526 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00429 to 0.00355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00355 to 0.00308, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_385\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2310 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1155 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_385 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2311 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1156 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2312 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1157 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2313 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_770 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2314 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_771 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2315 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2313\n",
      "Epoch 1: val_loss improved from inf to 0.09911, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.2313 - val_loss: 0.0991\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0626\n",
      "Epoch 2: val_loss improved from 0.09911 to 0.04152, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0626 - val_loss: 0.0415\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 3: val_loss improved from 0.04152 to 0.02091, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0288 - val_loss: 0.0209\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.02091 to 0.01215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0166 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01215 to 0.00612, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00612 to 0.00401, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00401 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00331 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00295 to 0.00266, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00266 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_386\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2316 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1158 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_386 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2317 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1159 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2318 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1160 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2319 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_772 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2320 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_773 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2321 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3069\n",
      "Epoch 1: val_loss improved from inf to 0.20101, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.3069 - val_loss: 0.2010\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1115\n",
      "Epoch 2: val_loss improved from 0.20101 to 0.05494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.1115 - val_loss: 0.0549\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0406\n",
      "Epoch 3: val_loss improved from 0.05494 to 0.02842, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0406 - val_loss: 0.0284\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0229\n",
      "Epoch 4: val_loss improved from 0.02842 to 0.01635, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0229 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 5: val_loss improved from 0.01635 to 0.00981, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0142 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.00981 to 0.00625, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00625 to 0.00464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00464 to 0.00349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00349 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 510ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00271 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_387\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2322 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1161 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_387 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2323 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1162 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2324 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1163 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2325 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_774 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2326 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_775 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2327 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2399\n",
      "Epoch 1: val_loss improved from inf to 0.09753, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 519ms/step - loss: 0.2399 - val_loss: 0.0975\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0561\n",
      "Epoch 2: val_loss improved from 0.09753 to 0.03371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 517ms/step - loss: 0.0561 - val_loss: 0.0337\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0250\n",
      "Epoch 3: val_loss improved from 0.03371 to 0.01704, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0250 - val_loss: 0.0170\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.01704 to 0.01029, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0148 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01029 to 0.00684, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 543ms/step - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00684 to 0.00521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 521ms/step - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00521 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 520ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00407 to 0.00333, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00333 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00282 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_388\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2328 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1164 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_388 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2329 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1165 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2330 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1166 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2331 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_776 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2332 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_777 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2333 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2432\n",
      "Epoch 1: val_loss improved from inf to 0.11791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.2432 - val_loss: 0.1179\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0710\n",
      "Epoch 2: val_loss improved from 0.11791 to 0.04821, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 521ms/step - loss: 0.0710 - val_loss: 0.0482\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0352\n",
      "Epoch 3: val_loss improved from 0.04821 to 0.02336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 521ms/step - loss: 0.0352 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 4: val_loss improved from 0.02336 to 0.01212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0182 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01212 to 0.00705, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00705 to 0.00527, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00527 to 0.00409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00409 to 0.00336, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00336 to 0.00287, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00287 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_389\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2334 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1167 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_389 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2335 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1168 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2336 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1169 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2337 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_778 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2338 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_779 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2339 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3131\n",
      "Epoch 1: val_loss improved from inf to 0.21298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 577ms/step - loss: 0.3131 - val_loss: 0.2130\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1141\n",
      "Epoch 2: val_loss improved from 0.21298 to 0.05560, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.1141 - val_loss: 0.0556\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.05560 to 0.02033, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0359 - val_loss: 0.0203\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 4: val_loss improved from 0.02033 to 0.00881, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0137 - val_loss: 0.0088\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.00881 to 0.00527, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0076 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00527 to 0.00380, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00380 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00310 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00264 to 0.00232, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 510ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00232 to 0.00208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_390\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2340 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1170 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_390 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2341 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1171 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2342 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1172 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2343 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_780 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2344 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_781 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2345 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2598\n",
      "Epoch 1: val_loss improved from inf to 0.14347, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.2598 - val_loss: 0.1435\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0766\n",
      "Epoch 2: val_loss improved from 0.14347 to 0.05558, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0766 - val_loss: 0.0556\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0388\n",
      "Epoch 3: val_loss improved from 0.05558 to 0.02649, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0388 - val_loss: 0.0265\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02649 to 0.01288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01288 to 0.00765, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0097 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00765 to 0.00542, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00542 to 0.00417, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00417 to 0.00349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 591ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00349 to 0.00308, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00308 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "finished training\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_391\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2346 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1173 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_391 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2347 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1174 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2348 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1175 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2349 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_782 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2350 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_783 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2351 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3134\n",
      "Epoch 1: val_loss improved from inf to 0.24642, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 572ms/step - loss: 0.3134 - val_loss: 0.2464\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1061\n",
      "Epoch 2: val_loss improved from 0.24642 to 0.05766, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.1061 - val_loss: 0.0577\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0406\n",
      "Epoch 3: val_loss improved from 0.05766 to 0.03435, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0406 - val_loss: 0.0344\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 4: val_loss improved from 0.03435 to 0.02164, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0239 - val_loss: 0.0216\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 5: val_loss improved from 0.02164 to 0.01503, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 6: val_loss improved from 0.01503 to 0.01046, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 7: val_loss improved from 0.01046 to 0.00795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 8: val_loss improved from 0.00795 to 0.00669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00669 to 0.00584, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00584 to 0.00516, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_392\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2352 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1176 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_392 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2353 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1177 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2354 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1178 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2355 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_784 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2356 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_785 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2357 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2253\n",
      "Epoch 1: val_loss improved from inf to 0.09627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 563ms/step - loss: 0.2253 - val_loss: 0.0963\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0522\n",
      "Epoch 2: val_loss improved from 0.09627 to 0.03523, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0522 - val_loss: 0.0352\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 3: val_loss improved from 0.03523 to 0.01838, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 521ms/step - loss: 0.0196 - val_loss: 0.0184\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 4: val_loss improved from 0.01838 to 0.01258, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 520ms/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 5: val_loss improved from 0.01258 to 0.00975, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00975 to 0.00795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 567ms/step - loss: 0.0057 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00795 to 0.00664, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00664 to 0.00578, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00578 to 0.00515, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00515 to 0.00467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "finished training\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_393\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2358 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1179 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_393 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2359 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1180 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2360 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1181 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2361 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_786 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2362 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_787 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2363 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2508\n",
      "Epoch 1: val_loss improved from inf to 0.17377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 558ms/step - loss: 0.2508 - val_loss: 0.1738\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0671\n",
      "Epoch 2: val_loss improved from 0.17377 to 0.05043, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0671 - val_loss: 0.0504\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0274\n",
      "Epoch 3: val_loss improved from 0.05043 to 0.02773, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.02773 to 0.01863, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 549ms/step - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01863 to 0.01340, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 589ms/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.01340 to 0.01017, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0068 - val_loss: 0.0102\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.01017 to 0.00821, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00821 to 0.00717, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0038 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00717 to 0.00653, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00653 to 0.00602, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0029 - val_loss: 0.0060\n",
      "finished training\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_394\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2364 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1182 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_394 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2365 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1183 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2366 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1184 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2367 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_788 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2368 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_789 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2369 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1832\n",
      "Epoch 1: val_loss improved from inf to 0.06938, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.1832 - val_loss: 0.0694\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 2: val_loss improved from 0.06938 to 0.03278, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0443 - val_loss: 0.0328\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 3: val_loss improved from 0.03278 to 0.01428, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0156 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 4: val_loss improved from 0.01428 to 0.01031, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 589ms/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 5: val_loss improved from 0.01031 to 0.00831, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0058 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 6: val_loss improved from 0.00831 to 0.00715, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00715 to 0.00625, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00625 to 0.00561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00561 to 0.00512, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00512 to 0.00468, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "finished training\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_395\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2370 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1185 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_395 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2371 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1186 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2372 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1187 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2373 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_790 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2374 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_791 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2375 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2827\n",
      "Epoch 1: val_loss improved from inf to 0.20744, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 565ms/step - loss: 0.2827 - val_loss: 0.2074\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0785\n",
      "Epoch 2: val_loss improved from 0.20744 to 0.04783, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0785 - val_loss: 0.0478\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 3: val_loss improved from 0.04783 to 0.02332, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0303 - val_loss: 0.0233\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 4: val_loss improved from 0.02332 to 0.01356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0147 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01356 to 0.00929, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 548ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00929 to 0.00701, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00701 to 0.00562, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 544ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00562 to 0.00490, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00490 to 0.00445, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00445 to 0.00415, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 490ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_396\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2376 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1188 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_396 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2377 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1189 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2378 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1190 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2379 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_792 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2380 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_793 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2381 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1881\n",
      "Epoch 1: val_loss improved from inf to 0.08246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.1881 - val_loss: 0.0825\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0531\n",
      "Epoch 2: val_loss improved from 0.08246 to 0.04387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 510ms/step - loss: 0.0531 - val_loss: 0.0439\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 3: val_loss improved from 0.04387 to 0.02494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0302 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02494 to 0.01474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 516ms/step - loss: 0.0176 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01474 to 0.00930, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00930 to 0.00648, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00648 to 0.00486, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00486 to 0.00384, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00384 to 0.00307, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00307 to 0.00260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_397\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2382 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1191 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_397 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2383 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1192 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2384 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1193 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2385 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_794 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2386 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_795 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2387 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2046\n",
      "Epoch 1: val_loss improved from inf to 0.10103, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.2046 - val_loss: 0.1010\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0668\n",
      "Epoch 2: val_loss improved from 0.10103 to 0.04771, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 567ms/step - loss: 0.0668 - val_loss: 0.0477\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0319\n",
      "Epoch 3: val_loss improved from 0.04771 to 0.02348, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0319 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02348 to 0.01331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0177 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01331 to 0.00674, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00674 to 0.00420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00420 to 0.00341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 567ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00341 to 0.00302, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00302 to 0.00275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00275 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 548ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_398\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2388 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1194 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_398 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2389 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1195 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2390 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1196 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2391 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_796 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2392 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_797 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2393 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3140\n",
      "Epoch 1: val_loss improved from inf to 0.23109, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.3140 - val_loss: 0.2311\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1360\n",
      "Epoch 2: val_loss improved from 0.23109 to 0.06694, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.1360 - val_loss: 0.0669\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0407\n",
      "Epoch 3: val_loss improved from 0.06694 to 0.02444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 555ms/step - loss: 0.0407 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 4: val_loss improved from 0.02444 to 0.01358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 540ms/step - loss: 0.0188 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01358 to 0.00742, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 537ms/step - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00742 to 0.00461, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 537ms/step - loss: 0.0069 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00461 to 0.00323, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00323 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00257 to 0.00222, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 521ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00222 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_399\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2394 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1197 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_399 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2395 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1198 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2396 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1199 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2397 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_798 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2398 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_799 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2399 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3321\n",
      "Epoch 1: val_loss improved from inf to 0.22860, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.3321 - val_loss: 0.2286\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1276\n",
      "Epoch 2: val_loss improved from 0.22860 to 0.05179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.1276 - val_loss: 0.0518\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0329\n",
      "Epoch 3: val_loss improved from 0.05179 to 0.01839, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 548ms/step - loss: 0.0329 - val_loss: 0.0184\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 4: val_loss improved from 0.01839 to 0.00815, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0131 - val_loss: 0.0081\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.00815 to 0.00509, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00509 to 0.00368, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00368 to 0.00293, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 542ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00293 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00250 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00220 to 0.00196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 544ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_400\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2400 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1200 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_400 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2401 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1201 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2402 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1202 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2403 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_800 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2404 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_801 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2405 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2911\n",
      "Epoch 1: val_loss improved from inf to 0.16605, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 541ms/step - loss: 0.2911 - val_loss: 0.1660\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0852\n",
      "Epoch 2: val_loss improved from 0.16605 to 0.04777, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0852 - val_loss: 0.0478\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 3: val_loss improved from 0.04777 to 0.02233, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 543ms/step - loss: 0.0328 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 4: val_loss improved from 0.02233 to 0.01321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0178 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01321 to 0.00801, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00801 to 0.00505, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00505 to 0.00349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00349 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00268 to 0.00227, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00227 to 0.00205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_401\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2406 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1203 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_401 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2407 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1204 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2408 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1205 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2409 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_802 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2410 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_803 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2411 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2574\n",
      "Epoch 1: val_loss improved from inf to 0.13317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.2574 - val_loss: 0.1332\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0815\n",
      "Epoch 2: val_loss improved from 0.13317 to 0.05492, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0815 - val_loss: 0.0549\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0351\n",
      "Epoch 3: val_loss improved from 0.05492 to 0.02200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0351 - val_loss: 0.0220\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 4: val_loss improved from 0.02200 to 0.01260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0170 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01260 to 0.00657, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00657 to 0.00443, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 526ms/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00443 to 0.00348, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 508ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00348 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00295 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00264 to 0.00241, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_402\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2412 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1206 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_402 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2413 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1207 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2414 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1208 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2415 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_804 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2416 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_805 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2417 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2472\n",
      "Epoch 1: val_loss improved from inf to 0.11784, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.2472 - val_loss: 0.1178\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0550\n",
      "Epoch 2: val_loss improved from 0.11784 to 0.03529, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0550 - val_loss: 0.0353\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 3: val_loss improved from 0.03529 to 0.01960, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0255 - val_loss: 0.0196\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.01960 to 0.01154, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01154 to 0.00577, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 6: val_loss improved from 0.00577 to 0.00367, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 7: val_loss improved from 0.00367 to 0.00316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 8: val_loss improved from 0.00316 to 0.00285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00285 to 0.00261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00261 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_403\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2418 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1209 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_403 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2419 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1210 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2420 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1211 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2421 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_806 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2422 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_807 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2423 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2861\n",
      "Epoch 1: val_loss improved from inf to 0.19089, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.2861 - val_loss: 0.1909\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0756\n",
      "Epoch 2: val_loss improved from 0.19089 to 0.03794, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0756 - val_loss: 0.0379\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0231\n",
      "Epoch 3: val_loss improved from 0.03794 to 0.01700, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0231 - val_loss: 0.0170\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 4: val_loss improved from 0.01700 to 0.01125, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01125 to 0.00738, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00738 to 0.00541, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 532ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00541 to 0.00449, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00449 to 0.00395, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00395 to 0.00359, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00359 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_404\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2424 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1212 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_404 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2425 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1213 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2426 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1214 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2427 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_808 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2428 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_809 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2429 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2565\n",
      "Epoch 1: val_loss improved from inf to 0.14181, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 556ms/step - loss: 0.2565 - val_loss: 0.1418\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0585\n",
      "Epoch 2: val_loss improved from 0.14181 to 0.04124, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0585 - val_loss: 0.0412\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 3: val_loss improved from 0.04124 to 0.02040, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0239 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 4: val_loss improved from 0.02040 to 0.01374, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01374 to 0.01016, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.01016 to 0.00829, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 629ms/step - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00829 to 0.00703, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 619ms/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00703 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 625ms/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00629 to 0.00577, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0034 - val_loss: 0.0058\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00577 to 0.00535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "finished training\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_405\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2430 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1215 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_405 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2431 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1216 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2432 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1217 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2433 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_810 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2434 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_811 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2435 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2568\n",
      "Epoch 1: val_loss improved from inf to 0.18199, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 543ms/step - loss: 0.2568 - val_loss: 0.1820\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0813\n",
      "Epoch 2: val_loss improved from 0.18199 to 0.05727, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0813 - val_loss: 0.0573\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0357\n",
      "Epoch 3: val_loss improved from 0.05727 to 0.03132, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 532ms/step - loss: 0.0357 - val_loss: 0.0313\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0184\n",
      "Epoch 4: val_loss improved from 0.03132 to 0.01702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 559ms/step - loss: 0.0184 - val_loss: 0.0170\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01702 to 0.01126, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0091 - val_loss: 0.0113\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.01126 to 0.00890, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00890 to 0.00762, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0046 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00762 to 0.00685, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0038 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00685 to 0.00627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 619ms/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00627 to 0.00581, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0030 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_406\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2436 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1218 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_406 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2437 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1219 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2438 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1220 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2439 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_812 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2440 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_813 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2441 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2639\n",
      "Epoch 1: val_loss improved from inf to 0.16476, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.2639 - val_loss: 0.1648\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0558\n",
      "Epoch 2: val_loss improved from 0.16476 to 0.03500, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0558 - val_loss: 0.0350\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 3: val_loss improved from 0.03500 to 0.01808, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0198 - val_loss: 0.0181\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 4: val_loss improved from 0.01808 to 0.01205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 589ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 5: val_loss improved from 0.01205 to 0.00912, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0071 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00912 to 0.00734, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00734 to 0.00620, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00620 to 0.00548, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00548 to 0.00493, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00493 to 0.00444, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_407\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2442 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1221 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_407 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2443 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1222 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2444 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1223 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2445 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_814 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2446 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_815 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2447 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2565\n",
      "Epoch 1: val_loss improved from inf to 0.14193, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 611ms/step - loss: 0.2565 - val_loss: 0.1419\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0705\n",
      "Epoch 2: val_loss improved from 0.14193 to 0.04861, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0705 - val_loss: 0.0486\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 3: val_loss improved from 0.04861 to 0.02634, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0328 - val_loss: 0.0263\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02634 to 0.01655, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0194 - val_loss: 0.0165\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01655 to 0.01000, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.01000 to 0.00674, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00674 to 0.00537, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 627ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00537 to 0.00472, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 610ms/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00472 to 0.00430, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 620ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00430 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 30s 660ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "finished training\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_408\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2448 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1224 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_408 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2449 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1225 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2450 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1226 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2451 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_816 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2452 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_817 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2453 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1825\n",
      "Epoch 1: val_loss improved from inf to 0.07124, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.1825 - val_loss: 0.0712\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0414\n",
      "Epoch 2: val_loss improved from 0.07124 to 0.02601, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 624ms/step - loss: 0.0414 - val_loss: 0.0260\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 3: val_loss improved from 0.02601 to 0.01305, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 638ms/step - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 4: val_loss improved from 0.01305 to 0.00847, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 621ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 5: val_loss improved from 0.00847 to 0.00583, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 6: val_loss improved from 0.00583 to 0.00408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 621ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 7: val_loss improved from 0.00408 to 0.00325, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 8: val_loss improved from 0.00325 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 9: val_loss improved from 0.00282 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 10: val_loss improved from 0.00247 to 0.00218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_409\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2454 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1227 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_409 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2455 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1228 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2456 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1229 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2457 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_818 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2458 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_819 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2459 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3218\n",
      "Epoch 1: val_loss improved from inf to 0.20335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.3218 - val_loss: 0.2033\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0997\n",
      "Epoch 2: val_loss improved from 0.20335 to 0.04218, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0997 - val_loss: 0.0422\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 3: val_loss improved from 0.04218 to 0.01936, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 649ms/step - loss: 0.0292 - val_loss: 0.0194\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.01936 to 0.01145, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 619ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01145 to 0.00702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00702 to 0.00467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 622ms/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00467 to 0.00352, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0049 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00352 to 0.00283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00283 to 0.00244, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 626ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00244 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 639ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_410\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2460 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1230 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_410 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2461 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1231 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2462 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1232 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2463 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_820 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2464 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_821 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2465 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1951\n",
      "Epoch 1: val_loss improved from inf to 0.06795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 626ms/step - loss: 0.1951 - val_loss: 0.0680\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0475\n",
      "Epoch 2: val_loss improved from 0.06795 to 0.02832, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 620ms/step - loss: 0.0475 - val_loss: 0.0283\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 3: val_loss improved from 0.02832 to 0.01298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0210 - val_loss: 0.0130\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 4: val_loss improved from 0.01298 to 0.00750, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 626ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.00750 to 0.00459, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 633ms/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00459 to 0.00300, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00300 to 0.00247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00247 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00221 to 0.00203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00203 to 0.00188, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_411\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2466 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1233 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_411 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2467 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1234 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2468 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1235 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2469 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_822 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2470 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_823 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2471 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3326\n",
      "Epoch 1: val_loss improved from inf to 0.22633, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 565ms/step - loss: 0.3326 - val_loss: 0.2263\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1269\n",
      "Epoch 2: val_loss improved from 0.22633 to 0.04533, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 559ms/step - loss: 0.1269 - val_loss: 0.0453\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 3: val_loss improved from 0.04533 to 0.02216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 559ms/step - loss: 0.0342 - val_loss: 0.0222\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02216 to 0.01149, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0179 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 5: val_loss improved from 0.01149 to 0.00774, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 6: val_loss improved from 0.00774 to 0.00586, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00586 to 0.00469, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00469 to 0.00384, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00384 to 0.00316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 647ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00316 to 0.00265, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 628ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_412\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2472 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1236 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_412 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2473 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1237 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2474 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1238 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2475 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_824 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2476 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_825 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2477 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2803\n",
      "Epoch 1: val_loss improved from inf to 0.16723, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 640ms/step - loss: 0.2803 - val_loss: 0.1672\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0928\n",
      "Epoch 2: val_loss improved from 0.16723 to 0.05151, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0928 - val_loss: 0.0515\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0392\n",
      "Epoch 3: val_loss improved from 0.05151 to 0.02569, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0392 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0197\n",
      "Epoch 4: val_loss improved from 0.02569 to 0.01215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 624ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01215 to 0.00495, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00495 to 0.00306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 628ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00306 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00250 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 625ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00220 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 632ms/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00197 to 0.00176, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_413\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2478 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1239 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_413 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2479 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1240 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2480 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1241 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2481 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_826 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2482 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_827 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2483 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1891\n",
      "Epoch 1: val_loss improved from inf to 0.09341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 30s 661ms/step - loss: 0.1891 - val_loss: 0.0934\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0733\n",
      "Epoch 2: val_loss improved from 0.09341 to 0.05464, saving model to best_weights.h5\n",
      "45/45 [==============================] - 31s 685ms/step - loss: 0.0733 - val_loss: 0.0546\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0395\n",
      "Epoch 3: val_loss improved from 0.05464 to 0.02625, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 646ms/step - loss: 0.0395 - val_loss: 0.0263\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02625 to 0.01485, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 639ms/step - loss: 0.0203 - val_loss: 0.0148\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 5: val_loss improved from 0.01485 to 0.00896, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 643ms/step - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00896 to 0.00565, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00565 to 0.00372, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 645ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00372 to 0.00291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 632ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00291 to 0.00251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 647ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00251 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 624ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_414\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2484 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1242 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_414 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2485 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1243 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2486 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1244 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2487 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_828 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2488 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_829 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2489 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2796\n",
      "Epoch 1: val_loss improved from inf to 0.16829, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 633ms/step - loss: 0.2796 - val_loss: 0.1683\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0842\n",
      "Epoch 2: val_loss improved from 0.16829 to 0.05206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 646ms/step - loss: 0.0842 - val_loss: 0.0521\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0340\n",
      "Epoch 3: val_loss improved from 0.05206 to 0.02165, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.0340 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02165 to 0.01196, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0158 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01196 to 0.00782, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 640ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00782 to 0.00559, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 622ms/step - loss: 0.0069 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00559 to 0.00417, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00417 to 0.00342, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 649ms/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00342 to 0.00299, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 651ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00299 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 639ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_415\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2490 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1245 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_415 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2491 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1246 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2492 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1247 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2493 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_830 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2494 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_831 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2495 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2060\n",
      "Epoch 1: val_loss improved from inf to 0.08318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 642ms/step - loss: 0.2060 - val_loss: 0.0832\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0495\n",
      "Epoch 2: val_loss improved from 0.08318 to 0.03709, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 642ms/step - loss: 0.0495 - val_loss: 0.0371\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0249\n",
      "Epoch 3: val_loss improved from 0.03709 to 0.01956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 636ms/step - loss: 0.0249 - val_loss: 0.0196\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01956 to 0.01105, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 637ms/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 5: val_loss improved from 0.01105 to 0.00680, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 6: val_loss improved from 0.00680 to 0.00510, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss improved from 0.00510 to 0.00428, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 650ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00428 to 0.00380, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00380 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 641ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00345 to 0.00313, saving model to best_weights.h5\n",
      "45/45 [==============================] - 30s 662ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "finished training\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_416\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2496 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1248 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_416 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2497 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1249 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2498 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1250 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2499 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_832 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2500 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_833 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2501 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2702\n",
      "Epoch 1: val_loss improved from inf to 0.17860, saving model to best_weights.h5\n",
      "45/45 [==============================] - 31s 670ms/step - loss: 0.2702 - val_loss: 0.1786\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0701\n",
      "Epoch 2: val_loss improved from 0.17860 to 0.04383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 30s 662ms/step - loss: 0.0701 - val_loss: 0.0438\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 3: val_loss improved from 0.04383 to 0.02303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 651ms/step - loss: 0.0254 - val_loss: 0.0230\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.02303 to 0.01623, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 656ms/step - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01623 to 0.01250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 652ms/step - loss: 0.0096 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.01250 to 0.01045, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.01045 to 0.00890, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0059 - val_loss: 0.0089\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00890 to 0.00760, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0048 - val_loss: 0.0076\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00760 to 0.00669, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0040 - val_loss: 0.0067\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00669 to 0.00603, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0035 - val_loss: 0.0060\n",
      "finished training\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_417\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2502 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1251 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_417 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2503 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1252 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2504 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1253 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2505 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_834 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2506 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_835 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2507 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2963\n",
      "Epoch 1: val_loss improved from inf to 0.26355, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 635ms/step - loss: 0.2963 - val_loss: 0.2636\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0872\n",
      "Epoch 2: val_loss improved from 0.26355 to 0.04062, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 631ms/step - loss: 0.0872 - val_loss: 0.0406\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 3: val_loss improved from 0.04062 to 0.02098, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 541ms/step - loss: 0.0226 - val_loss: 0.0210\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 4: val_loss improved from 0.02098 to 0.01426, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 5: val_loss improved from 0.01426 to 0.01064, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 525ms/step - loss: 0.0075 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.01064 to 0.00872, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 527ms/step - loss: 0.0054 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00872 to 0.00763, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 528ms/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00763 to 0.00682, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.0037 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00682 to 0.00619, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 526ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00619 to 0.00564, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 522ms/step - loss: 0.0029 - val_loss: 0.0056\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_418\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2508 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1254 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_418 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2509 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1255 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2510 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1256 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2511 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_836 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2512 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_837 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2513 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1698\n",
      "Epoch 1: val_loss improved from inf to 0.06206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 541ms/step - loss: 0.1698 - val_loss: 0.0621\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 2: val_loss improved from 0.06206 to 0.03064, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 532ms/step - loss: 0.0421 - val_loss: 0.0306\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0184\n",
      "Epoch 3: val_loss improved from 0.03064 to 0.01778, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 541ms/step - loss: 0.0184 - val_loss: 0.0178\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 4: val_loss improved from 0.01778 to 0.01226, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0111 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 5: val_loss improved from 0.01226 to 0.00915, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 542ms/step - loss: 0.0073 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00915 to 0.00724, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00724 to 0.00607, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00607 to 0.00531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00531 to 0.00484, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00484 to 0.00450, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_419\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2514 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1257 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_419 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2515 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1258 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2516 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1259 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2517 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_838 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2518 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_839 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2519 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3318\n",
      "Epoch 1: val_loss improved from inf to 0.29769, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 537ms/step - loss: 0.3318 - val_loss: 0.2977\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1337\n",
      "Epoch 2: val_loss improved from 0.29769 to 0.06809, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.1337 - val_loss: 0.0681\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 3: val_loss improved from 0.06809 to 0.02807, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 540ms/step - loss: 0.0419 - val_loss: 0.0281\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02807 to 0.01545, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 538ms/step - loss: 0.0191 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 5: val_loss improved from 0.01545 to 0.01032, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.01032 to 0.00788, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 536ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00788 to 0.00632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00632 to 0.00521, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00521 to 0.00452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 555ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00452 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 541ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_420\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2520 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1260 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_420 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2521 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1261 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2522 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1262 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2523 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_840 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2524 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_841 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2525 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2923\n",
      "Epoch 1: val_loss improved from inf to 0.19168, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 547ms/step - loss: 0.2923 - val_loss: 0.1917\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0817\n",
      "Epoch 2: val_loss improved from 0.19168 to 0.04201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 542ms/step - loss: 0.0817 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0301\n",
      "Epoch 3: val_loss improved from 0.04201 to 0.02026, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 545ms/step - loss: 0.0301 - val_loss: 0.0203\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 4: val_loss improved from 0.02026 to 0.01162, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 542ms/step - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01162 to 0.00792, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 542ms/step - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00792 to 0.00595, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 542ms/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00595 to 0.00466, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 543ms/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00466 to 0.00384, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 545ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00384 to 0.00334, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 549ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00334 to 0.00299, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 543ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_421\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2526 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1263 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_421 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2527 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1264 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2528 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1265 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2529 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_842 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2530 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_843 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2531 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3111\n",
      "Epoch 1: val_loss improved from inf to 0.16385, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.3111 - val_loss: 0.1639\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0804\n",
      "Epoch 2: val_loss improved from 0.16385 to 0.04200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0804 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 3: val_loss improved from 0.04200 to 0.01810, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0292 - val_loss: 0.0181\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 4: val_loss improved from 0.01810 to 0.01094, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01094 to 0.00711, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0101 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00711 to 0.00512, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00512 to 0.00398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00398 to 0.00323, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00323 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00281 to 0.00255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_422\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2532 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1266 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_422 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2533 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1267 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2534 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1268 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2535 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_844 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2536 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_845 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2537 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3135\n",
      "Epoch 1: val_loss improved from inf to 0.22014, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 548ms/step - loss: 0.3135 - val_loss: 0.2201\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1146\n",
      "Epoch 2: val_loss improved from 0.22014 to 0.04379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 547ms/step - loss: 0.1146 - val_loss: 0.0438\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0323\n",
      "Epoch 3: val_loss improved from 0.04379 to 0.01886, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 0.0323 - val_loss: 0.0189\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.01886 to 0.00950, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 543ms/step - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.00950 to 0.00608, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 545ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00608 to 0.00463, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00463 to 0.00378, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00378 to 0.00313, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00313 to 0.00256, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00256 to 0.00220, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_423\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2538 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1269 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_423 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2539 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1270 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2540 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1271 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2541 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_846 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2542 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_847 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2543 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2375\n",
      "Epoch 1: val_loss improved from inf to 0.10299, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 565ms/step - loss: 0.2375 - val_loss: 0.1030\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0559\n",
      "Epoch 2: val_loss improved from 0.10299 to 0.02957, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 546ms/step - loss: 0.0559 - val_loss: 0.0296\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 3: val_loss improved from 0.02957 to 0.01262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 548ms/step - loss: 0.0220 - val_loss: 0.0126\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 4: val_loss improved from 0.01262 to 0.00666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0114 - val_loss: 0.0067\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 5: val_loss improved from 0.00666 to 0.00424, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00424 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 542ms/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00310 to 0.00246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 543ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00246 to 0.00208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00208 to 0.00180, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00180 to 0.00158, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 535ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_424\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2544 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1272 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_424 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2545 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1273 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2546 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1274 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2547 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_848 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2548 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_849 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2549 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3156\n",
      "Epoch 1: val_loss improved from inf to 0.15613, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 560ms/step - loss: 0.3156 - val_loss: 0.1561\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0893\n",
      "Epoch 2: val_loss improved from 0.15613 to 0.05483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 559ms/step - loss: 0.0893 - val_loss: 0.0548\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0426\n",
      "Epoch 3: val_loss improved from 0.05483 to 0.02916, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0426 - val_loss: 0.0292\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 4: val_loss improved from 0.02916 to 0.01849, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0254 - val_loss: 0.0185\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 5: val_loss improved from 0.01849 to 0.01219, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0171 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 6: val_loss improved from 0.01219 to 0.00811, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 7: val_loss improved from 0.00811 to 0.00550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 548ms/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 8: val_loss improved from 0.00550 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00429 to 0.00362, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 10: val_loss improved from 0.00362 to 0.00315, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 538ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_425\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2550 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1275 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_425 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2551 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1276 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2552 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1277 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2553 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_850 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2554 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_851 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2555 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3138\n",
      "Epoch 1: val_loss improved from inf to 0.21036, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.3138 - val_loss: 0.2104\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0998\n",
      "Epoch 2: val_loss improved from 0.21036 to 0.04158, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0998 - val_loss: 0.0416\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0293\n",
      "Epoch 3: val_loss improved from 0.04158 to 0.01845, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0293 - val_loss: 0.0184\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.01845 to 0.00948, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 555ms/step - loss: 0.0146 - val_loss: 0.0095\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 5: val_loss improved from 0.00948 to 0.00530, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.00530 to 0.00389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00389 to 0.00316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00316 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00269 to 0.00234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00234 to 0.00207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 555ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_426\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2556 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1278 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_426 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2557 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1279 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2558 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1280 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2559 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_852 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2560 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_853 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2561 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1950\n",
      "Epoch 1: val_loss improved from inf to 0.07931, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.1950 - val_loss: 0.0793\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0574\n",
      "Epoch 2: val_loss improved from 0.07931 to 0.04098, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0574 - val_loss: 0.0410\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0293\n",
      "Epoch 3: val_loss improved from 0.04098 to 0.02234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0293 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0184\n",
      "Epoch 4: val_loss improved from 0.02234 to 0.01501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0184 - val_loss: 0.0150\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01501 to 0.00993, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.00993 to 0.00600, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0081 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00600 to 0.00425, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00425 to 0.00348, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00348 to 0.00300, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00300 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0033 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_427\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2562 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1281 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_427 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2563 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1282 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2564 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1283 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2565 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_854 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2566 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_855 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2567 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3072\n",
      "Epoch 1: val_loss improved from inf to 0.21942, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.3072 - val_loss: 0.2194\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0887\n",
      "Epoch 2: val_loss improved from 0.21942 to 0.04759, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0887 - val_loss: 0.0476\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 3: val_loss improved from 0.04759 to 0.02570, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0328 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 4: val_loss improved from 0.02570 to 0.01646, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0189 - val_loss: 0.0165\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 5: val_loss improved from 0.01646 to 0.01041, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.01041 to 0.00778, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00778 to 0.00645, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00645 to 0.00546, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00546 to 0.00467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 573ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00467 to 0.00419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_428\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2568 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1284 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_428 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2569 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1285 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2570 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1286 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2571 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_856 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2572 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_857 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2573 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1: val_loss improved from inf to 0.13922, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 584ms/step - loss: 0.2416 - val_loss: 0.1392\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0782\n",
      "Epoch 2: val_loss improved from 0.13922 to 0.05892, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0782 - val_loss: 0.0589\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0335\n",
      "Epoch 3: val_loss improved from 0.05892 to 0.02574, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0335 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.02574 to 0.01371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0146 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.01371 to 0.01052, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.01052 to 0.00911, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0062 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00911 to 0.00800, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0053 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00800 to 0.00713, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00713 to 0.00640, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00640 to 0.00583, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0036 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_429\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2574 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1287 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_429 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2575 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1288 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2576 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1289 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2577 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_858 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2578 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_859 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2579 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1837\n",
      "Epoch 1: val_loss improved from inf to 0.06617, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.1837 - val_loss: 0.0662\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0408\n",
      "Epoch 2: val_loss improved from 0.06617 to 0.03766, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0408 - val_loss: 0.0377\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0232\n",
      "Epoch 3: val_loss improved from 0.03766 to 0.02429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0232 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.02429 to 0.01689, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0146 - val_loss: 0.0169\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01689 to 0.01215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0091 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.01215 to 0.00961, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0061 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00961 to 0.00817, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0047 - val_loss: 0.0082\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00817 to 0.00711, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0038 - val_loss: 0.0071\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00711 to 0.00636, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0032 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00636 to 0.00575, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0028 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_430\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2580 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1290 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_430 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2581 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1291 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2582 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1292 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2583 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_860 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2584 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_861 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2585 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2824\n",
      "Epoch 1: val_loss improved from inf to 0.20689, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 579ms/step - loss: 0.2824 - val_loss: 0.2069\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0790\n",
      "Epoch 2: val_loss improved from 0.20689 to 0.05015, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0790 - val_loss: 0.0501\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 3: val_loss improved from 0.05015 to 0.02266, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0291 - val_loss: 0.0227\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 4: val_loss improved from 0.02266 to 0.01467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01467 to 0.01124, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.01124 to 0.00866, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0062 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00866 to 0.00701, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00701 to 0.00616, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00616 to 0.00561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00561 to 0.00517, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_431\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2586 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1293 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_431 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2587 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1294 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2588 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1295 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2589 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_862 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2590 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_863 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2591 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2968\n",
      "Epoch 1: val_loss improved from inf to 0.27118, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.2968 - val_loss: 0.2712\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1210\n",
      "Epoch 2: val_loss improved from 0.27118 to 0.06062, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.1210 - val_loss: 0.0606\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 3: val_loss improved from 0.06062 to 0.03404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0424 - val_loss: 0.0340\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 4: val_loss improved from 0.03404 to 0.01851, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0219 - val_loss: 0.0185\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01851 to 0.00982, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00982 to 0.00608, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00608 to 0.00489, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00489 to 0.00433, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00433 to 0.00390, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00390 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_432\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2592 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1296 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_432 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2593 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1297 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2594 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1298 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2595 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_864 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2596 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_865 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2597 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2766\n",
      "Epoch 1: val_loss improved from inf to 0.19467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.2766 - val_loss: 0.1947\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0873\n",
      "Epoch 2: val_loss improved from 0.19467 to 0.05091, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0873 - val_loss: 0.0509\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0350\n",
      "Epoch 3: val_loss improved from 0.05091 to 0.02341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0350 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss improved from 0.02341 to 0.01200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01200 to 0.00760, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00760 to 0.00535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00535 to 0.00398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00398 to 0.00329, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00329 to 0.00297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00297 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_433\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2598 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1299 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_433 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2599 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1300 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2600 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1301 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2601 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_866 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2602 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_867 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2603 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3007\n",
      "Epoch 1: val_loss improved from inf to 0.20382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.3007 - val_loss: 0.2038\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0894\n",
      "Epoch 2: val_loss improved from 0.20382 to 0.03726, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0894 - val_loss: 0.0373\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 3: val_loss improved from 0.03726 to 0.01587, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0241 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 4: val_loss improved from 0.01587 to 0.00957, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0130 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.00957 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00663 to 0.00496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00496 to 0.00385, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00385 to 0.00317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00317 to 0.00272, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00272 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_434\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2604 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1302 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_434 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2605 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1303 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2606 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1304 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2607 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_868 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2608 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_869 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2609 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3275\n",
      "Epoch 1: val_loss improved from inf to 0.24644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.3275 - val_loss: 0.2464\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1624\n",
      "Epoch 2: val_loss improved from 0.24644 to 0.05671, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.1624 - val_loss: 0.0567\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0407\n",
      "Epoch 3: val_loss improved from 0.05671 to 0.02409, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0407 - val_loss: 0.0241\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 4: val_loss improved from 0.02409 to 0.01251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0187 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01251 to 0.00700, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 589ms/step - loss: 0.0107 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00700 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00474 to 0.00350, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00350 to 0.00273, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00273 to 0.00231, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00231 to 0.00205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_435\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2610 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1305 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_435 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2611 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1306 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2612 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1307 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2613 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_870 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2614 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_871 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2615 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2047\n",
      "Epoch 1: val_loss improved from inf to 0.06721, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.2047 - val_loss: 0.0672\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0414\n",
      "Epoch 2: val_loss improved from 0.06721 to 0.02456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0414 - val_loss: 0.0246\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 3: val_loss improved from 0.02456 to 0.01002, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0176 - val_loss: 0.0100\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 4: val_loss improved from 0.01002 to 0.00508, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 5: val_loss improved from 0.00508 to 0.00340, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 6: val_loss improved from 0.00340 to 0.00262, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 7: val_loss improved from 0.00262 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 8: val_loss improved from 0.00225 to 0.00200, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00200 to 0.00179, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00179 to 0.00164, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_436\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2616 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1308 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_436 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2617 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1309 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2618 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1310 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2619 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_872 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2620 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_873 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2621 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2596\n",
      "Epoch 1: val_loss improved from inf to 0.10405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 632ms/step - loss: 0.2596 - val_loss: 0.1040\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0598\n",
      "Epoch 2: val_loss improved from 0.10405 to 0.03765, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0598 - val_loss: 0.0376\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0281\n",
      "Epoch 3: val_loss improved from 0.03765 to 0.01791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0281 - val_loss: 0.0179\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01791 to 0.00858, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0141 - val_loss: 0.0086\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.00858 to 0.00479, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 582ms/step - loss: 0.0079 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00479 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00331 to 0.00265, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00265 to 0.00225, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00225 to 0.00201, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00201 to 0.00182, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_437\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2622 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1311 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_437 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2623 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1312 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2624 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1313 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2625 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_874 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2626 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_875 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2627 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2815\n",
      "Epoch 1: val_loss improved from inf to 0.16869, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.2815 - val_loss: 0.1687\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0839\n",
      "Epoch 2: val_loss improved from 0.16869 to 0.04367, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0839 - val_loss: 0.0437\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0272\n",
      "Epoch 3: val_loss improved from 0.04367 to 0.01364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0272 - val_loss: 0.0136\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 4: val_loss improved from 0.01364 to 0.00710, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 5: val_loss improved from 0.00710 to 0.00524, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00524 to 0.00419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00419 to 0.00343, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00343 to 0.00287, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00287 to 0.00246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00246 to 0.00211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_438\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2628 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1314 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_438 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2629 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1315 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2630 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1316 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2631 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_876 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2632 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_877 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2633 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2248\n",
      "Epoch 1: val_loss improved from inf to 0.10672, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.2248 - val_loss: 0.1067\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0699\n",
      "Epoch 2: val_loss improved from 0.10672 to 0.04899, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0699 - val_loss: 0.0490\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 3: val_loss improved from 0.04899 to 0.02251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0330 - val_loss: 0.0225\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 4: val_loss improved from 0.02251 to 0.01253, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 619ms/step - loss: 0.0167 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01253 to 0.00795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00795 to 0.00584, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00584 to 0.00463, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00463 to 0.00384, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00384 to 0.00331, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00331 to 0.00295, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_439\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2634 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1317 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_439 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2635 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1318 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2636 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1319 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2637 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_878 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2638 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_879 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2639 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2888\n",
      "Epoch 1: val_loss improved from inf to 0.20108, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 616ms/step - loss: 0.2888 - val_loss: 0.2011\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0836\n",
      "Epoch 2: val_loss improved from 0.20108 to 0.04456, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0836 - val_loss: 0.0446\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 3: val_loss improved from 0.04456 to 0.02132, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0284 - val_loss: 0.0213\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.02132 to 0.01203, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 611ms/step - loss: 0.0145 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 5: val_loss improved from 0.01203 to 0.00753, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 611ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00753 to 0.00576, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00576 to 0.00481, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00481 to 0.00419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00419 to 0.00376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 611ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00376 to 0.00343, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_440\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2640 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1320 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_440 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2641 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1321 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2642 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1322 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2643 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_880 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2644 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_881 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2645 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2610\n",
      "Epoch 1: val_loss improved from inf to 0.17170, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 622ms/step - loss: 0.2610 - val_loss: 0.1717\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0740\n",
      "Epoch 2: val_loss improved from 0.17170 to 0.04960, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0740 - val_loss: 0.0496\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0290\n",
      "Epoch 3: val_loss improved from 0.04960 to 0.02469, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0290 - val_loss: 0.0247\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 4: val_loss improved from 0.02469 to 0.01700, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 616ms/step - loss: 0.0157 - val_loss: 0.0170\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01700 to 0.01283, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0107 - val_loss: 0.0128\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.01283 to 0.00990, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0077 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00990 to 0.00779, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00779 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00663 to 0.00600, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00600 to 0.00556, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.0033 - val_loss: 0.0056\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_441\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2646 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1323 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_441 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2647 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1324 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2648 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1325 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2649 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_882 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2650 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_883 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2651 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2455\n",
      "Epoch 1: val_loss improved from inf to 0.16499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 623ms/step - loss: 0.2455 - val_loss: 0.1650\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0816\n",
      "Epoch 2: val_loss improved from 0.16499 to 0.06640, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0816 - val_loss: 0.0664\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0413\n",
      "Epoch 3: val_loss improved from 0.06640 to 0.03405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0413 - val_loss: 0.0341\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 4: val_loss improved from 0.03405 to 0.01921, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01921 to 0.01296, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 611ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.01296 to 0.01017, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0069 - val_loss: 0.0102\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.01017 to 0.00855, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0054 - val_loss: 0.0085\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00855 to 0.00728, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00728 to 0.00641, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00641 to 0.00579, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0031 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_442\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2652 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1326 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_442 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2653 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1327 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2654 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1328 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2655 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_884 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2656 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_885 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2657 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1959\n",
      "Epoch 1: val_loss improved from inf to 0.07737, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.1959 - val_loss: 0.0774\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0485\n",
      "Epoch 2: val_loss improved from 0.07737 to 0.03496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0485 - val_loss: 0.0350\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 3: val_loss improved from 0.03496 to 0.01918, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0196 - val_loss: 0.0192\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 4: val_loss improved from 0.01918 to 0.01389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.01389 to 0.01060, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.01060 to 0.00878, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0057 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00878 to 0.00762, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0046 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00762 to 0.00685, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.0039 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00685 to 0.00626, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00626 to 0.00578, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0032 - val_loss: 0.0058\n",
      "finished training\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_443\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2658 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1329 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_443 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2659 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1330 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2660 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1331 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2661 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_886 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2662 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_887 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2663 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1: val_loss improved from inf to 0.13492, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.2451 - val_loss: 0.1349\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0739\n",
      "Epoch 2: val_loss improved from 0.13492 to 0.05472, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 611ms/step - loss: 0.0739 - val_loss: 0.0547\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0338\n",
      "Epoch 3: val_loss improved from 0.05472 to 0.02382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0338 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02382 to 0.01361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0162 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01361 to 0.00887, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00887 to 0.00678, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00678 to 0.00558, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00558 to 0.00483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00483 to 0.00436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00436 to 0.00404, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_444\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2664 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1332 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_444 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2665 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1333 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2666 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1334 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2667 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_888 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2668 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_889 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2669 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2817\n",
      "Epoch 1: val_loss improved from inf to 0.18720, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 611ms/step - loss: 0.2817 - val_loss: 0.1872\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0794\n",
      "Epoch 2: val_loss improved from 0.18720 to 0.04187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0794 - val_loss: 0.0419\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0275\n",
      "Epoch 3: val_loss improved from 0.04187 to 0.01629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0275 - val_loss: 0.0163\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 4: val_loss improved from 0.01629 to 0.00929, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0121 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00929 to 0.00647, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00647 to 0.00491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00491 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00405 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00354 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00321 to 0.00299, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_445\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2670 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1335 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_445 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2671 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1336 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2672 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1337 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2673 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_890 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2674 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_891 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2675 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2279\n",
      "Epoch 1: val_loss improved from inf to 0.09171, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.2279 - val_loss: 0.0917\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0509\n",
      "Epoch 2: val_loss improved from 0.09171 to 0.03153, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0509 - val_loss: 0.0315\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 3: val_loss improved from 0.03153 to 0.01502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0219 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 4: val_loss improved from 0.01502 to 0.00784, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 5: val_loss improved from 0.00784 to 0.00482, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0073 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 6: val_loss improved from 0.00482 to 0.00338, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00338 to 0.00275, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00275 to 0.00242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00242 to 0.00221, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00221 to 0.00202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_446\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2676 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1338 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_446 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2677 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1339 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2678 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1340 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2679 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_892 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2680 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_893 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2681 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3386\n",
      "Epoch 1: val_loss improved from inf to 0.26491, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 619ms/step - loss: 0.3386 - val_loss: 0.2649\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1754\n",
      "Epoch 2: val_loss improved from 0.26491 to 0.08082, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.1754 - val_loss: 0.0808\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0539\n",
      "Epoch 3: val_loss improved from 0.08082 to 0.02769, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0539 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0204\n",
      "Epoch 4: val_loss improved from 0.02769 to 0.01293, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0204 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01293 to 0.00667, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0110 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00667 to 0.00413, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00413 to 0.00319, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 611ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00319 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00271 to 0.00240, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 621ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00240 to 0.00216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_447\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2682 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1341 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_447 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2683 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1342 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2684 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1343 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2685 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_894 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2686 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_895 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2687 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2732\n",
      "Epoch 1: val_loss improved from inf to 0.09834, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 628ms/step - loss: 0.2732 - val_loss: 0.0983\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0648\n",
      "Epoch 2: val_loss improved from 0.09834 to 0.04495, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 620ms/step - loss: 0.0648 - val_loss: 0.0449\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0340\n",
      "Epoch 3: val_loss improved from 0.04495 to 0.02172, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0340 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0175\n",
      "Epoch 4: val_loss improved from 0.02172 to 0.01076, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0175 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01076 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0099 - val_loss: 0.0063\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00629 to 0.00398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 632ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00398 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00281 to 0.00223, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00223 to 0.00194, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00194 to 0.00177, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_448\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2688 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1344 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_448 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2689 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1345 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2690 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1346 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2691 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_896 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2692 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_897 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2693 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2567\n",
      "Epoch 1: val_loss improved from inf to 0.11561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 618ms/step - loss: 0.2567 - val_loss: 0.1156\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0686\n",
      "Epoch 2: val_loss improved from 0.11561 to 0.04512, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.0686 - val_loss: 0.0451\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 3: val_loss improved from 0.04512 to 0.01909, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 620ms/step - loss: 0.0311 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.01909 to 0.00971, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0153 - val_loss: 0.0097\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.00971 to 0.00525, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00525 to 0.00335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00335 to 0.00243, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 8: val_loss improved from 0.00243 to 0.00204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 9: val_loss improved from 0.00204 to 0.00183, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 10: val_loss improved from 0.00183 to 0.00165, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_449\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2694 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1347 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_449 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2695 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1348 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2696 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1349 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2697 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_898 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2698 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_899 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2699 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2726\n",
      "Epoch 1: val_loss improved from inf to 0.15264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 615ms/step - loss: 0.2726 - val_loss: 0.1526\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0819\n",
      "Epoch 2: val_loss improved from 0.15264 to 0.05181, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0819 - val_loss: 0.0518\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0387\n",
      "Epoch 3: val_loss improved from 0.05181 to 0.02657, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 619ms/step - loss: 0.0387 - val_loss: 0.0266\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0205\n",
      "Epoch 4: val_loss improved from 0.02657 to 0.01461, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 616ms/step - loss: 0.0205 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01461 to 0.00788, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 610ms/step - loss: 0.0119 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00788 to 0.00477, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 621ms/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00477 to 0.00358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 625ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00358 to 0.00298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00298 to 0.00257, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00257 to 0.00229, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_450\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2700 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1350 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_450 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2701 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1351 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2702 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1352 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2703 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_900 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2704 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_901 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2705 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2824\n",
      "Epoch 1: val_loss improved from inf to 0.17297, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 616ms/step - loss: 0.2824 - val_loss: 0.1730\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0773\n",
      "Epoch 2: val_loss improved from 0.17297 to 0.04150, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0773 - val_loss: 0.0415\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 3: val_loss improved from 0.04150 to 0.01470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0260 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 4: val_loss improved from 0.01470 to 0.00795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 620ms/step - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 5: val_loss improved from 0.00795 to 0.00520, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 6: val_loss improved from 0.00520 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss improved from 0.00364 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00303 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00271 to 0.00248, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 655ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00248 to 0.00230, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 636ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_451\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2706 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1353 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_451 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2707 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1354 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2708 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1355 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2709 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_902 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2710 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_903 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2711 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3066\n",
      "Epoch 1: val_loss improved from inf to 0.26946, saving model to best_weights.h5\n",
      "45/45 [==============================] - 31s 677ms/step - loss: 0.3066 - val_loss: 0.2695\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1292\n",
      "Epoch 2: val_loss improved from 0.26946 to 0.05279, saving model to best_weights.h5\n",
      "45/45 [==============================] - 29s 641ms/step - loss: 0.1292 - val_loss: 0.0528\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0383\n",
      "Epoch 3: val_loss improved from 0.05279 to 0.03128, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0383 - val_loss: 0.0313\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 4: val_loss improved from 0.03128 to 0.01525, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0211 - val_loss: 0.0153\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01525 to 0.00951, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 613ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00951 to 0.00688, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00688 to 0.00537, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00537 to 0.00450, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00450 to 0.00407, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00407 to 0.00379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_452\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2712 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1356 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_452 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2713 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1357 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2714 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1358 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2715 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_904 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2716 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_905 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2717 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2196\n",
      "Epoch 1: val_loss improved from inf to 0.09236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 605ms/step - loss: 0.2196 - val_loss: 0.0924\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0575\n",
      "Epoch 2: val_loss improved from 0.09236 to 0.04273, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0575 - val_loss: 0.0427\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 3: val_loss improved from 0.04273 to 0.02233, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0257 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 4: val_loss improved from 0.02233 to 0.01460, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01460 to 0.01039, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.01039 to 0.00773, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 609ms/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00773 to 0.00644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00644 to 0.00582, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00582 to 0.00539, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00539 to 0.00507, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0031 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_453\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2718 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1359 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_453 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2719 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1360 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2720 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1361 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2721 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_906 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2722 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_907 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2723 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2644\n",
      "Epoch 1: val_loss improved from inf to 0.18555, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 612ms/step - loss: 0.2644 - val_loss: 0.1856\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0703\n",
      "Epoch 2: val_loss improved from 0.18555 to 0.04197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 607ms/step - loss: 0.0703 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 3: val_loss improved from 0.04197 to 0.01658, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0194 - val_loss: 0.0166\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 4: val_loss improved from 0.01658 to 0.01169, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 5: val_loss improved from 0.01169 to 0.00893, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0056 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 6: val_loss improved from 0.00893 to 0.00740, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0041 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 7: val_loss improved from 0.00740 to 0.00655, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 8: val_loss improved from 0.00655 to 0.00596, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 605ms/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 9: val_loss improved from 0.00596 to 0.00541, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0027 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 10: val_loss improved from 0.00541 to 0.00487, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_454\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2724 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1362 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_454 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2725 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1363 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2726 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1364 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2727 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_908 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2728 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_909 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2729 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2344\n",
      "Epoch 1: val_loss improved from inf to 0.11416, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 625ms/step - loss: 0.2344 - val_loss: 0.1142\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0574\n",
      "Epoch 2: val_loss improved from 0.11416 to 0.04611, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 617ms/step - loss: 0.0574 - val_loss: 0.0461\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0285\n",
      "Epoch 3: val_loss improved from 0.04611 to 0.02383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0285 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.02383 to 0.01571, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0152 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01571 to 0.01156, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.01156 to 0.00910, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00910 to 0.00760, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00760 to 0.00663, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00663 to 0.00600, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00600 to 0.00549, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0032 - val_loss: 0.0055\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_455\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2730 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1365 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_455 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2731 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1366 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2732 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1367 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2733 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_910 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2734 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_911 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2735 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1966\n",
      "Epoch 1: val_loss improved from inf to 0.08408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 607ms/step - loss: 0.1966 - val_loss: 0.0841\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0462\n",
      "Epoch 2: val_loss improved from 0.08408 to 0.03553, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0462 - val_loss: 0.0355\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 3: val_loss improved from 0.03553 to 0.01967, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0237 - val_loss: 0.0197\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 4: val_loss improved from 0.01967 to 0.01251, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0136 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01251 to 0.00871, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00871 to 0.00665, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00665 to 0.00552, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 606ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00552 to 0.00480, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 601ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00480 to 0.00432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 616ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00432 to 0.00398, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 604ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_456\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2736 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1368 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_456 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2737 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1369 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2738 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1370 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2739 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_912 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2740 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_913 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2741 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2682\n",
      "Epoch 1: val_loss improved from inf to 0.16794, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 605ms/step - loss: 0.2682 - val_loss: 0.1679\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0609\n",
      "Epoch 2: val_loss improved from 0.16794 to 0.03035, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 608ms/step - loss: 0.0609 - val_loss: 0.0303\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0229\n",
      "Epoch 3: val_loss improved from 0.03035 to 0.01719, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.0229 - val_loss: 0.0172\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 4: val_loss improved from 0.01719 to 0.01088, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0139 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01088 to 0.00717, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00717 to 0.00535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00535 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00429 to 0.00364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00364 to 0.00320, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00320 to 0.00291, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 600ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_457\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2742 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1371 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_457 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2743 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1372 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2744 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1373 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2745 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_914 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2746 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_915 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2747 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3329\n",
      "Epoch 1: val_loss improved from inf to 0.24874, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.3329 - val_loss: 0.2487\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1432\n",
      "Epoch 2: val_loss improved from 0.24874 to 0.06054, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.1432 - val_loss: 0.0605\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0484\n",
      "Epoch 3: val_loss improved from 0.06054 to 0.03115, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0484 - val_loss: 0.0311\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0240\n",
      "Epoch 4: val_loss improved from 0.03115 to 0.01530, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0240 - val_loss: 0.0153\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01530 to 0.00827, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0132 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00827 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 589ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00499 to 0.00371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 588ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00371 to 0.00318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00318 to 0.00285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00285 to 0.00261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_458\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2748 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1374 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_458 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2749 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1375 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2750 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1376 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2751 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_916 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2752 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_917 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2753 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3052\n",
      "Epoch 1: val_loss improved from inf to 0.20781, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.3052 - val_loss: 0.2078\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1259\n",
      "Epoch 2: val_loss improved from 0.20781 to 0.05411, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 599ms/step - loss: 0.1259 - val_loss: 0.0541\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 3: val_loss improved from 0.05411 to 0.02066, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0403 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss improved from 0.02066 to 0.00888, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0159 - val_loss: 0.0089\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.00888 to 0.00566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00566 to 0.00372, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00372 to 0.00260, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00260 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00209 to 0.00184, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00184 to 0.00166, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_459\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2754 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1377 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_459 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2755 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1378 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2756 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1379 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2757 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_918 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2758 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_919 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2759 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1157\n",
      "Epoch 1: val_loss improved from inf to 0.04891, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.1157 - val_loss: 0.0489\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 2: val_loss improved from 0.04891 to 0.02148, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 589ms/step - loss: 0.0377 - val_loss: 0.0215\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 3: val_loss improved from 0.02148 to 0.01077, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0179 - val_loss: 0.0108\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 4: val_loss improved from 0.01077 to 0.00670, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 5: val_loss improved from 0.00670 to 0.00455, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00455 to 0.00316, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00316 to 0.00237, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00237 to 0.00197, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00197 to 0.00172, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00172 to 0.00152, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_460\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2760 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1380 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_460 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2761 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1381 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2762 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1382 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2763 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_920 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2764 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_921 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2765 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2807\n",
      "Epoch 1: val_loss improved from inf to 0.15590, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.2807 - val_loss: 0.1559\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1007\n",
      "Epoch 2: val_loss improved from 0.15590 to 0.06713, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.1007 - val_loss: 0.0671\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0526\n",
      "Epoch 3: val_loss improved from 0.06713 to 0.03247, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0526 - val_loss: 0.0325\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0253\n",
      "Epoch 4: val_loss improved from 0.03247 to 0.01589, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0253 - val_loss: 0.0159\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01589 to 0.00856, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0140 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 6: val_loss improved from 0.00856 to 0.00501, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00501 to 0.00341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00341 to 0.00271, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00271 to 0.00232, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 596ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00232 to 0.00206, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_461\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2766 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1383 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_461 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2767 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1384 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2768 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1385 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2769 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_922 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2770 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_923 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2771 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2307\n",
      "Epoch 1: val_loss improved from inf to 0.09512, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 587ms/step - loss: 0.2307 - val_loss: 0.0951\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0607\n",
      "Epoch 2: val_loss improved from 0.09512 to 0.04043, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0607 - val_loss: 0.0404\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 3: val_loss improved from 0.04043 to 0.01819, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0297 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.01819 to 0.01018, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.0153 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01018 to 0.00654, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00654 to 0.00452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00452 to 0.00337, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00337 to 0.00276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00276 to 0.00236, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00236 to 0.00209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_462\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2772 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1386 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_462 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2773 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1387 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2774 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1388 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2775 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_924 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2776 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_925 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2777 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2432\n",
      "Epoch 1: val_loss improved from inf to 0.13242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.2432 - val_loss: 0.1324\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0656\n",
      "Epoch 2: val_loss improved from 0.13242 to 0.04191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0656 - val_loss: 0.0419\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 3: val_loss improved from 0.04191 to 0.02132, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0311 - val_loss: 0.0213\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.02132 to 0.01233, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0166 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01233 to 0.00770, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00770 to 0.00553, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00553 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00429 to 0.00349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00349 to 0.00302, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00302 to 0.00268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0033 - val_loss: 0.0027\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_463\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2778 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1389 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_463 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2779 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1390 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2780 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1391 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2781 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_926 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2782 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_927 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2783 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2796\n",
      "Epoch 1: val_loss improved from inf to 0.18129, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 593ms/step - loss: 0.2796 - val_loss: 0.1813\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0834\n",
      "Epoch 2: val_loss improved from 0.18129 to 0.05155, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0834 - val_loss: 0.0516\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0371\n",
      "Epoch 3: val_loss improved from 0.05155 to 0.02789, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0371 - val_loss: 0.0279\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0205\n",
      "Epoch 4: val_loss improved from 0.02789 to 0.01749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0205 - val_loss: 0.0175\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.01749 to 0.01234, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0136 - val_loss: 0.0123\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01234 to 0.00940, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00940 to 0.00758, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 8: val_loss improved from 0.00758 to 0.00639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0062 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00639 to 0.00551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00551 to 0.00482, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 597ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_464\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2784 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1392 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_464 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2785 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1393 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2786 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1394 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2787 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_928 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2788 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_929 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2789 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2860\n",
      "Epoch 1: val_loss improved from inf to 0.22198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 28s 614ms/step - loss: 0.2860 - val_loss: 0.2220\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0958\n",
      "Epoch 2: val_loss improved from 0.22198 to 0.06207, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0958 - val_loss: 0.0621\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 3: val_loss improved from 0.06207 to 0.03496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 590ms/step - loss: 0.0419 - val_loss: 0.0350\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0238\n",
      "Epoch 4: val_loss improved from 0.03496 to 0.02285, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0238 - val_loss: 0.0229\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 5: val_loss improved from 0.02285 to 0.01572, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.0151 - val_loss: 0.0157\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 6: val_loss improved from 0.01572 to 0.01156, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 584ms/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.01156 to 0.00872, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0070 - val_loss: 0.0087\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00872 to 0.00731, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0053 - val_loss: 0.0073\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00731 to 0.00640, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 581ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00640 to 0.00570, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0038 - val_loss: 0.0057\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_465\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2790 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1395 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_465 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2791 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1396 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2792 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1397 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2793 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_930 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2794 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_931 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2795 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2337\n",
      "Epoch 1: val_loss improved from inf to 0.13341, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 584ms/step - loss: 0.2337 - val_loss: 0.1334\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0729\n",
      "Epoch 2: val_loss improved from 0.13341 to 0.05750, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 576ms/step - loss: 0.0729 - val_loss: 0.0575\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0332\n",
      "Epoch 3: val_loss improved from 0.05750 to 0.02682, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0332 - val_loss: 0.0268\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.02682 to 0.01565, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.01565 to 0.01061, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.01061 to 0.00881, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0052 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00881 to 0.00784, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0042 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00784 to 0.00719, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0037 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00719 to 0.00668, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0034 - val_loss: 0.0067\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00668 to 0.00627, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0031 - val_loss: 0.0063\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_466\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2796 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1398 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_466 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2797 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1399 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2798 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1400 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2799 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_932 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2800 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_933 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2801 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2840\n",
      "Epoch 1: val_loss improved from inf to 0.25790, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.2840 - val_loss: 0.2579\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1037\n",
      "Epoch 2: val_loss improved from 0.25790 to 0.05793, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.1037 - val_loss: 0.0579\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0352\n",
      "Epoch 3: val_loss improved from 0.05793 to 0.02675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0352 - val_loss: 0.0268\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 4: val_loss improved from 0.02675 to 0.01575, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 559ms/step - loss: 0.0165 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01575 to 0.01051, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.01051 to 0.00845, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00845 to 0.00726, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00726 to 0.00639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00639 to 0.00571, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00571 to 0.00523, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0031 - val_loss: 0.0052\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_467\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2802 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1401 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_467 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2803 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1402 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2804 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1403 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2805 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_934 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2806 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_935 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2807 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2690\n",
      "Epoch 1: val_loss improved from inf to 0.18132, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.2690 - val_loss: 0.1813\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0895\n",
      "Epoch 2: val_loss improved from 0.18132 to 0.06328, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 555ms/step - loss: 0.0895 - val_loss: 0.0633\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0389\n",
      "Epoch 3: val_loss improved from 0.06328 to 0.02527, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0389 - val_loss: 0.0253\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 4: val_loss improved from 0.02527 to 0.01294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0169 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01294 to 0.00792, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0085 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00792 to 0.00590, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00590 to 0.00489, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00489 to 0.00432, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00432 to 0.00394, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00394 to 0.00366, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0030 - val_loss: 0.0037\n",
      "finished training\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_468\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2808 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1404 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_468 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2809 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1405 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2810 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1406 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2811 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_936 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2812 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_937 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2813 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2605\n",
      "Epoch 1: val_loss improved from inf to 0.17813, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.2605 - val_loss: 0.1781\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0915\n",
      "Epoch 2: val_loss improved from 0.17813 to 0.05678, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0915 - val_loss: 0.0568\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0374\n",
      "Epoch 3: val_loss improved from 0.05678 to 0.02093, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0374 - val_loss: 0.0209\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.02093 to 0.01027, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.01027 to 0.00673, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00673 to 0.00505, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00505 to 0.00408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00408 to 0.00345, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00345 to 0.00299, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00299 to 0.00264, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_469\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2814 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1407 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_469 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2815 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1408 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2816 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1409 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2817 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_938 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2818 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_939 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2819 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3082\n",
      "Epoch 1: val_loss improved from inf to 0.21783, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.3082 - val_loss: 0.2178\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1216\n",
      "Epoch 2: val_loss improved from 0.21783 to 0.05775, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.1216 - val_loss: 0.0577\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0406\n",
      "Epoch 3: val_loss improved from 0.05775 to 0.02416, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 567ms/step - loss: 0.0406 - val_loss: 0.0242\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02416 to 0.01205, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0191 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 5: val_loss improved from 0.01205 to 0.00734, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00734 to 0.00517, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00517 to 0.00377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00377 to 0.00288, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00288 to 0.00239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00239 to 0.00212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_470\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2820 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1410 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_470 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2821 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1411 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2822 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1412 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2823 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_940 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2824 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_941 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2825 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2918\n",
      "Epoch 1: val_loss improved from inf to 0.17628, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.2918 - val_loss: 0.1763\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0997\n",
      "Epoch 2: val_loss improved from 0.17628 to 0.05242, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0997 - val_loss: 0.0524\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0408\n",
      "Epoch 3: val_loss improved from 0.05242 to 0.02308, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0408 - val_loss: 0.0231\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 4: val_loss improved from 0.02308 to 0.00985, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0183 - val_loss: 0.0099\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.00985 to 0.00458, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00458 to 0.00317, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00317 to 0.00250, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 555ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00250 to 0.00213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00213 to 0.00191, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00191 to 0.00174, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_471\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2826 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1413 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_471 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2827 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1414 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2828 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1415 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2829 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_942 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2830 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_943 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2831 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3271\n",
      "Epoch 1: val_loss improved from inf to 0.20259, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.3271 - val_loss: 0.2026\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1268\n",
      "Epoch 2: val_loss improved from 0.20259 to 0.05232, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.1268 - val_loss: 0.0523\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0410\n",
      "Epoch 3: val_loss improved from 0.05232 to 0.02379, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0410 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02379 to 0.01177, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0194 - val_loss: 0.0118\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 5: val_loss improved from 0.01177 to 0.00745, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0118 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.00745 to 0.00531, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00531 to 0.00362, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00362 to 0.00270, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00270 to 0.00216, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00216 to 0.00187, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_472\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2832 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1416 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_472 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2833 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1417 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2834 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1418 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2835 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_944 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2836 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_945 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2837 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.1785\n",
      "Epoch 1: val_loss improved from inf to 0.04618, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.1785 - val_loss: 0.0462\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 2: val_loss improved from 0.04618 to 0.02098, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0369 - val_loss: 0.0210\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 3: val_loss improved from 0.02098 to 0.01024, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0168 - val_loss: 0.0102\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 4: val_loss improved from 0.01024 to 0.00658, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0103 - val_loss: 0.0066\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.00658 to 0.00483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00483 to 0.00389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0062 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00389 to 0.00324, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 574ms/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00324 to 0.00270, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00270 to 0.00227, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00227 to 0.00198, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_473\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2838 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1419 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_473 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2839 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1420 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2840 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1421 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2841 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_946 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2842 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_947 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2843 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3138\n",
      "Epoch 1: val_loss improved from inf to 0.22309, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 584ms/step - loss: 0.3138 - val_loss: 0.2231\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1351\n",
      "Epoch 2: val_loss improved from 0.22309 to 0.06031, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.1351 - val_loss: 0.0603\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0414\n",
      "Epoch 3: val_loss improved from 0.06031 to 0.02208, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0414 - val_loss: 0.0221\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02208 to 0.01004, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0168 - val_loss: 0.0100\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01004 to 0.00541, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00541 to 0.00387, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00387 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00314 to 0.00269, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00269 to 0.00238, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00238 to 0.00215, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_474\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2844 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1422 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_474 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2845 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1423 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2846 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1424 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2847 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_948 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2848 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_949 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2849 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2649\n",
      "Epoch 1: val_loss improved from inf to 0.12383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.2649 - val_loss: 0.1238\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0685\n",
      "Epoch 2: val_loss improved from 0.12383 to 0.04666, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 552ms/step - loss: 0.0685 - val_loss: 0.0467\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0341\n",
      "Epoch 3: val_loss improved from 0.04666 to 0.02213, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0341 - val_loss: 0.0221\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02213 to 0.01329, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0179 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01329 to 0.00702, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 567ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00702 to 0.00458, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00458 to 0.00368, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 549ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00368 to 0.00315, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00315 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00281 to 0.00255, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_475\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2850 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1425 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_475 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2851 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1426 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2852 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1427 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2853 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_950 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2854 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_951 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2855 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2694\n",
      "Epoch 1: val_loss improved from inf to 0.18553, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 577ms/step - loss: 0.2694 - val_loss: 0.1855\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0793\n",
      "Epoch 2: val_loss improved from 0.18553 to 0.04277, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0793 - val_loss: 0.0428\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 3: val_loss improved from 0.04277 to 0.02034, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 560ms/step - loss: 0.0276 - val_loss: 0.0203\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.02034 to 0.01120, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.01120 to 0.00761, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 567ms/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 6: val_loss improved from 0.00761 to 0.00585, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 566ms/step - loss: 0.0056 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00585 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 562ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00474 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00405 to 0.00359, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 551ms/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00359 to 0.00321, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 564ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_476\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2856 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1428 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_476 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2857 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1429 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2858 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1430 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2859 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_952 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2860 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_953 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2861 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2664\n",
      "Epoch 1: val_loss improved from inf to 0.19276, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.2664 - val_loss: 0.1928\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0821\n",
      "Epoch 2: val_loss improved from 0.19276 to 0.04756, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0821 - val_loss: 0.0476\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.04756 to 0.02578, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 550ms/step - loss: 0.0294 - val_loss: 0.0258\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02578 to 0.01675, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0172 - val_loss: 0.0168\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01675 to 0.01081, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.01081 to 0.00760, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 561ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00760 to 0.00604, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00604 to 0.00528, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 9: val_loss improved from 0.00528 to 0.00476, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 572ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 10: val_loss improved from 0.00476 to 0.00437, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 553ms/step - loss: 0.0026 - val_loss: 0.0044\n",
      "finished training\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_477\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2862 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1431 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_477 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2863 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1432 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2864 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1433 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2865 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_954 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2866 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_955 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2867 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2874\n",
      "Epoch 1: val_loss improved from inf to 0.22434, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 580ms/step - loss: 0.2874 - val_loss: 0.2243\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0663\n",
      "Epoch 2: val_loss improved from 0.22434 to 0.03180, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 567ms/step - loss: 0.0663 - val_loss: 0.0318\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 3: val_loss improved from 0.03180 to 0.01899, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 558ms/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 4: val_loss improved from 0.01899 to 0.01426, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0110 - val_loss: 0.0143\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 5: val_loss improved from 0.01426 to 0.01102, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 579ms/step - loss: 0.0075 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.01102 to 0.00883, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 570ms/step - loss: 0.0055 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00883 to 0.00722, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 563ms/step - loss: 0.0042 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00722 to 0.00629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 565ms/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00629 to 0.00566, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 571ms/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00566 to 0.00512, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0027 - val_loss: 0.0051\n",
      "finished training\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_478\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2868 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1434 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_478 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2869 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1435 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2870 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1436 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2871 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_956 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2872 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_957 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2873 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2248\n",
      "Epoch 1: val_loss improved from inf to 0.11261, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 580ms/step - loss: 0.2248 - val_loss: 0.1126\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0618\n",
      "Epoch 2: val_loss improved from 0.11261 to 0.04239, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 568ms/step - loss: 0.0618 - val_loss: 0.0424\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0261\n",
      "Epoch 3: val_loss improved from 0.04239 to 0.02045, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0261 - val_loss: 0.0205\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 4: val_loss improved from 0.02045 to 0.01141, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 569ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 5: val_loss improved from 0.01141 to 0.00794, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 6: val_loss improved from 0.00794 to 0.00639, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 7: val_loss improved from 0.00639 to 0.00572, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 578ms/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00572 to 0.00532, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00532 to 0.00499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 583ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00499 to 0.00469, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 586ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "finished training\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_479\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2874 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1437 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_479 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2875 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1438 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2876 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1439 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2877 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_958 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2878 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_959 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2879 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3015\n",
      "Epoch 1: val_loss improved from inf to 0.22561, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.3015 - val_loss: 0.2256\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1092\n",
      "Epoch 2: val_loss improved from 0.22561 to 0.07294, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.1092 - val_loss: 0.0729\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0508\n",
      "Epoch 3: val_loss improved from 0.07294 to 0.03668, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 591ms/step - loss: 0.0508 - val_loss: 0.0367\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0262\n",
      "Epoch 4: val_loss improved from 0.03668 to 0.02039, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0262 - val_loss: 0.0204\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 5: val_loss improved from 0.02039 to 0.01185, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 585ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01185 to 0.00763, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00763 to 0.00569, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00569 to 0.00483, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00483 to 0.00438, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 588ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00438 to 0.00405, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 580ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "finished training\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_480\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2880 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1440 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_480 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2881 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1441 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2882 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1442 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2883 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_960 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2884 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_961 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2885 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2906\n",
      "Epoch 1: val_loss improved from inf to 0.19438, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 602ms/step - loss: 0.2906 - val_loss: 0.1944\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0764\n",
      "Epoch 2: val_loss improved from 0.19438 to 0.02848, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0764 - val_loss: 0.0285\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0185\n",
      "Epoch 3: val_loss improved from 0.02848 to 0.01212, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0185 - val_loss: 0.0121\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 4: val_loss improved from 0.01212 to 0.00738, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 592ms/step - loss: 0.0098 - val_loss: 0.0074\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 5: val_loss improved from 0.00738 to 0.00509, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 603ms/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 6: val_loss improved from 0.00509 to 0.00382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 598ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 7: val_loss improved from 0.00382 to 0.00325, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 587ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00325 to 0.00290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 594ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00290 to 0.00265, saving model to best_weights.h5\n",
      "45/45 [==============================] - 26s 575ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00265 to 0.00246, saving model to best_weights.h5\n",
      "45/45 [==============================] - 27s 595ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "finished training\n",
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    }
   ],
   "source": [
    "##Make prediction\n",
    "for lead_time in range(11,12):\n",
    "    for i in range (0,480,1):\n",
    "        X_train,y_train, X_test, y_test = prepare_data(lead_time)\n",
    "\n",
    "        ## The tuning process produced the hyperparameters below.\n",
    "        params = {'conv_depth': 32, 'hidden_size': 500,\n",
    "                  'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
    "\n",
    "\n",
    "        print(params)\n",
    "        param_string = '_'.join([str(e) for e in (N_train,num_epochs,lead_time)])\n",
    "\n",
    "\n",
    "        #run the model\n",
    "        model = build_model(**params)\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "\n",
    "        print('start training')\n",
    "        hist = model.fit(X_train, y_train,\n",
    "                           batch_size = batch_size,\n",
    "                 verbose=1, \n",
    "                 epochs = num_epochs,\n",
    "                 validation_data=(X_test,y_test),\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            min_delta=0,\n",
    "                                            patience=5, #To ensure a great deal of patience before ending\n",
    "                                            verbose=0, mode='auto'),\n",
    "                           keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', \n",
    "                                                        verbose=1, save_best_only=True, \n",
    "                                                        save_weights_only=True, mode='auto', period=1)]\n",
    "                 )\n",
    "\n",
    "        print('finished training')\n",
    "        \n",
    "        # To ensure the best model performance from the training based on learning curve,\n",
    "        # Because the early stopping callback saves the model's \"patience\" epochs after the best one, this is required.\n",
    "        model.load_weights('best_weights.h5')\n",
    "\n",
    "        # delete the file generated by Model Checkppoint\n",
    "        os.system('rm best_weights.h5')\n",
    "\n",
    "\n",
    "        model.save_weights(outdir+'weights_tunedparams_leadtime'+str(lead_time)+'train_'+str(i)+'params_'+param_string+'.h5')\n",
    "\n",
    "\n",
    "        # reformat history\n",
    "\n",
    "        hist =  hist.history\n",
    "\n",
    "\n",
    "        y_test_predicted = model.predict(X_test)\n",
    "\n",
    "        # compute accuracy\n",
    "        res = []\n",
    "        rmse = np.sqrt(np.mean((y_test_predicted - y_test)**2))\n",
    "        acc = acc_score(y_test_predicted, y_test)\n",
    "\n",
    "        res.append(dict(hist=hist,params=params, scores=[rmse,acc]))\n",
    "\n",
    "        pickle.dump(res,open(outdir+'training_result_sequential'+param_string+'.pkl','wb'))\n",
    "\n",
    "        #plot loss value\n",
    "        plt.figure()\n",
    "        plt.plot(hist['val_loss'], label='val_loss')\n",
    "        plt.plot(hist['loss'], label='train loss')\n",
    "\n",
    "        plt.legend()\n",
    "        \n",
    "        #save loss to .png\n",
    "        plt.savefig(outdir+'cwcnn_history_tunedparams_leadtime'+str(lead_time)+str(i)+'.png')\n",
    "\n",
    "        pd.DataFrame(hist).to_csv(outdir+'history_tunedparams_leadtime'+str(lead_time)+str(i)+'.csv')\n",
    "\n",
    "\n",
    "        '''y_test is a xarray dataarray, but y_test_predicted is now a numpy array.\n",
    "        Therefore, we convert it to an xarray with exactly the same coordinates and dims by using dim from y_test.'''\n",
    "        # save the validation\n",
    "        y_test_size= xr.open_dataarray(testsizepath+'y_testsize_'+str(i)+'_32_64_1.nc')\n",
    "\n",
    "        y_test_predicted_new = xr.DataArray(data=y_test_predicted, coords=y_test_size.coords, dims=y_test_size.dims)\n",
    "        y_test_new = xr.DataArray(data=y_test, coords=y_test_size.coords, dims=y_test_size.dims)\n",
    "\n",
    "        # save the predictions\n",
    "        y_test_predicted_new.to_netcdf(outdir+'/predictions_tuned_leadtime'+str(lead_time)+'train_'+str(N_train)+'month_'+str(i)+'params_'+param_string+'.nc')\n",
    "        y_test_new.to_netcdf(outdir+'/truevalues_tuned_leadtime'+str(lead_time)+'train_'+str(N_train)+'month_'+str(i)+'params_'+param_string+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58f55ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hist': {'loss': [0.21433058381080627, 0.06211373209953308, 0.03262367472052574, 0.016888760030269623, 0.011370740830898285, 0.008568724617362022, 0.006891950033605099, 0.0057090274058282375, 0.004772605374455452, 0.004051714204251766], 'val_loss': [0.10516417026519775, 0.046481866389513016, 0.023316631093621254, 0.014155803248286247, 0.010411395691335201, 0.008196555078029633, 0.006777796428650618, 0.005658963229507208, 0.004787841811776161, 0.004108403343707323]}, 'params': {'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}, 'scores': [0.06409682, 0.9802483707924725]}\n"
     ]
    }
   ],
   "source": [
    "##Read the accuracy\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "res = pickle.load(open(outdir+'training_result_sequential1188_10_0.pkl','rb'))\n",
    "\n",
    "# get each run's final validating loss\n",
    "\n",
    "final_val_losses = [e['hist']['val_loss'][-1] for e in res]\n",
    "\n",
    "# convert to array\n",
    "final_val_losses = np.array(final_val_losses)\n",
    "\n",
    "# find the smallest index.\n",
    "\n",
    "idx_smallest = np.argmin(final_val_losses)\n",
    "\n",
    "\n",
    "res_best = res[idx_smallest]\n",
    "\n",
    "print(res_best)\n",
    "\n",
    "with open('training_result.txt','w') as f :\n",
    "    f.write(str(res_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b124e4",
   "metadata": {},
   "source": [
    "# Prodicting PDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97e178a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the average trend of global SST \n",
    "\n",
    "gsst = xr.open_dataarray('C:/Users/user/Research/Research Code/CNN/Data/'+'ersst_1854_2022_mech.nc')\n",
    "gclm = gsst.groupby('time.month').mean(dim='time')\n",
    "ganm = (gsst.groupby('time.month') - gclm)\n",
    "mglobal=ganm.mean((\"lon\", \"lat\"), skipna=True)\n",
    "plt.plot(mglobal)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "665a377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 23, 64, 1)\n",
      "<xarray.Dataset>\n",
      "Dimensions:                        (time: 480, lon: 64, lat: 23, lev: 1)\n",
      "Coordinates:\n",
      "  * time                           (time) datetime64[ns] 1983-01-01 ... 2022-...\n",
      "  * lon                            (lon) float32 122.0 124.0 ... 246.0 248.0\n",
      "  * lat                            (lat) float32 64.0 62.0 60.0 ... 22.0 20.0\n",
      "  * lev                            (lev) float64 0.0\n",
      "Data variables:\n",
      "    __xarray_dataarray_variable__  (time, lat, lon, lev) float32 ...\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 2.0.4 (https://mpimet.mpg.de...\n",
      "    Conventions:  CF-1.6\n",
      "    history:      Sat Aug 12 14:12:32 2023: cdo mergetime predictions_tuned_l...\n",
      "    CDO:          Climate Data Operators version 2.0.4 (https://mpimet.mpg.de...\n"
     ]
    }
   ],
   "source": [
    "##Setup validation period\n",
    "ystr = 1983\n",
    "yend = 2022\n",
    "\n",
    "##setup dimension\n",
    "lead_time = 359\n",
    "N_train = 1428\n",
    "\n",
    "##Imported ensemble training results used to transform land mask\n",
    "ncin = Dataset(ifile+'combine_train_1428_lead_11.nc')\n",
    "\n",
    "\n",
    "sst  = ncin.variables['__xarray_dataarray_variable__'][:,:-9,:] \n",
    "time  = ncin.variables['time'][:]\n",
    "lat  = ncin.variables['lat'][:-9]\n",
    "lon  = ncin.variables['lon'][:]\n",
    "lev  = ncin.variables['lev'][:]\n",
    "ncin.close()\n",
    "\n",
    "nt,nlat,nlon,nlev = sst.shape    \n",
    "print(sst.shape )\n",
    "\n",
    "## Imported ensemble pred data\n",
    "ds = xr.open_dataset(ifile+'combine_train_1428_lead_11.nc')\n",
    "\n",
    "ds = ds.sel(lat=slice(70, 20), lon=slice(122, 250))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8983dbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 23, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##import land mask\n",
    "lmfile = 'data\\lsmask.nc'\n",
    "lmset  = Dataset(lmfile)\n",
    "lsmask = lmset['mask'][0,24:70:2,122:250:2]# read land mask\n",
    "lsmask = lsmask-1\n",
    "\n",
    "num_repeats = nt\n",
    "lsm = np.stack([lsmask]*num_repeats,axis=-1).transpose((2,0,1))\n",
    "lsm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "400a98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange('1983-01', '2023-01', dtype='datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a82ddcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 23, 64)\n"
     ]
    }
   ],
   "source": [
    "# === Climatology and Anomalies \n",
    "sst = ds.__xarray_dataarray_variable__\n",
    "clm = sst.sel(time=slice(f'{ystr}-01-01',f'{yend}-12-01')).groupby('time.month').mean(dim='time')\n",
    "anm = (sst.groupby('time.month') - clm)\n",
    "\n",
    "# remove lev dimension\n",
    "anm=anm.isel(lev=0)\n",
    "\n",
    "##Prediction\n",
    "#detrend\n",
    "dpdo = detrend_dim(anm,mglobal,'time',1)\n",
    "\n",
    "#Mask out land\n",
    "sst_diff = dpdo\n",
    "sst_diff = np.ma.masked_array(sst_diff, mask=lsm)\n",
    "sst_diff[lsm<0] = np.nan\n",
    "#sst_diff=sst_diff.to_numpy()\n",
    "print(sst_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "558c95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To perform the EOF analysis, create an EOF solver.\n",
    "#Prior to computing the EOFs, latitude weights are applied with a cosine.\n",
    "wgts   = np.sqrt(np.cos(np.deg2rad(lat)))\n",
    "wgts   = wgts.reshape(len(wgts), 1)\n",
    "wgts.shape\n",
    "\n",
    "#Obtained the leading EOFs\n",
    "solver = Eof(sst_diff, weights=wgts)\n",
    "\n",
    "eof1 = solver.eofs(neofs=1)\n",
    "pc1  = solver.pcs(npcs=1, pcscaling=1)\n",
    "varfrac = solver.varianceFraction()\n",
    "lambdas = solver.eigenvalues()\n",
    "Covariance_eof1 = solver.eofsAsCovariance(neofs=1, pcscaling=0)\n",
    "\n",
    "leading_eof = solver.eofsAsCorrelation(neofs=1)\n",
    "eigenvalue1 = solver.eigenvalues(neigs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64cdeb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creat PDO index\n",
    "pc=pc1 [:,]\n",
    "pc_mean=pc1[:,].mean()\n",
    "pc_std=pc1[:,].std()\n",
    "\n",
    "#Normalised\n",
    "pcs = xr.apply_ufunc(\n",
    "\n",
    "lambda x, m, s: x  / s,\n",
    "pc,\n",
    "pc_mean,\n",
    "pc_std, dask = 'allowed', vectorize = True)\n",
    "pcs.shape\n",
    "PDO=pcs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e2136b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothed with 10-year low pass\n",
    "cutoff = 0.05\n",
    "lw_pred = lowpass_filter(cutoff ,PDO)\n",
    "\n",
    "np.savetxt(outdir_smooth_pred+'Result_PDO index_pred_cwcnn_smoothed'+str(lead_time)+'.csv',lw_pred, delimiter=',', fmt='%s')\n",
    "\n",
    "##Imported and converted predicted data\n",
    "PDO_cnn = np.loadtxt(outdir_smooth_pred+'Result_PDO index_pred_cwcnn_smoothed'+str(lead_time)+'.csv', dtype=float)\n",
    "PDO_pred = adjust(PDO_cnn)\n",
    "\n",
    "\n",
    "##Import validation data from NCEI PDO index from 1983-2022 \n",
    "#https://www.ncei.noaa.gov/access/monitoring/pdo/\n",
    "\n",
    "PDO_ncei = pd.read_excel(ifile_data+'NCEI PDO index _overall.xlsx',header=None,index_col=None,\n",
    "                      skiprows=985, skipfooter = 0,\n",
    "                      usecols=[1]  \n",
    "                     )\n",
    "\n",
    "PDO_ncei = adjust(PDO_ncei)\n",
    "lw_ncei = lowpass_filter(cutoff ,PDO_ncei)\n",
    "PDO_ncei=adjust(lw_ncei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59d216cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot EOF map and PC Amplitude\n",
    "parallels = np.arange(-90,90,30.)\n",
    "meridians = np.arange(-180,180,30)\n",
    "\n",
    "for i in range(0,1):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    plt.subplot(211)\n",
    "    \n",
    "    m = Basemap(projection='cyl', llcrnrlon=min(lon), llcrnrlat=min(lat), urcrnrlon=max(lon), urcrnrlat=max(lat))   \n",
    "    x, y = m(*np.meshgrid(lon, lat))\n",
    "    clevs = np.linspace(np.min(eof1[i,:,:].squeeze()), np.max(eof1[i,:,:].squeeze()), 21)\n",
    "    cs = m.contourf(x, y, eof1[i,:,:].squeeze(), clevs, cmap=plt.cm.RdBu_r)\n",
    "    m.drawcoastlines()  \n",
    "    m.drawparallels(parallels, labels=[1,0,0,0])\n",
    "    m.drawmeridians(meridians, labels=[1,0,0,1])\n",
    "\n",
    "    cb = m.colorbar(cs, 'right', size='5%', pad='2%')\n",
    "    cb.set_label('EOF', fontsize=12)\n",
    "    plt.title('EOF ' + str(i+1), fontsize=16)\n",
    "\n",
    "    plt.subplot(212)\n",
    "    days = np.linspace(1983,2022,nt)\n",
    "    plt.plot(days, pc1[:,i], linewidth=2)\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('PC Amplitude')   \n",
    "    plt.ylim(np.min(pc1.squeeze()), np.max(pc1.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e14eed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation:  0.86\n"
     ]
    }
   ],
   "source": [
    "##Calculate the average correlation\n",
    "Correlation_cnn = []\n",
    "for i in range (1,481): \n",
    "    correlation(PDO_pred,PDO_ncei,Correlation_cnn)\n",
    "\n",
    "print('Correlation: ', mean(Correlation_cnn[1:481]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49c9a3",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanenv",
   "language": "python",
   "name": "oceanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
