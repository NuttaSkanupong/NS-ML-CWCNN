{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb37bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from keras.layers import Input, Convolution2D, Convolution1D, MaxPooling2D, Dense, Dropout, \\\n",
    "                          Flatten, concatenate, Activation, Reshape, \\\n",
    "                          UpSampling2D,ZeroPadding2D\n",
    "from keras import layers\n",
    "\n",
    "import keras\n",
    "from pylab import plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import plot, figure\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cmocean # for perceptually uniform colormaps\n",
    "import cartopy as cr # for geographic mapping\n",
    "import cartopy.crs as ccrs # for map projections\n",
    "import matplotlib.pyplot as plt # plotting tool\n",
    "import cartopy.feature as cfeature # to add coastlines, land and ocean\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfea\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pylab as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import geocat.viz as gv\n",
    "import cmaps\n",
    "import geocat.datafiles as gdf\n",
    "import geocat.viz as gv\n",
    "import geocat.viz.util as gvutil\n",
    "from scipy import stats\n",
    "from mpl_toolkits.basemap import Basemap, cm, shiftgrid, addcyclic\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import math\n",
    "import iris\n",
    "from datetime import datetime\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import numpy.polynomial.polynomial as poly\n",
    "from netCDF4 import Dataset\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from eofs.standard import Eof\n",
    "import pint\n",
    "import pint_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689c7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saved path\n",
    "outdir='C:/Users/user/Research/Research Code/CNN/trainning/channelwise_Nonnormalised/train_1428/'\n",
    "ifile_data ='C:/Users/user/Research/Research Code/CNN/Data/'\n",
    "testsizepath='C:/Users/user/Research/Research Code/CNN/y_test/y_testsize_480_32_64_1.nc'\n",
    "y_test_size= xr.open_dataarray(testsizepath)\n",
    "\n",
    "ifile ='C:/Users/user/Research/Research Code/CNN/trainning/channelwise_Nonnormalised/train_1428/'\n",
    "outdir_original_pred = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/original/pred/'\n",
    "outdir_original_test = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/original/test/'\n",
    "outdir_original_valid = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/original/validation/'\n",
    "outdir_smooth_pred = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/pred/'\n",
    "outdir_smooth_test= 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/test/'\n",
    "outdir_smooth_valid= 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/validation/'\n",
    "outdir_correlation = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/correlation/'\n",
    "outdir_smooth_pred_label = 'C:/Users/user/Research/Research Code/CNN/CW_PDO/smoothed/pred_label/'\n",
    "save_path = 'C:/Users/user/Research/Research Code/CNN/PDO/Heatmap/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be83e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set up all functions\n",
    "def weighted_areamean(ds):\n",
    "    '''area mean weighted by cos of latitude'''\n",
    "    weights = xr.ufuncs.cos(np.deg2rad(ds.lat))\n",
    "    norm = np.sum(weights) * len(ds.lon)\n",
    "    amean = (ds*weights).sum(('lat','lon')) / norm\n",
    "\n",
    "    return amean\n",
    "\n",
    "\n",
    "def acc_score(x,y):\n",
    "    '''timestepwise anomaly correlation coefficient, averaged over time\n",
    "        (simple version without seasonal climatoloty)'''\n",
    "    assert(x.shape==y.shape)\n",
    "    return np.mean([np.corrcoef(x[i].flatten(),y[i].flatten())[0,1] for i in range(len(x))])\n",
    "\n",
    "\n",
    "def corr_over_time(x,y):\n",
    "    '''timestepwise anomaly correlation coefficient, averaged over time\n",
    "        (simple version without seasonal climatoloty)'''    \n",
    "    mx = x[0:i].mean()\n",
    "    my = y[0:i].mean()\n",
    "    xm, ym = x[0:i]-mx, y[0:i]-my\n",
    "    r_num = (xm*ym).mean()\n",
    "    r_den = xm.std() * ym.std()\n",
    "    r = r_num / r_den\n",
    "        \n",
    "    return r\n",
    "\n",
    "def mean(x):\n",
    "    avg = sum(x)/len(x)\n",
    "    return round(avg,2)\n",
    "\n",
    "\n",
    "def adjust(ds):\n",
    "    '''transform the data'''\n",
    "    z1 = np.array(ds)\n",
    "    df = pd.DataFrame (z1)\n",
    "    pred = df.iloc[:,0]\n",
    "    return pred \n",
    "\n",
    "def correlation(x,y,z):\n",
    "    corr_test = np.corrcoef(x [0:i],y [0:i])[0,1]\n",
    "    z.append(corr_test)\n",
    "    \n",
    "def lowpass_filter (x,y):\n",
    "    '''fraction of nyquist frequency, here  it is 10 years'''\n",
    "    fs=1/12/30/24/3600 \n",
    "\n",
    "    nyquist = fs / 2 # 0.5 times the sampling frequency\n",
    "    cutoff=x # fraction of nyquist frequency, here  it is 10 years\n",
    "    b, a = signal.butter(5, cutoff, btype='lowpass') #low pass filter\n",
    "\n",
    "\n",
    "    dUfilt = signal.filtfilt(b, a, y)\n",
    "    dUfilt=np.array(dUfilt)\n",
    "    dUfilt=dUfilt.transpose()\n",
    "    return dUfilt\n",
    "\n",
    "def avg(myArray, N=12):\n",
    "    '''average every 12 months'''\n",
    "    cum = np.cumsum(myArray,0)\n",
    "    result = cum[N-1::N]/float(N)\n",
    "    result[1:] = result[1:] - result[:-1]\n",
    "\n",
    "    remainder = myArray.shape[0] % N\n",
    "    if remainder != 0:\n",
    "        if remainder < myArray.shape[0]:\n",
    "            lastAvg = (cum[-1]-cum[-1-remainder])/float(remainder)\n",
    "        else:\n",
    "            lastAvg = cum[-1]/float(remainder)\n",
    "        result = np.vstack([result, lastAvg])\n",
    "\n",
    "    return result\n",
    "\n",
    "def detrend_dim(da,trend, dim, deg=1):\n",
    "    '''detrend along a single dimension'''\n",
    "    p = da.polyfit(dim=dim, deg=deg)\n",
    "    fit = xr.polyval(trend[dim], p.polyfit_coefficients)\n",
    "    return da - fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a8ab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open inputdata\n"
     ]
    }
   ],
   "source": [
    "os.system('mkdir -p '+outdir)\n",
    "N_gpu = 0\n",
    "print('open inputdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9375ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (time: 2028, lat: 32, lon: 64, lev: 1)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1854-01-01 1854-02-01 ... 2022-12-01\n",
       "  * lat      (lat) float32 64.0 62.0 60.0 58.0 56.0 ... 10.0 8.0 6.0 4.0 2.0\n",
       "  * lon      (lon) float32 122.0 124.0 126.0 128.0 ... 242.0 244.0 246.0 248.0\n",
       "  * lev      (lev) float64 0.0\n",
       "Data variables:\n",
       "    sst      (time, lat, lon, lev) float32 ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-0cc835c2-15ba-40ba-8462-4571be27c3bc' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-0cc835c2-15ba-40ba-8462-4571be27c3bc' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 2028</li><li><span class='xr-has-index'>lat</span>: 32</li><li><span class='xr-has-index'>lon</span>: 64</li><li><span class='xr-has-index'>lev</span>: 1</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-819e57bf-b2c0-4ff9-91cb-916fb5490da4' class='xr-section-summary-in' type='checkbox'  checked><label for='section-819e57bf-b2c0-4ff9-91cb-916fb5490da4' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1854-01-01 ... 2022-12-01</div><input id='attrs-c421bc10-aae3-4e84-8cc4-ed6507ca7757' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c421bc10-aae3-4e84-8cc4-ed6507ca7757' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7d211fbb-4efd-4a54-88d1-5d6bbace959c' class='xr-var-data-in' type='checkbox'><label for='data-7d211fbb-4efd-4a54-88d1-5d6bbace959c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>delta_t :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>avg_period :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>prev_avg_period :</span></dt><dd>0000-00-07 00:00:00</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>actual_range :</span></dt><dd>[19723. 81418.]</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1854-01-01T00:00:00.000000000&#x27;, &#x27;1854-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;1854-03-01T00:00:00.000000000&#x27;, ..., &#x27;2022-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-11-01T00:00:00.000000000&#x27;, &#x27;2022-12-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>64.0 62.0 60.0 58.0 ... 6.0 4.0 2.0</div><input id='attrs-e14e29dd-23c6-46cf-a174-67ecf45cd441' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e14e29dd-23c6-46cf-a174-67ecf45cd441' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a2900777-9f07-4502-952d-8ce504d6518b' class='xr-var-data-in' type='checkbox'><label for='data-a2900777-9f07-4502-952d-8ce504d6518b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>actual_range :</span></dt><dd>[ 88. -88.]</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>coordinate_defines :</span></dt><dd>center</dd></dl></div><div class='xr-var-data'><pre>array([64., 62., 60., 58., 56., 54., 52., 50., 48., 46., 44., 42., 40., 38.,\n",
       "       36., 34., 32., 30., 28., 26., 24., 22., 20., 18., 16., 14., 12., 10.,\n",
       "        8.,  6.,  4.,  2.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>122.0 124.0 126.0 ... 246.0 248.0</div><input id='attrs-6b0717d6-12d1-47eb-b4d3-3fad42c783e8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6b0717d6-12d1-47eb-b4d3-3fad42c783e8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6367eedd-c571-4c21-83d5-556304c20407' class='xr-var-data-in' type='checkbox'><label for='data-6367eedd-c571-4c21-83d5-556304c20407' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>actual_range :</span></dt><dd>[  0. 358.]</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>coordinate_defines :</span></dt><dd>center</dd></dl></div><div class='xr-var-data'><pre>array([122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142., 144.,\n",
       "       146., 148., 150., 152., 154., 156., 158., 160., 162., 164., 166., 168.,\n",
       "       170., 172., 174., 176., 178., 180., 182., 184., 186., 188., 190., 192.,\n",
       "       194., 196., 198., 200., 202., 204., 206., 208., 210., 212., 214., 216.,\n",
       "       218., 220., 222., 224., 226., 228., 230., 232., 234., 236., 238., 240.,\n",
       "       242., 244., 246., 248.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lev</span></div><div class='xr-var-dims'>(lev)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0</div><input id='attrs-eb94631d-d1fc-4324-afeb-a7315aa01d67' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-eb94631d-d1fc-4324-afeb-a7315aa01d67' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b4de8b52-fea0-4d9a-a46e-5cc25ff455e9' class='xr-var-data-in' type='checkbox'><label for='data-b4de8b52-fea0-4d9a-a46e-5cc25ff455e9' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-d3f08f73-d7d6-4a34-b478-7048dd218814' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d3f08f73-d7d6-4a34-b478-7048dd218814' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>sst</span></div><div class='xr-var-dims'>(time, lat, lon, lev)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-008ba6e4-628b-4f82-b6cf-04f1e87f2e3d' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-008ba6e4-628b-4f82-b6cf-04f1e87f2e3d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8406eab9-6cab-48ae-8a42-7c2579baff2b' class='xr-var-data-in' type='checkbox'><label for='data-8406eab9-6cab-48ae-8a42-7c2579baff2b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Monthly Means of Sea Surface Temperature</dd><dt><span>units :</span></dt><dd>degC</dd><dt><span>var_desc :</span></dt><dd>Sea Surface Temperature</dd><dt><span>level_desc :</span></dt><dd>Surface</dd><dt><span>statistic :</span></dt><dd>Mean</dd><dt><span>dataset :</span></dt><dd>NOAA Extended Reconstructed SST V5</dd><dt><span>parent_stat :</span></dt><dd>Individual Values</dd><dt><span>actual_range :</span></dt><dd>[-1.8     42.32636]</dd><dt><span>valid_range :</span></dt><dd>[-1.8 45. ]</dd></dl></div><div class='xr-var-data'><pre>[4153344 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-548a9f07-17ff-47ec-99ab-2398b84cd94c' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-548a9f07-17ff-47ec-99ab-2398b84cd94c' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 2028, lat: 32, lon: 64, lev: 1)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1854-01-01 1854-02-01 ... 2022-12-01\n",
       "  * lat      (lat) float32 64.0 62.0 60.0 58.0 56.0 ... 10.0 8.0 6.0 4.0 2.0\n",
       "  * lon      (lon) float32 122.0 124.0 126.0 128.0 ... 242.0 244.0 246.0 248.0\n",
       "  * lev      (lev) float64 0.0\n",
       "Data variables:\n",
       "    sst      (time, lat, lon, lev) float32 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imported data\n",
    "ds = xr.open_dataset(ifile_data+'nonnorm_Datapreprcess_ersst_1854_2022.nc')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4d1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prepared data\n",
    "ds=ds['sst'].data \n",
    "ds[ds<0]=0 #treat nan values as 0\n",
    "np.nan_to_num(ds,copy=False)\n",
    "ds=ds/(np.nanmax(ds)) \n",
    "dates=pd.date_range(start='1854-01-01',periods=len(ds))\n",
    "label=np.array(dates.month)\n",
    "label=label-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cf2c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data separation\n",
    "N_total = 2028\n",
    "N_train = 1428\n",
    "N_gab_1 = 120\n",
    "N_test = 480\n",
    "N_skip = N_total-N_train-N_gab_1-N_test\n",
    "\n",
    "x = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1e25c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Verify that we have sufficient information for the requirements.\n",
    "if N_skip+N_train+N_gab_1+N_test > x.shape[0]:\n",
    "    raise Exception('not enough timesteps in input file!')\n",
    "\n",
    "x = x.astype('float32')\n",
    "x = x[:N_skip+N_train+N_gab_1+N_test]\n",
    "\n",
    "lat,lon,lev=x.shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e72f3464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(lead_time):\n",
    "    ''' Shift the data based on the lead time and \n",
    "    divide it into a predictor set and a predictant set. \n",
    "    Then divide it into a training set, a development set, and a test set.'''\n",
    "    if lead_time == 0:\n",
    "        X = x\n",
    "        y = X[:]\n",
    "\n",
    "    else:\n",
    "\n",
    "        X = x[:]\n",
    "        y = x[:]\n",
    "    \n",
    "  \n",
    "    X_train = X[N_skip:N_skip+N_train-lead_time]\n",
    "    y_train = y[N_skip:N_skip+N_train-lead_time]\n",
    "    \n",
    "    X_test = X[N_skip+N_train+N_gab_1:N_skip+N_train+N_gab_1+N_test]\n",
    "    y_test = y[N_skip+N_train+N_gab_1:N_skip+N_train+N_gab_1+N_test]\n",
    "    \n",
    "       \n",
    "    return X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fdb856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed (not-tuned params)\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "pool_size = 1\n",
    "drop_prob=0\n",
    "conv_activation='relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f517d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_score(x,y):\n",
    "    '''timestepwise anomaly correlation coefficient, averaged over time\n",
    "        (simple version without seasonal climatoloty)'''\n",
    "    assert(x.shape==y.shape)\n",
    "    return np.mean([np.corrcoef(x[i].flatten(),y[i].flatten())[0,1] for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a7c0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(conv_depth, kernel_size, hidden_size, n_hidden_layers, lr):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "            \n",
    "            ## Convolution which involves dimensionality reduction (similar to Encoder in an autoencoder)\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation, input_shape=(lat,lon,lev)),\n",
    "            layers.MaxPooling2D(pool_size=pool_size),\n",
    "            Dropout(drop_prob),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.MaxPooling2D(pool_size=pool_size),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.MaxPooling2D(pool_size= 1),\n",
    "        \n",
    "        \n",
    "            # end \"encoder\"\n",
    "            \n",
    "            \n",
    "            # dense layers (Automatic flattening and reshaping occurs.)\n",
    "            ] + [layers.Dense(hidden_size, activation='sigmoid') for i in range(n_hidden_layers)] +\n",
    "             \n",
    "            [\n",
    "            \n",
    "            \n",
    "            # start \"Decoder\" (upsampling of the encoder above)\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.UpSampling2D(size=pool_size),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.UpSampling2D(size=pool_size),\n",
    "            layers.Convolution2D(lev, kernel_size, padding='same', activation=None)\n",
    "            ]\n",
    "            )\n",
    "    \n",
    "    \n",
    "    optimizer= keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    if N_gpu > 1:\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            # convert the model to a model that can be trained with N_GPU GPUs\n",
    "             model = keras.utils.multi_gpu_model(model, gpus=N_gpu)\n",
    "             \n",
    "    model.compile(loss='mean_squared_error', optimizer = optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57305e4",
   "metadata": {},
   "source": [
    "# Start second training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26ea8f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2718\n",
      "Epoch 1: val_loss improved from inf to 0.16927, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 449ms/step - loss: 0.2718 - val_loss: 0.1693\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0742\n",
      "Epoch 2: val_loss improved from 0.16927 to 0.03835, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 528ms/step - loss: 0.0742 - val_loss: 0.0383\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0263\n",
      "Epoch 3: val_loss improved from 0.03835 to 0.01909, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 525ms/step - loss: 0.0263 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 4: val_loss improved from 0.01909 to 0.01155, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 500ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01155 to 0.00725, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 514ms/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00725 to 0.00526, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 534ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00526 to 0.00429, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 540ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00429 to 0.00371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 538ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00371 to 0.00333, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 512ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00333 to 0.00306, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 519ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3224\n",
      "Epoch 1: val_loss improved from inf to 0.23865, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 513ms/step - loss: 0.3224 - val_loss: 0.2387\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1078\n",
      "Epoch 2: val_loss improved from 0.23865 to 0.04795, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 518ms/step - loss: 0.1078 - val_loss: 0.0480\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 3: val_loss improved from 0.04795 to 0.01914, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 511ms/step - loss: 0.0288 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.01914 to 0.01169, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 530ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01169 to 0.00848, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 488ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00848 to 0.00644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 554ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00644 to 0.00512, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 557ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00512 to 0.00424, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 556ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00424 to 0.00362, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00362 to 0.00322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 531ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 69ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2808\n",
      "Epoch 1: val_loss improved from inf to 0.18662, saving model to best_weights.h5\n",
      "45/45 [==============================] - 25s 538ms/step - loss: 0.2808 - val_loss: 0.1866\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0911\n",
      "Epoch 2: val_loss improved from 0.18662 to 0.04775, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 520ms/step - loss: 0.0911 - val_loss: 0.0477\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0287\n",
      "Epoch 3: val_loss improved from 0.04775 to 0.01764, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 533ms/step - loss: 0.0287 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 4: val_loss improved from 0.01764 to 0.01049, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01049 to 0.00747, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 529ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00747 to 0.00574, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 523ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00574 to 0.00466, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 527ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00466 to 0.00403, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 515ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00403 to 0.00359, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00359 to 0.00327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 440ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_8 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2473\n",
      "Epoch 1: val_loss improved from inf to 0.11717, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 441ms/step - loss: 0.2473 - val_loss: 0.1172\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0666\n",
      "Epoch 2: val_loss improved from 0.11717 to 0.04375, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0666 - val_loss: 0.0437\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0282\n",
      "Epoch 3: val_loss improved from 0.04375 to 0.01948, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0282 - val_loss: 0.0195\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 4: val_loss improved from 0.01948 to 0.01120, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0143 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01120 to 0.00719, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00719 to 0.00537, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 453ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00537 to 0.00436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 452ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00436 to 0.00371, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 445ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00371 to 0.00329, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 510ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00329 to 0.00301, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2941\n",
      "Epoch 1: val_loss improved from inf to 0.20956, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 477ms/step - loss: 0.2941 - val_loss: 0.2096\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1018\n",
      "Epoch 2: val_loss improved from 0.20956 to 0.05714, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 499ms/step - loss: 0.1018 - val_loss: 0.0571\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0394\n",
      "Epoch 3: val_loss improved from 0.05714 to 0.02708, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 506ms/step - loss: 0.0394 - val_loss: 0.0271\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0201\n",
      "Epoch 4: val_loss improved from 0.02708 to 0.01615, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 513ms/step - loss: 0.0201 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 5: val_loss improved from 0.01615 to 0.01092, saving model to best_weights.h5\n",
      "45/45 [==============================] - 24s 523ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.01092 to 0.00843, saving model to best_weights.h5\n",
      "45/45 [==============================] - 23s 502ms/step - loss: 0.0091 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00843 to 0.00672, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 8: val_loss improved from 0.00672 to 0.00543, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 479ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00543 to 0.00452, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00452 to 0.00386, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 474ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2361\n",
      "Epoch 1: val_loss improved from inf to 0.13629, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 448ms/step - loss: 0.2361 - val_loss: 0.1363\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0787\n",
      "Epoch 2: val_loss improved from 0.13629 to 0.05535, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 473ms/step - loss: 0.0787 - val_loss: 0.0554\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.05535 to 0.02209, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0359 - val_loss: 0.0221\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.02209 to 0.01124, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01124 to 0.00689, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00689 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00478 to 0.00382, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 8: val_loss improved from 0.00382 to 0.00334, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 434ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00334 to 0.00303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00303 to 0.00281, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_15 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3436\n",
      "Epoch 1: val_loss improved from inf to 0.30882, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.3436 - val_loss: 0.3088\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1924\n",
      "Epoch 2: val_loss improved from 0.30882 to 0.05769, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.1924 - val_loss: 0.0577\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0391\n",
      "Epoch 3: val_loss improved from 0.05769 to 0.02349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0391 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 4: val_loss improved from 0.02349 to 0.01089, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 435ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01089 to 0.00792, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 402ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00792 to 0.00630, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00630 to 0.00494, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 401ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00494 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00410 to 0.00358, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00358 to 0.00325, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_17 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2295\n",
      "Epoch 1: val_loss improved from inf to 0.08695, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 427ms/step - loss: 0.2295 - val_loss: 0.0869\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0473\n",
      "Epoch 2: val_loss improved from 0.08695 to 0.03106, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 428ms/step - loss: 0.0473 - val_loss: 0.0311\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0207\n",
      "Epoch 3: val_loss improved from 0.03106 to 0.01502, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0207 - val_loss: 0.0150\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 4: val_loss improved from 0.01502 to 0.00967, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 5: val_loss improved from 0.00967 to 0.00709, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 406ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00709 to 0.00560, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00560 to 0.00467, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 408ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00467 to 0.00401, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00401 to 0.00354, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00354 to 0.00322, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_18 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_19 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3027\n",
      "Epoch 1: val_loss improved from inf to 0.22219, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.3027 - val_loss: 0.2222\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1104\n",
      "Epoch 2: val_loss improved from 0.22219 to 0.04737, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.1104 - val_loss: 0.0474\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0323\n",
      "Epoch 3: val_loss improved from 0.04737 to 0.02303, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.0323 - val_loss: 0.0230\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 4: val_loss improved from 0.02303 to 0.01383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 431ms/step - loss: 0.0174 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01383 to 0.00808, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 483ms/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00808 to 0.00536, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00536 to 0.00419, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 482ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00419 to 0.00368, saving model to best_weights.h5\n",
      "45/45 [==============================] - 21s 465ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00368 to 0.00335, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 437ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00335 to 0.00310, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 432ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_20 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_21 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2006\n",
      "Epoch 1: val_loss improved from inf to 0.08181, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 433ms/step - loss: 0.2006 - val_loss: 0.0818\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0560\n",
      "Epoch 2: val_loss improved from 0.08181 to 0.04012, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0560 - val_loss: 0.0401\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0270\n",
      "Epoch 3: val_loss improved from 0.04012 to 0.01971, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0270 - val_loss: 0.0197\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.01971 to 0.01270, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0152 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01270 to 0.00907, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00907 to 0.00703, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00703 to 0.00578, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 424ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00578 to 0.00470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 407ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00470 to 0.00389, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 404ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00389 to 0.00339, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_66 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_22 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_23 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3031\n",
      "Epoch 1: val_loss improved from inf to 0.24327, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.3031 - val_loss: 0.2433\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1256\n",
      "Epoch 2: val_loss improved from 0.24327 to 0.05499, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 422ms/step - loss: 0.1256 - val_loss: 0.0550\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0365\n",
      "Epoch 3: val_loss improved from 0.05499 to 0.02573, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0365 - val_loss: 0.0257\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 4: val_loss improved from 0.02573 to 0.01551, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0195 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01551 to 0.00926, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00926 to 0.00632, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 396ms/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00632 to 0.00478, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 499ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00478 to 0.00396, saving model to best_weights.h5\n",
      "45/45 [==============================] - 22s 481ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00396 to 0.00349, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 423ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00349 to 0.00318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_72 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_24 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_25 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2286\n",
      "Epoch 1: val_loss improved from inf to 0.10791, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.2286 - val_loss: 0.1079\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0721\n",
      "Epoch 2: val_loss improved from 0.10791 to 0.05439, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0721 - val_loss: 0.0544\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0367\n",
      "Epoch 3: val_loss improved from 0.05439 to 0.02685, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0367 - val_loss: 0.0269\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02685 to 0.01613, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0203 - val_loss: 0.0161\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01613 to 0.00952, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00952 to 0.00620, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00620 to 0.00453, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00453 to 0.00383, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00383 to 0.00330, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00330 to 0.00293, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_78 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_26 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_27 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2758\n",
      "Epoch 1: val_loss improved from inf to 0.17967, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 421ms/step - loss: 0.2758 - val_loss: 0.1797\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0876\n",
      "Epoch 2: val_loss improved from 0.17967 to 0.05087, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0876 - val_loss: 0.0509\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0340\n",
      "Epoch 3: val_loss improved from 0.05087 to 0.02214, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0340 - val_loss: 0.0221\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.02214 to 0.01155, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0154 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.01155 to 0.00711, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00711 to 0.00534, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00534 to 0.00436, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 420ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00436 to 0.00376, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00376 to 0.00334, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00334 to 0.00307, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_84 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_28 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_29 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2725\n",
      "Epoch 1: val_loss improved from inf to 0.14401, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 428ms/step - loss: 0.2725 - val_loss: 0.1440\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0635\n",
      "Epoch 2: val_loss improved from 0.14401 to 0.03749, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0635 - val_loss: 0.0375\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0265\n",
      "Epoch 3: val_loss improved from 0.03749 to 0.02023, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0265 - val_loss: 0.0202\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 4: val_loss improved from 0.02023 to 0.01364, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 5: val_loss improved from 0.01364 to 0.00999, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.00999 to 0.00761, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00761 to 0.00589, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00589 to 0.00474, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00474 to 0.00397, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00397 to 0.00340, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 429ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_90 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_30 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_31 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2169\n",
      "Epoch 1: val_loss improved from inf to 0.09333, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.2169 - val_loss: 0.0933\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0576\n",
      "Epoch 2: val_loss improved from 0.09333 to 0.04298, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0576 - val_loss: 0.0430\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 3: val_loss improved from 0.04298 to 0.02268, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0311 - val_loss: 0.0227\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02268 to 0.01308, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01308 to 0.00787, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00787 to 0.00550, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00550 to 0.00434, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00434 to 0.00356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00356 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00314 to 0.00282, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 410ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_96 (Conv2D)          (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_32 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_33 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.3427\n",
      "Epoch 1: val_loss improved from inf to 0.32754, saving model to best_weights.h5\n",
      "45/45 [==============================] - 20s 425ms/step - loss: 0.3427 - val_loss: 0.3275\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2527\n",
      "Epoch 2: val_loss improved from 0.32754 to 0.15211, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.2527 - val_loss: 0.1521\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0913\n",
      "Epoch 3: val_loss improved from 0.15211 to 0.07043, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 417ms/step - loss: 0.0913 - val_loss: 0.0704\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0517\n",
      "Epoch 4: val_loss improved from 0.07043 to 0.03618, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0517 - val_loss: 0.0362\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 5: val_loss improved from 0.03618 to 0.02134, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0266 - val_loss: 0.0213\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 6: val_loss improved from 0.02134 to 0.01448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0169 - val_loss: 0.0145\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 7: val_loss improved from 0.01448 to 0.01025, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 425ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 8: val_loss improved from 0.01025 to 0.00718, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 9: val_loss improved from 0.00718 to 0.00522, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00522 to 0.00422, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_102 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_34 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_35 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - ETA: 0s - loss: 0.2440\n",
      "Epoch 1: val_loss improved from inf to 0.12204, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.2440 - val_loss: 0.1220\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0473\n",
      "Epoch 2: val_loss improved from 0.12204 to 0.02304, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0473 - val_loss: 0.0230\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 3: val_loss improved from 0.02304 to 0.01157, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0150 - val_loss: 0.0116\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 4: val_loss improved from 0.01157 to 0.00856, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 5: val_loss improved from 0.00856 to 0.00644, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00644 to 0.00496, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00496 to 0.00408, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00408 to 0.00356, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 418ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00356 to 0.00318, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00318 to 0.00289, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_108 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_36 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_37 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/45 [============================>.] - ETA: 0s - loss: 0.2755\n",
      "Epoch 1: val_loss improved from inf to 0.16547, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 419ms/step - loss: 0.2752 - val_loss: 0.1655\n",
      "Epoch 2/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0795\n",
      "Epoch 2: val_loss improved from 0.16547 to 0.04202, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0794 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0281\n",
      "Epoch 3: val_loss improved from 0.04202 to 0.02017, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0281 - val_loss: 0.0202\n",
      "Epoch 4/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.02017 to 0.01217, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0148 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01217 to 0.00912, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00912 to 0.00713, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00713 to 0.00568, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00568 to 0.00470, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00470 to 0.00410, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00410 to 0.00361, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_114 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_38 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_39 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/45 [============================>.] - ETA: 0s - loss: 0.1735\n",
      "Epoch 1: val_loss improved from inf to 0.05190, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 416ms/step - loss: 0.1734 - val_loss: 0.0519\n",
      "Epoch 2/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0389\n",
      "Epoch 2: val_loss improved from 0.05190 to 0.02798, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0389 - val_loss: 0.0280\n",
      "Epoch 3/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0203\n",
      "Epoch 3: val_loss improved from 0.02798 to 0.01520, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 412ms/step - loss: 0.0203 - val_loss: 0.0152\n",
      "Epoch 4/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0111\n",
      "Epoch 4: val_loss improved from 0.01520 to 0.00855, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0111 - val_loss: 0.0085\n",
      "Epoch 5/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0066\n",
      "Epoch 5: val_loss improved from 0.00855 to 0.00571, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 6: val_loss improved from 0.00571 to 0.00448, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 414ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00448 to 0.00381, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 411ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00381 to 0.00342, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 415ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00342 to 0.00314, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 391ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00314 to 0.00290, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 400ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_120 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_40 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_41 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/45 [============================>.] - ETA: 0s - loss: 0.2038\n",
      "Epoch 1: val_loss improved from inf to 0.08668, saving model to best_weights.h5\n",
      "45/45 [==============================] - 19s 413ms/step - loss: 0.2037 - val_loss: 0.0867\n",
      "Epoch 2/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0431\n",
      "Epoch 2: val_loss improved from 0.08668 to 0.02755, saving model to best_weights.h5\n",
      "45/45 [==============================] - 18s 389ms/step - loss: 0.0431 - val_loss: 0.0276\n",
      "Epoch 3/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0201\n",
      "Epoch 3: val_loss improved from 0.02755 to 0.01667, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 383ms/step - loss: 0.0201 - val_loss: 0.0167\n",
      "Epoch 4/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0135\n",
      "Epoch 4: val_loss improved from 0.01667 to 0.01181, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 386ms/step - loss: 0.0135 - val_loss: 0.0118\n",
      "Epoch 5/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01181 to 0.00826, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 388ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00826 to 0.00607, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00607 to 0.00486, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 382ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00486 to 0.00420, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 389ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00420 to 0.00377, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 385ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00377 to 0.00342, saving model to best_weights.h5\n",
      "45/45 [==============================] - 17s 381ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 56ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_126 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_127 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_128 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_129 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_42 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_130 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_43 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_131 (Conv2D)         (None, 32, 64, 1)         513       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13272\\2592178749.py:69: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1268\n",
      "Epoch 1: val_loss improved from inf to 0.07202, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 404ms/step - loss: 0.1268 - val_loss: 0.0720\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 2: val_loss improved from 0.07202 to 0.03936, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0525 - val_loss: 0.0394\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0280\n",
      "Epoch 3: val_loss improved from 0.03936 to 0.02098, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.0280 - val_loss: 0.0210\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.02098 to 0.01194, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 392ms/step - loss: 0.0154 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01194 to 0.00697, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 399ms/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00697 to 0.00479, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 400ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00479 to 0.00388, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 399ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00388 to 0.00338, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 401ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00338 to 0.00306, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00306 to 0.00282, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 392ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_132 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_133 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_44 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_45 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2268\n",
      "Epoch 1: val_loss improved from inf to 0.10939, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 405ms/step - loss: 0.2268 - val_loss: 0.1094\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0462\n",
      "Epoch 2: val_loss improved from 0.10939 to 0.02438, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.0462 - val_loss: 0.0244\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 3: val_loss improved from 0.02438 to 0.01364, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0171 - val_loss: 0.0136\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 4: val_loss improved from 0.01364 to 0.00880, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 5: val_loss improved from 0.00880 to 0.00635, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00635 to 0.00481, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 390ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 7: val_loss improved from 0.00481 to 0.00402, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00402 to 0.00356, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00356 to 0.00322, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00322 to 0.00296, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 392ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 56ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_138 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_69 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_70 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_140 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_71 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_141 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_46 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_142 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_47 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_143 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.3367\n",
      "Epoch 1: val_loss improved from inf to 0.30734, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 399ms/step - loss: 0.3367 - val_loss: 0.3073\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1970\n",
      "Epoch 2: val_loss improved from 0.30734 to 0.07750, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 0.1970 - val_loss: 0.0775\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0503\n",
      "Epoch 3: val_loss improved from 0.07750 to 0.03385, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 391ms/step - loss: 0.0503 - val_loss: 0.0338\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.03385 to 0.01809, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 390ms/step - loss: 0.0234 - val_loss: 0.0181\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 5: val_loss improved from 0.01809 to 0.01112, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 6: val_loss improved from 0.01112 to 0.00734, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00734 to 0.00550, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 402ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00550 to 0.00447, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 406ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00447 to 0.00386, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 405ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00386 to 0.00347, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 398ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_144 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_145 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_146 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_147 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_48 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_49 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2493\n",
      "Epoch 1: val_loss improved from inf to 0.15842, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 404ms/step - loss: 0.2493 - val_loss: 0.1584\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0735\n",
      "Epoch 2: val_loss improved from 0.15842 to 0.04361, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 401ms/step - loss: 0.0735 - val_loss: 0.0436\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0282\n",
      "Epoch 3: val_loss improved from 0.04361 to 0.01781, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 391ms/step - loss: 0.0282 - val_loss: 0.0178\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 4: val_loss improved from 0.01781 to 0.00981, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 391ms/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 5: val_loss improved from 0.00981 to 0.00649, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 6: val_loss improved from 0.00649 to 0.00472, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00472 to 0.00387, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00387 to 0.00344, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 391ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00344 to 0.00314, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 404ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00314 to 0.00286, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 390ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 55ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_150 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_151 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_152 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_77 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_153 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_50 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_154 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_51 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_155 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2378\n",
      "Epoch 1: val_loss improved from inf to 0.07368, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 400ms/step - loss: 0.2378 - val_loss: 0.0737\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 2: val_loss improved from 0.07368 to 0.02370, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 399ms/step - loss: 0.0385 - val_loss: 0.0237\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 3: val_loss improved from 0.02370 to 0.01268, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 392ms/step - loss: 0.0163 - val_loss: 0.0127\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 4: val_loss improved from 0.01268 to 0.00826, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 388ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 5: val_loss improved from 0.00826 to 0.00568, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 6: val_loss improved from 0.00568 to 0.00444, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 395ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00444 to 0.00382, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 388ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00382 to 0.00342, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00342 to 0.00313, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00313 to 0.00288, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 56ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_156 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_157 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_158 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_159 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_52 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_160 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_53 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_161 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2705\n",
      "Epoch 1: val_loss improved from inf to 0.16539, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 401ms/step - loss: 0.2705 - val_loss: 0.1654\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0755\n",
      "Epoch 2: val_loss improved from 0.16539 to 0.04473, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 0.0755 - val_loss: 0.0447\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0306\n",
      "Epoch 3: val_loss improved from 0.04473 to 0.02007, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.0306 - val_loss: 0.0201\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 4: val_loss improved from 0.02007 to 0.00945, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 5: val_loss improved from 0.00945 to 0.00584, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 6: val_loss improved from 0.00584 to 0.00446, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 400ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00446 to 0.00384, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 399ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 8: val_loss improved from 0.00384 to 0.00346, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 390ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00346 to 0.00319, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 400ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00319 to 0.00297, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 55ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_162 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_163 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_164 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_165 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_54 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_55 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2983\n",
      "Epoch 1: val_loss improved from inf to 0.22471, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 400ms/step - loss: 0.2983 - val_loss: 0.2247\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1006\n",
      "Epoch 2: val_loss improved from 0.22471 to 0.03899, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 389ms/step - loss: 0.1006 - val_loss: 0.0390\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0256\n",
      "Epoch 3: val_loss improved from 0.03899 to 0.01911, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 399ms/step - loss: 0.0256 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.01911 to 0.01210, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 388ms/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01210 to 0.00826, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 394ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00826 to 0.00620, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00620 to 0.00495, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 393ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00495 to 0.00412, saving model to best_weights.h5\n",
      "44/44 [==============================] - 17s 390ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00412 to 0.00362, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 403ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00362 to 0.00328, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 485ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_168 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_84 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_169 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_85 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_170 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_86 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_56 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_172 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_57 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_173 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.1788\n",
      "Epoch 1: val_loss improved from inf to 0.07968, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 482ms/step - loss: 0.1788 - val_loss: 0.0797\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0548\n",
      "Epoch 2: val_loss improved from 0.07968 to 0.03369, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 488ms/step - loss: 0.0548 - val_loss: 0.0337\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 3: val_loss improved from 0.03369 to 0.01591, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 431ms/step - loss: 0.0220 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 4: val_loss improved from 0.01591 to 0.00868, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 453ms/step - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 5: val_loss improved from 0.00868 to 0.00611, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 460ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00611 to 0.00463, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 475ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 7: val_loss improved from 0.00463 to 0.00363, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 475ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 8: val_loss improved from 0.00363 to 0.00308, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 475ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 9: val_loss improved from 0.00308 to 0.00275, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 479ms/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 10: val_loss improved from 0.00275 to 0.00250, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 475ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "finished training\n",
      "15/15 [==============================] - 1s 67ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_174 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_175 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_177 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_58 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_178 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_59 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_179 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.3235\n",
      "Epoch 1: val_loss improved from inf to 0.27348, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 485ms/step - loss: 0.3235 - val_loss: 0.2735\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1515\n",
      "Epoch 2: val_loss improved from 0.27348 to 0.07046, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 497ms/step - loss: 0.1515 - val_loss: 0.0705\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 3: val_loss improved from 0.07046 to 0.03965, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 480ms/step - loss: 0.0525 - val_loss: 0.0397\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 4: val_loss improved from 0.03965 to 0.02013, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 477ms/step - loss: 0.0283 - val_loss: 0.0201\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 5: val_loss improved from 0.02013 to 0.01033, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 454ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.01033 to 0.00686, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 454ms/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00686 to 0.00526, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 458ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00526 to 0.00433, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 456ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00433 to 0.00371, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 457ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00371 to 0.00328, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 465ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_180 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_90 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_91 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_92 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_183 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_60 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_184 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_61 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_185 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.3081\n",
      "Epoch 1: val_loss improved from inf to 0.25404, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 465ms/step - loss: 0.3081 - val_loss: 0.2540\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1261\n",
      "Epoch 2: val_loss improved from 0.25404 to 0.05450, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 457ms/step - loss: 0.1261 - val_loss: 0.0545\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0371\n",
      "Epoch 3: val_loss improved from 0.05450 to 0.02630, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 455ms/step - loss: 0.0371 - val_loss: 0.0263\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 4: val_loss improved from 0.02630 to 0.01355, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 455ms/step - loss: 0.0181 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01355 to 0.00867, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 462ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00867 to 0.00635, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 453ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00635 to 0.00485, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 454ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00485 to 0.00409, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 459ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00409 to 0.00370, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 453ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00370 to 0.00340, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 451ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_186 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_93 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_187 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_94 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_188 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_189 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_62 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_190 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_63 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2805\n",
      "Epoch 1: val_loss improved from inf to 0.17839, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 458ms/step - loss: 0.2805 - val_loss: 0.1784\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0822\n",
      "Epoch 2: val_loss improved from 0.17839 to 0.04325, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 458ms/step - loss: 0.0822 - val_loss: 0.0432\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0264\n",
      "Epoch 3: val_loss improved from 0.04325 to 0.01757, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 465ms/step - loss: 0.0264 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 4: val_loss improved from 0.01757 to 0.01133, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 454ms/step - loss: 0.0134 - val_loss: 0.0113\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01133 to 0.00797, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 459ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00797 to 0.00591, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 455ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00591 to 0.00472, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 454ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00472 to 0.00401, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 456ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00401 to 0.00354, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 457ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00354 to 0.00320, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 495ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_192 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_98 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_64 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_65 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2263\n",
      "Epoch 1: val_loss improved from inf to 0.10602, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 521ms/step - loss: 0.2263 - val_loss: 0.1060\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0650\n",
      "Epoch 2: val_loss improved from 0.10602 to 0.04610, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 513ms/step - loss: 0.0650 - val_loss: 0.0461\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 3: val_loss improved from 0.04610 to 0.02074, saving model to best_weights.h5\n",
      "44/44 [==============================] - 24s 542ms/step - loss: 0.0303 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.02074 to 0.01170, saving model to best_weights.h5\n",
      "44/44 [==============================] - 24s 538ms/step - loss: 0.0151 - val_loss: 0.0117\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01170 to 0.00781, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 510ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00781 to 0.00577, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 521ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00577 to 0.00455, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 512ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00455 to 0.00382, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 514ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00382 to 0.00333, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 473ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00333 to 0.00290, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 453ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_198 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_99 (MaxPoolin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_199 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_100 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_200 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_101 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_201 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_66 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_202 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_67 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_203 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2813\n",
      "Epoch 1: val_loss improved from inf to 0.20083, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 462ms/step - loss: 0.2813 - val_loss: 0.2008\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0978\n",
      "Epoch 2: val_loss improved from 0.20083 to 0.05561, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 452ms/step - loss: 0.0978 - val_loss: 0.0556\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 3: val_loss improved from 0.05561 to 0.02658, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 475ms/step - loss: 0.0386 - val_loss: 0.0266\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 4: val_loss improved from 0.02658 to 0.01440, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 516ms/step - loss: 0.0189 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01440 to 0.00820, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 513ms/step - loss: 0.0105 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00820 to 0.00591, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 508ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00591 to 0.00477, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 515ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00477 to 0.00409, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 512ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00409 to 0.00364, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 496ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00364 to 0.00330, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 528ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 67ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_204 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_102 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_205 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_103 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_206 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_104 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_207 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_68 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_208 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_69 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_209 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2924\n",
      "Epoch 1: val_loss improved from inf to 0.20391, saving model to best_weights.h5\n",
      "44/44 [==============================] - 24s 531ms/step - loss: 0.2924 - val_loss: 0.2039\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0958\n",
      "Epoch 2: val_loss improved from 0.20391 to 0.05129, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 529ms/step - loss: 0.0958 - val_loss: 0.0513\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 3: val_loss improved from 0.05129 to 0.02306, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 527ms/step - loss: 0.0342 - val_loss: 0.0231\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 4: val_loss improved from 0.02306 to 0.01338, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 504ms/step - loss: 0.0170 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 5: val_loss improved from 0.01338 to 0.00838, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 522ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00838 to 0.00647, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 522ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00647 to 0.00521, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 484ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00521 to 0.00435, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 517ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00435 to 0.00376, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 499ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00376 to 0.00339, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 469ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_210 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_105 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_211 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_106 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_212 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_107 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_213 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_70 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_214 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_71 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_215 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.1924\n",
      "Epoch 1: val_loss improved from inf to 0.08127, saving model to best_weights.h5\n",
      "44/44 [==============================] - 24s 525ms/step - loss: 0.1924 - val_loss: 0.0813\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0531\n",
      "Epoch 2: val_loss improved from 0.08127 to 0.04001, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 520ms/step - loss: 0.0531 - val_loss: 0.0400\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0282\n",
      "Epoch 3: val_loss improved from 0.04001 to 0.01997, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 505ms/step - loss: 0.0282 - val_loss: 0.0200\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.01997 to 0.01117, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 517ms/step - loss: 0.0144 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.01117 to 0.00756, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 505ms/step - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00756 to 0.00608, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 459ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00608 to 0.00493, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 477ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00493 to 0.00404, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 534ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00404 to 0.00347, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 525ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00347 to 0.00311, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 517ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 65ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_216 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_108 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_217 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_109 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_218 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_110 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_219 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_72 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_220 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_73 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_221 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2522\n",
      "Epoch 1: val_loss improved from inf to 0.11644, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 518ms/step - loss: 0.2522 - val_loss: 0.1164\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0577\n",
      "Epoch 2: val_loss improved from 0.11644 to 0.03690, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 519ms/step - loss: 0.0577 - val_loss: 0.0369\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0256\n",
      "Epoch 3: val_loss improved from 0.03690 to 0.01927, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 507ms/step - loss: 0.0256 - val_loss: 0.0193\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.01927 to 0.01319, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 519ms/step - loss: 0.0153 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01319 to 0.00944, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 514ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00944 to 0.00727, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 524ms/step - loss: 0.0079 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00727 to 0.00587, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 511ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00587 to 0.00487, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 489ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00487 to 0.00414, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 452ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00414 to 0.00363, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 454ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_222 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_111 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_223 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_112 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_224 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_113 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_225 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_74 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_226 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_75 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_227 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2656\n",
      "Epoch 1: val_loss improved from inf to 0.16246, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 519ms/step - loss: 0.2656 - val_loss: 0.1625\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0754\n",
      "Epoch 2: val_loss improved from 0.16246 to 0.04348, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 515ms/step - loss: 0.0754 - val_loss: 0.0435\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.04348 to 0.02047, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 511ms/step - loss: 0.0294 - val_loss: 0.0205\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.02047 to 0.01235, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 462ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01235 to 0.00851, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 487ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00851 to 0.00643, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 478ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00643 to 0.00523, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 416ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00523 to 0.00444, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00444 to 0.00388, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 418ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00388 to 0.00345, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 418ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_228 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_114 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_229 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_115 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_230 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_116 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_231 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_76 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_232 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_77 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_233 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.1826\n",
      "Epoch 1: val_loss improved from inf to 0.03914, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 466ms/step - loss: 0.1826 - val_loss: 0.0391\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0280\n",
      "Epoch 2: val_loss improved from 0.03914 to 0.02055, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 466ms/step - loss: 0.0280 - val_loss: 0.0205\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 3: val_loss improved from 0.02055 to 0.01471, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 519ms/step - loss: 0.0163 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 4: val_loss improved from 0.01471 to 0.01159, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 508ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01159 to 0.00920, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 463ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00920 to 0.00750, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 509ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00750 to 0.00616, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 492ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00616 to 0.00497, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 476ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00497 to 0.00406, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 506ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00406 to 0.00343, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 500ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_234 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_117 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_235 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_118 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_236 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_119 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_237 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_78 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_238 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_79 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.3395\n",
      "Epoch 1: val_loss improved from inf to 0.30702, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 513ms/step - loss: 0.3395 - val_loss: 0.3070\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.2014\n",
      "Epoch 2: val_loss improved from 0.30702 to 0.08819, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 497ms/step - loss: 0.2014 - val_loss: 0.0882\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0596\n",
      "Epoch 3: val_loss improved from 0.08819 to 0.04096, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 504ms/step - loss: 0.0596 - val_loss: 0.0410\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 4: val_loss improved from 0.04096 to 0.02335, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 509ms/step - loss: 0.0303 - val_loss: 0.0234\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 5: val_loss improved from 0.02335 to 0.01335, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 507ms/step - loss: 0.0173 - val_loss: 0.0134\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01335 to 0.00760, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 497ms/step - loss: 0.0098 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00760 to 0.00497, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 515ms/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00497 to 0.00390, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 511ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00390 to 0.00338, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 512ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00338 to 0.00305, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_240 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_120 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_121 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_122 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_80 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_81 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_245 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2693\n",
      "Epoch 1: val_loss improved from inf to 0.14779, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 503ms/step - loss: 0.2693 - val_loss: 0.1478\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0667\n",
      "Epoch 2: val_loss improved from 0.14779 to 0.03871, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 486ms/step - loss: 0.0667 - val_loss: 0.0387\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Epoch 3: val_loss improved from 0.03871 to 0.01711, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 511ms/step - loss: 0.0247 - val_loss: 0.0171\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 4: val_loss improved from 0.01711 to 0.00941, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 512ms/step - loss: 0.0124 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 5: val_loss improved from 0.00941 to 0.00618, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 508ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 6: val_loss improved from 0.00618 to 0.00483, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00483 to 0.00407, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 449ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00407 to 0.00359, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 444ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00359 to 0.00326, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 440ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00326 to 0.00299, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 458ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_246 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_123 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_247 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_124 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_248 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_125 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_249 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_82 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_250 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_83 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_251 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.3134\n",
      "Epoch 1: val_loss improved from inf to 0.25540, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 453ms/step - loss: 0.3134 - val_loss: 0.2554\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1404\n",
      "Epoch 2: val_loss improved from 0.25540 to 0.07544, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 443ms/step - loss: 0.1404 - val_loss: 0.0754\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0528\n",
      "Epoch 3: val_loss improved from 0.07544 to 0.03423, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 442ms/step - loss: 0.0528 - val_loss: 0.0342\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 4: val_loss improved from 0.03423 to 0.01574, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 443ms/step - loss: 0.0222 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 5: val_loss improved from 0.01574 to 0.00862, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 442ms/step - loss: 0.0111 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00862 to 0.00622, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 443ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00622 to 0.00502, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 467ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00502 to 0.00420, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 509ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00420 to 0.00364, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 495ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00364 to 0.00325, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_252 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_126 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_253 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_127 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_254 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_128 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_255 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_84 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_256 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_85 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_257 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.3094\n",
      "Epoch 1: val_loss improved from inf to 0.25171, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 510ms/step - loss: 0.3094 - val_loss: 0.2517\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1251\n",
      "Epoch 2: val_loss improved from 0.25171 to 0.04090, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 498ms/step - loss: 0.1251 - val_loss: 0.0409\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 3: val_loss improved from 0.04090 to 0.02138, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 502ms/step - loss: 0.0297 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02138 to 0.01334, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 507ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01334 to 0.00900, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 505ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00900 to 0.00642, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 500ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00642 to 0.00480, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 502ms/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00480 to 0.00389, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 516ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00389 to 0.00334, saving model to best_weights.h5\n",
      "44/44 [==============================] - 20s 466ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00334 to 0.00297, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 486ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 69ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_258 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_129 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_259 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_130 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_260 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_131 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_261 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_86 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_262 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_87 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_263 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2729\n",
      "Epoch 1: val_loss improved from inf to 0.18355, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 495ms/step - loss: 0.2729 - val_loss: 0.1836\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0843\n",
      "Epoch 2: val_loss improved from 0.18355 to 0.04565, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 499ms/step - loss: 0.0843 - val_loss: 0.0456\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0320\n",
      "Epoch 3: val_loss improved from 0.04565 to 0.02136, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 497ms/step - loss: 0.0320 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 4: val_loss improved from 0.02136 to 0.01140, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 499ms/step - loss: 0.0147 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01140 to 0.00757, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 499ms/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00757 to 0.00552, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00552 to 0.00424, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 524ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00424 to 0.00359, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 487ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00359 to 0.00322, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 484ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00322 to 0.00295, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 67ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_264 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_132 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_265 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_133 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_266 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_134 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_267 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_88 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_268 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_89 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_269 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.3060\n",
      "Epoch 1: val_loss improved from inf to 0.25632, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 500ms/step - loss: 0.3060 - val_loss: 0.2563\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.1373\n",
      "Epoch 2: val_loss improved from 0.25632 to 0.05013, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 508ms/step - loss: 0.1373 - val_loss: 0.0501\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 3: val_loss improved from 0.05013 to 0.02081, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 506ms/step - loss: 0.0316 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.02081 to 0.01245, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 505ms/step - loss: 0.0154 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01245 to 0.00884, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 485ms/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00884 to 0.00653, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 511ms/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00653 to 0.00483, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 494ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00483 to 0.00389, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 506ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00389 to 0.00339, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 510ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00339 to 0.00306, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 516ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_270 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_135 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_271 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_136 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_272 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_137 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_273 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_90 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_274 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_91 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_275 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2919\n",
      "Epoch 1: val_loss improved from inf to 0.19051, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 518ms/step - loss: 0.2919 - val_loss: 0.1905\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0822\n",
      "Epoch 2: val_loss improved from 0.19051 to 0.04183, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 502ms/step - loss: 0.0822 - val_loss: 0.0418\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 3: val_loss improved from 0.04183 to 0.01779, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 509ms/step - loss: 0.0276 - val_loss: 0.0178\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01779 to 0.01082, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 514ms/step - loss: 0.0133 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01082 to 0.00723, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00723 to 0.00543, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 531ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00543 to 0.00435, saving model to best_weights.h5\n",
      "44/44 [==============================] - 24s 550ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00435 to 0.00378, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 520ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00378 to 0.00337, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 500ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00337 to 0.00307, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 506ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_276 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_138 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_277 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_139 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_278 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_140 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_279 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_92 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_280 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_93 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_281 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2122\n",
      "Epoch 1: val_loss improved from inf to 0.08183, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 503ms/step - loss: 0.2122 - val_loss: 0.0818\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0481\n",
      "Epoch 2: val_loss improved from 0.08183 to 0.03588, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 505ms/step - loss: 0.0481 - val_loss: 0.0359\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 3: val_loss improved from 0.03588 to 0.02142, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 506ms/step - loss: 0.0266 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02142 to 0.01378, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 516ms/step - loss: 0.0168 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01378 to 0.00854, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 522ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00854 to 0.00557, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 507ms/step - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00557 to 0.00421, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 485ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00421 to 0.00356, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 504ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00356 to 0.00320, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 506ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00320 to 0.00293, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 504ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_282 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_141 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_283 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_142 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_284 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_143 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_285 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_94 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_286 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_95 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_287 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2593\n",
      "Epoch 1: val_loss improved from inf to 0.16728, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 504ms/step - loss: 0.2593 - val_loss: 0.1673\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0901\n",
      "Epoch 2: val_loss improved from 0.16728 to 0.05976, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 509ms/step - loss: 0.0901 - val_loss: 0.0598\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0425\n",
      "Epoch 3: val_loss improved from 0.05976 to 0.02766, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 514ms/step - loss: 0.0425 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02766 to 0.01213, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 487ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01213 to 0.00700, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 6: val_loss improved from 0.00700 to 0.00531, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 519ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00531 to 0.00453, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 519ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00453 to 0.00397, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 503ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00397 to 0.00356, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 519ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00356 to 0.00321, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 513ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_288 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_144 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_289 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_145 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_290 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_146 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_291 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_96 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_292 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_97 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_293 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.1913\n",
      "Epoch 1: val_loss improved from inf to 0.08097, saving model to best_weights.h5\n",
      "44/44 [==============================] - 23s 511ms/step - loss: 0.1913 - val_loss: 0.0810\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0572\n",
      "Epoch 2: val_loss improved from 0.08097 to 0.03740, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 485ms/step - loss: 0.0572 - val_loss: 0.0374\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0240\n",
      "Epoch 3: val_loss improved from 0.03740 to 0.01764, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 497ms/step - loss: 0.0240 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01764 to 0.01090, saving model to best_weights.h5\n",
      "44/44 [==============================] - 22s 500ms/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01090 to 0.00778, saving model to best_weights.h5\n",
      "44/44 [==============================] - 21s 484ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00778 to 0.00578, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 415ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00578 to 0.00446, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 415ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00446 to 0.00377, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00377 to 0.00339, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00339 to 0.00309, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 416ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_294 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_147 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_295 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_148 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_296 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_149 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_297 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_98 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_298 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_99 (UpSamplin  (None, 32, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_299 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 0.2976\n",
      "Epoch 1: val_loss improved from inf to 0.18410, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 418ms/step - loss: 0.2976 - val_loss: 0.1841\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0769\n",
      "Epoch 2: val_loss improved from 0.18410 to 0.04053, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 413ms/step - loss: 0.0769 - val_loss: 0.0405\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 3: val_loss improved from 0.04053 to 0.02333, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0302 - val_loss: 0.0233\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02333 to 0.01455, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0179 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01455 to 0.00891, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 419ms/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00891 to 0.00657, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00657 to 0.00529, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 418ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00529 to 0.00445, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 418ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00445 to 0.00389, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 418ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00389 to 0.00347, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 422ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_300 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_150 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_301 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_151 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_302 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_152 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_303 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_100 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_304 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_101 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_305 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.2807\n",
      "Epoch 1: val_loss improved from inf to 0.19469, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 421ms/step - loss: 0.2805 - val_loss: 0.1947\n",
      "Epoch 2/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0856\n",
      "Epoch 2: val_loss improved from 0.19469 to 0.03652, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 413ms/step - loss: 0.0855 - val_loss: 0.0365\n",
      "Epoch 3/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0223\n",
      "Epoch 3: val_loss improved from 0.03652 to 0.01562, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 416ms/step - loss: 0.0223 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0123\n",
      "Epoch 4: val_loss improved from 0.01562 to 0.01043, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01043 to 0.00743, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 415ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00743 to 0.00558, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 418ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00558 to 0.00446, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 416ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00446 to 0.00382, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00382 to 0.00340, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 415ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00340 to 0.00311, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 413ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_306 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_153 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_307 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_154 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_308 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_155 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_309 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_102 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_310 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_103 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_311 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.3184\n",
      "Epoch 1: val_loss improved from inf to 0.26796, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 418ms/step - loss: 0.3183 - val_loss: 0.2680\n",
      "Epoch 2/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1295\n",
      "Epoch 2: val_loss improved from 0.26796 to 0.04679, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.1294 - val_loss: 0.0468\n",
      "Epoch 3/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0292\n",
      "Epoch 3: val_loss improved from 0.04679 to 0.02096, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 416ms/step - loss: 0.0292 - val_loss: 0.0210\n",
      "Epoch 4/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02096 to 0.01343, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0109\n",
      "Epoch 5: val_loss improved from 0.01343 to 0.00956, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00956 to 0.00678, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 416ms/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00678 to 0.00523, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 413ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00523 to 0.00429, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 430ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00429 to 0.00374, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00374 to 0.00340, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_312 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_156 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_313 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_157 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_314 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_158 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_315 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_104 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_316 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_105 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_317 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/44 [============================>.] - ETA: 0s - loss: 0.3553\n",
      "Epoch 1: val_loss improved from inf to 0.31937, saving model to best_weights.h5\n",
      "44/44 [==============================] - 19s 421ms/step - loss: 0.3553 - val_loss: 0.3194\n",
      "Epoch 2/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1959\n",
      "Epoch 2: val_loss improved from 0.31937 to 0.08187, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 415ms/step - loss: 0.1958 - val_loss: 0.0819\n",
      "Epoch 3/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0625\n",
      "Epoch 3: val_loss improved from 0.08187 to 0.04459, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 415ms/step - loss: 0.0625 - val_loss: 0.0446\n",
      "Epoch 4/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0296\n",
      "Epoch 4: val_loss improved from 0.04459 to 0.02084, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0296 - val_loss: 0.0208\n",
      "Epoch 5/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0157\n",
      "Epoch 5: val_loss improved from 0.02084 to 0.01254, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 419ms/step - loss: 0.0157 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01254 to 0.00781, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00781 to 0.00523, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 414ms/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00523 to 0.00422, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 416ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00422 to 0.00374, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 417ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00374 to 0.00344, saving model to best_weights.h5\n",
      "44/44 [==============================] - 18s 415ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_318 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_159 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_319 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_160 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_320 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_161 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_321 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_106 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_322 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_107 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_323 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2585\n",
      "Epoch 1: val_loss improved from inf to 0.15978, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 433ms/step - loss: 0.2585 - val_loss: 0.1598\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0690\n",
      "Epoch 2: val_loss improved from 0.15978 to 0.03809, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.0690 - val_loss: 0.0381\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 3: val_loss improved from 0.03809 to 0.01951, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0266 - val_loss: 0.0195\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 4: val_loss improved from 0.01951 to 0.01023, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 427ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.01023 to 0.00667, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 434ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00667 to 0.00518, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00518 to 0.00431, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00431 to 0.00379, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 428ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00379 to 0.00344, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00344 to 0.00317, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_324 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_162 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_325 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_163 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_326 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_164 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_327 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_108 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_328 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_109 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_329 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2997\n",
      "Epoch 1: val_loss improved from inf to 0.19274, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 430ms/step - loss: 0.2997 - val_loss: 0.1927\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0821\n",
      "Epoch 2: val_loss improved from 0.19274 to 0.03842, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 425ms/step - loss: 0.0821 - val_loss: 0.0384\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 3: val_loss improved from 0.03842 to 0.02283, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0283 - val_loss: 0.0228\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 4: val_loss improved from 0.02283 to 0.01564, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0181 - val_loss: 0.0156\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 5: val_loss improved from 0.01564 to 0.01064, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 422ms/step - loss: 0.0124 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 6: val_loss improved from 0.01064 to 0.00757, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 421ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00757 to 0.00583, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00583 to 0.00480, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 425ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00480 to 0.00418, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 431ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00418 to 0.00377, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 427ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_330 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_165 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_331 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_166 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_332 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_167 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_333 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_110 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_334 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_111 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_335 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3316\n",
      "Epoch 1: val_loss improved from inf to 0.29303, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 426ms/step - loss: 0.3316 - val_loss: 0.2930\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1760\n",
      "Epoch 2: val_loss improved from 0.29303 to 0.06293, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.1760 - val_loss: 0.0629\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 3: val_loss improved from 0.06293 to 0.02965, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 421ms/step - loss: 0.0435 - val_loss: 0.0296\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 4: val_loss improved from 0.02965 to 0.01584, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0208 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 5: val_loss improved from 0.01584 to 0.01077, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 6: val_loss improved from 0.01077 to 0.00810, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 428ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 7: val_loss improved from 0.00810 to 0.00609, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 425ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00609 to 0.00488, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00488 to 0.00405, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00405 to 0.00354, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 428ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_336 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_168 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_337 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_169 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_338 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_170 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_339 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_112 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_340 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_113 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_341 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2583\n",
      "Epoch 1: val_loss improved from inf to 0.14707, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 428ms/step - loss: 0.2583 - val_loss: 0.1471\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0727\n",
      "Epoch 2: val_loss improved from 0.14707 to 0.04745, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0727 - val_loss: 0.0475\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 3: val_loss improved from 0.04745 to 0.02459, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.0330 - val_loss: 0.0246\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0190\n",
      "Epoch 4: val_loss improved from 0.02459 to 0.01584, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.0190 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01584 to 0.01080, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01080 to 0.00783, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 431ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00783 to 0.00591, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00591 to 0.00479, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 403ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00479 to 0.00406, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 406ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00406 to 0.00349, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 396ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_342 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_171 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_343 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_172 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_344 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_173 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_345 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_114 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_346 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_115 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_347 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2940\n",
      "Epoch 1: val_loss improved from inf to 0.18794, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 409ms/step - loss: 0.2940 - val_loss: 0.1879\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0817\n",
      "Epoch 2: val_loss improved from 0.18794 to 0.04394, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0817 - val_loss: 0.0439\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 3: val_loss improved from 0.04394 to 0.01980, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 407ms/step - loss: 0.0292 - val_loss: 0.0198\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.01980 to 0.01222, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0149 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01222 to 0.00844, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0097 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00844 to 0.00636, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00636 to 0.00505, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 394ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00505 to 0.00412, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00412 to 0.00354, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 395ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00354 to 0.00319, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 392ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 56ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_348 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_174 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_349 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_175 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_350 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_176 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_351 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_116 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_352 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_117 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_353 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2230\n",
      "Epoch 1: val_loss improved from inf to 0.09615, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 403ms/step - loss: 0.2230 - val_loss: 0.0961\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0608\n",
      "Epoch 2: val_loss improved from 0.09615 to 0.04147, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 405ms/step - loss: 0.0608 - val_loss: 0.0415\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0267\n",
      "Epoch 3: val_loss improved from 0.04147 to 0.01899, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0267 - val_loss: 0.0190\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.01899 to 0.01143, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 395ms/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01143 to 0.00749, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00749 to 0.00539, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 395ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00539 to 0.00422, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 392ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00422 to 0.00366, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00366 to 0.00337, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 396ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00337 to 0.00317, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_354 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_177 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_355 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_178 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_356 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_179 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_357 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_118 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_358 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_119 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_359 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2830\n",
      "Epoch 1: val_loss improved from inf to 0.18982, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 407ms/step - loss: 0.2830 - val_loss: 0.1898\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0891\n",
      "Epoch 2: val_loss improved from 0.18982 to 0.05255, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0891 - val_loss: 0.0525\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0379\n",
      "Epoch 3: val_loss improved from 0.05255 to 0.02772, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0379 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02772 to 0.01626, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.0203 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01626 to 0.01092, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 6: val_loss improved from 0.01092 to 0.00828, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 396ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00828 to 0.00667, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 396ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00667 to 0.00559, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 395ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00559 to 0.00473, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00473 to 0.00407, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_360 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_180 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_361 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_181 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_362 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_182 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_363 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_120 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_364 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_121 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_365 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2799\n",
      "Epoch 1: val_loss improved from inf to 0.19302, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 407ms/step - loss: 0.2799 - val_loss: 0.1930\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0873\n",
      "Epoch 2: val_loss improved from 0.19302 to 0.04900, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 396ms/step - loss: 0.0873 - val_loss: 0.0490\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0348\n",
      "Epoch 3: val_loss improved from 0.04900 to 0.02461, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0348 - val_loss: 0.0246\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02461 to 0.01360, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.0176 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01360 to 0.00912, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 408ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00912 to 0.00697, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 498ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00697 to 0.00542, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 451ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00542 to 0.00430, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 450ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00430 to 0.00359, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 452ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00359 to 0.00322, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 451ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_366 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_183 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_367 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_184 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_368 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_185 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_369 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_122 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_370 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_123 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_371 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3061\n",
      "Epoch 1: val_loss improved from inf to 0.24522, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 456ms/step - loss: 0.3061 - val_loss: 0.2452\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1152\n",
      "Epoch 2: val_loss improved from 0.24522 to 0.04677, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 450ms/step - loss: 0.1152 - val_loss: 0.0468\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0306\n",
      "Epoch 3: val_loss improved from 0.04677 to 0.01994, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 449ms/step - loss: 0.0306 - val_loss: 0.0199\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.01994 to 0.01165, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 453ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01165 to 0.00821, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 450ms/step - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00821 to 0.00614, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 452ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00614 to 0.00483, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 448ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00483 to 0.00400, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 439ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00400 to 0.00349, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00349 to 0.00316, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_372 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_186 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_373 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_187 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_374 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_188 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_375 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_124 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_376 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_125 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_377 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3415\n",
      "Epoch 1: val_loss improved from inf to 0.31971, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 404ms/step - loss: 0.3415 - val_loss: 0.3197\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2054\n",
      "Epoch 2: val_loss improved from 0.31971 to 0.05828, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.2054 - val_loss: 0.0583\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0364\n",
      "Epoch 3: val_loss improved from 0.05828 to 0.02488, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 403ms/step - loss: 0.0364 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 4: val_loss improved from 0.02488 to 0.01301, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0173 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01301 to 0.00827, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00827 to 0.00624, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00624 to 0.00512, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 403ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00512 to 0.00439, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00439 to 0.00388, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00388 to 0.00345, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_378 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_189 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_379 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_190 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_380 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_191 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_381 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_126 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_382 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_127 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_383 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2361\n",
      "Epoch 1: val_loss improved from inf to 0.12712, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 407ms/step - loss: 0.2361 - val_loss: 0.1271\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0610\n",
      "Epoch 2: val_loss improved from 0.12712 to 0.03874, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0610 - val_loss: 0.0387\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 3: val_loss improved from 0.03874 to 0.01865, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0268 - val_loss: 0.0186\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 4: val_loss improved from 0.01865 to 0.01084, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 5: val_loss improved from 0.01084 to 0.00747, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00747 to 0.00584, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00584 to 0.00495, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00495 to 0.00437, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 403ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00437 to 0.00399, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00399 to 0.00368, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_384 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_192 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_385 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_193 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_386 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_194 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_387 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_128 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_388 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_129 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_389 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2979\n",
      "Epoch 1: val_loss improved from inf to 0.21421, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 410ms/step - loss: 0.2979 - val_loss: 0.2142\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0752\n",
      "Epoch 2: val_loss improved from 0.21421 to 0.02126, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 403ms/step - loss: 0.0752 - val_loss: 0.0213\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 3: val_loss improved from 0.02126 to 0.01216, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0150 - val_loss: 0.0122\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 4: val_loss improved from 0.01216 to 0.00943, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.00943 to 0.00757, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 404ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00757 to 0.00602, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00602 to 0.00472, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00472 to 0.00368, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00368 to 0.00305, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 396ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00305 to 0.00270, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_390 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_195 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_391 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_196 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_392 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_197 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_393 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_130 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_394 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_131 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_395 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3480\n",
      "Epoch 1: val_loss improved from inf to 0.30346, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 414ms/step - loss: 0.3480 - val_loss: 0.3035\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1915\n",
      "Epoch 2: val_loss improved from 0.30346 to 0.07505, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.1915 - val_loss: 0.0750\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0592\n",
      "Epoch 3: val_loss improved from 0.07505 to 0.04649, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 416ms/step - loss: 0.0592 - val_loss: 0.0465\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0338\n",
      "Epoch 4: val_loss improved from 0.04649 to 0.02444, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0338 - val_loss: 0.0244\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 5: val_loss improved from 0.02444 to 0.01387, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0177 - val_loss: 0.0139\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 6: val_loss improved from 0.01387 to 0.00889, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00889 to 0.00681, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00681 to 0.00547, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00547 to 0.00442, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 407ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00442 to 0.00363, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 406ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_396 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_198 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_397 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_199 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_398 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_200 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_399 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_132 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_400 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_133 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_401 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2976\n",
      "Epoch 1: val_loss improved from inf to 0.23106, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 406ms/step - loss: 0.2976 - val_loss: 0.2311\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1101\n",
      "Epoch 2: val_loss improved from 0.23106 to 0.04914, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.1101 - val_loss: 0.0491\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0309\n",
      "Epoch 3: val_loss improved from 0.04914 to 0.02159, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0309 - val_loss: 0.0216\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02159 to 0.01455, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 413ms/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01455 to 0.00998, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.00998 to 0.00750, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00750 to 0.00604, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00604 to 0.00512, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00512 to 0.00447, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00447 to 0.00400, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_402 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_201 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_403 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_202 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_404 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_203 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_405 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_134 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_406 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_135 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_407 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2998\n",
      "Epoch 1: val_loss improved from inf to 0.22602, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 405ms/step - loss: 0.2998 - val_loss: 0.2260\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1074\n",
      "Epoch 2: val_loss improved from 0.22602 to 0.05188, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.1074 - val_loss: 0.0519\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0351\n",
      "Epoch 3: val_loss improved from 0.05188 to 0.02394, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0351 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 4: val_loss improved from 0.02394 to 0.01367, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 403ms/step - loss: 0.0173 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01367 to 0.00891, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 412ms/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00891 to 0.00685, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00685 to 0.00557, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00557 to 0.00467, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00467 to 0.00399, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00399 to 0.00350, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_408 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_204 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_409 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_205 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_410 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_206 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_411 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_136 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_412 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_137 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_413 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2426\n",
      "Epoch 1: val_loss improved from inf to 0.13892, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 403ms/step - loss: 0.2426 - val_loss: 0.1389\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0749\n",
      "Epoch 2: val_loss improved from 0.13892 to 0.04839, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0749 - val_loss: 0.0484\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 3: val_loss improved from 0.04839 to 0.02346, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0324 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 4: val_loss improved from 0.02346 to 0.01464, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0180 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01464 to 0.00871, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 403ms/step - loss: 0.0110 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00871 to 0.00619, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00619 to 0.00488, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00488 to 0.00409, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00409 to 0.00355, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00355 to 0.00317, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_414 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_207 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_415 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_208 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_416 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_209 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_417 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_138 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_418 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_139 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_419 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3034\n",
      "Epoch 1: val_loss improved from inf to 0.23611, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 404ms/step - loss: 0.3034 - val_loss: 0.2361\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1347\n",
      "Epoch 2: val_loss improved from 0.23611 to 0.07996, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.1347 - val_loss: 0.0800\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0611\n",
      "Epoch 3: val_loss improved from 0.07996 to 0.04475, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 400ms/step - loss: 0.0611 - val_loss: 0.0447\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0314\n",
      "Epoch 4: val_loss improved from 0.04475 to 0.02352, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0314 - val_loss: 0.0235\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 5: val_loss improved from 0.02352 to 0.01332, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0172 - val_loss: 0.0133\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 6: val_loss improved from 0.01332 to 0.00866, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 401ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00866 to 0.00646, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00646 to 0.00495, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00495 to 0.00414, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00414 to 0.00369, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_420 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_210 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_421 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_211 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_422 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_212 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_423 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_140 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_424 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_141 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_425 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2379\n",
      "Epoch 1: val_loss improved from inf to 0.10869, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 407ms/step - loss: 0.2379 - val_loss: 0.1087\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0517\n",
      "Epoch 2: val_loss improved from 0.10869 to 0.03209, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 398ms/step - loss: 0.0517 - val_loss: 0.0321\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 3: val_loss improved from 0.03209 to 0.01671, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 405ms/step - loss: 0.0219 - val_loss: 0.0167\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 4: val_loss improved from 0.01671 to 0.00964, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 406ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 5: val_loss improved from 0.00964 to 0.00651, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00651 to 0.00505, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 397ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00505 to 0.00427, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 399ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00427 to 0.00378, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00378 to 0.00335, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00335 to 0.00301, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 394ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_426 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_213 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_427 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_214 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_428 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_215 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_429 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_142 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_430 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_143 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_431 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2249\n",
      "Epoch 1: val_loss improved from inf to 0.10204, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 404ms/step - loss: 0.2249 - val_loss: 0.1020\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0496\n",
      "Epoch 2: val_loss improved from 0.10204 to 0.03449, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 394ms/step - loss: 0.0496 - val_loss: 0.0345\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 3: val_loss improved from 0.03449 to 0.01912, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 497ms/step - loss: 0.0255 - val_loss: 0.0191\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.01912 to 0.01118, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 444ms/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01118 to 0.00734, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 435ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00734 to 0.00531, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 436ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00531 to 0.00413, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 437ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00413 to 0.00345, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 435ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 9: val_loss improved from 0.00345 to 0.00303, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 433ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 10: val_loss improved from 0.00303 to 0.00273, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 435ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_432 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_216 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_433 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_217 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_434 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_218 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_435 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_144 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_436 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_145 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_437 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3129\n",
      "Epoch 1: val_loss improved from inf to 0.25599, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 468ms/step - loss: 0.3129 - val_loss: 0.2560\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1304\n",
      "Epoch 2: val_loss improved from 0.25599 to 0.05228, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 441ms/step - loss: 0.1304 - val_loss: 0.0523\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0321\n",
      "Epoch 3: val_loss improved from 0.05228 to 0.01996, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 437ms/step - loss: 0.0321 - val_loss: 0.0200\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.01996 to 0.01153, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 437ms/step - loss: 0.0145 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01153 to 0.00783, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 454ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00783 to 0.00579, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 459ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00579 to 0.00453, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00453 to 0.00382, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00382 to 0.00337, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 462ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00337 to 0.00301, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 456ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 65ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_438 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_219 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_439 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_220 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_440 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_221 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_441 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_146 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_442 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_147 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_443 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2781\n",
      "Epoch 1: val_loss improved from inf to 0.17720, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 459ms/step - loss: 0.2781 - val_loss: 0.1772\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0836\n",
      "Epoch 2: val_loss improved from 0.17720 to 0.04755, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 454ms/step - loss: 0.0836 - val_loss: 0.0475\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0305\n",
      "Epoch 3: val_loss improved from 0.04755 to 0.01989, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0305 - val_loss: 0.0199\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 4: val_loss improved from 0.01989 to 0.01103, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 461ms/step - loss: 0.0144 - val_loss: 0.0110\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01103 to 0.00709, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 454ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00709 to 0.00538, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 456ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00538 to 0.00447, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 454ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00447 to 0.00385, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 455ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00385 to 0.00342, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00342 to 0.00310, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 459ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_444 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_222 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_445 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_223 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_446 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_224 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_447 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_148 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_448 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_149 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_449 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2487\n",
      "Epoch 1: val_loss improved from inf to 0.16375, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 461ms/step - loss: 0.2487 - val_loss: 0.1638\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0924\n",
      "Epoch 2: val_loss improved from 0.16375 to 0.06311, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 455ms/step - loss: 0.0924 - val_loss: 0.0631\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0453\n",
      "Epoch 3: val_loss improved from 0.06311 to 0.03095, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 458ms/step - loss: 0.0453 - val_loss: 0.0309\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 4: val_loss improved from 0.03095 to 0.01628, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 462ms/step - loss: 0.0216 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01628 to 0.00954, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0122 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00954 to 0.00641, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00641 to 0.00484, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 466ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00484 to 0.00401, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 469ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00401 to 0.00354, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 458ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00354 to 0.00320, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 458ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_450 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_225 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_451 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_226 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_452 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_227 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_453 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_150 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_454 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_151 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_455 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2456\n",
      "Epoch 1: val_loss improved from inf to 0.11630, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 451ms/step - loss: 0.2456 - val_loss: 0.1163\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0709\n",
      "Epoch 2: val_loss improved from 0.11630 to 0.04839, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 440ms/step - loss: 0.0709 - val_loss: 0.0484\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 3: val_loss improved from 0.04839 to 0.01641, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 433ms/step - loss: 0.0286 - val_loss: 0.0164\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 4: val_loss improved from 0.01641 to 0.00874, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 435ms/step - loss: 0.0114 - val_loss: 0.0087\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 5: val_loss improved from 0.00874 to 0.00590, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 437ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 6: val_loss improved from 0.00590 to 0.00459, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 437ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 7: val_loss improved from 0.00459 to 0.00394, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00394 to 0.00356, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 436ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00356 to 0.00329, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 438ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00329 to 0.00310, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 477ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_456 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_228 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_457 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_229 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_458 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_230 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_459 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_152 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_460 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_153 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_461 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2392\n",
      "Epoch 1: val_loss improved from inf to 0.10802, saving model to best_weights.h5\n",
      "43/43 [==============================] - 22s 492ms/step - loss: 0.2392 - val_loss: 0.1080\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0604\n",
      "Epoch 2: val_loss improved from 0.10802 to 0.03935, saving model to best_weights.h5\n",
      "43/43 [==============================] - 22s 515ms/step - loss: 0.0604 - val_loss: 0.0393\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0265\n",
      "Epoch 3: val_loss improved from 0.03935 to 0.01982, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 476ms/step - loss: 0.0265 - val_loss: 0.0198\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.01982 to 0.01159, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 486ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 5: val_loss improved from 0.01159 to 0.00836, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 486ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00836 to 0.00675, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 501ms/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00675 to 0.00565, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 488ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00565 to 0.00478, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 498ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00478 to 0.00415, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 490ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00415 to 0.00368, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 495ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 69ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_462 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_231 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_463 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_232 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_464 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_233 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_465 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_154 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_466 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_155 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_467 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3162\n",
      "Epoch 1: val_loss improved from inf to 0.26162, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 486ms/step - loss: 0.3162 - val_loss: 0.2616\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1352\n",
      "Epoch 2: val_loss improved from 0.26162 to 0.06344, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 422ms/step - loss: 0.1352 - val_loss: 0.0634\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 3: val_loss improved from 0.06344 to 0.02797, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 420ms/step - loss: 0.0421 - val_loss: 0.0280\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 4: val_loss improved from 0.02797 to 0.01747, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 454ms/step - loss: 0.0208 - val_loss: 0.0175\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01747 to 0.01211, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 411ms/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01211 to 0.00879, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 415ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 7: val_loss improved from 0.00879 to 0.00713, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 8: val_loss improved from 0.00713 to 0.00612, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 9: val_loss improved from 0.00612 to 0.00533, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 424ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 10: val_loss improved from 0.00533 to 0.00467, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 437ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_468 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_234 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_469 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_235 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_470 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_236 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_471 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_156 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_472 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_157 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_473 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2928\n",
      "Epoch 1: val_loss improved from inf to 0.21725, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 428ms/step - loss: 0.2928 - val_loss: 0.2173\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1088\n",
      "Epoch 2: val_loss improved from 0.21725 to 0.06593, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 415ms/step - loss: 0.1088 - val_loss: 0.0659\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0477\n",
      "Epoch 3: val_loss improved from 0.06593 to 0.03281, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 414ms/step - loss: 0.0477 - val_loss: 0.0328\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0218\n",
      "Epoch 4: val_loss improved from 0.03281 to 0.01507, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 442ms/step - loss: 0.0218 - val_loss: 0.0151\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01507 to 0.00895, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 432ms/step - loss: 0.0110 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00895 to 0.00694, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 418ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00694 to 0.00582, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00582 to 0.00499, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 422ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00499 to 0.00435, saving model to best_weights.h5\n",
      "43/43 [==============================] - 17s 402ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00435 to 0.00387, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_474 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_237 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_475 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_238 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_476 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_239 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_477 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_158 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_478 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_159 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_479 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.3339\n",
      "Epoch 1: val_loss improved from inf to 0.31135, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 441ms/step - loss: 0.3339 - val_loss: 0.3114\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.2259\n",
      "Epoch 2: val_loss improved from 0.31135 to 0.12032, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.2259 - val_loss: 0.1203\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0806\n",
      "Epoch 3: val_loss improved from 0.12032 to 0.06489, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 430ms/step - loss: 0.0806 - val_loss: 0.0649\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0462\n",
      "Epoch 4: val_loss improved from 0.06489 to 0.03129, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 444ms/step - loss: 0.0462 - val_loss: 0.0313\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 5: val_loss improved from 0.03129 to 0.01534, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 428ms/step - loss: 0.0210 - val_loss: 0.0153\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 6: val_loss improved from 0.01534 to 0.00896, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 468ms/step - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00896 to 0.00620, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 463ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00620 to 0.00492, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 473ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00492 to 0.00425, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 461ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00425 to 0.00383, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 476ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_480 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_240 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_481 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_241 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_482 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_242 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_483 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_160 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_484 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_161 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_485 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2623\n",
      "Epoch 1: val_loss improved from inf to 0.16056, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 467ms/step - loss: 0.2623 - val_loss: 0.1606\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0969\n",
      "Epoch 2: val_loss improved from 0.16056 to 0.07181, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 457ms/step - loss: 0.0969 - val_loss: 0.0718\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0524\n",
      "Epoch 3: val_loss improved from 0.07181 to 0.03567, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 452ms/step - loss: 0.0524 - val_loss: 0.0357\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0231\n",
      "Epoch 4: val_loss improved from 0.03567 to 0.01545, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 474ms/step - loss: 0.0231 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01545 to 0.00810, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 470ms/step - loss: 0.0105 - val_loss: 0.0081\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00810 to 0.00594, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 467ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00594 to 0.00472, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 467ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00472 to 0.00399, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 473ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00399 to 0.00353, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 479ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00353 to 0.00321, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 473ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 69ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_486 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_243 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_487 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_244 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_488 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_245 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_489 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_162 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_490 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_163 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_491 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2868\n",
      "Epoch 1: val_loss improved from inf to 0.20288, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 477ms/step - loss: 0.2868 - val_loss: 0.2029\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.1052\n",
      "Epoch 2: val_loss improved from 0.20288 to 0.06270, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 471ms/step - loss: 0.1052 - val_loss: 0.0627\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0426\n",
      "Epoch 3: val_loss improved from 0.06270 to 0.02913, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 468ms/step - loss: 0.0426 - val_loss: 0.0291\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 4: val_loss improved from 0.02913 to 0.01653, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 475ms/step - loss: 0.0214 - val_loss: 0.0165\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01653 to 0.01020, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 476ms/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.01020 to 0.00739, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 467ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00739 to 0.00599, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 476ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00599 to 0.00505, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 480ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00505 to 0.00437, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 490ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00437 to 0.00384, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 481ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_492 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_246 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_493 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_247 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_494 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_248 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_495 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_164 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_496 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_165 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_497 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - ETA: 0s - loss: 0.2273\n",
      "Epoch 1: val_loss improved from inf to 0.11993, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 469ms/step - loss: 0.2273 - val_loss: 0.1199\n",
      "Epoch 2/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0722\n",
      "Epoch 2: val_loss improved from 0.11993 to 0.05376, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 416ms/step - loss: 0.0722 - val_loss: 0.0538\n",
      "Epoch 3/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0383\n",
      "Epoch 3: val_loss improved from 0.05376 to 0.02667, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 434ms/step - loss: 0.0383 - val_loss: 0.0267\n",
      "Epoch 4/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0195\n",
      "Epoch 4: val_loss improved from 0.02667 to 0.01547, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 423ms/step - loss: 0.0195 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01547 to 0.00990, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 467ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00990 to 0.00684, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 477ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00684 to 0.00518, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 482ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00518 to 0.00417, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 467ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00417 to 0.00365, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 471ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00365 to 0.00332, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 480ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_498 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_249 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_499 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_250 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_500 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_251 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_501 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_166 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_502 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_167 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_503 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/43 [============================>.] - ETA: 0s - loss: 0.2823\n",
      "Epoch 1: val_loss improved from inf to 0.17930, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 486ms/step - loss: 0.2822 - val_loss: 0.1793\n",
      "Epoch 2/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0778\n",
      "Epoch 2: val_loss improved from 0.17930 to 0.04275, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 475ms/step - loss: 0.0777 - val_loss: 0.0427\n",
      "Epoch 3/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0297\n",
      "Epoch 3: val_loss improved from 0.04275 to 0.02122, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 469ms/step - loss: 0.0297 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.02122 to 0.01321, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 469ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01321 to 0.00893, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 476ms/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00893 to 0.00690, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 465ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00690 to 0.00561, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 460ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00561 to 0.00458, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 463ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00458 to 0.00391, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 454ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00391 to 0.00349, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 460ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_504 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_252 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_505 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_253 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_506 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_254 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_507 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_168 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_508 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_169 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_509 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/43 [============================>.] - ETA: 0s - loss: 0.2197\n",
      "Epoch 1: val_loss improved from inf to 0.09907, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 478ms/step - loss: 0.2196 - val_loss: 0.0991\n",
      "Epoch 2/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0683\n",
      "Epoch 2: val_loss improved from 0.09907 to 0.04809, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 470ms/step - loss: 0.0683 - val_loss: 0.0481\n",
      "Epoch 3/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0347\n",
      "Epoch 3: val_loss improved from 0.04809 to 0.02746, saving model to best_weights.h5\n",
      "43/43 [==============================] - 20s 467ms/step - loss: 0.0347 - val_loss: 0.0275\n",
      "Epoch 4/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0212\n",
      "Epoch 4: val_loss improved from 0.02746 to 0.01702, saving model to best_weights.h5\n",
      "43/43 [==============================] - 21s 480ms/step - loss: 0.0212 - val_loss: 0.0170\n",
      "Epoch 5/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss improved from 0.01702 to 0.01053, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 452ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.01053 to 0.00714, saving model to best_weights.h5\n",
      "43/43 [==============================] - 19s 450ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00714 to 0.00548, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 413ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00548 to 0.00452, saving model to best_weights.h5\n",
      "43/43 [==============================] - 18s 426ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00452 to 0.00396, saving model to best_weights.h5\n",
      "43/43 [==============================] - 23s 543ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00396 to 0.00358, saving model to best_weights.h5\n",
      "43/43 [==============================] - 23s 526ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_510 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_255 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_511 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_256 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_512 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_257 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_513 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_170 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_514 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_171 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_515 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.3022\n",
      "Epoch 1: val_loss improved from inf to 0.20564, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 535ms/step - loss: 0.3022 - val_loss: 0.2056\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0917\n",
      "Epoch 2: val_loss improved from 0.20564 to 0.04726, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 565ms/step - loss: 0.0917 - val_loss: 0.0473\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0336\n",
      "Epoch 3: val_loss improved from 0.04726 to 0.02502, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 568ms/step - loss: 0.0336 - val_loss: 0.0250\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02502 to 0.01408, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 558ms/step - loss: 0.0179 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01408 to 0.00868, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 532ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00868 to 0.00581, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 544ms/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00581 to 0.00458, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 542ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00458 to 0.00399, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 549ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00399 to 0.00362, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 568ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00362 to 0.00332, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 549ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_516 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_258 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_517 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_259 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_518 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_260 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_519 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_172 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_520 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_173 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_521 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2244\n",
      "Epoch 1: val_loss improved from inf to 0.11279, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 534ms/step - loss: 0.2244 - val_loss: 0.1128\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0634\n",
      "Epoch 2: val_loss improved from 0.11279 to 0.04549, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 473ms/step - loss: 0.0634 - val_loss: 0.0455\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 3: val_loss improved from 0.04549 to 0.02214, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 406ms/step - loss: 0.0315 - val_loss: 0.0221\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 4: val_loss improved from 0.02214 to 0.01318, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 408ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01318 to 0.00902, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 404ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00902 to 0.00720, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 438ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00720 to 0.00600, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 421ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00600 to 0.00505, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 432ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00505 to 0.00428, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 438ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00428 to 0.00372, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 414ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_522 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_261 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_523 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_262 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_524 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_263 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_525 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_174 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_526 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_175 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_527 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2600\n",
      "Epoch 1: val_loss improved from inf to 0.18402, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 409ms/step - loss: 0.2600 - val_loss: 0.1840\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0886\n",
      "Epoch 2: val_loss improved from 0.18402 to 0.04939, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 407ms/step - loss: 0.0886 - val_loss: 0.0494\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0348\n",
      "Epoch 3: val_loss improved from 0.04939 to 0.02514, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 407ms/step - loss: 0.0348 - val_loss: 0.0251\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 4: val_loss improved from 0.02514 to 0.01382, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 404ms/step - loss: 0.0178 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01382 to 0.00918, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 405ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00918 to 0.00651, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 407ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00651 to 0.00489, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 408ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00489 to 0.00402, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 403ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00402 to 0.00354, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 409ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00354 to 0.00322, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 407ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_528 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_264 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_529 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_265 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_530 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_266 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_531 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_176 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_532 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_177 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_533 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2964\n",
      "Epoch 1: val_loss improved from inf to 0.23622, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 414ms/step - loss: 0.2964 - val_loss: 0.2362\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1212\n",
      "Epoch 2: val_loss improved from 0.23622 to 0.06355, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 409ms/step - loss: 0.1212 - val_loss: 0.0635\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 3: val_loss improved from 0.06355 to 0.02683, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 408ms/step - loss: 0.0424 - val_loss: 0.0268\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 4: val_loss improved from 0.02683 to 0.01327, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 410ms/step - loss: 0.0182 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01327 to 0.00764, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 408ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00764 to 0.00557, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 407ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00557 to 0.00452, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 410ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00452 to 0.00392, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 418ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00392 to 0.00356, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 403ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00356 to 0.00326, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 402ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_534 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_267 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_535 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_268 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_536 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_269 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_537 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_178 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_538 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_179 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_539 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2751\n",
      "Epoch 1: val_loss improved from inf to 0.17302, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 422ms/step - loss: 0.2751 - val_loss: 0.1730\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0780\n",
      "Epoch 2: val_loss improved from 0.17302 to 0.04341, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 405ms/step - loss: 0.0780 - val_loss: 0.0434\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.04341 to 0.02037, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 404ms/step - loss: 0.0294 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.02037 to 0.01226, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 405ms/step - loss: 0.0151 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01226 to 0.00775, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 404ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00775 to 0.00544, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 404ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00544 to 0.00436, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 404ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00436 to 0.00377, saving model to best_weights.h5\n",
      "42/42 [==============================] - 17s 406ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00377 to 0.00341, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 458ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00341 to 0.00315, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 500ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 91ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_540 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_270 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_541 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_271 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_542 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_272 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_543 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_180 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_544 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_181 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_545 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2858\n",
      "Epoch 1: val_loss improved from inf to 0.19018, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 588ms/step - loss: 0.2858 - val_loss: 0.1902\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0873\n",
      "Epoch 2: val_loss improved from 0.19018 to 0.04857, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 577ms/step - loss: 0.0873 - val_loss: 0.0486\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0298\n",
      "Epoch 3: val_loss improved from 0.04857 to 0.01822, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 599ms/step - loss: 0.0298 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 4: val_loss improved from 0.01822 to 0.01113, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 571ms/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01113 to 0.00771, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 580ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00771 to 0.00609, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 583ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00609 to 0.00512, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 579ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00512 to 0.00441, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 588ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00441 to 0.00390, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 589ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00390 to 0.00355, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 572ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_546 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_273 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_547 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_274 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_548 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_275 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_549 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_182 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_550 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_183 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_551 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2652\n",
      "Epoch 1: val_loss improved from inf to 0.15018, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 595ms/step - loss: 0.2652 - val_loss: 0.1502\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0720\n",
      "Epoch 2: val_loss improved from 0.15018 to 0.04313, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 575ms/step - loss: 0.0720 - val_loss: 0.0431\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 3: val_loss improved from 0.04313 to 0.02181, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 579ms/step - loss: 0.0297 - val_loss: 0.0218\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.02181 to 0.01368, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 593ms/step - loss: 0.0166 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01368 to 0.00933, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 575ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00933 to 0.00717, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 575ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00717 to 0.00582, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 578ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00582 to 0.00485, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 528ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00485 to 0.00420, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 586ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00420 to 0.00375, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 583ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 69ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_552 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_276 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_553 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_277 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_554 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_278 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_555 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_184 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_556 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_185 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_557 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2151\n",
      "Epoch 1: val_loss improved from inf to 0.09709, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 592ms/step - loss: 0.2151 - val_loss: 0.0971\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0659\n",
      "Epoch 2: val_loss improved from 0.09709 to 0.04630, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 574ms/step - loss: 0.0659 - val_loss: 0.0463\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0317\n",
      "Epoch 3: val_loss improved from 0.04630 to 0.02429, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 575ms/step - loss: 0.0317 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 4: val_loss improved from 0.02429 to 0.01451, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 579ms/step - loss: 0.0183 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01451 to 0.00879, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 576ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00879 to 0.00633, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 578ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00633 to 0.00518, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 565ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00518 to 0.00447, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 565ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00447 to 0.00399, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 571ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00399 to 0.00361, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 572ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_558 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_279 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_559 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_280 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_560 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_281 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_561 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_186 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_562 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_187 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_563 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2967\n",
      "Epoch 1: val_loss improved from inf to 0.23085, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 553ms/step - loss: 0.2967 - val_loss: 0.2308\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1209\n",
      "Epoch 2: val_loss improved from 0.23085 to 0.06325, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 569ms/step - loss: 0.1209 - val_loss: 0.0632\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0457\n",
      "Epoch 3: val_loss improved from 0.06325 to 0.03375, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 584ms/step - loss: 0.0457 - val_loss: 0.0337\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.03375 to 0.01709, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 595ms/step - loss: 0.0234 - val_loss: 0.0171\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 5: val_loss improved from 0.01709 to 0.00961, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 581ms/step - loss: 0.0125 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00961 to 0.00652, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 599ms/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00652 to 0.00515, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 590ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00515 to 0.00427, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 596ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00427 to 0.00368, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 569ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00368 to 0.00326, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 584ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 67ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_564 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_282 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_565 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_283 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_566 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_284 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_567 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_188 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_568 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_189 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_569 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.3183\n",
      "Epoch 1: val_loss improved from inf to 0.25647, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 537ms/step - loss: 0.3183 - val_loss: 0.2565\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1221\n",
      "Epoch 2: val_loss improved from 0.25647 to 0.05095, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 597ms/step - loss: 0.1221 - val_loss: 0.0509\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 3: val_loss improved from 0.05095 to 0.02998, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 601ms/step - loss: 0.0377 - val_loss: 0.0300\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 4: val_loss improved from 0.02998 to 0.01811, saving model to best_weights.h5\n",
      "42/42 [==============================] - 26s 619ms/step - loss: 0.0227 - val_loss: 0.0181\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 5: val_loss improved from 0.01811 to 0.01102, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 597ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01102 to 0.00700, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 602ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00700 to 0.00538, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 584ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00538 to 0.00458, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 551ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00458 to 0.00407, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 563ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00407 to 0.00368, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 573ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_570 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_285 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_571 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_286 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_572 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_287 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_573 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_190 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_574 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_191 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_575 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2058\n",
      "Epoch 1: val_loss improved from inf to 0.09651, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 586ms/step - loss: 0.2058 - val_loss: 0.0965\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0598\n",
      "Epoch 2: val_loss improved from 0.09651 to 0.04302, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 573ms/step - loss: 0.0598 - val_loss: 0.0430\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 3: val_loss improved from 0.04302 to 0.01984, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 574ms/step - loss: 0.0288 - val_loss: 0.0198\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 4: val_loss improved from 0.01984 to 0.01090, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 567ms/step - loss: 0.0143 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01090 to 0.00677, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 569ms/step - loss: 0.0081 - val_loss: 0.0068\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00677 to 0.00513, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 564ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00513 to 0.00416, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 567ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00416 to 0.00354, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 542ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00354 to 0.00314, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 560ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00314 to 0.00285, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 554ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_576 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_288 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_577 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_289 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_578 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_290 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_579 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_192 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_580 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_193 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_581 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2509\n",
      "Epoch 1: val_loss improved from inf to 0.15407, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 513ms/step - loss: 0.2509 - val_loss: 0.1541\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0828\n",
      "Epoch 2: val_loss improved from 0.15407 to 0.05505, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 501ms/step - loss: 0.0828 - val_loss: 0.0551\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0368\n",
      "Epoch 3: val_loss improved from 0.05505 to 0.02446, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 499ms/step - loss: 0.0368 - val_loss: 0.0245\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 4: val_loss improved from 0.02446 to 0.01436, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 502ms/step - loss: 0.0180 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01436 to 0.00956, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 482ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00956 to 0.00711, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 468ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00711 to 0.00551, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 504ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00551 to 0.00454, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 506ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00454 to 0.00396, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 502ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00396 to 0.00359, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 509ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_582 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_291 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_583 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_292 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_584 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_293 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_585 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_194 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_586 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_195 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_587 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.1829\n",
      "Epoch 1: val_loss improved from inf to 0.07702, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 512ms/step - loss: 0.1829 - val_loss: 0.0770\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0560\n",
      "Epoch 2: val_loss improved from 0.07702 to 0.03977, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 499ms/step - loss: 0.0560 - val_loss: 0.0398\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0282\n",
      "Epoch 3: val_loss improved from 0.03977 to 0.02175, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 502ms/step - loss: 0.0282 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 4: val_loss improved from 0.02175 to 0.01365, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 498ms/step - loss: 0.0167 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01365 to 0.00850, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 535ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 6: val_loss improved from 0.00850 to 0.00584, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 510ms/step - loss: 0.0066 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00584 to 0.00473, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 503ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00473 to 0.00415, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 530ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00415 to 0.00372, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 502ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00372 to 0.00342, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 502ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_588 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_294 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_589 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_295 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_590 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_296 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_591 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_196 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_592 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_197 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_593 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2918\n",
      "Epoch 1: val_loss improved from inf to 0.20724, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 508ms/step - loss: 0.2918 - val_loss: 0.2072\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1028\n",
      "Epoch 2: val_loss improved from 0.20724 to 0.05187, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 494ms/step - loss: 0.1028 - val_loss: 0.0519\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0373\n",
      "Epoch 3: val_loss improved from 0.05187 to 0.02791, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 501ms/step - loss: 0.0373 - val_loss: 0.0279\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 4: val_loss improved from 0.02791 to 0.01712, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 510ms/step - loss: 0.0211 - val_loss: 0.0171\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss improved from 0.01712 to 0.01055, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 531ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01055 to 0.00708, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 503ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00708 to 0.00504, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 504ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00504 to 0.00395, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 512ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00395 to 0.00332, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 508ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00332 to 0.00294, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 497ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 67ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_594 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_297 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_595 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_298 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_596 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_299 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_597 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_198 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_598 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_199 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_599 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2291\n",
      "Epoch 1: val_loss improved from inf to 0.11199, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 517ms/step - loss: 0.2291 - val_loss: 0.1120\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0541\n",
      "Epoch 2: val_loss improved from 0.11199 to 0.03481, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 503ms/step - loss: 0.0541 - val_loss: 0.0348\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 3: val_loss improved from 0.03481 to 0.01427, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 512ms/step - loss: 0.0228 - val_loss: 0.0143\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 4: val_loss improved from 0.01427 to 0.00840, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 518ms/step - loss: 0.0103 - val_loss: 0.0084\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 5: val_loss improved from 0.00840 to 0.00622, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 488ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 6: val_loss improved from 0.00622 to 0.00504, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 455ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 7: val_loss improved from 0.00504 to 0.00424, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 449ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00424 to 0.00368, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 476ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00368 to 0.00323, saving model to best_weights.h5\n",
      "42/42 [==============================] - 18s 439ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00323 to 0.00289, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 507ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_600 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_300 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_601 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_301 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_602 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_302 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_603 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_200 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_604 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_201 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_605 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2814\n",
      "Epoch 1: val_loss improved from inf to 0.19295, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 556ms/step - loss: 0.2814 - val_loss: 0.1930\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0949\n",
      "Epoch 2: val_loss improved from 0.19295 to 0.05762, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 575ms/step - loss: 0.0949 - val_loss: 0.0576\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0393\n",
      "Epoch 3: val_loss improved from 0.05762 to 0.02756, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 578ms/step - loss: 0.0393 - val_loss: 0.0276\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0205\n",
      "Epoch 4: val_loss improved from 0.02756 to 0.01643, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 580ms/step - loss: 0.0205 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 5: val_loss improved from 0.01643 to 0.01138, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 553ms/step - loss: 0.0131 - val_loss: 0.0114\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 6: val_loss improved from 0.01138 to 0.00825, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 554ms/step - loss: 0.0093 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00825 to 0.00603, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 560ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00603 to 0.00478, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 550ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00478 to 0.00401, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 590ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00401 to 0.00351, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 580ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_606 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_303 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_607 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_304 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_608 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_305 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_609 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_202 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_610 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_203 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_611 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2760\n",
      "Epoch 1: val_loss improved from inf to 0.17221, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 558ms/step - loss: 0.2760 - val_loss: 0.1722\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0876\n",
      "Epoch 2: val_loss improved from 0.17221 to 0.05707, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 525ms/step - loss: 0.0876 - val_loss: 0.0571\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 3: val_loss improved from 0.05707 to 0.03354, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 541ms/step - loss: 0.0436 - val_loss: 0.0335\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 4: val_loss improved from 0.03354 to 0.01624, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 524ms/step - loss: 0.0226 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 5: val_loss improved from 0.01624 to 0.00999, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 531ms/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.00999 to 0.00755, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 535ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00755 to 0.00599, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 513ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00599 to 0.00484, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 479ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00484 to 0.00405, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 457ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00405 to 0.00347, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 505ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_612 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_306 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_613 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_307 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_614 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_308 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_615 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_204 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_616 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_205 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_617 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.3254\n",
      "Epoch 1: val_loss improved from inf to 0.29540, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 522ms/step - loss: 0.3254 - val_loss: 0.2954\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1921\n",
      "Epoch 2: val_loss improved from 0.29540 to 0.07857, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 522ms/step - loss: 0.1921 - val_loss: 0.0786\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0547\n",
      "Epoch 3: val_loss improved from 0.07857 to 0.03766, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 536ms/step - loss: 0.0547 - val_loss: 0.0377\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 4: val_loss improved from 0.03766 to 0.01729, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 544ms/step - loss: 0.0244 - val_loss: 0.0173\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 5: val_loss improved from 0.01729 to 0.01024, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 546ms/step - loss: 0.0129 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.01024 to 0.00688, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 531ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00688 to 0.00550, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 519ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00550 to 0.00456, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 508ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00456 to 0.00390, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00390 to 0.00343, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 509ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_618 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_309 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_619 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_310 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_620 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_311 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_621 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_206 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_622 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_207 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_623 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2141\n",
      "Epoch 1: val_loss improved from inf to 0.09946, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 512ms/step - loss: 0.2141 - val_loss: 0.0995\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0624\n",
      "Epoch 2: val_loss improved from 0.09946 to 0.04192, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 513ms/step - loss: 0.0624 - val_loss: 0.0419\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0282\n",
      "Epoch 3: val_loss improved from 0.04192 to 0.02098, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 0.0282 - val_loss: 0.0210\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.02098 to 0.01204, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 559ms/step - loss: 0.0153 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 5: val_loss improved from 0.01204 to 0.00838, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 525ms/step - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00838 to 0.00646, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00646 to 0.00525, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 466ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00525 to 0.00432, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00432 to 0.00367, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 533ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00367 to 0.00324, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 532ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_624 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_312 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_625 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_313 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_626 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_314 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_627 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_208 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_628 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_209 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_629 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2460\n",
      "Epoch 1: val_loss improved from inf to 0.11938, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 533ms/step - loss: 0.2460 - val_loss: 0.1194\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0670\n",
      "Epoch 2: val_loss improved from 0.11938 to 0.04968, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 522ms/step - loss: 0.0670 - val_loss: 0.0497\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0331\n",
      "Epoch 3: val_loss improved from 0.04968 to 0.01999, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 460ms/step - loss: 0.0331 - val_loss: 0.0200\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 4: val_loss improved from 0.01999 to 0.01151, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 506ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.01151 to 0.00824, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 539ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00824 to 0.00633, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 516ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00633 to 0.00515, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 476ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00515 to 0.00433, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 448ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00433 to 0.00369, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00369 to 0.00332, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 536ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_630 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_315 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_631 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_316 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_632 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_317 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_633 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_210 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_634 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_211 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_635 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2269\n",
      "Epoch 1: val_loss improved from inf to 0.10126, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 577ms/step - loss: 0.2269 - val_loss: 0.1013\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0557\n",
      "Epoch 2: val_loss improved from 0.10126 to 0.03857, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 573ms/step - loss: 0.0557 - val_loss: 0.0386\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0258\n",
      "Epoch 3: val_loss improved from 0.03857 to 0.01885, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 584ms/step - loss: 0.0258 - val_loss: 0.0189\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.01885 to 0.01210, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 575ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01210 to 0.00845, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 554ms/step - loss: 0.0096 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00845 to 0.00648, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 567ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00648 to 0.00531, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 573ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00531 to 0.00445, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 559ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00445 to 0.00386, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 570ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00386 to 0.00346, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 557ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 82ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_636 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_318 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_637 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_319 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_638 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_320 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_639 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_212 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_640 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_213 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_641 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2852\n",
      "Epoch 1: val_loss improved from inf to 0.17645, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 572ms/step - loss: 0.2852 - val_loss: 0.1765\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0848\n",
      "Epoch 2: val_loss improved from 0.17645 to 0.04961, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 582ms/step - loss: 0.0848 - val_loss: 0.0496\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0326\n",
      "Epoch 3: val_loss improved from 0.04961 to 0.02158, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 559ms/step - loss: 0.0326 - val_loss: 0.0216\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02158 to 0.01333, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 559ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01333 to 0.00938, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 574ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00938 to 0.00729, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 553ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00729 to 0.00602, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 575ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00602 to 0.00512, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 559ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00512 to 0.00444, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 569ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00444 to 0.00390, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 562ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_642 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_321 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_643 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_322 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_644 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_323 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_645 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_214 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_646 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_215 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_647 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.1990\n",
      "Epoch 1: val_loss improved from inf to 0.07045, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 551ms/step - loss: 0.1990 - val_loss: 0.0704\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Epoch 2: val_loss improved from 0.07045 to 0.02999, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 522ms/step - loss: 0.0432 - val_loss: 0.0300\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0212\n",
      "Epoch 3: val_loss improved from 0.02999 to 0.01688, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 509ms/step - loss: 0.0212 - val_loss: 0.0169\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 4: val_loss improved from 0.01688 to 0.01048, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 517ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01048 to 0.00673, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 520ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 6: val_loss improved from 0.00673 to 0.00491, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 507ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 7: val_loss improved from 0.00491 to 0.00403, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 508ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 8: val_loss improved from 0.00403 to 0.00350, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 480ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00350 to 0.00312, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 508ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00312 to 0.00280, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 528ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "finished training\n",
      "15/15 [==============================] - 1s 65ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_648 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_324 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_649 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_325 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_650 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_326 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_651 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_216 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_652 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_217 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_653 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2861\n",
      "Epoch 1: val_loss improved from inf to 0.20097, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 534ms/step - loss: 0.2861 - val_loss: 0.2010\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0899\n",
      "Epoch 2: val_loss improved from 0.20097 to 0.04859, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 512ms/step - loss: 0.0899 - val_loss: 0.0486\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.04859 to 0.02818, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 505ms/step - loss: 0.0359 - val_loss: 0.0282\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 4: val_loss improved from 0.02818 to 0.01656, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 507ms/step - loss: 0.0214 - val_loss: 0.0166\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01656 to 0.00906, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 517ms/step - loss: 0.0119 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00906 to 0.00602, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 522ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00602 to 0.00482, saving model to best_weights.h5\n",
      "42/42 [==============================] - 25s 588ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00482 to 0.00409, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 525ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00409 to 0.00357, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 582ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00357 to 0.00322, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 555ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_654 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_327 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_655 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_328 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_656 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_329 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_657 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_218 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_658 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_219 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_659 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2406\n",
      "Epoch 1: val_loss improved from inf to 0.09854, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 567ms/step - loss: 0.2406 - val_loss: 0.0985\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0524\n",
      "Epoch 2: val_loss improved from 0.09854 to 0.03635, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 557ms/step - loss: 0.0524 - val_loss: 0.0364\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 3: val_loss improved from 0.03635 to 0.01852, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 560ms/step - loss: 0.0255 - val_loss: 0.0185\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 4: val_loss improved from 0.01852 to 0.01104, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 566ms/step - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01104 to 0.00758, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 574ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00758 to 0.00598, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 569ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00598 to 0.00497, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 564ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00497 to 0.00430, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 478ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00430 to 0.00384, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 488ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00384 to 0.00349, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 496ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_660 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_330 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_661 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_331 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_662 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_332 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_663 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_220 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_664 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_221 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_665 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.3086\n",
      "Epoch 1: val_loss improved from inf to 0.24846, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 498ms/step - loss: 0.3086 - val_loss: 0.2485\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1340\n",
      "Epoch 2: val_loss improved from 0.24846 to 0.06115, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 479ms/step - loss: 0.1340 - val_loss: 0.0612\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0454\n",
      "Epoch 3: val_loss improved from 0.06115 to 0.03276, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 494ms/step - loss: 0.0454 - val_loss: 0.0328\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 4: val_loss improved from 0.03276 to 0.01596, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 511ms/step - loss: 0.0220 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 5: val_loss improved from 0.01596 to 0.01073, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 499ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01073 to 0.00794, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 507ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00794 to 0.00624, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 494ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00624 to 0.00521, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 486ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00521 to 0.00449, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 492ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00449 to 0.00393, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 523ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_666 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_333 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_667 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_334 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_668 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_335 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_669 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_222 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_670 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_223 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_671 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2311\n",
      "Epoch 1: val_loss improved from inf to 0.10715, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 528ms/step - loss: 0.2311 - val_loss: 0.1072\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0617\n",
      "Epoch 2: val_loss improved from 0.10715 to 0.04584, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 519ms/step - loss: 0.0617 - val_loss: 0.0458\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 3: val_loss improved from 0.04584 to 0.02172, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 514ms/step - loss: 0.0324 - val_loss: 0.0217\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.02172 to 0.01342, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 510ms/step - loss: 0.0163 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01342 to 0.00950, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 513ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00950 to 0.00724, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 496ms/step - loss: 0.0079 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00724 to 0.00573, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 475ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00573 to 0.00467, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 514ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00467 to 0.00400, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 528ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00400 to 0.00359, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 540ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_672 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_336 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_673 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_337 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_674 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_338 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_675 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_224 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_676 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_225 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_677 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.2295\n",
      "Epoch 1: val_loss improved from inf to 0.11573, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 550ms/step - loss: 0.2295 - val_loss: 0.1157\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0701\n",
      "Epoch 2: val_loss improved from 0.11573 to 0.05052, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 531ms/step - loss: 0.0701 - val_loss: 0.0505\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0334\n",
      "Epoch 3: val_loss improved from 0.05052 to 0.02117, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 530ms/step - loss: 0.0334 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.02117 to 0.01182, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 514ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01182 to 0.00776, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 533ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00776 to 0.00559, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 536ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00559 to 0.00430, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 528ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00430 to 0.00362, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 540ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00362 to 0.00320, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 513ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00320 to 0.00290, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 523ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_678 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_339 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_679 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_340 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_680 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_341 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_681 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_226 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_682 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_227 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_683 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.3193\n",
      "Epoch 1: val_loss improved from inf to 0.26170, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 483ms/step - loss: 0.3193 - val_loss: 0.2617\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1347\n",
      "Epoch 2: val_loss improved from 0.26170 to 0.06235, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 453ms/step - loss: 0.1347 - val_loss: 0.0624\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 3: val_loss improved from 0.06235 to 0.03112, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 517ms/step - loss: 0.0436 - val_loss: 0.0311\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 4: val_loss improved from 0.03112 to 0.01724, saving model to best_weights.h5\n",
      "42/42 [==============================] - 20s 484ms/step - loss: 0.0224 - val_loss: 0.0172\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01724 to 0.01094, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 462ms/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 6: val_loss improved from 0.01094 to 0.00823, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 502ms/step - loss: 0.0090 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00823 to 0.00663, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 492ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 8: val_loss improved from 0.00663 to 0.00538, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 514ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00538 to 0.00452, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 510ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00452 to 0.00395, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 503ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 67ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_684 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_342 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_685 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_343 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_686 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_344 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_687 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_228 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_688 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_229 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_689 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - ETA: 0s - loss: 0.1385\n",
      "Epoch 1: val_loss improved from inf to 0.07040, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 521ms/step - loss: 0.1385 - val_loss: 0.0704\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0536\n",
      "Epoch 2: val_loss improved from 0.07040 to 0.03885, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 541ms/step - loss: 0.0536 - val_loss: 0.0388\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0269\n",
      "Epoch 3: val_loss improved from 0.03885 to 0.01996, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 534ms/step - loss: 0.0269 - val_loss: 0.0200\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.01996 to 0.01154, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 537ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01154 to 0.00753, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 525ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 6: val_loss improved from 0.00753 to 0.00553, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 527ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00553 to 0.00429, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 541ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00429 to 0.00360, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 524ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00360 to 0.00317, saving model to best_weights.h5\n",
      "42/42 [==============================] - 21s 506ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00317 to 0.00286, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 525ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_690 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_345 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_691 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_346 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_692 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_347 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_693 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_230 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_694 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_231 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_695 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/42 [============================>.] - ETA: 0s - loss: 0.2456\n",
      "Epoch 1: val_loss improved from inf to 0.13664, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 525ms/step - loss: 0.2455 - val_loss: 0.1366\n",
      "Epoch 2/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0799\n",
      "Epoch 2: val_loss improved from 0.13664 to 0.05721, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 527ms/step - loss: 0.0798 - val_loss: 0.0572\n",
      "Epoch 3/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0390\n",
      "Epoch 3: val_loss improved from 0.05721 to 0.02485, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 539ms/step - loss: 0.0390 - val_loss: 0.0248\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02485 to 0.01392, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 573ms/step - loss: 0.0179 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01392 to 0.00882, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 532ms/step - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00882 to 0.00621, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 527ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00621 to 0.00488, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 542ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00488 to 0.00416, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 550ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00416 to 0.00375, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 533ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00375 to 0.00340, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 522ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_696 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_348 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_697 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_349 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_698 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_350 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_699 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_232 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_700 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_233 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_701 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/42 [============================>.] - ETA: 0s - loss: 0.3222\n",
      "Epoch 1: val_loss improved from inf to 0.25540, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 508ms/step - loss: 0.3221 - val_loss: 0.2554\n",
      "Epoch 2/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1284\n",
      "Epoch 2: val_loss improved from 0.25540 to 0.05057, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 464ms/step - loss: 0.1284 - val_loss: 0.0506\n",
      "Epoch 3/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0371\n",
      "Epoch 3: val_loss improved from 0.05057 to 0.02646, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 458ms/step - loss: 0.0370 - val_loss: 0.0265\n",
      "Epoch 4/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0182\n",
      "Epoch 4: val_loss improved from 0.02646 to 0.01390, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 457ms/step - loss: 0.0182 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0109\n",
      "Epoch 5: val_loss improved from 0.01390 to 0.00944, saving model to best_weights.h5\n",
      "42/42 [==============================] - 19s 460ms/step - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00944 to 0.00691, saving model to best_weights.h5\n",
      "42/42 [==============================] - 24s 571ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00691 to 0.00532, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 525ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00532 to 0.00428, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 555ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00428 to 0.00370, saving model to best_weights.h5\n",
      "42/42 [==============================] - 23s 560ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00370 to 0.00337, saving model to best_weights.h5\n",
      "42/42 [==============================] - 22s 512ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_702 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_351 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_703 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_352 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_704 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_353 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_705 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_234 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_706 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_235 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_707 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3410\n",
      "Epoch 1: val_loss improved from inf to 0.31651, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 577ms/step - loss: 0.3410 - val_loss: 0.3165\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2233\n",
      "Epoch 2: val_loss improved from 0.31651 to 0.10477, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 570ms/step - loss: 0.2233 - val_loss: 0.1048\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0617\n",
      "Epoch 3: val_loss improved from 0.10477 to 0.03996, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 533ms/step - loss: 0.0617 - val_loss: 0.0400\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 4: val_loss improved from 0.03996 to 0.01753, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 547ms/step - loss: 0.0257 - val_loss: 0.0175\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01753 to 0.01082, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 586ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 6: val_loss improved from 0.01082 to 0.00739, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 579ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00739 to 0.00542, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 563ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00542 to 0.00443, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 533ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00443 to 0.00387, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 534ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00387 to 0.00350, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 535ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_708 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_354 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_709 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_355 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_710 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_356 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_711 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_236 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_712 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_237 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_713 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3038\n",
      "Epoch 1: val_loss improved from inf to 0.23576, saving model to best_weights.h5\n",
      "41/41 [==============================] - 20s 476ms/step - loss: 0.3038 - val_loss: 0.2358\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1127\n",
      "Epoch 2: val_loss improved from 0.23576 to 0.05150, saving model to best_weights.h5\n",
      "41/41 [==============================] - 20s 482ms/step - loss: 0.1127 - val_loss: 0.0515\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0333\n",
      "Epoch 3: val_loss improved from 0.05150 to 0.02199, saving model to best_weights.h5\n",
      "41/41 [==============================] - 21s 521ms/step - loss: 0.0333 - val_loss: 0.0220\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss improved from 0.02199 to 0.01234, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 563ms/step - loss: 0.0159 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01234 to 0.00803, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 571ms/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00803 to 0.00590, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 593ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00590 to 0.00482, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 580ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00482 to 0.00413, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 553ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00413 to 0.00364, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00364 to 0.00332, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 565ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 75ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_714 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_357 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_715 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_358 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_716 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_359 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_717 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_238 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_718 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_239 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_719 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2019\n",
      "Epoch 1: val_loss improved from inf to 0.09489, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 579ms/step - loss: 0.2019 - val_loss: 0.0949\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0555\n",
      "Epoch 2: val_loss improved from 0.09489 to 0.03613, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 539ms/step - loss: 0.0555 - val_loss: 0.0361\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0240\n",
      "Epoch 3: val_loss improved from 0.03613 to 0.01789, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 564ms/step - loss: 0.0240 - val_loss: 0.0179\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01789 to 0.01210, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 594ms/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01210 to 0.00878, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 566ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00878 to 0.00676, saving model to best_weights.h5\n",
      "41/41 [==============================] - 21s 512ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00676 to 0.00552, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 535ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00552 to 0.00474, saving model to best_weights.h5\n",
      "41/41 [==============================] - 21s 520ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00474 to 0.00422, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 616ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00422 to 0.00383, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 717ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_720 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_360 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_721 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_361 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_722 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_362 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_723 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_240 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_724 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_241 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_725 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2662\n",
      "Epoch 1: val_loss improved from inf to 0.17019, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 687ms/step - loss: 0.2662 - val_loss: 0.1702\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0912\n",
      "Epoch 2: val_loss improved from 0.17019 to 0.06049, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 703ms/step - loss: 0.0912 - val_loss: 0.0605\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0416\n",
      "Epoch 3: val_loss improved from 0.06049 to 0.02835, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 658ms/step - loss: 0.0416 - val_loss: 0.0284\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 4: val_loss improved from 0.02835 to 0.01441, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 717ms/step - loss: 0.0196 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01441 to 0.00860, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 711ms/step - loss: 0.0106 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00860 to 0.00635, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 630ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00635 to 0.00497, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 631ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00497 to 0.00397, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 670ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00397 to 0.00344, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 637ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00344 to 0.00313, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 650ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_726 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_363 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_727 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_364 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_728 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_365 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_729 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_242 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_730 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_243 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_731 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2416\n",
      "Epoch 1: val_loss improved from inf to 0.13655, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 702ms/step - loss: 0.2416 - val_loss: 0.1366\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0744\n",
      "Epoch 2: val_loss improved from 0.13655 to 0.04903, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 685ms/step - loss: 0.0744 - val_loss: 0.0490\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 3: val_loss improved from 0.04903 to 0.02041, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 700ms/step - loss: 0.0315 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 4: val_loss improved from 0.02041 to 0.01042, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 718ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01042 to 0.00696, saving model to best_weights.h5\n",
      "41/41 [==============================] - 30s 733ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00696 to 0.00554, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 707ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00554 to 0.00470, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 676ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00470 to 0.00410, saving model to best_weights.h5\n",
      "41/41 [==============================] - 30s 738ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00410 to 0.00368, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 700ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00368 to 0.00337, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 694ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 2s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_732 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_366 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_733 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_367 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_734 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_368 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_735 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_244 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_736 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_245 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_737 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2709\n",
      "Epoch 1: val_loss improved from inf to 0.16926, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 684ms/step - loss: 0.2709 - val_loss: 0.1693\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0842\n",
      "Epoch 2: val_loss improved from 0.16926 to 0.05278, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 692ms/step - loss: 0.0842 - val_loss: 0.0528\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0372\n",
      "Epoch 3: val_loss improved from 0.05278 to 0.02828, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 659ms/step - loss: 0.0372 - val_loss: 0.0283\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0207\n",
      "Epoch 4: val_loss improved from 0.02828 to 0.01531, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 632ms/step - loss: 0.0207 - val_loss: 0.0153\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01531 to 0.00819, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 707ms/step - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00819 to 0.00555, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 704ms/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00555 to 0.00441, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 697ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00441 to 0.00380, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 658ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00380 to 0.00337, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 641ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00337 to 0.00303, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 696ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_738 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_369 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_739 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_370 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_740 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_371 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_741 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_246 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_742 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_247 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_743 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2076\n",
      "Epoch 1: val_loss improved from inf to 0.09075, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 699ms/step - loss: 0.2076 - val_loss: 0.0907\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0595\n",
      "Epoch 2: val_loss improved from 0.09075 to 0.04717, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 606ms/step - loss: 0.0595 - val_loss: 0.0472\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 3: val_loss improved from 0.04717 to 0.03086, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 666ms/step - loss: 0.0369 - val_loss: 0.0309\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 4: val_loss improved from 0.03086 to 0.01806, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 690ms/step - loss: 0.0237 - val_loss: 0.0181\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 5: val_loss improved from 0.01806 to 0.00867, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 680ms/step - loss: 0.0121 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00867 to 0.00553, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 683ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00553 to 0.00442, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 696ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00442 to 0.00387, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 688ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00387 to 0.00346, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 675ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00346 to 0.00312, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 707ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 89ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_744 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_372 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_745 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_373 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_746 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_374 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_747 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_248 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_748 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_249 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_749 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3014\n",
      "Epoch 1: val_loss improved from inf to 0.23519, saving model to best_weights.h5\n",
      "41/41 [==============================] - 30s 706ms/step - loss: 0.3014 - val_loss: 0.2352\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1177\n",
      "Epoch 2: val_loss improved from 0.23519 to 0.05223, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 697ms/step - loss: 0.1177 - val_loss: 0.0522\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0320\n",
      "Epoch 3: val_loss improved from 0.05223 to 0.02056, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 690ms/step - loss: 0.0320 - val_loss: 0.0206\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.02056 to 0.01200, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 702ms/step - loss: 0.0151 - val_loss: 0.0120\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.01200 to 0.00777, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 676ms/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00777 to 0.00576, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 675ms/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00576 to 0.00469, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 661ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00469 to 0.00405, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 650ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00405 to 0.00368, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 657ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00368 to 0.00342, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 675ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_750 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_375 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_751 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_376 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_752 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_377 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_753 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_250 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_754 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_251 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_755 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2586\n",
      "Epoch 1: val_loss improved from inf to 0.16432, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 689ms/step - loss: 0.2586 - val_loss: 0.1643\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0881\n",
      "Epoch 2: val_loss improved from 0.16432 to 0.05769, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 548ms/step - loss: 0.0881 - val_loss: 0.0577\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0410\n",
      "Epoch 3: val_loss improved from 0.05769 to 0.02947, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 677ms/step - loss: 0.0410 - val_loss: 0.0295\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 4: val_loss improved from 0.02947 to 0.01714, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 666ms/step - loss: 0.0216 - val_loss: 0.0171\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01714 to 0.01082, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 642ms/step - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01082 to 0.00696, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 625ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00696 to 0.00507, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 580ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00507 to 0.00417, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 626ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00417 to 0.00365, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 632ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00365 to 0.00327, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 629ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_756 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_378 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_757 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_379 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_758 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_380 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_759 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_252 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_760 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_253 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_761 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2288\n",
      "Epoch 1: val_loss improved from inf to 0.12885, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 597ms/step - loss: 0.2288 - val_loss: 0.1288\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0851\n",
      "Epoch 2: val_loss improved from 0.12885 to 0.06649, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 579ms/step - loss: 0.0851 - val_loss: 0.0665\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0490\n",
      "Epoch 3: val_loss improved from 0.06649 to 0.03571, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 531ms/step - loss: 0.0490 - val_loss: 0.0357\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0263\n",
      "Epoch 4: val_loss improved from 0.03571 to 0.02071, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 523ms/step - loss: 0.0263 - val_loss: 0.0207\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 5: val_loss improved from 0.02071 to 0.01175, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 596ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01175 to 0.00738, saving model to best_weights.h5\n",
      "41/41 [==============================] - 20s 493ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00738 to 0.00584, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 568ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00584 to 0.00483, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 609ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00483 to 0.00409, saving model to best_weights.h5\n",
      "41/41 [==============================] - 20s 497ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00409 to 0.00355, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 634ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 65ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_762 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_381 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_763 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_382 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_764 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_383 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_765 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_254 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_766 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_255 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_767 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2720\n",
      "Epoch 1: val_loss improved from inf to 0.15476, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 598ms/step - loss: 0.2720 - val_loss: 0.1548\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0661\n",
      "Epoch 2: val_loss improved from 0.15476 to 0.03488, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 589ms/step - loss: 0.0661 - val_loss: 0.0349\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0229\n",
      "Epoch 3: val_loss improved from 0.03488 to 0.01558, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 556ms/step - loss: 0.0229 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 4: val_loss improved from 0.01558 to 0.01069, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 716ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 5: val_loss improved from 0.01069 to 0.00778, saving model to best_weights.h5\n",
      "41/41 [==============================] - 31s 745ms/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00778 to 0.00572, saving model to best_weights.h5\n",
      "41/41 [==============================] - 30s 712ms/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00572 to 0.00459, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 664ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00459 to 0.00398, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 699ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00398 to 0.00356, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 652ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00356 to 0.00324, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 633ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_768 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_384 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_769 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_385 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_770 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_386 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_771 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_256 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_772 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_257 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_773 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.1699\n",
      "Epoch 1: val_loss improved from inf to 0.05231, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 647ms/step - loss: 0.1699 - val_loss: 0.0523\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0352\n",
      "Epoch 2: val_loss improved from 0.05231 to 0.02607, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 649ms/step - loss: 0.0352 - val_loss: 0.0261\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 3: val_loss improved from 0.02607 to 0.01558, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 645ms/step - loss: 0.0194 - val_loss: 0.0156\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 4: val_loss improved from 0.01558 to 0.01049, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 588ms/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 5: val_loss improved from 0.01049 to 0.00753, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 467ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00753 to 0.00569, saving model to best_weights.h5\n",
      "41/41 [==============================] - 20s 473ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00569 to 0.00459, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 453ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00459 to 0.00393, saving model to best_weights.h5\n",
      "41/41 [==============================] - 21s 511ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00393 to 0.00349, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 546ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00349 to 0.00317, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 576ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 79ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_774 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_387 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_775 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_388 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_776 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_389 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_777 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_258 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_778 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_259 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_779 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3690\n",
      "Epoch 1: val_loss improved from inf to 0.34170, saving model to best_weights.h5\n",
      "41/41 [==============================] - 28s 671ms/step - loss: 0.3690 - val_loss: 0.3417\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2712\n",
      "Epoch 2: val_loss improved from 0.34170 to 0.18654, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 628ms/step - loss: 0.2712 - val_loss: 0.1865\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0872\n",
      "Epoch 3: val_loss improved from 0.18654 to 0.04665, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 655ms/step - loss: 0.0872 - val_loss: 0.0466\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0305\n",
      "Epoch 4: val_loss improved from 0.04665 to 0.02130, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 659ms/step - loss: 0.0305 - val_loss: 0.0213\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 5: val_loss improved from 0.02130 to 0.01323, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 642ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 6: val_loss improved from 0.01323 to 0.00819, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 634ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00819 to 0.00562, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 646ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00562 to 0.00450, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 654ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00450 to 0.00397, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 671ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00397 to 0.00362, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 670ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 80ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_780 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_390 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_781 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_391 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_782 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_392 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_783 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_260 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_784 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_261 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_785 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2368\n",
      "Epoch 1: val_loss improved from inf to 0.11958, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 644ms/step - loss: 0.2368 - val_loss: 0.1196\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0626\n",
      "Epoch 2: val_loss improved from 0.11958 to 0.04408, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 638ms/step - loss: 0.0626 - val_loss: 0.0441\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0317\n",
      "Epoch 3: val_loss improved from 0.04408 to 0.02330, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 645ms/step - loss: 0.0317 - val_loss: 0.0233\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0175\n",
      "Epoch 4: val_loss improved from 0.02330 to 0.01447, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 637ms/step - loss: 0.0175 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 5: val_loss improved from 0.01447 to 0.01002, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 643ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.01002 to 0.00717, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 643ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00717 to 0.00531, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 650ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00531 to 0.00415, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 621ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00415 to 0.00348, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 568ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00348 to 0.00301, saving model to best_weights.h5\n",
      "41/41 [==============================] - 21s 519ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_786 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_393 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_787 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_394 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_788 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_395 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_789 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_262 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_790 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_263 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_791 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3013\n",
      "Epoch 1: val_loss improved from inf to 0.24595, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 606ms/step - loss: 0.3013 - val_loss: 0.2460\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1322\n",
      "Epoch 2: val_loss improved from 0.24595 to 0.06242, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 640ms/step - loss: 0.1322 - val_loss: 0.0624\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0409\n",
      "Epoch 3: val_loss improved from 0.06242 to 0.02400, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 602ms/step - loss: 0.0409 - val_loss: 0.0240\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 4: val_loss improved from 0.02400 to 0.01051, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 623ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01051 to 0.00695, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 587ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00695 to 0.00547, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 594ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00547 to 0.00448, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 627ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00448 to 0.00388, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 631ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00388 to 0.00341, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 624ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00341 to 0.00309, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 636ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 76ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_792 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_396 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_793 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_397 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_794 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_398 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_795 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_264 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_796 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_265 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_797 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3487\n",
      "Epoch 1: val_loss improved from inf to 0.34384, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 633ms/step - loss: 0.3487 - val_loss: 0.3438\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2943\n",
      "Epoch 2: val_loss improved from 0.34384 to 0.23965, saving model to best_weights.h5\n",
      "41/41 [==============================] - 25s 622ms/step - loss: 0.2943 - val_loss: 0.2396\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1204\n",
      "Epoch 3: val_loss improved from 0.23965 to 0.05392, saving model to best_weights.h5\n",
      "41/41 [==============================] - 26s 626ms/step - loss: 0.1204 - val_loss: 0.0539\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 4: val_loss improved from 0.05392 to 0.02208, saving model to best_weights.h5\n",
      "41/41 [==============================] - 29s 704ms/step - loss: 0.0330 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 5: val_loss improved from 0.02208 to 0.01219, saving model to best_weights.h5\n",
      "41/41 [==============================] - 27s 653ms/step - loss: 0.0159 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 6: val_loss improved from 0.01219 to 0.00801, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 540ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 7: val_loss improved from 0.00801 to 0.00657, saving model to best_weights.h5\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00657 to 0.00569, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 456ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00569 to 0.00499, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 460ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00499 to 0.00434, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 465ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 69ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_798 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_399 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_799 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_400 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_800 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_401 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_801 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_266 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_802 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_267 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_803 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2711\n",
      "Epoch 1: val_loss improved from inf to 0.15033, saving model to best_weights.h5\n",
      "41/41 [==============================] - 20s 478ms/step - loss: 0.2711 - val_loss: 0.1503\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0728\n",
      "Epoch 2: val_loss improved from 0.15033 to 0.04802, saving model to best_weights.h5\n",
      "41/41 [==============================] - 22s 539ms/step - loss: 0.0728 - val_loss: 0.0480\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 3: val_loss improved from 0.04802 to 0.02648, saving model to best_weights.h5\n",
      "41/41 [==============================] - 23s 551ms/step - loss: 0.0359 - val_loss: 0.0265\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 4: val_loss improved from 0.02648 to 0.01629, saving model to best_weights.h5\n",
      "41/41 [==============================] - 24s 581ms/step - loss: 0.0198 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss improved from 0.01629 to 0.01133, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 466ms/step - loss: 0.0130 - val_loss: 0.0113\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.01133 to 0.00827, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 456ms/step - loss: 0.0092 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00827 to 0.00652, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 432ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00652 to 0.00539, saving model to best_weights.h5\n",
      "41/41 [==============================] - 19s 459ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00539 to 0.00454, saving model to best_weights.h5\n",
      "41/41 [==============================] - 21s 510ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00454 to 0.00387, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 428ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_804 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_402 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_805 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_403 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_806 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_404 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_807 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_268 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_808 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_269 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_809 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3121\n",
      "Epoch 1: val_loss improved from inf to 0.24874, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 426ms/step - loss: 0.3121 - val_loss: 0.2487\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1267\n",
      "Epoch 2: val_loss improved from 0.24874 to 0.05901, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.1267 - val_loss: 0.0590\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0428\n",
      "Epoch 3: val_loss improved from 0.05901 to 0.03176, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0428 - val_loss: 0.0318\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0235\n",
      "Epoch 4: val_loss improved from 0.03176 to 0.01876, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 421ms/step - loss: 0.0235 - val_loss: 0.0188\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 5: val_loss improved from 0.01876 to 0.01218, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 420ms/step - loss: 0.0146 - val_loss: 0.0122\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01218 to 0.00840, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 421ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00840 to 0.00642, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00642 to 0.00505, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00505 to 0.00409, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00409 to 0.00357, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 421ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_810 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_405 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_811 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_406 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_812 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_407 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_813 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_270 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_814 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_271 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_815 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.1943\n",
      "Epoch 1: val_loss improved from inf to 0.09499, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 424ms/step - loss: 0.1943 - val_loss: 0.0950\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0584\n",
      "Epoch 2: val_loss improved from 0.09499 to 0.03937, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0584 - val_loss: 0.0394\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0266\n",
      "Epoch 3: val_loss improved from 0.03937 to 0.01991, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 415ms/step - loss: 0.0266 - val_loss: 0.0199\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 4: val_loss improved from 0.01991 to 0.01269, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0152 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01269 to 0.00864, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 424ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00864 to 0.00660, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 424ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00660 to 0.00552, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00552 to 0.00477, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00477 to 0.00420, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 421ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00420 to 0.00377, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_816 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_408 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_817 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_409 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_818 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_410 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_819 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_272 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_820 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_273 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_821 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3219\n",
      "Epoch 1: val_loss improved from inf to 0.25712, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 426ms/step - loss: 0.3219 - val_loss: 0.2571\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1512\n",
      "Epoch 2: val_loss improved from 0.25712 to 0.08573, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 414ms/step - loss: 0.1512 - val_loss: 0.0857\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0662\n",
      "Epoch 3: val_loss improved from 0.08573 to 0.05116, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0662 - val_loss: 0.0512\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0371\n",
      "Epoch 4: val_loss improved from 0.05116 to 0.02884, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 421ms/step - loss: 0.0371 - val_loss: 0.0288\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 5: val_loss improved from 0.02884 to 0.01798, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0222 - val_loss: 0.0180\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 6: val_loss improved from 0.01798 to 0.01090, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 7: val_loss improved from 0.01090 to 0.00752, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 8: val_loss improved from 0.00752 to 0.00564, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00564 to 0.00468, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00468 to 0.00415, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 420ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_822 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_411 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_823 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_412 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_824 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_413 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_825 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_274 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_826 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_275 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_827 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2598\n",
      "Epoch 1: val_loss improved from inf to 0.16073, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 423ms/step - loss: 0.2598 - val_loss: 0.1607\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0812\n",
      "Epoch 2: val_loss improved from 0.16073 to 0.04556, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0812 - val_loss: 0.0456\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 3: val_loss improved from 0.04556 to 0.01754, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0276 - val_loss: 0.0175\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 4: val_loss improved from 0.01754 to 0.01072, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 430ms/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01072 to 0.00803, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00803 to 0.00648, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00648 to 0.00534, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00534 to 0.00455, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 420ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00455 to 0.00398, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00398 to 0.00361, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_828 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_414 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_829 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_415 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_830 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_416 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_831 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_276 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_832 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_277 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_833 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3152\n",
      "Epoch 1: val_loss improved from inf to 0.25055, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 436ms/step - loss: 0.3152 - val_loss: 0.2506\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1376\n",
      "Epoch 2: val_loss improved from 0.25055 to 0.07501, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 431ms/step - loss: 0.1376 - val_loss: 0.0750\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0567\n",
      "Epoch 3: val_loss improved from 0.07501 to 0.04324, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 430ms/step - loss: 0.0567 - val_loss: 0.0432\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 4: val_loss improved from 0.04324 to 0.02471, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 426ms/step - loss: 0.0316 - val_loss: 0.0247\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 5: val_loss improved from 0.02471 to 0.01482, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 429ms/step - loss: 0.0186 - val_loss: 0.0148\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 6: val_loss improved from 0.01482 to 0.00914, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 420ms/step - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00914 to 0.00603, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 422ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00603 to 0.00479, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00479 to 0.00414, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 423ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00414 to 0.00368, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_834 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_417 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_835 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_418 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_836 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_419 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_837 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_278 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_838 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_279 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_839 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3053\n",
      "Epoch 1: val_loss improved from inf to 0.24250, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 426ms/step - loss: 0.3053 - val_loss: 0.2425\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1336\n",
      "Epoch 2: val_loss improved from 0.24250 to 0.04950, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 425ms/step - loss: 0.1336 - val_loss: 0.0495\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0339\n",
      "Epoch 3: val_loss improved from 0.04950 to 0.02120, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 416ms/step - loss: 0.0339 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 4: val_loss improved from 0.02120 to 0.01330, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0160 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 5: val_loss improved from 0.01330 to 0.00864, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00864 to 0.00606, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 416ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00606 to 0.00482, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00482 to 0.00414, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00414 to 0.00364, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00364 to 0.00328, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 415ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_840 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_420 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_841 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_421 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_842 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_422 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_843 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_280 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_844 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_281 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_845 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2389\n",
      "Epoch 1: val_loss improved from inf to 0.12942, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 424ms/step - loss: 0.2389 - val_loss: 0.1294\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0565\n",
      "Epoch 2: val_loss improved from 0.12942 to 0.03593, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 415ms/step - loss: 0.0565 - val_loss: 0.0359\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0279\n",
      "Epoch 3: val_loss improved from 0.03593 to 0.02228, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0279 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0179\n",
      "Epoch 4: val_loss improved from 0.02228 to 0.01539, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 415ms/step - loss: 0.0179 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01539 to 0.01051, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 416ms/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01051 to 0.00797, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 7: val_loss improved from 0.00797 to 0.00605, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 423ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00605 to 0.00485, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 416ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00485 to 0.00408, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 416ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00408 to 0.00362, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 416ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_846 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_423 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_847 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_424 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_848 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_425 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_849 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_282 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_850 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_283 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_851 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2522\n",
      "Epoch 1: val_loss improved from inf to 0.15406, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 422ms/step - loss: 0.2522 - val_loss: 0.1541\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0865\n",
      "Epoch 2: val_loss improved from 0.15406 to 0.06139, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 419ms/step - loss: 0.0865 - val_loss: 0.0614\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0420\n",
      "Epoch 3: val_loss improved from 0.06139 to 0.02841, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 414ms/step - loss: 0.0420 - val_loss: 0.0284\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 4: val_loss improved from 0.02841 to 0.01738, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 413ms/step - loss: 0.0216 - val_loss: 0.0174\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 5: val_loss improved from 0.01738 to 0.01112, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01112 to 0.00754, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00754 to 0.00552, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 425ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00552 to 0.00445, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 421ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00445 to 0.00384, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00384 to 0.00341, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 422ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_852 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_426 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_853 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_427 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_854 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_428 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_855 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_284 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_856 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_285 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_857 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2892\n",
      "Epoch 1: val_loss improved from inf to 0.21061, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 424ms/step - loss: 0.2892 - val_loss: 0.2106\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1068\n",
      "Epoch 2: val_loss improved from 0.21061 to 0.06525, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 416ms/step - loss: 0.1068 - val_loss: 0.0652\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0460\n",
      "Epoch 3: val_loss improved from 0.06525 to 0.03113, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 413ms/step - loss: 0.0460 - val_loss: 0.0311\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 4: val_loss improved from 0.03113 to 0.01772, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 423ms/step - loss: 0.0226 - val_loss: 0.0177\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 5: val_loss improved from 0.01772 to 0.01099, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01099 to 0.00780, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 425ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00780 to 0.00597, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 422ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00597 to 0.00483, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 414ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00483 to 0.00406, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 398ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00406 to 0.00356, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 396ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_858 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_429 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_859 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_430 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_860 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_431 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_861 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_286 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_862 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_287 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_863 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.1434\n",
      "Epoch 1: val_loss improved from inf to 0.04503, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 411ms/step - loss: 0.1434 - val_loss: 0.0450\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0318\n",
      "Epoch 2: val_loss improved from 0.04503 to 0.02201, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 398ms/step - loss: 0.0318 - val_loss: 0.0220\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 3: val_loss improved from 0.02201 to 0.01339, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0163 - val_loss: 0.0134\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 4: val_loss improved from 0.01339 to 0.00944, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 397ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00944 to 0.00707, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 401ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00707 to 0.00549, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 394ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00549 to 0.00450, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 394ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00450 to 0.00391, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 396ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00391 to 0.00353, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 397ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00353 to 0.00327, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 56ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_864 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_432 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_865 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_433 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_866 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_434 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_867 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_288 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_868 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_289 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_869 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.2421\n",
      "Epoch 1: val_loss improved from inf to 0.11891, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 414ms/step - loss: 0.2421 - val_loss: 0.1189\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0620\n",
      "Epoch 2: val_loss improved from 0.11891 to 0.04367, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 403ms/step - loss: 0.0620 - val_loss: 0.0437\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0327\n",
      "Epoch 3: val_loss improved from 0.04367 to 0.02518, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0327 - val_loss: 0.0252\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0192\n",
      "Epoch 4: val_loss improved from 0.02518 to 0.01545, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 392ms/step - loss: 0.0192 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01545 to 0.00988, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 398ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00988 to 0.00687, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0079 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00687 to 0.00503, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 395ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00503 to 0.00400, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 392ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00400 to 0.00347, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 398ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00347 to 0.00314, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_870 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_435 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_871 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_436 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_872 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_437 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_873 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_290 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_874 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_291 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_875 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3033\n",
      "Epoch 1: val_loss improved from inf to 0.19774, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 425ms/step - loss: 0.3033 - val_loss: 0.1977\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1006\n",
      "Epoch 2: val_loss improved from 0.19774 to 0.05593, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 392ms/step - loss: 0.1006 - val_loss: 0.0559\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0396\n",
      "Epoch 3: val_loss improved from 0.05593 to 0.02892, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 402ms/step - loss: 0.0396 - val_loss: 0.0289\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 4: val_loss improved from 0.02892 to 0.01580, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 392ms/step - loss: 0.0209 - val_loss: 0.0158\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01580 to 0.00994, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 392ms/step - loss: 0.0120 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.00994 to 0.00696, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 397ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00696 to 0.00524, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 398ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00524 to 0.00427, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 392ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00427 to 0.00373, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 391ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00373 to 0.00342, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_876 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_438 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_877 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_439 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_878 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_440 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_879 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_292 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_880 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_293 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_881 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/41 [============================>.] - ETA: 0s - loss: 0.2338\n",
      "Epoch 1: val_loss improved from inf to 0.11676, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 414ms/step - loss: 0.2335 - val_loss: 0.1168\n",
      "Epoch 2/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0658\n",
      "Epoch 2: val_loss improved from 0.11676 to 0.04999, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0658 - val_loss: 0.0500\n",
      "Epoch 3/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0379\n",
      "Epoch 3: val_loss improved from 0.04999 to 0.02799, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0379 - val_loss: 0.0280\n",
      "Epoch 4/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02799 to 0.01415, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 402ms/step - loss: 0.0194 - val_loss: 0.0142\n",
      "Epoch 5/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01415 to 0.00795, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0102 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00795 to 0.00543, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 391ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00543 to 0.00423, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 8/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00423 to 0.00365, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00365 to 0.00330, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00330 to 0.00300, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 391ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_882 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_441 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_883 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_442 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_884 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_443 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_885 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_294 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_886 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_295 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_887 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/41 [============================>.] - ETA: 0s - loss: 0.3710\n",
      "Epoch 1: val_loss improved from inf to 0.27085, saving model to best_weights.h5\n",
      "41/41 [==============================] - 18s 426ms/step - loss: 0.3708 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.1554\n",
      "Epoch 2: val_loss improved from 0.27085 to 0.06016, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 395ms/step - loss: 0.1553 - val_loss: 0.0602\n",
      "Epoch 3/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0474\n",
      "Epoch 3: val_loss improved from 0.06016 to 0.03546, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 394ms/step - loss: 0.0474 - val_loss: 0.0355\n",
      "Epoch 4/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0253\n",
      "Epoch 4: val_loss improved from 0.03546 to 0.01865, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 403ms/step - loss: 0.0253 - val_loss: 0.0187\n",
      "Epoch 5/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0147\n",
      "Epoch 5: val_loss improved from 0.01865 to 0.01295, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 407ms/step - loss: 0.0147 - val_loss: 0.0130\n",
      "Epoch 6/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0109\n",
      "Epoch 6: val_loss improved from 0.01295 to 0.01012, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 407ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0087\n",
      "Epoch 7: val_loss improved from 0.01012 to 0.00827, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 404ms/step - loss: 0.0087 - val_loss: 0.0083\n",
      "Epoch 8/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0072\n",
      "Epoch 8: val_loss improved from 0.00827 to 0.00690, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 403ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 9: val_loss improved from 0.00690 to 0.00573, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0050\n",
      "Epoch 10: val_loss improved from 0.00573 to 0.00488, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 402ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_888 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_444 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_889 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_445 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_890 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_446 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_891 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_296 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_892 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_297 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_893 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/41 [============================>.] - ETA: 0s - loss: 0.3696\n",
      "Epoch 1: val_loss improved from inf to 0.34615, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 408ms/step - loss: 0.3695 - val_loss: 0.3462\n",
      "Epoch 2/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.2926\n",
      "Epoch 2: val_loss improved from 0.34615 to 0.22412, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 401ms/step - loss: 0.2925 - val_loss: 0.2241\n",
      "Epoch 3/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.1088\n",
      "Epoch 3: val_loss improved from 0.22412 to 0.06273, saving model to best_weights.h5\n",
      "41/41 [==============================] - 17s 404ms/step - loss: 0.1088 - val_loss: 0.0627\n",
      "Epoch 4/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0474\n",
      "Epoch 4: val_loss improved from 0.06273 to 0.03597, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 0.0474 - val_loss: 0.0360\n",
      "Epoch 5/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0257\n",
      "Epoch 5: val_loss improved from 0.03597 to 0.01976, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 395ms/step - loss: 0.0257 - val_loss: 0.0198\n",
      "Epoch 6/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0148\n",
      "Epoch 6: val_loss improved from 0.01976 to 0.01175, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 7/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0093\n",
      "Epoch 7: val_loss improved from 0.01175 to 0.00803, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 394ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0064\n",
      "Epoch 8: val_loss improved from 0.00803 to 0.00563, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 394ms/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00563 to 0.00444, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 400ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00444 to 0.00382, saving model to best_weights.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_894 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_447 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_895 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_448 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_896 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_449 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_897 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_298 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_898 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_299 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_899 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2838\n",
      "Epoch 1: val_loss improved from inf to 0.19307, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 419ms/step - loss: 0.2838 - val_loss: 0.1931\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0872\n",
      "Epoch 2: val_loss improved from 0.19307 to 0.04548, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0872 - val_loss: 0.0455\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0305\n",
      "Epoch 3: val_loss improved from 0.04548 to 0.02103, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 412ms/step - loss: 0.0305 - val_loss: 0.0210\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss improved from 0.02103 to 0.01261, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0154 - val_loss: 0.0126\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01261 to 0.00860, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00860 to 0.00666, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00666 to 0.00534, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 415ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00534 to 0.00436, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00436 to 0.00373, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00373 to 0.00334, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 412ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_900 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_450 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_901 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_451 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_902 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_452 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_903 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_300 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_904 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_301 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_905 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3515\n",
      "Epoch 1: val_loss improved from inf to 0.32386, saving model to best_weights.h5\n",
      "40/40 [==============================] - 18s 431ms/step - loss: 0.3515 - val_loss: 0.3239\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2275\n",
      "Epoch 2: val_loss improved from 0.32386 to 0.10582, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.2275 - val_loss: 0.1058\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0571\n",
      "Epoch 3: val_loss improved from 0.10582 to 0.03898, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0571 - val_loss: 0.0390\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 4: val_loss improved from 0.03898 to 0.02395, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 415ms/step - loss: 0.0292 - val_loss: 0.0240\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0189\n",
      "Epoch 5: val_loss improved from 0.02395 to 0.01591, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0189 - val_loss: 0.0159\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 6: val_loss improved from 0.01591 to 0.01095, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 7: val_loss improved from 0.01095 to 0.00736, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0087 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00736 to 0.00516, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00516 to 0.00421, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00421 to 0.00371, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_906 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_453 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_907 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_454 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_908 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_455 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_909 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_302 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_910 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_303 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_911 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3239\n",
      "Epoch 1: val_loss improved from inf to 0.27960, saving model to best_weights.h5\n",
      "40/40 [==============================] - 18s 431ms/step - loss: 0.3239 - val_loss: 0.2796\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1675\n",
      "Epoch 2: val_loss improved from 0.27960 to 0.07510, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.1675 - val_loss: 0.0751\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0546\n",
      "Epoch 3: val_loss improved from 0.07510 to 0.03716, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0546 - val_loss: 0.0372\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0245\n",
      "Epoch 4: val_loss improved from 0.03716 to 0.01758, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0245 - val_loss: 0.0176\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.01758 to 0.01141, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 414ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.01141 to 0.00820, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 7: val_loss improved from 0.00820 to 0.00643, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00643 to 0.00538, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00538 to 0.00459, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 413ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00459 to 0.00404, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_912 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_456 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_913 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_457 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_914 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_458 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_915 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_304 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_916 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_305 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_917 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2394\n",
      "Epoch 1: val_loss improved from inf to 0.11024, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 416ms/step - loss: 0.2394 - val_loss: 0.1102\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0485\n",
      "Epoch 2: val_loss improved from 0.11024 to 0.03099, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0485 - val_loss: 0.0310\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 3: val_loss improved from 0.03099 to 0.01660, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0222 - val_loss: 0.0166\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 4: val_loss improved from 0.01660 to 0.01059, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0126 - val_loss: 0.0106\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 5: val_loss improved from 0.01059 to 0.00774, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 413ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 6: val_loss improved from 0.00774 to 0.00613, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00613 to 0.00518, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00518 to 0.00451, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00451 to 0.00402, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00402 to 0.00365, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_918 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_459 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_919 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_460 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_920 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_461 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_921 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_306 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_922 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_307 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_923 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2784\n",
      "Epoch 1: val_loss improved from inf to 0.19269, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 418ms/step - loss: 0.2784 - val_loss: 0.1927\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1015\n",
      "Epoch 2: val_loss improved from 0.19269 to 0.06947, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.1015 - val_loss: 0.0695\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0537\n",
      "Epoch 3: val_loss improved from 0.06947 to 0.04199, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 419ms/step - loss: 0.0537 - val_loss: 0.0420\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0310\n",
      "Epoch 4: val_loss improved from 0.04199 to 0.02430, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0310 - val_loss: 0.0243\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 5: val_loss improved from 0.02430 to 0.01344, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0178 - val_loss: 0.0134\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01344 to 0.00793, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00793 to 0.00590, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00590 to 0.00486, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00486 to 0.00411, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00411 to 0.00360, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_924 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_462 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_925 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_463 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_926 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_464 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_927 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_308 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_928 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_309 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_929 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3145\n",
      "Epoch 1: val_loss improved from inf to 0.26008, saving model to best_weights.h5\n",
      "40/40 [==============================] - 18s 434ms/step - loss: 0.3145 - val_loss: 0.2601\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1251\n",
      "Epoch 2: val_loss improved from 0.26008 to 0.05122, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 419ms/step - loss: 0.1251 - val_loss: 0.0512\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0361\n",
      "Epoch 3: val_loss improved from 0.05122 to 0.02771, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 413ms/step - loss: 0.0361 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 4: val_loss improved from 0.02771 to 0.01711, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0208 - val_loss: 0.0171\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 5: val_loss improved from 0.01711 to 0.01229, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 6: val_loss improved from 0.01229 to 0.00945, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 7: val_loss improved from 0.00945 to 0.00763, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 8: val_loss improved from 0.00763 to 0.00630, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 9: val_loss improved from 0.00630 to 0.00525, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00525 to 0.00447, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_930 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_465 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_931 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_466 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_932 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_467 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_933 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_310 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_934 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_311 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_935 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.1651\n",
      "Epoch 1: val_loss improved from inf to 0.06831, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 415ms/step - loss: 0.1651 - val_loss: 0.0683\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0465\n",
      "Epoch 2: val_loss improved from 0.06831 to 0.03451, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0465 - val_loss: 0.0345\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0231\n",
      "Epoch 3: val_loss improved from 0.03451 to 0.01700, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0231 - val_loss: 0.0170\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0128\n",
      "Epoch 4: val_loss improved from 0.01700 to 0.01051, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.01051 to 0.00720, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 412ms/step - loss: 0.0083 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00720 to 0.00541, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 7: val_loss improved from 0.00541 to 0.00428, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 8: val_loss improved from 0.00428 to 0.00363, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 9: val_loss improved from 0.00363 to 0.00326, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00326 to 0.00300, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_936 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_468 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_937 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_469 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_938 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_470 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_939 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_312 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_940 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_313 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_941 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2829\n",
      "Epoch 1: val_loss improved from inf to 0.21218, saving model to best_weights.h5\n",
      "40/40 [==============================] - 18s 434ms/step - loss: 0.2829 - val_loss: 0.2122\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1118\n",
      "Epoch 2: val_loss improved from 0.21218 to 0.06673, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.1118 - val_loss: 0.0667\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0517\n",
      "Epoch 3: val_loss improved from 0.06673 to 0.04180, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0517 - val_loss: 0.0418\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0313\n",
      "Epoch 4: val_loss improved from 0.04180 to 0.02417, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0313 - val_loss: 0.0242\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 5: val_loss improved from 0.02417 to 0.01452, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0180 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 6: val_loss improved from 0.01452 to 0.00880, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0111 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00880 to 0.00573, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00573 to 0.00445, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00445 to 0.00383, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00383 to 0.00344, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_942 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_471 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_943 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_472 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_944 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_473 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_945 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_314 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_946 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_315 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_947 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2638\n",
      "Epoch 1: val_loss improved from inf to 0.14413, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 421ms/step - loss: 0.2638 - val_loss: 0.1441\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0686\n",
      "Epoch 2: val_loss improved from 0.14413 to 0.04490, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0686 - val_loss: 0.0449\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 3: val_loss improved from 0.04490 to 0.02503, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0328 - val_loss: 0.0250\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02503 to 0.01557, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0191 - val_loss: 0.0156\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 5: val_loss improved from 0.01557 to 0.01027, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0121 - val_loss: 0.0103\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01027 to 0.00756, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00756 to 0.00609, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00609 to 0.00518, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00518 to 0.00452, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00452 to 0.00407, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_948 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_474 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_949 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_475 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_950 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_476 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_951 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_316 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_952 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_317 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_953 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2610\n",
      "Epoch 1: val_loss improved from inf to 0.15171, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 421ms/step - loss: 0.2610 - val_loss: 0.1517\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0802\n",
      "Epoch 2: val_loss improved from 0.15171 to 0.05706, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0802 - val_loss: 0.0571\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0401\n",
      "Epoch 3: val_loss improved from 0.05706 to 0.02607, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 415ms/step - loss: 0.0401 - val_loss: 0.0261\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 4: val_loss improved from 0.02607 to 0.01551, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 428ms/step - loss: 0.0194 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 5: val_loss improved from 0.01551 to 0.00865, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0113 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00865 to 0.00608, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 412ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00608 to 0.00504, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00504 to 0.00424, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00424 to 0.00367, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00367 to 0.00330, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_954 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_477 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_955 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_478 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_956 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_479 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_957 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_318 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_958 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_319 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_959 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2502\n",
      "Epoch 1: val_loss improved from inf to 0.16767, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 421ms/step - loss: 0.2502 - val_loss: 0.1677\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0879\n",
      "Epoch 2: val_loss improved from 0.16767 to 0.05215, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0879 - val_loss: 0.0522\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0321\n",
      "Epoch 3: val_loss improved from 0.05215 to 0.01970, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0321 - val_loss: 0.0197\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 4: val_loss improved from 0.01970 to 0.01237, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01237 to 0.00866, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 418ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00866 to 0.00647, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00647 to 0.00509, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00509 to 0.00424, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00424 to 0.00371, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00371 to 0.00333, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_960 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_480 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_961 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_481 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_962 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_482 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_963 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_320 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_964 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_321 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_965 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3421\n",
      "Epoch 1: val_loss improved from inf to 0.32619, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 413ms/step - loss: 0.3421 - val_loss: 0.3262\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2501\n",
      "Epoch 2: val_loss improved from 0.32619 to 0.15134, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 417ms/step - loss: 0.2501 - val_loss: 0.1513\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0685\n",
      "Epoch 3: val_loss improved from 0.15134 to 0.04010, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0685 - val_loss: 0.0401\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0264\n",
      "Epoch 4: val_loss improved from 0.04010 to 0.01901, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0264 - val_loss: 0.0190\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 5: val_loss improved from 0.01901 to 0.01285, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0150 - val_loss: 0.0128\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 6: val_loss improved from 0.01285 to 0.00888, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 7: val_loss improved from 0.00888 to 0.00655, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 396ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00655 to 0.00508, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00508 to 0.00421, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00421 to 0.00366, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 51ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_966 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_483 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_967 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_484 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_968 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_485 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_969 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_322 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_970 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_323 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_971 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2609\n",
      "Epoch 1: val_loss improved from inf to 0.14925, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 408ms/step - loss: 0.2609 - val_loss: 0.1493\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0700\n",
      "Epoch 2: val_loss improved from 0.14925 to 0.04277, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 396ms/step - loss: 0.0700 - val_loss: 0.0428\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 3: val_loss improved from 0.04277 to 0.02530, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0311 - val_loss: 0.0253\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 4: val_loss improved from 0.02530 to 0.01715, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0202 - val_loss: 0.0172\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01715 to 0.01101, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01101 to 0.00768, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00768 to 0.00556, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00556 to 0.00436, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00436 to 0.00363, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 394ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00363 to 0.00318, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_972 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_486 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_973 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_487 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_974 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_488 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_975 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_324 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_976 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_325 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_977 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2022\n",
      "Epoch 1: val_loss improved from inf to 0.08871, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 421ms/step - loss: 0.2022 - val_loss: 0.0887\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0556\n",
      "Epoch 2: val_loss improved from 0.08871 to 0.04322, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0556 - val_loss: 0.0432\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0325\n",
      "Epoch 3: val_loss improved from 0.04322 to 0.02514, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0325 - val_loss: 0.0251\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 4: val_loss improved from 0.02514 to 0.01467, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0186 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 5: val_loss improved from 0.01467 to 0.00898, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0110 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 6: val_loss improved from 0.00898 to 0.00640, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00640 to 0.00508, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00508 to 0.00423, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00423 to 0.00373, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00373 to 0.00340, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_978 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_489 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_979 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_490 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_980 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_491 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_981 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_326 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_982 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_327 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_983 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2407\n",
      "Epoch 1: val_loss improved from inf to 0.13280, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 417ms/step - loss: 0.2407 - val_loss: 0.1328\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0684\n",
      "Epoch 2: val_loss improved from 0.13280 to 0.04610, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 415ms/step - loss: 0.0684 - val_loss: 0.0461\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0318\n",
      "Epoch 3: val_loss improved from 0.04610 to 0.02092, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 414ms/step - loss: 0.0318 - val_loss: 0.0209\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 4: val_loss improved from 0.02092 to 0.01033, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 5: val_loss improved from 0.01033 to 0.00734, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 413ms/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00734 to 0.00578, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 421ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00578 to 0.00477, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00477 to 0.00413, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00413 to 0.00371, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00371 to 0.00337, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_984 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_492 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_985 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_493 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_986 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_494 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_987 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_328 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_988 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_329 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_989 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2711\n",
      "Epoch 1: val_loss improved from inf to 0.20692, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 418ms/step - loss: 0.2711 - val_loss: 0.2069\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1260\n",
      "Epoch 2: val_loss improved from 0.20692 to 0.09060, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.1260 - val_loss: 0.0906\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0675\n",
      "Epoch 3: val_loss improved from 0.09060 to 0.04800, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0675 - val_loss: 0.0480\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0332\n",
      "Epoch 4: val_loss improved from 0.04800 to 0.02479, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0332 - val_loss: 0.0248\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 5: val_loss improved from 0.02479 to 0.01381, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0181 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 6: val_loss improved from 0.01381 to 0.00885, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0107 - val_loss: 0.0089\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00885 to 0.00625, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00625 to 0.00487, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 396ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00487 to 0.00402, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00402 to 0.00348, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_990 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_495 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_991 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_496 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_992 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_497 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_993 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_330 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_994 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_331 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_995 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3089\n",
      "Epoch 1: val_loss improved from inf to 0.25771, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 422ms/step - loss: 0.3089 - val_loss: 0.2577\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1300\n",
      "Epoch 2: val_loss improved from 0.25771 to 0.05281, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.1300 - val_loss: 0.0528\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0387\n",
      "Epoch 3: val_loss improved from 0.05281 to 0.02937, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0387 - val_loss: 0.0294\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0223\n",
      "Epoch 4: val_loss improved from 0.02937 to 0.01885, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0223 - val_loss: 0.0188\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 5: val_loss improved from 0.01885 to 0.01236, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0149 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01236 to 0.00833, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0096 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 7: val_loss improved from 0.00833 to 0.00651, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00651 to 0.00533, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00533 to 0.00439, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00439 to 0.00369, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_996 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_498 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_997 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_499 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_998 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_500 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_999 (Conv2D)         (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_332 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1000 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_333 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1001 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3027\n",
      "Epoch 1: val_loss improved from inf to 0.23409, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 417ms/step - loss: 0.3027 - val_loss: 0.2341\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1189\n",
      "Epoch 2: val_loss improved from 0.23409 to 0.05375, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.1189 - val_loss: 0.0537\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0360\n",
      "Epoch 3: val_loss improved from 0.05375 to 0.02440, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0360 - val_loss: 0.0244\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 4: val_loss improved from 0.02440 to 0.01472, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0180 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 5: val_loss improved from 0.01472 to 0.00998, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.00998 to 0.00703, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00703 to 0.00520, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00520 to 0.00430, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00430 to 0.00386, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00386 to 0.00358, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1002 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_501 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1003 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_502 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1004 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_503 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1005 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_334 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1006 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_335 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1007 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2260\n",
      "Epoch 1: val_loss improved from inf to 0.11471, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 416ms/step - loss: 0.2260 - val_loss: 0.1147\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0713\n",
      "Epoch 2: val_loss improved from 0.11471 to 0.05375, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0713 - val_loss: 0.0537\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0383\n",
      "Epoch 3: val_loss improved from 0.05375 to 0.02660, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0383 - val_loss: 0.0266\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 4: val_loss improved from 0.02660 to 0.01498, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0193 - val_loss: 0.0150\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01498 to 0.00897, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0112 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00897 to 0.00598, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00598 to 0.00449, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 413ms/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00449 to 0.00376, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00376 to 0.00331, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00331 to 0.00299, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1008 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_504 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1009 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_505 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1010 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_506 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1011 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_336 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1012 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_337 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1013 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3250\n",
      "Epoch 1: val_loss improved from inf to 0.27199, saving model to best_weights.h5\n",
      "40/40 [==============================] - 18s 433ms/step - loss: 0.3250 - val_loss: 0.2720\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1422\n",
      "Epoch 2: val_loss improved from 0.27199 to 0.06704, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.1422 - val_loss: 0.0670\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0454\n",
      "Epoch 3: val_loss improved from 0.06704 to 0.02671, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0454 - val_loss: 0.0267\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 4: val_loss improved from 0.02671 to 0.01330, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0174 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01330 to 0.00920, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00920 to 0.00712, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00712 to 0.00573, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00573 to 0.00486, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00486 to 0.00414, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00414 to 0.00359, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1014 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_507 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1015 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_508 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1016 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_509 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1017 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_338 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1018 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_339 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1019 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2189\n",
      "Epoch 1: val_loss improved from inf to 0.12100, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 421ms/step - loss: 0.2189 - val_loss: 0.1210\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0809\n",
      "Epoch 2: val_loss improved from 0.12100 to 0.06162, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0809 - val_loss: 0.0616\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 3: val_loss improved from 0.06162 to 0.02840, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0419 - val_loss: 0.0284\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 4: val_loss improved from 0.02840 to 0.01942, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0225 - val_loss: 0.0194\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 5: val_loss improved from 0.01942 to 0.01383, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 412ms/step - loss: 0.0158 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 6: val_loss improved from 0.01383 to 0.01011, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 7: val_loss improved from 0.01011 to 0.00763, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 8: val_loss improved from 0.00763 to 0.00572, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00572 to 0.00453, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00453 to 0.00385, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1020 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_510 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1021 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_511 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1022 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_512 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1023 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_340 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1024 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_341 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1025 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2994\n",
      "Epoch 1: val_loss improved from inf to 0.20418, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 428ms/step - loss: 0.2994 - val_loss: 0.2042\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1015\n",
      "Epoch 2: val_loss improved from 0.20418 to 0.05587, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.1015 - val_loss: 0.0559\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0391\n",
      "Epoch 3: val_loss improved from 0.05587 to 0.02854, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0391 - val_loss: 0.0285\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0204\n",
      "Epoch 4: val_loss improved from 0.02854 to 0.01536, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0204 - val_loss: 0.0154\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01536 to 0.00943, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 6: val_loss improved from 0.00943 to 0.00674, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00674 to 0.00523, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00523 to 0.00426, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00426 to 0.00370, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00370 to 0.00332, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1026 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_513 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1027 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_514 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1028 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_515 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1029 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_342 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1030 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_343 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1031 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3264\n",
      "Epoch 1: val_loss improved from inf to 0.27015, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 426ms/step - loss: 0.3264 - val_loss: 0.2701\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1369\n",
      "Epoch 2: val_loss improved from 0.27015 to 0.04270, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.1369 - val_loss: 0.0427\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0304\n",
      "Epoch 3: val_loss improved from 0.04270 to 0.02084, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 414ms/step - loss: 0.0304 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss improved from 0.02084 to 0.01272, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0159 - val_loss: 0.0127\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 5: val_loss improved from 0.01272 to 0.00793, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00793 to 0.00561, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00561 to 0.00437, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00437 to 0.00373, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00373 to 0.00336, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00336 to 0.00309, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1032 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_516 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1033 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_517 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1034 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_518 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1035 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_344 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1036 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_345 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1037 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2665\n",
      "Epoch 1: val_loss improved from inf to 0.16396, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 428ms/step - loss: 0.2665 - val_loss: 0.1640\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0901\n",
      "Epoch 2: val_loss improved from 0.16396 to 0.05740, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0901 - val_loss: 0.0574\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0383\n",
      "Epoch 3: val_loss improved from 0.05740 to 0.02588, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 417ms/step - loss: 0.0383 - val_loss: 0.0259\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 4: val_loss improved from 0.02588 to 0.01415, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 415ms/step - loss: 0.0186 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01415 to 0.00896, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00896 to 0.00667, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00667 to 0.00526, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00526 to 0.00445, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00445 to 0.00392, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00392 to 0.00354, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1038 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_519 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1039 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_520 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1040 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_521 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1041 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_346 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1042 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_347 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1043 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2862\n",
      "Epoch 1: val_loss improved from inf to 0.21276, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 425ms/step - loss: 0.2862 - val_loss: 0.2128\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1116\n",
      "Epoch 2: val_loss improved from 0.21276 to 0.06402, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.1116 - val_loss: 0.0640\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0453\n",
      "Epoch 3: val_loss improved from 0.06402 to 0.03134, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0453 - val_loss: 0.0313\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 4: val_loss improved from 0.03134 to 0.01451, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 415ms/step - loss: 0.0214 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01451 to 0.00784, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0102 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00784 to 0.00566, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00566 to 0.00468, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00468 to 0.00408, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00408 to 0.00366, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00366 to 0.00333, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1044 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_522 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1045 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_523 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1046 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_524 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1047 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_348 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1048 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_349 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1049 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3542\n",
      "Epoch 1: val_loss improved from inf to 0.32389, saving model to best_weights.h5\n",
      "40/40 [==============================] - 18s 430ms/step - loss: 0.3542 - val_loss: 0.3239\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2223\n",
      "Epoch 2: val_loss improved from 0.32389 to 0.10344, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.2223 - val_loss: 0.1034\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0591\n",
      "Epoch 3: val_loss improved from 0.10344 to 0.04253, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0591 - val_loss: 0.0425\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0289\n",
      "Epoch 4: val_loss improved from 0.04253 to 0.02018, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0289 - val_loss: 0.0202\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 5: val_loss improved from 0.02018 to 0.01403, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0161 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 6: val_loss improved from 0.01403 to 0.01026, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 7: val_loss improved from 0.01026 to 0.00795, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 8: val_loss improved from 0.00795 to 0.00655, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 9: val_loss improved from 0.00655 to 0.00548, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 10: val_loss improved from 0.00548 to 0.00467, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1050 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_525 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1051 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_526 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1052 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_527 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1053 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_350 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1054 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_351 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1055 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.3154\n",
      "Epoch 1: val_loss improved from inf to 0.24623, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 416ms/step - loss: 0.3154 - val_loss: 0.2462\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1330\n",
      "Epoch 2: val_loss improved from 0.24623 to 0.07395, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 418ms/step - loss: 0.1330 - val_loss: 0.0739\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0555\n",
      "Epoch 3: val_loss improved from 0.07395 to 0.04164, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0555 - val_loss: 0.0416\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 4: val_loss improved from 0.04164 to 0.02383, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0300 - val_loss: 0.0238\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 5: val_loss improved from 0.02383 to 0.01575, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0188 - val_loss: 0.0158\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 6: val_loss improved from 0.01575 to 0.01024, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 7: val_loss improved from 0.01024 to 0.00693, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 396ms/step - loss: 0.0080 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00693 to 0.00526, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00526 to 0.00457, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00457 to 0.00417, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1056 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_528 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1057 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_529 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1058 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_530 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1059 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_352 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1060 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_353 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1061 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2530\n",
      "Epoch 1: val_loss improved from inf to 0.13700, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 417ms/step - loss: 0.2530 - val_loss: 0.1370\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0632\n",
      "Epoch 2: val_loss improved from 0.13700 to 0.03895, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0632 - val_loss: 0.0389\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 3: val_loss improved from 0.03895 to 0.02124, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0286 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02124 to 0.01296, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0158 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01296 to 0.00964, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.00964 to 0.00747, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00747 to 0.00589, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00589 to 0.00476, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00476 to 0.00404, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00404 to 0.00352, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1062 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_531 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1063 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_532 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1064 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_533 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1065 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_354 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1066 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_355 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1067 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.2778\n",
      "Epoch 1: val_loss improved from inf to 0.19338, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 416ms/step - loss: 0.2778 - val_loss: 0.1934\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0959\n",
      "Epoch 2: val_loss improved from 0.19338 to 0.05397, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0959 - val_loss: 0.0540\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0357\n",
      "Epoch 3: val_loss improved from 0.05397 to 0.02373, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0357 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 4: val_loss improved from 0.02373 to 0.01464, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0180 - val_loss: 0.0146\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 5: val_loss improved from 0.01464 to 0.01015, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01015 to 0.00779, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00779 to 0.00641, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00641 to 0.00541, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 413ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00541 to 0.00462, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00462 to 0.00401, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1068 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_534 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1069 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_535 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1070 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_536 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1071 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_356 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1072 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_357 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1073 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/40 [============================>.] - ETA: 0s - loss: 0.2582\n",
      "Epoch 1: val_loss improved from inf to 0.15776, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 416ms/step - loss: 0.2579 - val_loss: 0.1578\n",
      "Epoch 2/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0789\n",
      "Epoch 2: val_loss improved from 0.15776 to 0.04650, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0788 - val_loss: 0.0465\n",
      "Epoch 3/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0295\n",
      "Epoch 3: val_loss improved from 0.04650 to 0.01848, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0295 - val_loss: 0.0185\n",
      "Epoch 4/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01848 to 0.01037, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 5/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0081\n",
      "Epoch 5: val_loss improved from 0.01037 to 0.00714, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 6: val_loss improved from 0.00714 to 0.00567, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00567 to 0.00497, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00497 to 0.00448, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 399ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00448 to 0.00408, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00408 to 0.00374, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1074 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_537 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1075 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_538 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1076 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_539 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1077 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_358 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1078 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_359 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1079 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/40 [============================>.] - ETA: 0s - loss: 0.2195\n",
      "Epoch 1: val_loss improved from inf to 0.09182, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 417ms/step - loss: 0.2193 - val_loss: 0.0918\n",
      "Epoch 2/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0552\n",
      "Epoch 2: val_loss improved from 0.09182 to 0.04110, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0552 - val_loss: 0.0411\n",
      "Epoch 3/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0295\n",
      "Epoch 3: val_loss improved from 0.04110 to 0.02136, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.0295 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02136 to 0.01299, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 396ms/step - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 5/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01299 to 0.00881, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00881 to 0.00643, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00643 to 0.00502, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00502 to 0.00414, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 396ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00414 to 0.00361, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00361 to 0.00323, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1080 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_540 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1081 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_541 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1082 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_542 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1083 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_360 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1084 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_361 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1085 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/40 [============================>.] - ETA: 0s - loss: 0.1840\n",
      "Epoch 1: val_loss improved from inf to 0.06224, saving model to best_weights.h5\n",
      "40/40 [==============================] - 17s 414ms/step - loss: 0.1839 - val_loss: 0.0622\n",
      "Epoch 2/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0432\n",
      "Epoch 2: val_loss improved from 0.06224 to 0.03086, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.0432 - val_loss: 0.0309\n",
      "Epoch 3/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0217\n",
      "Epoch 3: val_loss improved from 0.03086 to 0.01586, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 0.0217 - val_loss: 0.0159\n",
      "Epoch 4/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0127\n",
      "Epoch 4: val_loss improved from 0.01586 to 0.01116, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 5/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.01116 to 0.00819, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00819 to 0.00635, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00635 to 0.00520, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00520 to 0.00446, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00446 to 0.00394, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "39/40 [============================>.] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00394 to 0.00356, saving model to best_weights.h5\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1086 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_543 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1087 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_544 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1088 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_545 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1089 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_362 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1090 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_363 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1091 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2297\n",
      "Epoch 1: val_loss improved from inf to 0.12361, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 427ms/step - loss: 0.2297 - val_loss: 0.1236\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0593\n",
      "Epoch 2: val_loss improved from 0.12361 to 0.04010, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0593 - val_loss: 0.0401\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 3: val_loss improved from 0.04010 to 0.02339, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0302 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 4: val_loss improved from 0.02339 to 0.01390, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0174 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01390 to 0.00925, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00925 to 0.00671, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00671 to 0.00476, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00476 to 0.00385, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00385 to 0.00338, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00338 to 0.00301, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1092 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_546 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1093 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_547 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1094 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_548 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1095 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_364 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1096 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_365 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1097 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.4019\n",
      "Epoch 1: val_loss improved from inf to 0.33682, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 439ms/step - loss: 0.4019 - val_loss: 0.3368\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2454\n",
      "Epoch 2: val_loss improved from 0.33682 to 0.14952, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.2454 - val_loss: 0.1495\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0792\n",
      "Epoch 3: val_loss improved from 0.14952 to 0.05533, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0792 - val_loss: 0.0553\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0416\n",
      "Epoch 4: val_loss improved from 0.05533 to 0.03146, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0416 - val_loss: 0.0315\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 5: val_loss improved from 0.03146 to 0.01900, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0237 - val_loss: 0.0190\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 6: val_loss improved from 0.01900 to 0.01214, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0145 - val_loss: 0.0121\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 7: val_loss improved from 0.01214 to 0.00808, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0095 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 8: val_loss improved from 0.00808 to 0.00567, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00567 to 0.00449, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00449 to 0.00384, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1098 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_549 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1099 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_550 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1100 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_551 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1101 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_366 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1102 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_367 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1103 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3142\n",
      "Epoch 1: val_loss improved from inf to 0.27321, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 423ms/step - loss: 0.3142 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1729\n",
      "Epoch 2: val_loss improved from 0.27321 to 0.07416, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.1729 - val_loss: 0.0742\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0500\n",
      "Epoch 3: val_loss improved from 0.07416 to 0.03585, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0500 - val_loss: 0.0358\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 4: val_loss improved from 0.03585 to 0.01631, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 0.0237 - val_loss: 0.0163\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 5: val_loss improved from 0.01631 to 0.01019, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0123 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.01019 to 0.00707, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00707 to 0.00543, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00543 to 0.00450, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00450 to 0.00391, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00391 to 0.00349, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1104 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_552 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1105 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_553 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1106 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_554 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1107 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_368 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1108 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_369 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1109 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3591\n",
      "Epoch 1: val_loss improved from inf to 0.35072, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 426ms/step - loss: 0.3591 - val_loss: 0.3507\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2869\n",
      "Epoch 2: val_loss improved from 0.35072 to 0.20838, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.2869 - val_loss: 0.2084\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0923\n",
      "Epoch 3: val_loss improved from 0.20838 to 0.04376, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0923 - val_loss: 0.0438\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0289\n",
      "Epoch 4: val_loss improved from 0.04376 to 0.02108, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 0.0289 - val_loss: 0.0211\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 5: val_loss improved from 0.02108 to 0.01450, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 6: val_loss improved from 0.01450 to 0.01077, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 7: val_loss improved from 0.01077 to 0.00864, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 8: val_loss improved from 0.00864 to 0.00735, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 9: val_loss improved from 0.00735 to 0.00623, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 10: val_loss improved from 0.00623 to 0.00539, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1110 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_555 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1111 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_556 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1112 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_557 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1113 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_370 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1114 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_371 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1115 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3024\n",
      "Epoch 1: val_loss improved from inf to 0.24551, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 422ms/step - loss: 0.3024 - val_loss: 0.2455\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1144\n",
      "Epoch 2: val_loss improved from 0.24551 to 0.03315, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.1144 - val_loss: 0.0331\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 3: val_loss improved from 0.03315 to 0.02038, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0257 - val_loss: 0.0204\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02038 to 0.01333, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0158 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01333 to 0.00922, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00922 to 0.00668, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00668 to 0.00505, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00505 to 0.00411, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00411 to 0.00353, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00353 to 0.00316, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1116 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_558 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1117 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_559 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1118 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_560 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1119 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_372 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1120 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_373 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1121 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.1428\n",
      "Epoch 1: val_loss improved from inf to 0.07347, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 424ms/step - loss: 0.1428 - val_loss: 0.0735\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0582\n",
      "Epoch 2: val_loss improved from 0.07347 to 0.04434, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0582 - val_loss: 0.0443\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 3: val_loss improved from 0.04434 to 0.02110, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 430ms/step - loss: 0.0294 - val_loss: 0.0211\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 4: val_loss improved from 0.02110 to 0.01285, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0159 - val_loss: 0.0129\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01285 to 0.00846, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00846 to 0.00623, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00623 to 0.00496, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 421ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00496 to 0.00426, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00426 to 0.00385, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00385 to 0.00356, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1122 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_561 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1123 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_562 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1124 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_563 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1125 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_374 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1126 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_375 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1127 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3189\n",
      "Epoch 1: val_loss improved from inf to 0.25497, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 0.3189 - val_loss: 0.2550\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1370\n",
      "Epoch 2: val_loss improved from 0.25497 to 0.05984, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.1370 - val_loss: 0.0598\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0461\n",
      "Epoch 3: val_loss improved from 0.05984 to 0.03552, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0461 - val_loss: 0.0355\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0274\n",
      "Epoch 4: val_loss improved from 0.03552 to 0.02304, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0274 - val_loss: 0.0230\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 5: val_loss improved from 0.02304 to 0.01614, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0186 - val_loss: 0.0161\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 6: val_loss improved from 0.01614 to 0.01153, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 7: val_loss improved from 0.01153 to 0.00812, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 8: val_loss improved from 0.00812 to 0.00594, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00594 to 0.00484, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00484 to 0.00421, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1128 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_564 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1129 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_565 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1130 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_566 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1131 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_376 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1132 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_377 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1133 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3216\n",
      "Epoch 1: val_loss improved from inf to 0.28018, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 420ms/step - loss: 0.3216 - val_loss: 0.2802\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1718\n",
      "Epoch 2: val_loss improved from 0.28018 to 0.06509, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.1718 - val_loss: 0.0651\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0496\n",
      "Epoch 3: val_loss improved from 0.06509 to 0.03793, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0496 - val_loss: 0.0379\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 4: val_loss improved from 0.03793 to 0.02405, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0292 - val_loss: 0.0240\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 5: val_loss improved from 0.02405 to 0.01621, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.0191 - val_loss: 0.0162\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 6: val_loss improved from 0.01621 to 0.01138, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 7: val_loss improved from 0.01138 to 0.00899, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 8: val_loss improved from 0.00899 to 0.00752, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 9: val_loss improved from 0.00752 to 0.00641, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 10: val_loss improved from 0.00641 to 0.00548, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1134 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_567 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1135 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_568 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1136 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_569 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1137 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_378 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1138 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_379 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1139 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3199\n",
      "Epoch 1: val_loss improved from inf to 0.28488, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 431ms/step - loss: 0.3199 - val_loss: 0.2849\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1720\n",
      "Epoch 2: val_loss improved from 0.28488 to 0.06556, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.1720 - val_loss: 0.0656\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0508\n",
      "Epoch 3: val_loss improved from 0.06556 to 0.03788, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 0.0508 - val_loss: 0.0379\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0280\n",
      "Epoch 4: val_loss improved from 0.03788 to 0.02215, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0280 - val_loss: 0.0222\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 5: val_loss improved from 0.02215 to 0.01346, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0168 - val_loss: 0.0135\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 6: val_loss improved from 0.01346 to 0.00884, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 418ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00884 to 0.00702, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00702 to 0.00590, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00590 to 0.00494, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00494 to 0.00414, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1140 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_570 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1141 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_571 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1142 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_572 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1143 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_380 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1144 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_381 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1145 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2988\n",
      "Epoch 1: val_loss improved from inf to 0.23677, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 429ms/step - loss: 0.2988 - val_loss: 0.2368\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1174\n",
      "Epoch 2: val_loss improved from 0.23677 to 0.04277, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.1174 - val_loss: 0.0428\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0279\n",
      "Epoch 3: val_loss improved from 0.04277 to 0.01709, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 0.0279 - val_loss: 0.0171\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 4: val_loss improved from 0.01709 to 0.01074, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01074 to 0.00775, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00775 to 0.00569, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0063 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00569 to 0.00461, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00461 to 0.00398, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00398 to 0.00358, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00358 to 0.00331, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1146 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_573 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1147 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_574 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1148 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_575 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1149 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_382 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1150 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_383 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1151 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2203\n",
      "Epoch 1: val_loss improved from inf to 0.10980, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 425ms/step - loss: 0.2203 - val_loss: 0.1098\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0615\n",
      "Epoch 2: val_loss improved from 0.10980 to 0.04201, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0615 - val_loss: 0.0420\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 3: val_loss improved from 0.04201 to 0.02300, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0300 - val_loss: 0.0230\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 4: val_loss improved from 0.02300 to 0.01379, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 0.0171 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01379 to 0.00928, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00928 to 0.00668, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00668 to 0.00506, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00506 to 0.00419, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00419 to 0.00374, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 421ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00374 to 0.00345, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1152 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_576 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1153 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_577 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1154 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_578 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1155 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_384 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1156 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_385 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1157 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.1786\n",
      "Epoch 1: val_loss improved from inf to 0.06207, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 435ms/step - loss: 0.1786 - val_loss: 0.0621\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0463\n",
      "Epoch 2: val_loss improved from 0.06207 to 0.03365, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 420ms/step - loss: 0.0463 - val_loss: 0.0336\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 3: val_loss improved from 0.03365 to 0.02014, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0244 - val_loss: 0.0201\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 4: val_loss improved from 0.02014 to 0.01368, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01368 to 0.00906, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00906 to 0.00656, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00656 to 0.00529, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00529 to 0.00453, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00453 to 0.00401, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00401 to 0.00361, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1158 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_579 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1159 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_580 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1160 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_581 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1161 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_386 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1162 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_387 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1163 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.1950\n",
      "Epoch 1: val_loss improved from inf to 0.09733, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 433ms/step - loss: 0.1950 - val_loss: 0.0973\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0600\n",
      "Epoch 2: val_loss improved from 0.09733 to 0.04031, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0600 - val_loss: 0.0403\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 3: val_loss improved from 0.04031 to 0.02147, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 0.0283 - val_loss: 0.0215\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02147 to 0.01321, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01321 to 0.00857, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00857 to 0.00592, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00592 to 0.00446, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00446 to 0.00375, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00375 to 0.00332, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00332 to 0.00302, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1164 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_582 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1165 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_583 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1166 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_584 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1167 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_388 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1168 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_389 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1169 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2435\n",
      "Epoch 1: val_loss improved from inf to 0.14811, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 422ms/step - loss: 0.2435 - val_loss: 0.1481\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0663\n",
      "Epoch 2: val_loss improved from 0.14811 to 0.03610, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0663 - val_loss: 0.0361\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0256\n",
      "Epoch 3: val_loss improved from 0.03610 to 0.01960, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0256 - val_loss: 0.0196\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.01960 to 0.01281, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0153 - val_loss: 0.0128\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01281 to 0.00831, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00831 to 0.00604, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 7: val_loss improved from 0.00604 to 0.00472, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00472 to 0.00393, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00393 to 0.00344, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00344 to 0.00312, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1170 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_585 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1171 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_586 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1172 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_587 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1173 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_390 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1174 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_391 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1175 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3325\n",
      "Epoch 1: val_loss improved from inf to 0.29912, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 425ms/step - loss: 0.3325 - val_loss: 0.2991\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1915\n",
      "Epoch 2: val_loss improved from 0.29912 to 0.06005, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.1915 - val_loss: 0.0601\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0346\n",
      "Epoch 3: val_loss improved from 0.06005 to 0.02233, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0346 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 4: val_loss improved from 0.02233 to 0.01245, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0160 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01245 to 0.00820, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00820 to 0.00626, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00626 to 0.00507, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00507 to 0.00429, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00429 to 0.00373, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00373 to 0.00334, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 417ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1176 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_588 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1177 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_589 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1178 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_590 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1179 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_392 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1180 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_393 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1181 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2463\n",
      "Epoch 1: val_loss improved from inf to 0.15138, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 418ms/step - loss: 0.2463 - val_loss: 0.1514\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0746\n",
      "Epoch 2: val_loss improved from 0.15138 to 0.04836, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0746 - val_loss: 0.0484\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0347\n",
      "Epoch 3: val_loss improved from 0.04836 to 0.02489, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0347 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0185\n",
      "Epoch 4: val_loss improved from 0.02489 to 0.01474, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0185 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 5: val_loss improved from 0.01474 to 0.00953, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00953 to 0.00706, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00706 to 0.00527, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00527 to 0.00422, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00422 to 0.00362, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00362 to 0.00322, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 419ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1182 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_591 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1183 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_592 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1184 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_593 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1185 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_394 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1186 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_395 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1187 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2474\n",
      "Epoch 1: val_loss improved from inf to 0.13880, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 421ms/step - loss: 0.2474 - val_loss: 0.1388\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0763\n",
      "Epoch 2: val_loss improved from 0.13880 to 0.04878, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0763 - val_loss: 0.0488\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0323\n",
      "Epoch 3: val_loss improved from 0.04878 to 0.02315, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0323 - val_loss: 0.0232\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02315 to 0.01352, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0172 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 5: val_loss improved from 0.01352 to 0.00901, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00901 to 0.00661, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00661 to 0.00516, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00516 to 0.00436, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00436 to 0.00388, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00388 to 0.00356, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1188 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_594 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1189 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_595 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1190 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_596 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1191 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_396 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1192 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_397 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1193 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2999\n",
      "Epoch 1: val_loss improved from inf to 0.21987, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 0.2999 - val_loss: 0.2199\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1102\n",
      "Epoch 2: val_loss improved from 0.21987 to 0.04952, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.1102 - val_loss: 0.0495\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0379\n",
      "Epoch 3: val_loss improved from 0.04952 to 0.02924, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0379 - val_loss: 0.0292\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 4: val_loss improved from 0.02924 to 0.01838, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0224 - val_loss: 0.0184\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 5: val_loss improved from 0.01838 to 0.01139, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 6: val_loss improved from 0.01139 to 0.00723, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00723 to 0.00540, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00540 to 0.00453, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00453 to 0.00398, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00398 to 0.00362, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1194 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_597 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1195 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_598 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1196 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_599 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1197 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_398 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1198 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_399 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1199 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2586\n",
      "Epoch 1: val_loss improved from inf to 0.16889, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 431ms/step - loss: 0.2586 - val_loss: 0.1689\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0883\n",
      "Epoch 2: val_loss improved from 0.16889 to 0.05215, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0883 - val_loss: 0.0522\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0367\n",
      "Epoch 3: val_loss improved from 0.05215 to 0.02818, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0367 - val_loss: 0.0282\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0217\n",
      "Epoch 4: val_loss improved from 0.02818 to 0.01805, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0217 - val_loss: 0.0180\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 5: val_loss improved from 0.01805 to 0.01115, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.01115 to 0.00668, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00668 to 0.00516, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00516 to 0.00437, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00437 to 0.00387, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00387 to 0.00351, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 56ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1200 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_600 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1201 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_601 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1202 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_602 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1203 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_400 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1204 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_401 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1205 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3238\n",
      "Epoch 1: val_loss improved from inf to 0.27081, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 433ms/step - loss: 0.3238 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1402\n",
      "Epoch 2: val_loss improved from 0.27081 to 0.05572, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.1402 - val_loss: 0.0557\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 3: val_loss improved from 0.05572 to 0.02965, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0415 - val_loss: 0.0296\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 4: val_loss improved from 0.02965 to 0.01782, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0220 - val_loss: 0.0178\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 5: val_loss improved from 0.01782 to 0.01178, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 6: val_loss improved from 0.01178 to 0.00846, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00846 to 0.00658, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00658 to 0.00532, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00532 to 0.00440, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00440 to 0.00376, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1206 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_603 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1207 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_604 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1208 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_605 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1209 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_402 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1210 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_403 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1211 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3506\n",
      "Epoch 1: val_loss improved from inf to 0.29770, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 434ms/step - loss: 0.3506 - val_loss: 0.2977\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1874\n",
      "Epoch 2: val_loss improved from 0.29770 to 0.07330, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.1874 - val_loss: 0.0733\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0454\n",
      "Epoch 3: val_loss improved from 0.07330 to 0.03273, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0454 - val_loss: 0.0327\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0232\n",
      "Epoch 4: val_loss improved from 0.03273 to 0.01747, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0232 - val_loss: 0.0175\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 5: val_loss improved from 0.01747 to 0.01122, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.01122 to 0.00828, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00828 to 0.00653, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00653 to 0.00509, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00509 to 0.00417, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00417 to 0.00359, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1212 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_606 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1213 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_607 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1214 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_608 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1215 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_404 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1216 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_405 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1217 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3299\n",
      "Epoch 1: val_loss improved from inf to 0.25964, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 0.3299 - val_loss: 0.2596\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1275\n",
      "Epoch 2: val_loss improved from 0.25964 to 0.03864, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.1275 - val_loss: 0.0386\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 3: val_loss improved from 0.03864 to 0.02395, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0300 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 4: val_loss improved from 0.02395 to 0.01657, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0191 - val_loss: 0.0166\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 5: val_loss improved from 0.01657 to 0.01175, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 6: val_loss improved from 0.01175 to 0.00876, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00876 to 0.00629, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00629 to 0.00450, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00450 to 0.00360, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00360 to 0.00321, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 423ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1218 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_609 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1219 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_610 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1220 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_611 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1221 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_406 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1222 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_407 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1223 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3036\n",
      "Epoch 1: val_loss improved from inf to 0.23944, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 0.3036 - val_loss: 0.2394\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1387\n",
      "Epoch 2: val_loss improved from 0.23944 to 0.06594, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.1387 - val_loss: 0.0659\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0523\n",
      "Epoch 3: val_loss improved from 0.06594 to 0.04216, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0523 - val_loss: 0.0422\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 4: val_loss improved from 0.04216 to 0.02388, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0311 - val_loss: 0.0239\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 5: val_loss improved from 0.02388 to 0.01346, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0177 - val_loss: 0.0135\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 6: val_loss improved from 0.01346 to 0.00779, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0097 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00779 to 0.00560, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00560 to 0.00452, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00452 to 0.00395, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00395 to 0.00357, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1224 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_612 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1225 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_613 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1226 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_614 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1227 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_408 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1228 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_409 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1229 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3402\n",
      "Epoch 1: val_loss improved from inf to 0.31509, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 436ms/step - loss: 0.3402 - val_loss: 0.3151\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2227\n",
      "Epoch 2: val_loss improved from 0.31509 to 0.10464, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.2227 - val_loss: 0.1046\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0537\n",
      "Epoch 3: val_loss improved from 0.10464 to 0.03474, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0537 - val_loss: 0.0347\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 4: val_loss improved from 0.03474 to 0.01702, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0227 - val_loss: 0.0170\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 5: val_loss improved from 0.01702 to 0.01124, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0133 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 6: val_loss improved from 0.01124 to 0.00778, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00778 to 0.00582, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00582 to 0.00478, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00478 to 0.00408, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00408 to 0.00360, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1230 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_615 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1231 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_616 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1232 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_617 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1233 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_410 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1234 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_411 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1235 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.3307\n",
      "Epoch 1: val_loss improved from inf to 0.30910, saving model to best_weights.h5\n",
      "39/39 [==============================] - 18s 435ms/step - loss: 0.3307 - val_loss: 0.3091\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.2122\n",
      "Epoch 2: val_loss improved from 0.30910 to 0.08274, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.2122 - val_loss: 0.0827\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Epoch 3: val_loss improved from 0.08274 to 0.02646, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0432 - val_loss: 0.0265\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0187\n",
      "Epoch 4: val_loss improved from 0.02646 to 0.01408, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0187 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01408 to 0.00893, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00893 to 0.00706, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00706 to 0.00573, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00573 to 0.00477, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00477 to 0.00406, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00406 to 0.00359, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1236 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_618 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1237 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_619 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1238 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_620 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1239 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_412 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1240 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_413 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1241 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2934\n",
      "Epoch 1: val_loss improved from inf to 0.22031, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 419ms/step - loss: 0.2934 - val_loss: 0.2203\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.1138\n",
      "Epoch 2: val_loss improved from 0.22031 to 0.05594, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.1138 - val_loss: 0.0559\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0433\n",
      "Epoch 3: val_loss improved from 0.05594 to 0.03393, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0433 - val_loss: 0.0339\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 4: val_loss improved from 0.03393 to 0.01828, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0248 - val_loss: 0.0183\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 5: val_loss improved from 0.01828 to 0.01246, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0144 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 6: val_loss improved from 0.01246 to 0.00907, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00907 to 0.00693, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00693 to 0.00542, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00542 to 0.00419, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00419 to 0.00351, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1242 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_621 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1243 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_622 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1244 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_623 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1245 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_414 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1246 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_415 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1247 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2912\n",
      "Epoch 1: val_loss improved from inf to 0.19325, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 421ms/step - loss: 0.2912 - val_loss: 0.1933\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0976\n",
      "Epoch 2: val_loss improved from 0.19325 to 0.05379, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0976 - val_loss: 0.0538\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0388\n",
      "Epoch 3: val_loss improved from 0.05379 to 0.02734, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0388 - val_loss: 0.0273\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02734 to 0.01637, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0203 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 5: val_loss improved from 0.01637 to 0.01050, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01050 to 0.00737, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0084 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00737 to 0.00554, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00554 to 0.00444, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00444 to 0.00376, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00376 to 0.00333, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1248 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_624 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1249 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_625 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1250 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_626 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1251 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_416 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1252 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_417 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1253 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2530\n",
      "Epoch 1: val_loss improved from inf to 0.15562, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 422ms/step - loss: 0.2530 - val_loss: 0.1556\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0837\n",
      "Epoch 2: val_loss improved from 0.15562 to 0.05919, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 413ms/step - loss: 0.0837 - val_loss: 0.0592\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 3: val_loss improved from 0.05919 to 0.03098, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0435 - val_loss: 0.0310\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0217\n",
      "Epoch 4: val_loss improved from 0.03098 to 0.01601, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 0.0217 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01601 to 0.00876, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0115 - val_loss: 0.0088\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00876 to 0.00616, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 416ms/step - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 7: val_loss improved from 0.00616 to 0.00498, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00498 to 0.00419, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 399ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00419 to 0.00371, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00371 to 0.00340, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 400ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1254 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_627 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1255 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_628 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1256 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_629 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1257 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_418 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1258 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_419 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1259 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - ETA: 0s - loss: 0.2451\n",
      "Epoch 1: val_loss improved from inf to 0.13884, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 425ms/step - loss: 0.2451 - val_loss: 0.1388\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0831\n",
      "Epoch 2: val_loss improved from 0.13884 to 0.05681, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0831 - val_loss: 0.0568\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0396\n",
      "Epoch 3: val_loss improved from 0.05681 to 0.02957, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 414ms/step - loss: 0.0396 - val_loss: 0.0296\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 4: val_loss improved from 0.02957 to 0.01824, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0227 - val_loss: 0.0182\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01824 to 0.01184, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 6: val_loss improved from 0.01184 to 0.00881, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 7: val_loss improved from 0.00881 to 0.00708, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 412ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00708 to 0.00582, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00582 to 0.00484, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00484 to 0.00410, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 415ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1260 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_630 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1261 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_631 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1262 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_632 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1263 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_420 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1264 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_421 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1265 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/39 [============================>.] - ETA: 0s - loss: 0.3047\n",
      "Epoch 1: val_loss improved from inf to 0.21066, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 432ms/step - loss: 0.3045 - val_loss: 0.2107\n",
      "Epoch 2/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.1020\n",
      "Epoch 2: val_loss improved from 0.21066 to 0.05124, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.1019 - val_loss: 0.0512\n",
      "Epoch 3/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0350\n",
      "Epoch 3: val_loss improved from 0.05124 to 0.02431, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0350 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0182\n",
      "Epoch 4: val_loss improved from 0.02431 to 0.01468, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0182 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0115\n",
      "Epoch 5: val_loss improved from 0.01468 to 0.00981, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.00981 to 0.00734, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00734 to 0.00573, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 406ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00573 to 0.00468, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00468 to 0.00396, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 404ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00396 to 0.00348, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 401ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1266 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_633 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1267 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_634 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1268 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_635 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1269 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_422 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1270 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_423 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1271 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/39 [============================>.] - ETA: 0s - loss: 0.3094\n",
      "Epoch 1: val_loss improved from inf to 0.24192, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 419ms/step - loss: 0.3093 - val_loss: 0.2419\n",
      "Epoch 2/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.1343\n",
      "Epoch 2: val_loss improved from 0.24192 to 0.06358, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.1342 - val_loss: 0.0636\n",
      "Epoch 3/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0423\n",
      "Epoch 3: val_loss improved from 0.06358 to 0.02509, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0423 - val_loss: 0.0251\n",
      "Epoch 4/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0174\n",
      "Epoch 4: val_loss improved from 0.02509 to 0.01410, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 402ms/step - loss: 0.0174 - val_loss: 0.0141\n",
      "Epoch 5/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0113\n",
      "Epoch 5: val_loss improved from 0.01410 to 0.00988, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 410ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0081\n",
      "Epoch 6: val_loss improved from 0.00988 to 0.00735, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00735 to 0.00592, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 405ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00592 to 0.00495, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00495 to 0.00428, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00428 to 0.00374, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 409ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1272 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_636 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_212 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1273 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_637 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1274 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_638 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1275 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_424 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1276 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_425 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1277 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/39 [============================>.] - ETA: 0s - loss: 0.2285\n",
      "Epoch 1: val_loss improved from inf to 0.13398, saving model to best_weights.h5\n",
      "39/39 [==============================] - 17s 422ms/step - loss: 0.2284 - val_loss: 0.1340\n",
      "Epoch 2/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0647\n",
      "Epoch 2: val_loss improved from 0.13398 to 0.03903, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 3/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0286\n",
      "Epoch 3: val_loss improved from 0.03903 to 0.02138, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 411ms/step - loss: 0.0286 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0158\n",
      "Epoch 4: val_loss improved from 0.02138 to 0.01249, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0158 - val_loss: 0.0125\n",
      "Epoch 5/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0099\n",
      "Epoch 5: val_loss improved from 0.01249 to 0.00864, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 403ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 6/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00864 to 0.00663, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00663 to 0.00538, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00538 to 0.00442, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 408ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00442 to 0.00379, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 398ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00379 to 0.00339, saving model to best_weights.h5\n",
      "39/39 [==============================] - 16s 407ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1278 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_639 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_213 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1279 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_640 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1280 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_641 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1281 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_426 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1282 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_427 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1283 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.3184\n",
      "Epoch 1: val_loss improved from inf to 0.29554, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 437ms/step - loss: 0.3184 - val_loss: 0.2955\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2135\n",
      "Epoch 2: val_loss improved from 0.29554 to 0.12344, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.2135 - val_loss: 0.1234\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0632\n",
      "Epoch 3: val_loss improved from 0.12344 to 0.04119, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0632 - val_loss: 0.0412\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 4: val_loss improved from 0.04119 to 0.02258, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0296 - val_loss: 0.0226\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 5: val_loss improved from 0.02258 to 0.01359, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0170 - val_loss: 0.0136\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 6: val_loss improved from 0.01359 to 0.00868, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 7: val_loss improved from 0.00868 to 0.00608, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00608 to 0.00466, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 426ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00466 to 0.00392, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00392 to 0.00351, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1284 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_642 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_214 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1285 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_643 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1286 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_644 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1287 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_428 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1288 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_429 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1289 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.3381\n",
      "Epoch 1: val_loss improved from inf to 0.29023, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 431ms/step - loss: 0.3381 - val_loss: 0.2902\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1530\n",
      "Epoch 2: val_loss improved from 0.29023 to 0.04077, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 428ms/step - loss: 0.1530 - val_loss: 0.0408\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0310\n",
      "Epoch 3: val_loss improved from 0.04077 to 0.02298, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 424ms/step - loss: 0.0310 - val_loss: 0.0230\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 4: val_loss improved from 0.02298 to 0.01403, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0170 - val_loss: 0.0140\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 5: val_loss improved from 0.01403 to 0.01003, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 422ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01003 to 0.00761, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00761 to 0.00608, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 422ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00608 to 0.00505, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00505 to 0.00428, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00428 to 0.00367, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1290 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_645 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_215 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1291 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_646 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1292 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_647 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1293 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_430 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1294 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_431 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1295 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2749\n",
      "Epoch 1: val_loss improved from inf to 0.18748, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 430ms/step - loss: 0.2749 - val_loss: 0.1875\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0849\n",
      "Epoch 2: val_loss improved from 0.18748 to 0.04390, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0849 - val_loss: 0.0439\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 3: val_loss improved from 0.04390 to 0.02201, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 422ms/step - loss: 0.0296 - val_loss: 0.0220\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 4: val_loss improved from 0.02201 to 0.01426, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0171 - val_loss: 0.0143\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 5: val_loss improved from 0.01426 to 0.00987, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00987 to 0.00707, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 429ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00707 to 0.00576, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00576 to 0.00487, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00487 to 0.00425, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00425 to 0.00382, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 422ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1296 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_648 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_216 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1297 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_649 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1298 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_650 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1299 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_432 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1300 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_433 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1301 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2766\n",
      "Epoch 1: val_loss improved from inf to 0.20644, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 429ms/step - loss: 0.2766 - val_loss: 0.2064\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1047\n",
      "Epoch 2: val_loss improved from 0.20644 to 0.05239, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.1047 - val_loss: 0.0524\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0343\n",
      "Epoch 3: val_loss improved from 0.05239 to 0.02530, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0343 - val_loss: 0.0253\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 4: val_loss improved from 0.02530 to 0.01574, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 0.0193 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0122\n",
      "Epoch 5: val_loss improved from 0.01574 to 0.01038, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 6: val_loss improved from 0.01038 to 0.00765, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0085 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00765 to 0.00589, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00589 to 0.00461, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00461 to 0.00384, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00384 to 0.00343, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1302 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_651 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_217 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1303 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_652 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1304 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_653 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1305 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_434 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1306 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_435 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1307 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2162\n",
      "Epoch 1: val_loss improved from inf to 0.11761, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 449ms/step - loss: 0.2162 - val_loss: 0.1176\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0769\n",
      "Epoch 2: val_loss improved from 0.11761 to 0.05881, saving model to best_weights.h5\n",
      "38/38 [==============================] - 19s 496ms/step - loss: 0.0769 - val_loss: 0.0588\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0412\n",
      "Epoch 3: val_loss improved from 0.05881 to 0.02929, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0412 - val_loss: 0.0293\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 4: val_loss improved from 0.02929 to 0.01548, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0208 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 5: val_loss improved from 0.01548 to 0.00988, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00988 to 0.00690, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00690 to 0.00522, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00522 to 0.00441, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00441 to 0.00398, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00398 to 0.00368, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1308 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_654 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_218 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1309 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_655 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1310 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_656 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1311 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_436 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1312 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_437 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1313 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.1945\n",
      "Epoch 1: val_loss improved from inf to 0.06558, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 437ms/step - loss: 0.1945 - val_loss: 0.0656\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0353\n",
      "Epoch 2: val_loss improved from 0.06558 to 0.02667, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0353 - val_loss: 0.0267\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 3: val_loss improved from 0.02667 to 0.01752, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0208 - val_loss: 0.0175\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01752 to 0.01225, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 5: val_loss improved from 0.01225 to 0.00868, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00868 to 0.00661, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00661 to 0.00516, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00516 to 0.00412, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00412 to 0.00355, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00355 to 0.00316, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1314 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_657 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_219 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1315 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_658 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1316 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_659 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1317 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_438 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1318 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_439 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1319 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2383\n",
      "Epoch 1: val_loss improved from inf to 0.12402, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 428ms/step - loss: 0.2383 - val_loss: 0.1240\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0606\n",
      "Epoch 2: val_loss improved from 0.12402 to 0.04043, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0606 - val_loss: 0.0404\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0289\n",
      "Epoch 3: val_loss improved from 0.04043 to 0.02064, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0289 - val_loss: 0.0206\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.02064 to 0.01147, saving model to best_weights.h5\n",
      "38/38 [==============================] - 20s 529ms/step - loss: 0.0148 - val_loss: 0.0115\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01147 to 0.00750, saving model to best_weights.h5\n",
      "38/38 [==============================] - 18s 476ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 6: val_loss improved from 0.00750 to 0.00593, saving model to best_weights.h5\n",
      "38/38 [==============================] - 20s 517ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00593 to 0.00498, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00498 to 0.00425, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 426ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00425 to 0.00374, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00374 to 0.00336, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1320 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_660 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_220 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1321 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_661 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1322 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_662 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1323 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_440 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1324 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_441 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1325 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2824\n",
      "Epoch 1: val_loss improved from inf to 0.23133, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 436ms/step - loss: 0.2824 - val_loss: 0.2313\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1323\n",
      "Epoch 2: val_loss improved from 0.23133 to 0.07171, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.1323 - val_loss: 0.0717\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0530\n",
      "Epoch 3: val_loss improved from 0.07171 to 0.03870, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0530 - val_loss: 0.0387\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0272\n",
      "Epoch 4: val_loss improved from 0.03870 to 0.02108, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0272 - val_loss: 0.0211\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0160\n",
      "Epoch 5: val_loss improved from 0.02108 to 0.01296, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0160 - val_loss: 0.0130\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 6: val_loss improved from 0.01296 to 0.00848, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 429ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 7: val_loss improved from 0.00848 to 0.00614, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 429ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00614 to 0.00477, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00477 to 0.00406, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00406 to 0.00366, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1326 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_663 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_221 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1327 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_664 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1328 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_665 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1329 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_442 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1330 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_443 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1331 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2932\n",
      "Epoch 1: val_loss improved from inf to 0.24075, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 434ms/step - loss: 0.2932 - val_loss: 0.2407\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1454\n",
      "Epoch 2: val_loss improved from 0.24075 to 0.08877, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.1454 - val_loss: 0.0888\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0650\n",
      "Epoch 3: val_loss improved from 0.08877 to 0.04557, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0650 - val_loss: 0.0456\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 4: val_loss improved from 0.04557 to 0.02156, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0303 - val_loss: 0.0216\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0158\n",
      "Epoch 5: val_loss improved from 0.02156 to 0.01241, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0158 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 6: val_loss improved from 0.01241 to 0.00834, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 7: val_loss improved from 0.00834 to 0.00619, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00619 to 0.00501, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00501 to 0.00433, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00433 to 0.00388, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1332 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_666 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_222 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1333 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_667 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1334 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_668 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1335 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_444 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1336 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_445 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1337 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2872\n",
      "Epoch 1: val_loss improved from inf to 0.20876, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 432ms/step - loss: 0.2872 - val_loss: 0.2088\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1124\n",
      "Epoch 2: val_loss improved from 0.20876 to 0.06904, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.1124 - val_loss: 0.0690\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0543\n",
      "Epoch 3: val_loss improved from 0.06904 to 0.04465, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 426ms/step - loss: 0.0543 - val_loss: 0.0446\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0337\n",
      "Epoch 4: val_loss improved from 0.04465 to 0.02589, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.0337 - val_loss: 0.0259\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 5: val_loss improved from 0.02589 to 0.01661, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0199 - val_loss: 0.0166\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 6: val_loss improved from 0.01661 to 0.01008, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0126 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 7: val_loss improved from 0.01008 to 0.00640, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0077 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00640 to 0.00463, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00463 to 0.00394, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00394 to 0.00360, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1338 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_669 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_223 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1339 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_670 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1340 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_671 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1341 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_446 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1342 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_447 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1343 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2068\n",
      "Epoch 1: val_loss improved from inf to 0.11451, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 434ms/step - loss: 0.2068 - val_loss: 0.1145\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0603\n",
      "Epoch 2: val_loss improved from 0.11451 to 0.04210, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0603 - val_loss: 0.0421\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 3: val_loss improved from 0.04210 to 0.01981, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0297 - val_loss: 0.0198\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 4: val_loss improved from 0.01981 to 0.01018, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 5: val_loss improved from 0.01018 to 0.00710, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0080 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00710 to 0.00554, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00554 to 0.00451, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00451 to 0.00384, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00384 to 0.00334, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 10: val_loss improved from 0.00334 to 0.00298, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1344 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_672 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_224 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1345 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_673 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1346 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_674 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1347 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_448 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1348 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_449 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1349 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2057\n",
      "Epoch 1: val_loss improved from inf to 0.09837, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 429ms/step - loss: 0.2057 - val_loss: 0.0984\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0679\n",
      "Epoch 2: val_loss improved from 0.09837 to 0.05372, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0679 - val_loss: 0.0537\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 3: val_loss improved from 0.05372 to 0.02633, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0377 - val_loss: 0.0263\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 4: val_loss improved from 0.02633 to 0.01573, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 0.0196 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 5: val_loss improved from 0.01573 to 0.01009, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.01009 to 0.00697, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00697 to 0.00523, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00523 to 0.00428, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00428 to 0.00375, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00375 to 0.00344, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1350 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_675 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_225 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1351 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_676 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1352 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_677 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1353 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_450 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1354 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_451 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1355 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.3133\n",
      "Epoch 1: val_loss improved from inf to 0.25360, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 430ms/step - loss: 0.3133 - val_loss: 0.2536\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1333\n",
      "Epoch 2: val_loss improved from 0.25360 to 0.05847, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.1333 - val_loss: 0.0585\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 3: val_loss improved from 0.05847 to 0.03292, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0443 - val_loss: 0.0329\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 4: val_loss improved from 0.03292 to 0.01896, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 0.0241 - val_loss: 0.0190\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 5: val_loss improved from 0.01896 to 0.01187, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 6: val_loss improved from 0.01187 to 0.00841, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0094 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00841 to 0.00655, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00655 to 0.00542, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00542 to 0.00463, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00463 to 0.00406, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 55ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1356 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_678 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_226 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1357 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_679 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1358 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_680 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1359 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_452 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1360 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_453 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1361 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2168\n",
      "Epoch 1: val_loss improved from inf to 0.10303, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 429ms/step - loss: 0.2168 - val_loss: 0.1030\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0543\n",
      "Epoch 2: val_loss improved from 0.10303 to 0.03862, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0543 - val_loss: 0.0386\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Epoch 3: val_loss improved from 0.03862 to 0.02367, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0295 - val_loss: 0.0237\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0185\n",
      "Epoch 4: val_loss improved from 0.02367 to 0.01570, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 424ms/step - loss: 0.0185 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01570 to 0.01109, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 6: val_loss improved from 0.01109 to 0.00787, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00787 to 0.00554, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00554 to 0.00430, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00430 to 0.00361, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00361 to 0.00313, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 55ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1362 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_681 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_227 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1363 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_682 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1364 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_683 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1365 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_454 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1366 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_455 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1367 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.3493\n",
      "Epoch 1: val_loss improved from inf to 0.32435, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 431ms/step - loss: 0.3493 - val_loss: 0.3244\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2598\n",
      "Epoch 2: val_loss improved from 0.32435 to 0.18836, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.2598 - val_loss: 0.1884\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0946\n",
      "Epoch 3: val_loss improved from 0.18836 to 0.05460, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0946 - val_loss: 0.0546\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0372\n",
      "Epoch 4: val_loss improved from 0.05460 to 0.02628, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0372 - val_loss: 0.0263\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 5: val_loss improved from 0.02628 to 0.01489, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0193 - val_loss: 0.0149\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 6: val_loss improved from 0.01489 to 0.00915, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 7: val_loss improved from 0.00915 to 0.00655, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00655 to 0.00515, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00515 to 0.00437, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00437 to 0.00386, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1368 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_684 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_228 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1369 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_685 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1370 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_686 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1371 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_456 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1372 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_457 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1373 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2991\n",
      "Epoch 1: val_loss improved from inf to 0.24308, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 430ms/step - loss: 0.2991 - val_loss: 0.2431\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1318\n",
      "Epoch 2: val_loss improved from 0.24308 to 0.05449, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.1318 - val_loss: 0.0545\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0429\n",
      "Epoch 3: val_loss improved from 0.05449 to 0.03239, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0429 - val_loss: 0.0324\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 4: val_loss improved from 0.03239 to 0.01707, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 0.0227 - val_loss: 0.0171\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss improved from 0.01707 to 0.01053, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0130 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.01053 to 0.00665, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 424ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00665 to 0.00504, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00504 to 0.00430, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00430 to 0.00383, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00383 to 0.00346, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 424ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1374 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_687 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_229 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1375 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_688 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1376 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_689 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1377 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_458 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1378 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_459 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1379 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2663\n",
      "Epoch 1: val_loss improved from inf to 0.18601, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 431ms/step - loss: 0.2663 - val_loss: 0.1860\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0901\n",
      "Epoch 2: val_loss improved from 0.18601 to 0.03931, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0901 - val_loss: 0.0393\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 3: val_loss improved from 0.03931 to 0.01892, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0268 - val_loss: 0.0189\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 4: val_loss improved from 0.01892 to 0.01142, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 436ms/step - loss: 0.0141 - val_loss: 0.0114\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 5: val_loss improved from 0.01142 to 0.00798, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 6: val_loss improved from 0.00798 to 0.00631, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00631 to 0.00521, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 424ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00521 to 0.00451, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00451 to 0.00403, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00403 to 0.00368, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1380 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_690 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_230 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1381 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_691 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1382 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_692 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1383 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_460 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1384 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_461 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1385 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2593\n",
      "Epoch 1: val_loss improved from inf to 0.17651, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 431ms/step - loss: 0.2593 - val_loss: 0.1765\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0983\n",
      "Epoch 2: val_loss improved from 0.17651 to 0.06219, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0983 - val_loss: 0.0622\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0454\n",
      "Epoch 3: val_loss improved from 0.06219 to 0.03307, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0454 - val_loss: 0.0331\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0242\n",
      "Epoch 4: val_loss improved from 0.03307 to 0.01867, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0242 - val_loss: 0.0187\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 5: val_loss improved from 0.01867 to 0.01201, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 6: val_loss improved from 0.01201 to 0.00816, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 7: val_loss improved from 0.00816 to 0.00595, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00595 to 0.00480, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00480 to 0.00415, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00415 to 0.00373, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1386 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_693 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_231 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1387 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_694 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1388 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_695 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1389 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_462 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1390 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_463 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1391 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2752\n",
      "Epoch 1: val_loss improved from inf to 0.18548, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 427ms/step - loss: 0.2752 - val_loss: 0.1855\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0912\n",
      "Epoch 2: val_loss improved from 0.18548 to 0.05270, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0912 - val_loss: 0.0527\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0370\n",
      "Epoch 3: val_loss improved from 0.05270 to 0.02680, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0370 - val_loss: 0.0268\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 4: val_loss improved from 0.02680 to 0.01442, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0193 - val_loss: 0.0144\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 5: val_loss improved from 0.01442 to 0.00818, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00818 to 0.00567, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0064 - val_loss: 0.0057\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00567 to 0.00456, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 8: val_loss improved from 0.00456 to 0.00394, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 9: val_loss improved from 0.00394 to 0.00350, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00350 to 0.00318, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1392 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_696 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_232 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1393 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_697 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1394 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_698 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1395 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_464 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1396 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_465 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1397 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2576\n",
      "Epoch 1: val_loss improved from inf to 0.14189, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 433ms/step - loss: 0.2576 - val_loss: 0.1419\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0699\n",
      "Epoch 2: val_loss improved from 0.14189 to 0.04293, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0699 - val_loss: 0.0429\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 3: val_loss improved from 0.04293 to 0.01861, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0283 - val_loss: 0.0186\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 4: val_loss improved from 0.01861 to 0.01235, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 5: val_loss improved from 0.01235 to 0.00888, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00888 to 0.00681, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00681 to 0.00547, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00547 to 0.00447, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00447 to 0.00381, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00381 to 0.00338, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 54ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1398 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_699 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_233 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1399 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_700 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1400 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_701 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1401 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_466 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1402 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_467 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1403 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2763\n",
      "Epoch 1: val_loss improved from inf to 0.20021, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 427ms/step - loss: 0.2763 - val_loss: 0.2002\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1036\n",
      "Epoch 2: val_loss improved from 0.20021 to 0.06097, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.1036 - val_loss: 0.0610\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0448\n",
      "Epoch 3: val_loss improved from 0.06097 to 0.03277, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0448 - val_loss: 0.0328\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0232\n",
      "Epoch 4: val_loss improved from 0.03277 to 0.01822, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0232 - val_loss: 0.0182\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 5: val_loss improved from 0.01822 to 0.01153, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0141 - val_loss: 0.0115\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 6: val_loss improved from 0.01153 to 0.00753, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00753 to 0.00541, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00541 to 0.00431, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00431 to 0.00366, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 10: val_loss improved from 0.00366 to 0.00325, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1404 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_702 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1405 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_703 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1406 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_704 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1407 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_468 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1408 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_469 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1409 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.3091\n",
      "Epoch 1: val_loss improved from inf to 0.24626, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 429ms/step - loss: 0.3091 - val_loss: 0.2463\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1375\n",
      "Epoch 2: val_loss improved from 0.24626 to 0.05867, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.1375 - val_loss: 0.0587\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0428\n",
      "Epoch 3: val_loss improved from 0.05867 to 0.02717, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 0.0428 - val_loss: 0.0272\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02717 to 0.01328, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0176 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 5: val_loss improved from 0.01328 to 0.00854, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 6: val_loss improved from 0.00854 to 0.00632, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00632 to 0.00508, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00508 to 0.00429, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00429 to 0.00382, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00382 to 0.00353, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1410 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_705 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1411 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_706 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1412 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_707 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1413 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_470 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1414 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_471 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1415 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2445\n",
      "Epoch 1: val_loss improved from inf to 0.15166, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 429ms/step - loss: 0.2445 - val_loss: 0.1517\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0813\n",
      "Epoch 2: val_loss improved from 0.15166 to 0.05730, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.0813 - val_loss: 0.0573\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0430\n",
      "Epoch 3: val_loss improved from 0.05730 to 0.03207, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0430 - val_loss: 0.0321\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 4: val_loss improved from 0.03207 to 0.01691, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0227 - val_loss: 0.0169\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01691 to 0.01016, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.01016 to 0.00684, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00684 to 0.00527, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00527 to 0.00439, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00439 to 0.00387, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00387 to 0.00352, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1416 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_708 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1417 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_709 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1418 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_710 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1419 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_472 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1420 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_473 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1421 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.3072\n",
      "Epoch 1: val_loss improved from inf to 0.24726, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 428ms/step - loss: 0.3072 - val_loss: 0.2473\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1246\n",
      "Epoch 2: val_loss improved from 0.24726 to 0.06158, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.1246 - val_loss: 0.0616\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0430\n",
      "Epoch 3: val_loss improved from 0.06158 to 0.02943, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.0430 - val_loss: 0.0294\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 4: val_loss improved from 0.02943 to 0.01644, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0209 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 5: val_loss improved from 0.01644 to 0.01016, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 6: val_loss improved from 0.01016 to 0.00679, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00679 to 0.00511, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 422ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00511 to 0.00424, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00424 to 0.00376, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00376 to 0.00343, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1422 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_711 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_237 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1423 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_712 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1424 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_713 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1425 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_474 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1426 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_475 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1427 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.3329\n",
      "Epoch 1: val_loss improved from inf to 0.30349, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 433ms/step - loss: 0.3329 - val_loss: 0.3035\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2002\n",
      "Epoch 2: val_loss improved from 0.30349 to 0.08734, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.2002 - val_loss: 0.0873\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0649\n",
      "Epoch 3: val_loss improved from 0.08734 to 0.05116, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0649 - val_loss: 0.0512\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 4: val_loss improved from 0.05116 to 0.03059, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0386 - val_loss: 0.0306\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 5: val_loss improved from 0.03059 to 0.01883, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0234 - val_loss: 0.0188\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 6: val_loss improved from 0.01883 to 0.01102, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0140 - val_loss: 0.0110\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 7: val_loss improved from 0.01102 to 0.00743, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0085 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 8: val_loss improved from 0.00743 to 0.00590, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00590 to 0.00504, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00504 to 0.00442, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1428 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_714 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_238 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1429 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_715 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1430 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_716 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1431 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_476 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1432 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_477 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1433 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2837\n",
      "Epoch 1: val_loss improved from inf to 0.17455, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 430ms/step - loss: 0.2837 - val_loss: 0.1745\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0924\n",
      "Epoch 2: val_loss improved from 0.17455 to 0.06243, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 423ms/step - loss: 0.0924 - val_loss: 0.0624\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0478\n",
      "Epoch 3: val_loss improved from 0.06243 to 0.03804, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 439ms/step - loss: 0.0478 - val_loss: 0.0380\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0293\n",
      "Epoch 4: val_loss improved from 0.03804 to 0.02429, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0293 - val_loss: 0.0243\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 5: val_loss improved from 0.02429 to 0.01651, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0194 - val_loss: 0.0165\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 6: val_loss improved from 0.01651 to 0.01112, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 7: val_loss improved from 0.01112 to 0.00834, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 8: val_loss improved from 0.00834 to 0.00672, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 9: val_loss improved from 0.00672 to 0.00564, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 10: val_loss improved from 0.00564 to 0.00491, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 409ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1434 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_717 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_239 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1435 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_718 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1436 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_719 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1437 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_478 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1438 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_479 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1439 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2988\n",
      "Epoch 1: val_loss improved from inf to 0.23814, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 430ms/step - loss: 0.2988 - val_loss: 0.2381\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1346\n",
      "Epoch 2: val_loss improved from 0.23814 to 0.06142, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.1346 - val_loss: 0.0614\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0453\n",
      "Epoch 3: val_loss improved from 0.06142 to 0.03069, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.0453 - val_loss: 0.0307\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 4: val_loss improved from 0.03069 to 0.01806, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 0.0228 - val_loss: 0.0181\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.01806 to 0.01105, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0136 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01105 to 0.00774, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00774 to 0.00592, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00592 to 0.00484, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00484 to 0.00422, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00422 to 0.00379, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1440 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_720 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_240 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1441 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_721 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1442 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_722 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1443 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_480 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1444 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_481 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1445 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2265\n",
      "Epoch 1: val_loss improved from inf to 0.09880, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 450ms/step - loss: 0.2265 - val_loss: 0.0988\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0571\n",
      "Epoch 2: val_loss improved from 0.09880 to 0.03840, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0571 - val_loss: 0.0384\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0264\n",
      "Epoch 3: val_loss improved from 0.03840 to 0.01991, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 427ms/step - loss: 0.0264 - val_loss: 0.0199\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0156\n",
      "Epoch 4: val_loss improved from 0.01991 to 0.01311, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0156 - val_loss: 0.0131\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01311 to 0.00944, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.00944 to 0.00745, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 419ms/step - loss: 0.0080 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00745 to 0.00613, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00613 to 0.00516, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00516 to 0.00438, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00438 to 0.00383, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1446 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_723 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_241 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1447 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_724 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1448 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_725 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1449 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_482 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1450 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_483 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1451 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - ETA: 0s - loss: 0.2137\n",
      "Epoch 1: val_loss improved from inf to 0.11439, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 429ms/step - loss: 0.2137 - val_loss: 0.1144\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0723\n",
      "Epoch 2: val_loss improved from 0.11439 to 0.05234, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0723 - val_loss: 0.0523\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 3: val_loss improved from 0.05234 to 0.02718, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.0366 - val_loss: 0.0272\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 4: val_loss improved from 0.02718 to 0.01670, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0208 - val_loss: 0.0167\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 5: val_loss improved from 0.01670 to 0.01087, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01087 to 0.00757, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00757 to 0.00563, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00563 to 0.00462, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00462 to 0.00395, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00395 to 0.00345, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1452 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_726 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_242 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1453 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_727 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1454 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_728 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1455 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_484 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1456 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_485 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1457 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/38 [============================>.] - ETA: 0s - loss: 0.3021\n",
      "Epoch 1: val_loss improved from inf to 0.23795, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 426ms/step - loss: 0.3019 - val_loss: 0.2380\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.1342\n",
      "Epoch 2: val_loss improved from 0.23795 to 0.08004, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.1342 - val_loss: 0.0800\n",
      "Epoch 3/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0558\n",
      "Epoch 3: val_loss improved from 0.08004 to 0.03715, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 420ms/step - loss: 0.0558 - val_loss: 0.0372\n",
      "Epoch 4/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0255\n",
      "Epoch 4: val_loss improved from 0.03715 to 0.01826, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 411ms/step - loss: 0.0255 - val_loss: 0.0183\n",
      "Epoch 5/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0135\n",
      "Epoch 5: val_loss improved from 0.01826 to 0.01093, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 6/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0090\n",
      "Epoch 6: val_loss improved from 0.01093 to 0.00834, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0072\n",
      "Epoch 7: val_loss improved from 0.00834 to 0.00688, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0060\n",
      "Epoch 8: val_loss improved from 0.00688 to 0.00577, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00577 to 0.00489, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00489 to 0.00424, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1458 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_729 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_243 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1459 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_730 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1460 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_731 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1461 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_486 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1462 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_487 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1463 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/38 [============================>.] - ETA: 0s - loss: 0.2173\n",
      "Epoch 1: val_loss improved from inf to 0.08120, saving model to best_weights.h5\n",
      "38/38 [==============================] - 18s 469ms/step - loss: 0.2171 - val_loss: 0.0812\n",
      "Epoch 2/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0372\n",
      "Epoch 2: val_loss improved from 0.08120 to 0.02364, saving model to best_weights.h5\n",
      "38/38 [==============================] - 21s 550ms/step - loss: 0.0372 - val_loss: 0.0236\n",
      "Epoch 3/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0173\n",
      "Epoch 3: val_loss improved from 0.02364 to 0.01411, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 455ms/step - loss: 0.0173 - val_loss: 0.0141\n",
      "Epoch 4/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0117\n",
      "Epoch 4: val_loss improved from 0.01411 to 0.01054, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 5/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0089\n",
      "Epoch 5: val_loss improved from 0.01054 to 0.00828, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00828 to 0.00663, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 460ms/step - loss: 0.0070 - val_loss: 0.0066\n",
      "Epoch 7/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0057\n",
      "Epoch 7: val_loss improved from 0.00663 to 0.00546, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 435ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00546 to 0.00461, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 450ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 9/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00461 to 0.00402, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 452ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00402 to 0.00365, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 436ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1464 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_732 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_244 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1465 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_733 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1466 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_734 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1467 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_488 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1468 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_489 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1469 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/38 [============================>.] - ETA: 0s - loss: 0.3038\n",
      "Epoch 1: val_loss improved from inf to 0.20134, saving model to best_weights.h5\n",
      "38/38 [==============================] - 17s 440ms/step - loss: 0.3036 - val_loss: 0.2013\n",
      "Epoch 2/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1024\n",
      "Epoch 2: val_loss improved from 0.20134 to 0.06051, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 417ms/step - loss: 0.1024 - val_loss: 0.0605\n",
      "Epoch 3/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0428\n",
      "Epoch 3: val_loss improved from 0.06051 to 0.03005, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.0428 - val_loss: 0.0300\n",
      "Epoch 4/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0217\n",
      "Epoch 4: val_loss improved from 0.03005 to 0.01723, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 407ms/step - loss: 0.0217 - val_loss: 0.0172\n",
      "Epoch 5/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0137\n",
      "Epoch 5: val_loss improved from 0.01723 to 0.01175, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 405ms/step - loss: 0.0137 - val_loss: 0.0118\n",
      "Epoch 6/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0095\n",
      "Epoch 6: val_loss improved from 0.01175 to 0.00848, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00848 to 0.00661, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0057\n",
      "Epoch 8: val_loss improved from 0.00661 to 0.00549, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 404ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00549 to 0.00483, saving model to best_weights.h5\n",
      "38/38 [==============================] - 15s 406ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00483 to 0.00437, saving model to best_weights.h5\n",
      "38/38 [==============================] - 16s 413ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1470 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_735 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_245 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1471 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_736 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1472 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_737 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1473 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_490 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1474 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_491 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1475 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.0873\n",
      "Epoch 1: val_loss improved from inf to 0.06000, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 442ms/step - loss: 0.0873 - val_loss: 0.0600\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Epoch 2: val_loss improved from 0.06000 to 0.03058, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0419 - val_loss: 0.0306\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0222\n",
      "Epoch 3: val_loss improved from 0.03058 to 0.01659, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0222 - val_loss: 0.0166\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 4: val_loss improved from 0.01659 to 0.00978, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0121 - val_loss: 0.0098\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 5: val_loss improved from 0.00978 to 0.00671, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 6: val_loss improved from 0.00671 to 0.00512, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 7: val_loss improved from 0.00512 to 0.00413, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 8: val_loss improved from 0.00413 to 0.00352, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 9: val_loss improved from 0.00352 to 0.00314, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 10: val_loss improved from 0.00314 to 0.00285, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1476 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_738 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_246 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1477 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_739 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1478 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_740 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1479 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_492 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1480 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_493 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1481 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2812\n",
      "Epoch 1: val_loss improved from inf to 0.21531, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 438ms/step - loss: 0.2812 - val_loss: 0.2153\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1064\n",
      "Epoch 2: val_loss improved from 0.21531 to 0.04152, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.1064 - val_loss: 0.0415\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 3: val_loss improved from 0.04152 to 0.02232, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0303 - val_loss: 0.0223\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 4: val_loss improved from 0.02232 to 0.01430, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0172 - val_loss: 0.0143\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 5: val_loss improved from 0.01430 to 0.00966, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00966 to 0.00700, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00700 to 0.00560, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00560 to 0.00470, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00470 to 0.00408, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00408 to 0.00366, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 429ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1482 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_741 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_247 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1483 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_742 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1484 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_743 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1485 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_494 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1486 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_495 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1487 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2893\n",
      "Epoch 1: val_loss improved from inf to 0.21422, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 439ms/step - loss: 0.2893 - val_loss: 0.2142\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0964\n",
      "Epoch 2: val_loss improved from 0.21422 to 0.04054, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0964 - val_loss: 0.0405\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0265\n",
      "Epoch 3: val_loss improved from 0.04054 to 0.01823, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0265 - val_loss: 0.0182\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0135\n",
      "Epoch 4: val_loss improved from 0.01823 to 0.01089, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0135 - val_loss: 0.0109\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 5: val_loss improved from 0.01089 to 0.00710, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 6: val_loss improved from 0.00710 to 0.00545, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00545 to 0.00445, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00445 to 0.00389, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00389 to 0.00349, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00349 to 0.00318, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1488 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_744 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_248 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1489 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_745 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1490 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_746 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1491 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_496 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1492 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_497 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1493 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1907\n",
      "Epoch 1: val_loss improved from inf to 0.08672, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 439ms/step - loss: 0.1907 - val_loss: 0.0867\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0536\n",
      "Epoch 2: val_loss improved from 0.08672 to 0.04069, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.0536 - val_loss: 0.0407\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 3: val_loss improved from 0.04069 to 0.02310, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0300 - val_loss: 0.0231\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0177\n",
      "Epoch 4: val_loss improved from 0.02310 to 0.01473, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 430ms/step - loss: 0.0177 - val_loss: 0.0147\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 5: val_loss improved from 0.01473 to 0.00972, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 429ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00972 to 0.00692, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00692 to 0.00549, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00549 to 0.00475, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00475 to 0.00427, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00427 to 0.00391, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1494 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_747 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_249 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1495 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_748 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1496 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_749 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1497 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_498 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1498 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_499 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1499 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2046\n",
      "Epoch 1: val_loss improved from inf to 0.09099, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 438ms/step - loss: 0.2046 - val_loss: 0.0910\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0524\n",
      "Epoch 2: val_loss improved from 0.09099 to 0.03660, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0524 - val_loss: 0.0366\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 3: val_loss improved from 0.03660 to 0.02246, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0276 - val_loss: 0.0225\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 4: val_loss improved from 0.02246 to 0.01420, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0173 - val_loss: 0.0142\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 5: val_loss improved from 0.01420 to 0.00895, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0109 - val_loss: 0.0090\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 6: val_loss improved from 0.00895 to 0.00578, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 7: val_loss improved from 0.00578 to 0.00444, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 8: val_loss improved from 0.00444 to 0.00389, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 9: val_loss improved from 0.00389 to 0.00353, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00353 to 0.00325, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1500 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_750 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_250 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1501 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_751 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1502 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_752 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1503 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_500 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1504 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_501 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1505 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2740\n",
      "Epoch 1: val_loss improved from inf to 0.20087, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 447ms/step - loss: 0.2740 - val_loss: 0.2009\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1081\n",
      "Epoch 2: val_loss improved from 0.20087 to 0.06856, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.1081 - val_loss: 0.0686\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0495\n",
      "Epoch 3: val_loss improved from 0.06856 to 0.03666, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0495 - val_loss: 0.0367\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 4: val_loss improved from 0.03666 to 0.02367, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0284 - val_loss: 0.0237\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0184\n",
      "Epoch 5: val_loss improved from 0.02367 to 0.01477, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0184 - val_loss: 0.0148\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 6: val_loss improved from 0.01477 to 0.00879, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 429ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 7: val_loss improved from 0.00879 to 0.00592, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00592 to 0.00472, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00472 to 0.00418, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00418 to 0.00378, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1506 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_753 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_251 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1507 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_754 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1508 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_755 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1509 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_502 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1510 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_503 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1511 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3458\n",
      "Epoch 1: val_loss improved from inf to 0.32392, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 436ms/step - loss: 0.3458 - val_loss: 0.3239\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2491\n",
      "Epoch 2: val_loss improved from 0.32392 to 0.15360, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.2491 - val_loss: 0.1536\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0726\n",
      "Epoch 3: val_loss improved from 0.15360 to 0.04455, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0726 - val_loss: 0.0446\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 4: val_loss improved from 0.04455 to 0.01921, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0296 - val_loss: 0.0192\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0147\n",
      "Epoch 5: val_loss improved from 0.01921 to 0.01231, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0147 - val_loss: 0.0123\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01231 to 0.00872, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00872 to 0.00701, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00701 to 0.00598, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00598 to 0.00508, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00508 to 0.00434, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1512 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_756 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_252 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1513 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_757 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1514 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_758 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1515 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_504 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1516 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_505 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1517 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3021\n",
      "Epoch 1: val_loss improved from inf to 0.24149, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.3021 - val_loss: 0.2415\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1236\n",
      "Epoch 2: val_loss improved from 0.24149 to 0.06713, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.1236 - val_loss: 0.0671\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0468\n",
      "Epoch 3: val_loss improved from 0.06713 to 0.03396, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 433ms/step - loss: 0.0468 - val_loss: 0.0340\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0262\n",
      "Epoch 4: val_loss improved from 0.03396 to 0.02210, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0262 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 5: val_loss improved from 0.02210 to 0.01504, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0176 - val_loss: 0.0150\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 6: val_loss improved from 0.01504 to 0.01049, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 7: val_loss improved from 0.01049 to 0.00776, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 8: val_loss improved from 0.00776 to 0.00598, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00598 to 0.00484, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00484 to 0.00412, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1518 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_759 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_253 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1519 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_760 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1520 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_761 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1521 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_506 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1522 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_507 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1523 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3040\n",
      "Epoch 1: val_loss improved from inf to 0.24918, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 440ms/step - loss: 0.3040 - val_loss: 0.2492\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1385\n",
      "Epoch 2: val_loss improved from 0.24918 to 0.06483, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.1385 - val_loss: 0.0648\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0519\n",
      "Epoch 3: val_loss improved from 0.06483 to 0.04103, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0519 - val_loss: 0.0410\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 4: val_loss improved from 0.04103 to 0.02318, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0300 - val_loss: 0.0232\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 5: val_loss improved from 0.02318 to 0.01447, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0178 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 6: val_loss improved from 0.01447 to 0.00940, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 435ms/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 7: val_loss improved from 0.00940 to 0.00671, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00671 to 0.00526, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00526 to 0.00440, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00440 to 0.00387, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1524 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_762 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_254 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1525 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_763 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1526 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_764 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1527 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_508 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1528 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_509 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1529 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3278\n",
      "Epoch 1: val_loss improved from inf to 0.28485, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 437ms/step - loss: 0.3278 - val_loss: 0.2848\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1869\n",
      "Epoch 2: val_loss improved from 0.28485 to 0.09536, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.1869 - val_loss: 0.0954\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0629\n",
      "Epoch 3: val_loss improved from 0.09536 to 0.04170, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0629 - val_loss: 0.0417\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 4: val_loss improved from 0.04170 to 0.01745, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0257 - val_loss: 0.0175\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 5: val_loss improved from 0.01745 to 0.01065, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01065 to 0.00801, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 430ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 7: val_loss improved from 0.00801 to 0.00661, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 8: val_loss improved from 0.00661 to 0.00556, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 412ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00556 to 0.00468, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00468 to 0.00401, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1530 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_765 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_255 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1531 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_766 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1532 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_767 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1533 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_510 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1534 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_511 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1535 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3193\n",
      "Epoch 1: val_loss improved from inf to 0.25687, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 438ms/step - loss: 0.3193 - val_loss: 0.2569\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1368\n",
      "Epoch 2: val_loss improved from 0.25687 to 0.05305, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.1368 - val_loss: 0.0531\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0439\n",
      "Epoch 3: val_loss improved from 0.05305 to 0.03556, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0439 - val_loss: 0.0356\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0271\n",
      "Epoch 4: val_loss improved from 0.03556 to 0.02205, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0271 - val_loss: 0.0221\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 5: val_loss improved from 0.02205 to 0.01459, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0174 - val_loss: 0.0146\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 6: val_loss improved from 0.01459 to 0.00987, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 7: val_loss improved from 0.00987 to 0.00708, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 8: val_loss improved from 0.00708 to 0.00549, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00549 to 0.00470, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00470 to 0.00412, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1536 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_768 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_256 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1537 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_769 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1538 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_770 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1539 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_512 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1540 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_513 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1541 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2958\n",
      "Epoch 1: val_loss improved from inf to 0.24580, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 443ms/step - loss: 0.2958 - val_loss: 0.2458\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1334\n",
      "Epoch 2: val_loss improved from 0.24580 to 0.05235, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1334 - val_loss: 0.0524\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0375\n",
      "Epoch 3: val_loss improved from 0.05235 to 0.02284, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0375 - val_loss: 0.0228\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 4: val_loss improved from 0.02284 to 0.01107, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 5: val_loss improved from 0.01107 to 0.00775, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00775 to 0.00602, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 7: val_loss improved from 0.00602 to 0.00491, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 8: val_loss improved from 0.00491 to 0.00414, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00414 to 0.00356, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00356 to 0.00321, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1542 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_771 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_257 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1543 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_772 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1544 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_773 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1545 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_514 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1546 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_515 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1547 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3292\n",
      "Epoch 1: val_loss improved from inf to 0.28202, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 438ms/step - loss: 0.3292 - val_loss: 0.2820\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1629\n",
      "Epoch 2: val_loss improved from 0.28202 to 0.05357, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.1629 - val_loss: 0.0536\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0399\n",
      "Epoch 3: val_loss improved from 0.05357 to 0.02817, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0399 - val_loss: 0.0282\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 4: val_loss improved from 0.02817 to 0.01772, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0211 - val_loss: 0.0177\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 5: val_loss improved from 0.01772 to 0.01277, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 6: val_loss improved from 0.01277 to 0.00947, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 7: val_loss improved from 0.00947 to 0.00716, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 8: val_loss improved from 0.00716 to 0.00560, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00560 to 0.00458, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00458 to 0.00392, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1548 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_774 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_258 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1549 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_775 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1550 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_776 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1551 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_516 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1552 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_517 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1553 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2791\n",
      "Epoch 1: val_loss improved from inf to 0.18932, saving model to best_weights.h5\n",
      "37/37 [==============================] - 19s 502ms/step - loss: 0.2791 - val_loss: 0.1893\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0967\n",
      "Epoch 2: val_loss improved from 0.18932 to 0.06106, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0967 - val_loss: 0.0611\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0451\n",
      "Epoch 3: val_loss improved from 0.06106 to 0.03416, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0451 - val_loss: 0.0342\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0259\n",
      "Epoch 4: val_loss improved from 0.03416 to 0.02166, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0259 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0172\n",
      "Epoch 5: val_loss improved from 0.02166 to 0.01461, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0172 - val_loss: 0.0146\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 6: val_loss improved from 0.01461 to 0.01029, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 7: val_loss improved from 0.01029 to 0.00808, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 8: val_loss improved from 0.00808 to 0.00651, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 9: val_loss improved from 0.00651 to 0.00523, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 419ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00523 to 0.00431, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1554 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_777 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_259 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1555 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_778 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1556 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_779 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1557 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_518 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1558 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_519 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1559 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2516\n",
      "Epoch 1: val_loss improved from inf to 0.16069, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 436ms/step - loss: 0.2516 - val_loss: 0.1607\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0845\n",
      "Epoch 2: val_loss improved from 0.16069 to 0.05491, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0845 - val_loss: 0.0549\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 3: val_loss improved from 0.05491 to 0.02779, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 429ms/step - loss: 0.0386 - val_loss: 0.0278\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 4: val_loss improved from 0.02779 to 0.01547, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0198 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 5: val_loss improved from 0.01547 to 0.00982, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.00982 to 0.00735, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00735 to 0.00593, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00593 to 0.00497, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 459ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00497 to 0.00424, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00424 to 0.00372, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1560 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_780 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_260 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1561 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_781 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1562 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_782 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1563 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_520 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1564 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_521 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1565 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3191\n",
      "Epoch 1: val_loss improved from inf to 0.28162, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 435ms/step - loss: 0.3191 - val_loss: 0.2816\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1794\n",
      "Epoch 2: val_loss improved from 0.28162 to 0.07267, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.1794 - val_loss: 0.0727\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0504\n",
      "Epoch 3: val_loss improved from 0.07267 to 0.03566, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0504 - val_loss: 0.0357\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.03566 to 0.01616, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0233 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 5: val_loss improved from 0.01616 to 0.01040, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01040 to 0.00749, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00749 to 0.00581, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00581 to 0.00477, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00477 to 0.00412, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00412 to 0.00364, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1566 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_783 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_261 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1567 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_784 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1568 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_785 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1569 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_522 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1570 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_523 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1571 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2711\n",
      "Epoch 1: val_loss improved from inf to 0.18769, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 438ms/step - loss: 0.2711 - val_loss: 0.1877\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0907\n",
      "Epoch 2: val_loss improved from 0.18769 to 0.04801, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0907 - val_loss: 0.0480\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0334\n",
      "Epoch 3: val_loss improved from 0.04801 to 0.02355, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0334 - val_loss: 0.0235\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 4: val_loss improved from 0.02355 to 0.01449, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0176 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 5: val_loss improved from 0.01449 to 0.00975, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00975 to 0.00674, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 7: val_loss improved from 0.00674 to 0.00517, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00517 to 0.00440, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00440 to 0.00396, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00396 to 0.00361, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1572 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_786 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_262 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1573 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_787 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1574 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_788 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1575 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_524 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1576 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_525 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1577 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3176\n",
      "Epoch 1: val_loss improved from inf to 0.27698, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 455ms/step - loss: 0.3176 - val_loss: 0.2770\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1658\n",
      "Epoch 2: val_loss improved from 0.27698 to 0.06161, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 441ms/step - loss: 0.1658 - val_loss: 0.0616\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0450\n",
      "Epoch 3: val_loss improved from 0.06161 to 0.03222, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0450 - val_loss: 0.0322\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.03222 to 0.01842, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0234 - val_loss: 0.0184\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 5: val_loss improved from 0.01842 to 0.01226, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 6: val_loss improved from 0.01226 to 0.00903, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 7: val_loss improved from 0.00903 to 0.00734, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0077 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 8: val_loss improved from 0.00734 to 0.00604, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00604 to 0.00503, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00503 to 0.00439, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_263\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1578 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_789 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_263 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1579 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_790 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1580 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_791 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1581 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_526 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1582 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_527 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1583 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1853\n",
      "Epoch 1: val_loss improved from inf to 0.08804, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 440ms/step - loss: 0.1853 - val_loss: 0.0880\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0628\n",
      "Epoch 2: val_loss improved from 0.08804 to 0.04144, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0628 - val_loss: 0.0414\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0274\n",
      "Epoch 3: val_loss improved from 0.04144 to 0.02074, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0274 - val_loss: 0.0207\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0167\n",
      "Epoch 4: val_loss improved from 0.02074 to 0.01452, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0167 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01452 to 0.01059, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0119 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01059 to 0.00792, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0087 - val_loss: 0.0079\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 7: val_loss improved from 0.00792 to 0.00618, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00618 to 0.00508, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00508 to 0.00429, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00429 to 0.00376, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1584 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_792 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_264 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1585 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_793 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1586 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_794 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1587 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_528 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1588 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_529 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1589 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3099\n",
      "Epoch 1: val_loss improved from inf to 0.24934, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 434ms/step - loss: 0.3099 - val_loss: 0.2493\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1403\n",
      "Epoch 2: val_loss improved from 0.24934 to 0.07138, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.1403 - val_loss: 0.0714\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0513\n",
      "Epoch 3: val_loss improved from 0.07138 to 0.03145, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0513 - val_loss: 0.0315\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0206\n",
      "Epoch 4: val_loss improved from 0.03145 to 0.01553, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0206 - val_loss: 0.0155\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0123\n",
      "Epoch 5: val_loss improved from 0.01553 to 0.01074, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 6: val_loss improved from 0.01074 to 0.00831, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00831 to 0.00669, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 8: val_loss improved from 0.00669 to 0.00553, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00553 to 0.00470, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00470 to 0.00414, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_265\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1590 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_795 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_265 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1591 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_796 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1592 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_797 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1593 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_530 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1594 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_531 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1595 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3467\n",
      "Epoch 1: val_loss improved from inf to 0.23314, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 436ms/step - loss: 0.3467 - val_loss: 0.2331\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1099\n",
      "Epoch 2: val_loss improved from 0.23314 to 0.03787, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.1099 - val_loss: 0.0379\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 3: val_loss improved from 0.03787 to 0.02136, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0283 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 4: val_loss improved from 0.02136 to 0.01453, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 5: val_loss improved from 0.01453 to 0.01097, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.01097 to 0.00834, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00834 to 0.00667, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00667 to 0.00558, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00558 to 0.00478, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00478 to 0.00422, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_266\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1596 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_798 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_266 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1597 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_799 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1598 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_800 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1599 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_532 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1600 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_533 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1601 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3008\n",
      "Epoch 1: val_loss improved from inf to 0.20289, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 437ms/step - loss: 0.3008 - val_loss: 0.2029\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0993\n",
      "Epoch 2: val_loss improved from 0.20289 to 0.05824, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 429ms/step - loss: 0.0993 - val_loss: 0.0582\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0416\n",
      "Epoch 3: val_loss improved from 0.05824 to 0.02996, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0416 - val_loss: 0.0300\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0235\n",
      "Epoch 4: val_loss improved from 0.02996 to 0.02029, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0235 - val_loss: 0.0203\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0166\n",
      "Epoch 5: val_loss improved from 0.02029 to 0.01452, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0166 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 6: val_loss improved from 0.01452 to 0.01010, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 7: val_loss improved from 0.01010 to 0.00746, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 8: val_loss improved from 0.00746 to 0.00608, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00608 to 0.00517, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00517 to 0.00451, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_267\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1602 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_801 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_267 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1603 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_802 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1604 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_803 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1605 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_534 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1606 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_535 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1607 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2846\n",
      "Epoch 1: val_loss improved from inf to 0.21472, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 438ms/step - loss: 0.2846 - val_loss: 0.2147\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1096\n",
      "Epoch 2: val_loss improved from 0.21472 to 0.04757, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.1096 - val_loss: 0.0476\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0356\n",
      "Epoch 3: val_loss improved from 0.04757 to 0.02491, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0356 - val_loss: 0.0249\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 4: val_loss improved from 0.02491 to 0.01231, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 5: val_loss improved from 0.01231 to 0.00763, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 6: val_loss improved from 0.00763 to 0.00564, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 7: val_loss improved from 0.00564 to 0.00467, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 8: val_loss improved from 0.00467 to 0.00409, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00409 to 0.00366, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00366 to 0.00335, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_268\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1608 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_804 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_268 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1609 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_805 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1610 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_806 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1611 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_536 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1612 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_537 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1613 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2909\n",
      "Epoch 1: val_loss improved from inf to 0.22833, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 434ms/step - loss: 0.2909 - val_loss: 0.2283\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1290\n",
      "Epoch 2: val_loss improved from 0.22833 to 0.07015, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.1290 - val_loss: 0.0702\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0557\n",
      "Epoch 3: val_loss improved from 0.07015 to 0.04331, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0557 - val_loss: 0.0433\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 4: val_loss improved from 0.04331 to 0.02733, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0330 - val_loss: 0.0273\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 5: val_loss improved from 0.02733 to 0.01773, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0216 - val_loss: 0.0177\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 6: val_loss improved from 0.01773 to 0.01080, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0136 - val_loss: 0.0108\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 7: val_loss improved from 0.01080 to 0.00607, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00607 to 0.00440, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00440 to 0.00385, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00385 to 0.00354, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_269\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1614 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_807 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_269 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1615 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_808 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1616 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_809 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1617 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_538 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1618 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_539 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1619 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.2863\n",
      "Epoch 1: val_loss improved from inf to 0.19337, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 437ms/step - loss: 0.2863 - val_loss: 0.1934\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1115\n",
      "Epoch 2: val_loss improved from 0.19337 to 0.07687, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.1115 - val_loss: 0.0769\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0563\n",
      "Epoch 3: val_loss improved from 0.07687 to 0.04184, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0563 - val_loss: 0.0418\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 4: val_loss improved from 0.04184 to 0.02508, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0312 - val_loss: 0.0251\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 5: val_loss improved from 0.02508 to 0.01559, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0194 - val_loss: 0.0156\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 6: val_loss improved from 0.01559 to 0.00931, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00931 to 0.00660, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00660 to 0.00519, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00519 to 0.00434, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00434 to 0.00380, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_270\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1620 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_810 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_270 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1621 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_811 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1622 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_812 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1623 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_540 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1624 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_541 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1625 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3096\n",
      "Epoch 1: val_loss improved from inf to 0.24389, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 439ms/step - loss: 0.3096 - val_loss: 0.2439\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1361\n",
      "Epoch 2: val_loss improved from 0.24389 to 0.08304, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.1361 - val_loss: 0.0830\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0631\n",
      "Epoch 3: val_loss improved from 0.08304 to 0.04470, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0631 - val_loss: 0.0447\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0308\n",
      "Epoch 4: val_loss improved from 0.04470 to 0.02324, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0308 - val_loss: 0.0232\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 5: val_loss improved from 0.02324 to 0.01384, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0173 - val_loss: 0.0138\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 6: val_loss improved from 0.01384 to 0.00882, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00882 to 0.00633, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 433ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00633 to 0.00488, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00488 to 0.00417, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 429ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00417 to 0.00376, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_271\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1626 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_813 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_271 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1627 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_814 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1628 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_815 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1629 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_542 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1630 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_543 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1631 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3444\n",
      "Epoch 1: val_loss improved from inf to 0.32654, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 437ms/step - loss: 0.3444 - val_loss: 0.3265\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2190\n",
      "Epoch 2: val_loss improved from 0.32654 to 0.10013, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.2190 - val_loss: 0.1001\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0564\n",
      "Epoch 3: val_loss improved from 0.10013 to 0.04227, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0564 - val_loss: 0.0423\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0318\n",
      "Epoch 4: val_loss improved from 0.04227 to 0.02505, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0318 - val_loss: 0.0251\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0198\n",
      "Epoch 5: val_loss improved from 0.02505 to 0.01661, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0198 - val_loss: 0.0166\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 6: val_loss improved from 0.01661 to 0.01092, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 7: val_loss improved from 0.01092 to 0.00711, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0085 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 8: val_loss improved from 0.00711 to 0.00530, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0057 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00530 to 0.00450, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00450 to 0.00400, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 430ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_272\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1632 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_816 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_272 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1633 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_817 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1634 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_818 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1635 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_544 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1636 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_545 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1637 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.1847\n",
      "Epoch 1: val_loss improved from inf to 0.08064, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 437ms/step - loss: 0.1847 - val_loss: 0.0806\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0537\n",
      "Epoch 2: val_loss improved from 0.08064 to 0.04156, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0537 - val_loss: 0.0416\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0307\n",
      "Epoch 3: val_loss improved from 0.04156 to 0.02277, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 426ms/step - loss: 0.0307 - val_loss: 0.0228\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 4: val_loss improved from 0.02277 to 0.01381, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 440ms/step - loss: 0.0171 - val_loss: 0.0138\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01381 to 0.00906, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 430ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00906 to 0.00637, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 432ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00637 to 0.00505, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 433ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 8: val_loss improved from 0.00505 to 0.00443, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 434ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00443 to 0.00405, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 419ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00405 to 0.00376, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_273\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1638 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_819 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_273 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1639 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_820 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1640 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_821 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1641 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_546 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1642 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_547 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1643 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA: 0s - loss: 0.3134\n",
      "Epoch 1: val_loss improved from inf to 0.26327, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 434ms/step - loss: 0.3134 - val_loss: 0.2633\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 2: val_loss improved from 0.26327 to 0.06707, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1471 - val_loss: 0.0671\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0488\n",
      "Epoch 3: val_loss improved from 0.06707 to 0.03413, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0488 - val_loss: 0.0341\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0246\n",
      "Epoch 4: val_loss improved from 0.03413 to 0.01911, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0246 - val_loss: 0.0191\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 5: val_loss improved from 0.01911 to 0.01268, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0150 - val_loss: 0.0127\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 6: val_loss improved from 0.01268 to 0.00908, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00908 to 0.00715, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 8: val_loss improved from 0.00715 to 0.00602, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00602 to 0.00521, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 10: val_loss improved from 0.00521 to 0.00458, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 412ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_274\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1644 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_822 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_274 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1645 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_823 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1646 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_824 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1647 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_548 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1648 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_549 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1649 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/37 [============================>.] - ETA: 0s - loss: 0.1791\n",
      "Epoch 1: val_loss improved from inf to 0.07124, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 435ms/step - loss: 0.1788 - val_loss: 0.0712\n",
      "Epoch 2/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0502\n",
      "Epoch 2: val_loss improved from 0.07124 to 0.03822, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0502 - val_loss: 0.0382\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.0278\n",
      "Epoch 3: val_loss improved from 0.03822 to 0.02064, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 431ms/step - loss: 0.0278 - val_loss: 0.0206\n",
      "Epoch 4/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0160\n",
      "Epoch 4: val_loss improved from 0.02064 to 0.01351, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0160 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01351 to 0.00929, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00929 to 0.00736, saving model to best_weights.h5\n",
      "37/37 [==============================] - 18s 491ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00736 to 0.00612, saving model to best_weights.h5\n",
      "37/37 [==============================] - 19s 506ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00612 to 0.00517, saving model to best_weights.h5\n",
      "37/37 [==============================] - 18s 500ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00517 to 0.00441, saving model to best_weights.h5\n",
      "37/37 [==============================] - 18s 486ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00441 to 0.00387, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 452ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 93ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_275\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1650 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_825 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_275 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1651 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_826 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1652 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_827 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1653 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_550 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1654 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_551 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1655 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/37 [============================>.] - ETA: 0s - loss: 0.2144\n",
      "Epoch 1: val_loss improved from inf to 0.10209, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 433ms/step - loss: 0.2142 - val_loss: 0.1021\n",
      "Epoch 2/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0632\n",
      "Epoch 2: val_loss improved from 0.10209 to 0.04428, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0632 - val_loss: 0.0443\n",
      "Epoch 3/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0308\n",
      "Epoch 3: val_loss improved from 0.04428 to 0.02223, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 420ms/step - loss: 0.0308 - val_loss: 0.0222\n",
      "Epoch 4/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0170\n",
      "Epoch 4: val_loss improved from 0.02223 to 0.01388, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0170 - val_loss: 0.0139\n",
      "Epoch 5/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01388 to 0.00923, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0075\n",
      "Epoch 6: val_loss improved from 0.00923 to 0.00685, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 7/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00685 to 0.00553, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00553 to 0.00471, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00471 to 0.00414, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 410ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00414 to 0.00372, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_276\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1656 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_828 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_276 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1657 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_829 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1658 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_830 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1659 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_552 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1660 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_553 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1661 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/37 [============================>.] - ETA: 0s - loss: 0.3180\n",
      "Epoch 1: val_loss improved from inf to 0.26535, saving model to best_weights.h5\n",
      "37/37 [==============================] - 17s 437ms/step - loss: 0.3179 - val_loss: 0.2653\n",
      "Epoch 2/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.1549\n",
      "Epoch 2: val_loss improved from 0.26535 to 0.04822, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1548 - val_loss: 0.0482\n",
      "Epoch 3/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0370\n",
      "Epoch 3: val_loss improved from 0.04822 to 0.02777, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 424ms/step - loss: 0.0370 - val_loss: 0.0278\n",
      "Epoch 4/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0217\n",
      "Epoch 4: val_loss improved from 0.02777 to 0.01820, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 425ms/step - loss: 0.0217 - val_loss: 0.0182\n",
      "Epoch 5/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0145\n",
      "Epoch 5: val_loss improved from 0.01820 to 0.01249, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 422ms/step - loss: 0.0145 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0102\n",
      "Epoch 6: val_loss improved from 0.01249 to 0.00915, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00915 to 0.00689, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00689 to 0.00543, saving model to best_weights.h5\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00543 to 0.00447, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 428ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00447 to 0.00390, saving model to best_weights.h5\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_277\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1662 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_831 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_277 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1663 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_832 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1664 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_833 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1665 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_554 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1666 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_555 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1667 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2674\n",
      "Epoch 1: val_loss improved from inf to 0.20161, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 456ms/step - loss: 0.2674 - val_loss: 0.2016\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1075\n",
      "Epoch 2: val_loss improved from 0.20161 to 0.06796, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.1075 - val_loss: 0.0680\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0501\n",
      "Epoch 3: val_loss improved from 0.06796 to 0.03874, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0501 - val_loss: 0.0387\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0282\n",
      "Epoch 4: val_loss improved from 0.03874 to 0.02194, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0282 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0169\n",
      "Epoch 5: val_loss improved from 0.02194 to 0.01403, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0169 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 6: val_loss improved from 0.01403 to 0.00954, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 7: val_loss improved from 0.00954 to 0.00749, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 8: val_loss improved from 0.00749 to 0.00616, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00616 to 0.00513, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00513 to 0.00429, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_278\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1668 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_834 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_278 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1669 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_835 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1670 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_836 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1671 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_556 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1672 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_557 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1673 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2294\n",
      "Epoch 1: val_loss improved from inf to 0.12922, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 451ms/step - loss: 0.2294 - val_loss: 0.1292\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0781\n",
      "Epoch 2: val_loss improved from 0.12922 to 0.06287, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0781 - val_loss: 0.0629\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0506\n",
      "Epoch 3: val_loss improved from 0.06287 to 0.04144, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0506 - val_loss: 0.0414\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0306\n",
      "Epoch 4: val_loss improved from 0.04144 to 0.02338, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0306 - val_loss: 0.0234\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 5: val_loss improved from 0.02338 to 0.01538, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0182 - val_loss: 0.0154\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 6: val_loss improved from 0.01538 to 0.01007, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 7: val_loss improved from 0.01007 to 0.00665, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00665 to 0.00508, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 440ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00508 to 0.00436, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 432ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00436 to 0.00394, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_279\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1674 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_837 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_279 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1675 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_838 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1676 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_839 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1677 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_558 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1678 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_559 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1679 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2933\n",
      "Epoch 1: val_loss improved from inf to 0.23495, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 447ms/step - loss: 0.2933 - val_loss: 0.2350\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1278\n",
      "Epoch 2: val_loss improved from 0.23495 to 0.05808, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.1278 - val_loss: 0.0581\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0446\n",
      "Epoch 3: val_loss improved from 0.05808 to 0.03312, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0446 - val_loss: 0.0331\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.03312 to 0.01704, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0233 - val_loss: 0.0170\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 5: val_loss improved from 0.01704 to 0.00918, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 6: val_loss improved from 0.00918 to 0.00644, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 7: val_loss improved from 0.00644 to 0.00509, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00509 to 0.00423, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 9: val_loss improved from 0.00423 to 0.00373, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 10: val_loss improved from 0.00373 to 0.00341, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_280\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1680 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_840 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_280 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1681 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_841 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1682 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_842 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1683 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_560 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1684 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_561 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1685 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2156\n",
      "Epoch 1: val_loss improved from inf to 0.12562, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 443ms/step - loss: 0.2156 - val_loss: 0.1256\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0856\n",
      "Epoch 2: val_loss improved from 0.12562 to 0.06647, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0856 - val_loss: 0.0665\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0466\n",
      "Epoch 3: val_loss improved from 0.06647 to 0.03263, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0466 - val_loss: 0.0326\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0236\n",
      "Epoch 4: val_loss improved from 0.03263 to 0.01763, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0236 - val_loss: 0.0176\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 5: val_loss improved from 0.01763 to 0.01047, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0129 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 6: val_loss improved from 0.01047 to 0.00745, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 7: val_loss improved from 0.00745 to 0.00579, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00579 to 0.00479, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00479 to 0.00419, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00419 to 0.00381, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 438ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_281\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1686 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_843 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_281 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1687 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_844 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1688 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_845 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1689 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_562 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1690 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_563 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1691 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3000\n",
      "Epoch 1: val_loss improved from inf to 0.24651, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 451ms/step - loss: 0.3000 - val_loss: 0.2465\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1357\n",
      "Epoch 2: val_loss improved from 0.24651 to 0.04814, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.1357 - val_loss: 0.0481\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0343\n",
      "Epoch 3: val_loss improved from 0.04814 to 0.02093, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0343 - val_loss: 0.0209\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 4: val_loss improved from 0.02093 to 0.01109, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.0139 - val_loss: 0.0111\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 5: val_loss improved from 0.01109 to 0.00831, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 6: val_loss improved from 0.00831 to 0.00651, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 7: val_loss improved from 0.00651 to 0.00529, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 8: val_loss improved from 0.00529 to 0.00443, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00443 to 0.00383, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00383 to 0.00344, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 441ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_282\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1692 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_846 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_282 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1693 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_847 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1694 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_848 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1695 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_564 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1696 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_565 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1697 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2554\n",
      "Epoch 1: val_loss improved from inf to 0.17349, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 451ms/step - loss: 0.2554 - val_loss: 0.1735\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1005\n",
      "Epoch 2: val_loss improved from 0.17349 to 0.06771, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.1005 - val_loss: 0.0677\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0502\n",
      "Epoch 3: val_loss improved from 0.06771 to 0.03812, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0502 - val_loss: 0.0381\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0274\n",
      "Epoch 4: val_loss improved from 0.03812 to 0.02005, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 435ms/step - loss: 0.0274 - val_loss: 0.0200\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 5: val_loss improved from 0.02005 to 0.01143, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0145 - val_loss: 0.0114\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01143 to 0.00749, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 7: val_loss improved from 0.00749 to 0.00565, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 8: val_loss improved from 0.00565 to 0.00469, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 9: val_loss improved from 0.00469 to 0.00404, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00404 to 0.00361, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_283\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1698 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_849 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_283 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1699 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_850 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1700 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_851 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1701 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_566 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1702 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_567 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1703 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2131\n",
      "Epoch 1: val_loss improved from inf to 0.10979, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 446ms/step - loss: 0.2131 - val_loss: 0.1098\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0703\n",
      "Epoch 2: val_loss improved from 0.10979 to 0.05216, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0703 - val_loss: 0.0522\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0368\n",
      "Epoch 3: val_loss improved from 0.05216 to 0.02871, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0368 - val_loss: 0.0287\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0232\n",
      "Epoch 4: val_loss improved from 0.02871 to 0.01998, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0232 - val_loss: 0.0200\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 5: val_loss improved from 0.01998 to 0.01396, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 435ms/step - loss: 0.0161 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 6: val_loss improved from 0.01396 to 0.01011, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 7: val_loss improved from 0.01011 to 0.00773, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 8: val_loss improved from 0.00773 to 0.00619, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00619 to 0.00519, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 10: val_loss improved from 0.00519 to 0.00454, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_284\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1704 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_852 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_284 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1705 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_853 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1706 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_854 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1707 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_568 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1708 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_569 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1709 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3207\n",
      "Epoch 1: val_loss improved from inf to 0.27901, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 444ms/step - loss: 0.3207 - val_loss: 0.2790\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1707\n",
      "Epoch 2: val_loss improved from 0.27901 to 0.07451, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 440ms/step - loss: 0.1707 - val_loss: 0.0745\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0561\n",
      "Epoch 3: val_loss improved from 0.07451 to 0.04222, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0561 - val_loss: 0.0422\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 4: val_loss improved from 0.04222 to 0.02288, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0302 - val_loss: 0.0229\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0175\n",
      "Epoch 5: val_loss improved from 0.02288 to 0.01447, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0175 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 6: val_loss improved from 0.01447 to 0.00925, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 7: val_loss improved from 0.00925 to 0.00626, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00626 to 0.00504, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00504 to 0.00428, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00428 to 0.00374, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_285\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1710 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_855 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_285 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1711 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_856 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1712 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_857 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1713 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_570 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1714 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_571 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1715 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2192\n",
      "Epoch 1: val_loss improved from inf to 0.10105, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 440ms/step - loss: 0.2192 - val_loss: 0.1010\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0606\n",
      "Epoch 2: val_loss improved from 0.10105 to 0.04518, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0606 - val_loss: 0.0452\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0339\n",
      "Epoch 3: val_loss improved from 0.04518 to 0.02660, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0339 - val_loss: 0.0266\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0203\n",
      "Epoch 4: val_loss improved from 0.02660 to 0.01635, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0203 - val_loss: 0.0164\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01635 to 0.01067, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 419ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 6: val_loss improved from 0.01067 to 0.00779, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00779 to 0.00615, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00615 to 0.00515, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00515 to 0.00447, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00447 to 0.00399, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_286\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1716 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_858 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_286 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1717 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_859 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1718 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_860 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1719 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_572 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1720 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_573 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1721 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2876\n",
      "Epoch 1: val_loss improved from inf to 0.21819, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 448ms/step - loss: 0.2876 - val_loss: 0.2182\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1209\n",
      "Epoch 2: val_loss improved from 0.21819 to 0.06073, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 482ms/step - loss: 0.1209 - val_loss: 0.0607\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0459\n",
      "Epoch 3: val_loss improved from 0.06073 to 0.03262, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0459 - val_loss: 0.0326\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 4: val_loss improved from 0.03262 to 0.01886, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0237 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 5: val_loss improved from 0.01886 to 0.01257, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0149 - val_loss: 0.0126\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 6: val_loss improved from 0.01257 to 0.00867, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 7: val_loss improved from 0.00867 to 0.00676, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 445ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00676 to 0.00566, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00566 to 0.00489, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00489 to 0.00434, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 78ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_287\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1722 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_861 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_287 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1723 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_862 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1724 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_863 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1725 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_574 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1726 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_575 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1727 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2702\n",
      "Epoch 1: val_loss improved from inf to 0.17510, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 452ms/step - loss: 0.2702 - val_loss: 0.1751\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0774\n",
      "Epoch 2: val_loss improved from 0.17510 to 0.03258, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0774 - val_loss: 0.0326\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 3: val_loss improved from 0.03258 to 0.02017, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0251 - val_loss: 0.0202\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0162\n",
      "Epoch 4: val_loss improved from 0.02017 to 0.01435, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0162 - val_loss: 0.0143\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 5: val_loss improved from 0.01435 to 0.01050, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 6: val_loss improved from 0.01050 to 0.00800, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0087 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 7: val_loss improved from 0.00800 to 0.00610, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00610 to 0.00468, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 442ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 9: val_loss improved from 0.00468 to 0.00385, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 435ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00385 to 0.00334, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_288\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1728 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_864 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_288 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1729 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_865 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1730 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_866 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1731 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_576 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1732 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_577 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1733 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3384\n",
      "Epoch 1: val_loss improved from inf to 0.30910, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 443ms/step - loss: 0.3384 - val_loss: 0.3091\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2189\n",
      "Epoch 2: val_loss improved from 0.30910 to 0.12213, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 435ms/step - loss: 0.2189 - val_loss: 0.1221\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0849\n",
      "Epoch 3: val_loss improved from 0.12213 to 0.06512, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0849 - val_loss: 0.0651\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0454\n",
      "Epoch 4: val_loss improved from 0.06512 to 0.03126, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0454 - val_loss: 0.0313\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 5: val_loss improved from 0.03126 to 0.01837, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0228 - val_loss: 0.0184\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 6: val_loss improved from 0.01837 to 0.01152, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0139 - val_loss: 0.0115\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 7: val_loss improved from 0.01152 to 0.00836, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 8: val_loss improved from 0.00836 to 0.00675, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 438ms/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 9: val_loss improved from 0.00675 to 0.00570, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 10: val_loss improved from 0.00570 to 0.00495, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_289\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1734 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_867 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_289 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1735 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_868 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1736 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_869 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1737 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_578 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1738 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_579 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1739 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2901\n",
      "Epoch 1: val_loss improved from inf to 0.21817, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 449ms/step - loss: 0.2901 - val_loss: 0.2182\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1187\n",
      "Epoch 2: val_loss improved from 0.21817 to 0.06776, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.1187 - val_loss: 0.0678\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0521\n",
      "Epoch 3: val_loss improved from 0.06776 to 0.03941, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 419ms/step - loss: 0.0521 - val_loss: 0.0394\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0287\n",
      "Epoch 4: val_loss improved from 0.03941 to 0.02282, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0287 - val_loss: 0.0228\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Epoch 5: val_loss improved from 0.02282 to 0.01448, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0176 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 6: val_loss improved from 0.01448 to 0.00998, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 7: val_loss improved from 0.00998 to 0.00761, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0083 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 8: val_loss improved from 0.00761 to 0.00601, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00601 to 0.00500, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00500 to 0.00435, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_290\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1740 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_870 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_290 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1741 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_871 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1742 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_872 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1743 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_580 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1744 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_581 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1745 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3111\n",
      "Epoch 1: val_loss improved from inf to 0.23091, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 443ms/step - loss: 0.3111 - val_loss: 0.2309\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1222\n",
      "Epoch 2: val_loss improved from 0.23091 to 0.06753, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.1222 - val_loss: 0.0675\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0531\n",
      "Epoch 3: val_loss improved from 0.06753 to 0.04213, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0531 - val_loss: 0.0421\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 4: val_loss improved from 0.04213 to 0.02006, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0294 - val_loss: 0.0201\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 5: val_loss improved from 0.02006 to 0.01166, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0146 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.01166 to 0.00805, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0092 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00805 to 0.00621, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00621 to 0.00502, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00502 to 0.00432, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00432 to 0.00388, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_291\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1746 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_873 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_291 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1747 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_874 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1748 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_875 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1749 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_582 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1750 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_583 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1751 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3425\n",
      "Epoch 1: val_loss improved from inf to 0.32451, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 447ms/step - loss: 0.3425 - val_loss: 0.3245\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2470\n",
      "Epoch 2: val_loss improved from 0.32451 to 0.15164, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.2470 - val_loss: 0.1516\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0741\n",
      "Epoch 3: val_loss improved from 0.15164 to 0.04108, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0741 - val_loss: 0.0411\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 4: val_loss improved from 0.04108 to 0.01659, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0252 - val_loss: 0.0166\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 5: val_loss improved from 0.01659 to 0.01074, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 6: val_loss improved from 0.01074 to 0.00826, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0089 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00826 to 0.00690, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00690 to 0.00596, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00596 to 0.00522, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 10: val_loss improved from 0.00522 to 0.00460, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_292\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1752 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_876 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_292 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1753 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_877 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1754 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_878 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1755 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_584 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1756 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_585 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1757 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3508\n",
      "Epoch 1: val_loss improved from inf to 0.30242, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 441ms/step - loss: 0.3508 - val_loss: 0.3024\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2007\n",
      "Epoch 2: val_loss improved from 0.30242 to 0.08486, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.2007 - val_loss: 0.0849\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0573\n",
      "Epoch 3: val_loss improved from 0.08486 to 0.04415, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0573 - val_loss: 0.0441\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 4: val_loss improved from 0.04415 to 0.02477, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0316 - val_loss: 0.0248\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 5: val_loss improved from 0.02477 to 0.01742, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 444ms/step - loss: 0.0202 - val_loss: 0.0174\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 6: val_loss improved from 0.01742 to 0.01141, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0137 - val_loss: 0.0114\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 7: val_loss improved from 0.01141 to 0.00787, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 8: val_loss improved from 0.00787 to 0.00609, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00609 to 0.00509, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00509 to 0.00447, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_293\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1758 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_879 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_293 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1759 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_880 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1760 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_881 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1761 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_586 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1762 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_587 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1763 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3454\n",
      "Epoch 1: val_loss improved from inf to 0.34124, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 442ms/step - loss: 0.3454 - val_loss: 0.3412\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2854\n",
      "Epoch 2: val_loss improved from 0.34124 to 0.22474, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.2854 - val_loss: 0.2247\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1121\n",
      "Epoch 3: val_loss improved from 0.22474 to 0.04571, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.1121 - val_loss: 0.0457\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0298\n",
      "Epoch 4: val_loss improved from 0.04571 to 0.01933, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.0298 - val_loss: 0.0193\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0140\n",
      "Epoch 5: val_loss improved from 0.01933 to 0.01133, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 438ms/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 6: val_loss improved from 0.01133 to 0.00848, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0093 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 7: val_loss improved from 0.00848 to 0.00684, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 8: val_loss improved from 0.00684 to 0.00574, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00574 to 0.00492, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00492 to 0.00429, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_294\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1764 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_882 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_294 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1765 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_883 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1766 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_884 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1767 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_588 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1768 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_589 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1769 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2813\n",
      "Epoch 1: val_loss improved from inf to 0.20713, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 448ms/step - loss: 0.2813 - val_loss: 0.2071\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1221\n",
      "Epoch 2: val_loss improved from 0.20713 to 0.07913, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.1221 - val_loss: 0.0791\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0626\n",
      "Epoch 3: val_loss improved from 0.07913 to 0.04943, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0626 - val_loss: 0.0494\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0354\n",
      "Epoch 4: val_loss improved from 0.04943 to 0.02576, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0354 - val_loss: 0.0258\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0201\n",
      "Epoch 5: val_loss improved from 0.02576 to 0.01711, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 435ms/step - loss: 0.0201 - val_loss: 0.0171\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 6: val_loss improved from 0.01711 to 0.01120, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 7: val_loss improved from 0.01120 to 0.00768, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 8: val_loss improved from 0.00768 to 0.00585, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00585 to 0.00480, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00480 to 0.00413, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_295\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1770 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_885 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_295 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1771 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_886 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1772 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_887 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1773 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_590 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1774 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_591 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1775 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2852\n",
      "Epoch 1: val_loss improved from inf to 0.23239, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 443ms/step - loss: 0.2852 - val_loss: 0.2324\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1174\n",
      "Epoch 2: val_loss improved from 0.23239 to 0.04979, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.1174 - val_loss: 0.0498\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0326\n",
      "Epoch 3: val_loss improved from 0.04979 to 0.02378, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0326 - val_loss: 0.0238\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 4: val_loss improved from 0.02378 to 0.01601, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 418ms/step - loss: 0.0188 - val_loss: 0.0160\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0131\n",
      "Epoch 5: val_loss improved from 0.01601 to 0.01155, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01155 to 0.00878, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00878 to 0.00682, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 8: val_loss improved from 0.00682 to 0.00544, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0057 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00544 to 0.00463, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00463 to 0.00405, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_296\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1776 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_888 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_296 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1777 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_889 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1778 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_890 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1779 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_592 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1780 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_593 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1781 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2911\n",
      "Epoch 1: val_loss improved from inf to 0.21790, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 438ms/step - loss: 0.2911 - val_loss: 0.2179\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1242\n",
      "Epoch 2: val_loss improved from 0.21790 to 0.06850, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.1242 - val_loss: 0.0685\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0537\n",
      "Epoch 3: val_loss improved from 0.06850 to 0.04136, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0537 - val_loss: 0.0414\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 4: val_loss improved from 0.04136 to 0.02316, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0299 - val_loss: 0.0232\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 5: val_loss improved from 0.02316 to 0.01524, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0183 - val_loss: 0.0152\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 6: val_loss improved from 0.01524 to 0.00964, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0118 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00964 to 0.00673, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00673 to 0.00505, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00505 to 0.00420, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00420 to 0.00373, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_297\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1782 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_891 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_297 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1783 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_892 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1784 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_893 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1785 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_594 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1786 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_595 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1787 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3197\n",
      "Epoch 1: val_loss improved from inf to 0.28970, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 445ms/step - loss: 0.3197 - val_loss: 0.2897\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2070\n",
      "Epoch 2: val_loss improved from 0.28970 to 0.11681, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.2070 - val_loss: 0.1168\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0714\n",
      "Epoch 3: val_loss improved from 0.11681 to 0.05473, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0714 - val_loss: 0.0547\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0418\n",
      "Epoch 4: val_loss improved from 0.05473 to 0.03184, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0418 - val_loss: 0.0318\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0226\n",
      "Epoch 5: val_loss improved from 0.03184 to 0.01673, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0226 - val_loss: 0.0167\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 6: val_loss improved from 0.01673 to 0.01018, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0124 - val_loss: 0.0102\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 7: val_loss improved from 0.01018 to 0.00718, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00718 to 0.00588, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00588 to 0.00497, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 445ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00497 to 0.00429, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 462ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_298\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1788 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_894 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_298 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1789 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_895 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1790 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_896 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1791 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_596 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1792 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_597 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1793 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.1875\n",
      "Epoch 1: val_loss improved from inf to 0.10428, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 441ms/step - loss: 0.1875 - val_loss: 0.1043\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0709\n",
      "Epoch 2: val_loss improved from 0.10428 to 0.05436, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 440ms/step - loss: 0.0709 - val_loss: 0.0544\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 3: val_loss improved from 0.05436 to 0.02595, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0386 - val_loss: 0.0259\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0178\n",
      "Epoch 4: val_loss improved from 0.02595 to 0.01362, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 442ms/step - loss: 0.0178 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 5: val_loss improved from 0.01362 to 0.00908, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 439ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 6: val_loss improved from 0.00908 to 0.00651, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 442ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 7: val_loss improved from 0.00651 to 0.00498, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00498 to 0.00417, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 9: val_loss improved from 0.00417 to 0.00359, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 10: val_loss improved from 0.00359 to 0.00316, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "finished training\n",
      "15/15 [==============================] - 1s 65ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_299\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1794 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_897 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_299 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1795 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_898 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1796 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_899 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1797 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_598 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1798 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_599 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1799 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2459\n",
      "Epoch 1: val_loss improved from inf to 0.16302, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 439ms/step - loss: 0.2459 - val_loss: 0.1630\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0865\n",
      "Epoch 2: val_loss improved from 0.16302 to 0.05049, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0865 - val_loss: 0.0505\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Epoch 3: val_loss improved from 0.05049 to 0.02940, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 437ms/step - loss: 0.0363 - val_loss: 0.0294\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0232\n",
      "Epoch 4: val_loss improved from 0.02940 to 0.01917, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0232 - val_loss: 0.0192\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 5: val_loss improved from 0.01917 to 0.01250, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0149 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 6: val_loss improved from 0.01250 to 0.00885, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00885 to 0.00684, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00684 to 0.00543, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00543 to 0.00453, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00453 to 0.00391, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_300\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1800 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_900 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_300 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1801 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_901 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1802 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_902 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1803 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_600 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1804 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_601 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1805 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2354\n",
      "Epoch 1: val_loss improved from inf to 0.14001, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 440ms/step - loss: 0.2354 - val_loss: 0.1400\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0851\n",
      "Epoch 2: val_loss improved from 0.14001 to 0.06782, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0851 - val_loss: 0.0678\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0541\n",
      "Epoch 3: val_loss improved from 0.06782 to 0.04226, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0541 - val_loss: 0.0423\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 4: val_loss improved from 0.04226 to 0.01992, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0286 - val_loss: 0.0199\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 5: val_loss improved from 0.01992 to 0.01199, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 6: val_loss improved from 0.01199 to 0.00821, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0095 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 7: val_loss improved from 0.00821 to 0.00621, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00621 to 0.00506, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 418ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00506 to 0.00442, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00442 to 0.00397, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_301\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1806 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_903 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_301 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1807 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_904 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1808 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_905 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1809 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_602 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1810 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_603 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1811 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2674\n",
      "Epoch 1: val_loss improved from inf to 0.18295, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 441ms/step - loss: 0.2674 - val_loss: 0.1829\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1095\n",
      "Epoch 2: val_loss improved from 0.18295 to 0.08006, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.1095 - val_loss: 0.0801\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0564\n",
      "Epoch 3: val_loss improved from 0.08006 to 0.03795, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0564 - val_loss: 0.0380\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 4: val_loss improved from 0.03795 to 0.02091, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0273 - val_loss: 0.0209\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 5: val_loss improved from 0.02091 to 0.01255, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01255 to 0.00820, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00820 to 0.00605, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00605 to 0.00485, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00485 to 0.00410, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00410 to 0.00362, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_302\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1812 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_906 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_302 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1813 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_907 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1814 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_908 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1815 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_604 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1816 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_605 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1817 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2498\n",
      "Epoch 1: val_loss improved from inf to 0.13592, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 444ms/step - loss: 0.2498 - val_loss: 0.1359\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0750\n",
      "Epoch 2: val_loss improved from 0.13592 to 0.05383, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0750 - val_loss: 0.0538\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0389\n",
      "Epoch 3: val_loss improved from 0.05383 to 0.02819, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0389 - val_loss: 0.0282\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0218\n",
      "Epoch 4: val_loss improved from 0.02819 to 0.01841, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0218 - val_loss: 0.0184\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 5: val_loss improved from 0.01841 to 0.01275, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0148 - val_loss: 0.0128\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 6: val_loss improved from 0.01275 to 0.00918, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 7: val_loss improved from 0.00918 to 0.00677, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00677 to 0.00512, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00512 to 0.00410, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00410 to 0.00352, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_303\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1818 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_909 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_303 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1819 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_910 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1820 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_911 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1821 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_606 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1822 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_607 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1823 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2819\n",
      "Epoch 1: val_loss improved from inf to 0.20468, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 444ms/step - loss: 0.2819 - val_loss: 0.2047\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0923\n",
      "Epoch 2: val_loss improved from 0.20468 to 0.03892, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0923 - val_loss: 0.0389\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 3: val_loss improved from 0.03892 to 0.01465, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0228 - val_loss: 0.0147\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 4: val_loss improved from 0.01465 to 0.00961, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 419ms/step - loss: 0.0114 - val_loss: 0.0096\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00961 to 0.00700, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 6: val_loss improved from 0.00700 to 0.00547, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 7: val_loss improved from 0.00547 to 0.00439, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 435ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 8: val_loss improved from 0.00439 to 0.00373, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0033\n",
      "Epoch 9: val_loss improved from 0.00373 to 0.00333, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 10: val_loss improved from 0.00333 to 0.00306, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_304\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1824 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_912 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_304 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1825 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_913 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1826 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_914 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1827 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_608 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1828 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_609 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1829 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.2600\n",
      "Epoch 1: val_loss improved from inf to 0.17898, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 455ms/step - loss: 0.2600 - val_loss: 0.1790\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1040\n",
      "Epoch 2: val_loss improved from 0.17898 to 0.07247, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.1040 - val_loss: 0.0725\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0545\n",
      "Epoch 3: val_loss improved from 0.07247 to 0.03933, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 420ms/step - loss: 0.0545 - val_loss: 0.0393\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 4: val_loss improved from 0.03933 to 0.01959, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0268 - val_loss: 0.0196\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0145\n",
      "Epoch 5: val_loss improved from 0.01959 to 0.01160, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 6: val_loss improved from 0.01160 to 0.00805, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 419ms/step - loss: 0.0092 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00805 to 0.00614, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00614 to 0.00500, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00500 to 0.00428, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00428 to 0.00385, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_305\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1830 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_915 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_305 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1831 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_916 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1832 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_917 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1833 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_610 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1834 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_611 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1835 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.3215\n",
      "Epoch 1: val_loss improved from inf to 0.27949, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 449ms/step - loss: 0.3215 - val_loss: 0.2795\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1766\n",
      "Epoch 2: val_loss improved from 0.27949 to 0.08969, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.1766 - val_loss: 0.0897\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0722\n",
      "Epoch 3: val_loss improved from 0.08969 to 0.05813, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 427ms/step - loss: 0.0722 - val_loss: 0.0581\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 4: val_loss improved from 0.05813 to 0.03140, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0422 - val_loss: 0.0314\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0243\n",
      "Epoch 5: val_loss improved from 0.03140 to 0.02004, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0243 - val_loss: 0.0200\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 6: val_loss improved from 0.02004 to 0.01258, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0155 - val_loss: 0.0126\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 7: val_loss improved from 0.01258 to 0.00798, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0096 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 8: val_loss improved from 0.00798 to 0.00580, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00580 to 0.00469, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00469 to 0.00402, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_306\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1836 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_918 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_306 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1837 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_919 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1838 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_920 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1839 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_612 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1840 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_613 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1841 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - ETA: 0s - loss: 0.1493\n",
      "Epoch 1: val_loss improved from inf to 0.06916, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 445ms/step - loss: 0.1493 - val_loss: 0.0692\n",
      "Epoch 2/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0520\n",
      "Epoch 2: val_loss improved from 0.06916 to 0.03793, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0520 - val_loss: 0.0379\n",
      "Epoch 3/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0276\n",
      "Epoch 3: val_loss improved from 0.03793 to 0.02115, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0276 - val_loss: 0.0212\n",
      "Epoch 4/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0163\n",
      "Epoch 4: val_loss improved from 0.02115 to 0.01356, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 434ms/step - loss: 0.0163 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01356 to 0.00928, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 431ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0077\n",
      "Epoch 6: val_loss improved from 0.00928 to 0.00703, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0058\n",
      "Epoch 7: val_loss improved from 0.00703 to 0.00536, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 8/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0045\n",
      "Epoch 8: val_loss improved from 0.00536 to 0.00435, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00435 to 0.00380, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 421ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00380 to 0.00347, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_307\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1842 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_921 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_307 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1843 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_922 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1844 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_923 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1845 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_614 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1846 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_615 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1847 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/36 [============================>.] - ETA: 0s - loss: 0.2969\n",
      "Epoch 1: val_loss improved from inf to 0.22175, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 445ms/step - loss: 0.2968 - val_loss: 0.2217\n",
      "Epoch 2/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.1102\n",
      "Epoch 2: val_loss improved from 0.22175 to 0.06066, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.1101 - val_loss: 0.0607\n",
      "Epoch 3/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0443\n",
      "Epoch 3: val_loss improved from 0.06066 to 0.03274, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 419ms/step - loss: 0.0442 - val_loss: 0.0327\n",
      "Epoch 4/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0245\n",
      "Epoch 4: val_loss improved from 0.03274 to 0.02038, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0245 - val_loss: 0.0204\n",
      "Epoch 5/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0165\n",
      "Epoch 5: val_loss improved from 0.02038 to 0.01404, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 425ms/step - loss: 0.0165 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0113\n",
      "Epoch 6: val_loss improved from 0.01404 to 0.00969, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0078\n",
      "Epoch 7: val_loss improved from 0.00969 to 0.00702, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 423ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 8: val_loss improved from 0.00702 to 0.00551, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 424ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00551 to 0.00465, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 428ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00465 to 0.00409, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_308\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1848 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_924 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_308 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1849 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_925 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1850 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_926 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1851 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_616 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1852 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_617 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1853 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/36 [============================>.] - ETA: 0s - loss: 0.1851\n",
      "Epoch 1: val_loss improved from inf to 0.07792, saving model to best_weights.h5\n",
      "36/36 [==============================] - 17s 449ms/step - loss: 0.1850 - val_loss: 0.0779\n",
      "Epoch 2/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0473\n",
      "Epoch 2: val_loss improved from 0.07792 to 0.03482, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0473 - val_loss: 0.0348\n",
      "Epoch 3/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0256\n",
      "Epoch 3: val_loss improved from 0.03482 to 0.01967, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0256 - val_loss: 0.0197\n",
      "Epoch 4/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0156\n",
      "Epoch 4: val_loss improved from 0.01967 to 0.01346, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0156 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01346 to 0.00952, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 426ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0078\n",
      "Epoch 6: val_loss improved from 0.00952 to 0.00705, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 430ms/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0059\n",
      "Epoch 7: val_loss improved from 0.00705 to 0.00548, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 433ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00548 to 0.00446, saving model to best_weights.h5\n",
      "36/36 [==============================] - 16s 432ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 9/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0039\n",
      "Epoch 9: val_loss improved from 0.00446 to 0.00383, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 422ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "35/36 [============================>.] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00383 to 0.00343, saving model to best_weights.h5\n",
      "36/36 [==============================] - 15s 429ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_309\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1854 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_927 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_309 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1855 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_928 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1856 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_929 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1857 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_618 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1858 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_619 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1859 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3557\n",
      "Epoch 1: val_loss improved from inf to 0.31688, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 453ms/step - loss: 0.3557 - val_loss: 0.3169\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.2469\n",
      "Epoch 2: val_loss improved from 0.31688 to 0.17122, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.2469 - val_loss: 0.1712\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0843\n",
      "Epoch 3: val_loss improved from 0.17122 to 0.05183, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0843 - val_loss: 0.0518\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 4: val_loss improved from 0.05183 to 0.03033, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 444ms/step - loss: 0.0386 - val_loss: 0.0303\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0230\n",
      "Epoch 5: val_loss improved from 0.03033 to 0.01922, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 443ms/step - loss: 0.0230 - val_loss: 0.0192\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 6: val_loss improved from 0.01922 to 0.01335, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0155 - val_loss: 0.0133\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 7: val_loss improved from 0.01335 to 0.00930, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 8: val_loss improved from 0.00930 to 0.00719, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 443ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 9: val_loss improved from 0.00719 to 0.00569, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 10: val_loss improved from 0.00569 to 0.00469, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_310\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1860 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_930 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_310 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1861 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_931 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1862 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_932 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1863 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_620 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1864 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_621 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1865 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2452\n",
      "Epoch 1: val_loss improved from inf to 0.15056, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 456ms/step - loss: 0.2452 - val_loss: 0.1506\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0786\n",
      "Epoch 2: val_loss improved from 0.15056 to 0.05077, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.0786 - val_loss: 0.0508\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0345\n",
      "Epoch 3: val_loss improved from 0.05077 to 0.02317, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.0345 - val_loss: 0.0232\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 4: val_loss improved from 0.02317 to 0.01350, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0168 - val_loss: 0.0135\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 5: val_loss improved from 0.01350 to 0.00957, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 6: val_loss improved from 0.00957 to 0.00752, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 443ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00752 to 0.00610, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 458ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00610 to 0.00500, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 449ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00500 to 0.00426, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00426 to 0.00375, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_311\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1866 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_933 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_311 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1867 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_934 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1868 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_935 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1869 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_622 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1870 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_623 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1871 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2745\n",
      "Epoch 1: val_loss improved from inf to 0.21024, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 456ms/step - loss: 0.2745 - val_loss: 0.2102\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1165\n",
      "Epoch 2: val_loss improved from 0.21024 to 0.06326, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.1165 - val_loss: 0.0633\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0528\n",
      "Epoch 3: val_loss improved from 0.06326 to 0.04376, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0528 - val_loss: 0.0438\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0332\n",
      "Epoch 4: val_loss improved from 0.04376 to 0.02726, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0332 - val_loss: 0.0273\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 5: val_loss improved from 0.02726 to 0.01987, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0224 - val_loss: 0.0199\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 6: val_loss improved from 0.01987 to 0.01456, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 7: val_loss improved from 0.01456 to 0.01070, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 8: val_loss improved from 0.01070 to 0.00778, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 445ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 9: val_loss improved from 0.00778 to 0.00541, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00541 to 0.00423, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_312\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1872 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_936 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_312 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1873 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_937 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1874 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_938 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1875 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_624 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1876 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_625 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1877 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3067\n",
      "Epoch 1: val_loss improved from inf to 0.25099, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 461ms/step - loss: 0.3067 - val_loss: 0.2510\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1307\n",
      "Epoch 2: val_loss improved from 0.25099 to 0.06882, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.1307 - val_loss: 0.0688\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0516\n",
      "Epoch 3: val_loss improved from 0.06882 to 0.04162, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.0516 - val_loss: 0.0416\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0317\n",
      "Epoch 4: val_loss improved from 0.04162 to 0.02529, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.0317 - val_loss: 0.0253\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 5: val_loss improved from 0.02529 to 0.01556, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0193 - val_loss: 0.0156\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0119\n",
      "Epoch 6: val_loss improved from 0.01556 to 0.00986, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0119 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0079\n",
      "Epoch 7: val_loss improved from 0.00986 to 0.00698, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00698 to 0.00538, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00538 to 0.00448, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 10: val_loss improved from 0.00448 to 0.00393, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_313\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1878 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_939 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_313 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1879 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_940 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1880 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_941 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1881 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_626 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1882 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_627 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1883 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2727\n",
      "Epoch 1: val_loss improved from inf to 0.12451, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 451ms/step - loss: 0.2727 - val_loss: 0.1245\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0637\n",
      "Epoch 2: val_loss improved from 0.12451 to 0.04357, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0637 - val_loss: 0.0436\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 3: val_loss improved from 0.04357 to 0.02250, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.0311 - val_loss: 0.0225\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 4: val_loss improved from 0.02250 to 0.01343, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0108\n",
      "Epoch 5: val_loss improved from 0.01343 to 0.00978, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.00978 to 0.00777, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00777 to 0.00646, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 454ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00646 to 0.00550, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 451ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00550 to 0.00476, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 448ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00476 to 0.00414, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 455ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_314\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1884 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_942 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_314 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1885 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_943 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1886 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_944 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1887 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_628 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1888 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_629 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1889 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2527\n",
      "Epoch 1: val_loss improved from inf to 0.18158, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 462ms/step - loss: 0.2527 - val_loss: 0.1816\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1113\n",
      "Epoch 2: val_loss improved from 0.18158 to 0.07869, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.1113 - val_loss: 0.0787\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0600\n",
      "Epoch 3: val_loss improved from 0.07869 to 0.04437, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 447ms/step - loss: 0.0600 - val_loss: 0.0444\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0301\n",
      "Epoch 4: val_loss improved from 0.04437 to 0.02264, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0301 - val_loss: 0.0226\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0168\n",
      "Epoch 5: val_loss improved from 0.02264 to 0.01328, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0168 - val_loss: 0.0133\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 6: val_loss improved from 0.01328 to 0.00834, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 7: val_loss improved from 0.00834 to 0.00587, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 8: val_loss improved from 0.00587 to 0.00480, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 444ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00480 to 0.00421, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00421 to 0.00378, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 426ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_315\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1890 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_945 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_315 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1891 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_946 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1892 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_947 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1893 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_630 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1894 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_631 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1895 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3103\n",
      "Epoch 1: val_loss improved from inf to 0.26500, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 456ms/step - loss: 0.3103 - val_loss: 0.2650\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1452\n",
      "Epoch 2: val_loss improved from 0.26500 to 0.05239, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 452ms/step - loss: 0.1452 - val_loss: 0.0524\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 3: val_loss improved from 0.05239 to 0.03166, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 453ms/step - loss: 0.0421 - val_loss: 0.0317\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 4: val_loss improved from 0.03166 to 0.01827, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.0234 - val_loss: 0.0183\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 5: val_loss improved from 0.01827 to 0.01194, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0142 - val_loss: 0.0119\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0095\n",
      "Epoch 6: val_loss improved from 0.01194 to 0.00829, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 7: val_loss improved from 0.00829 to 0.00623, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00623 to 0.00500, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00500 to 0.00423, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00423 to 0.00374, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_316\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1896 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_948 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_316 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1897 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_949 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1898 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_950 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1899 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_632 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1900 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_633 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1901 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2164\n",
      "Epoch 1: val_loss improved from inf to 0.11554, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 453ms/step - loss: 0.2164 - val_loss: 0.1155\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0656\n",
      "Epoch 2: val_loss improved from 0.11554 to 0.04897, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.0656 - val_loss: 0.0490\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0374\n",
      "Epoch 3: val_loss improved from 0.04897 to 0.02938, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0374 - val_loss: 0.0294\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 4: val_loss improved from 0.02938 to 0.01846, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.0224 - val_loss: 0.0185\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 5: val_loss improved from 0.01846 to 0.01168, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 6: val_loss improved from 0.01168 to 0.00818, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00818 to 0.00618, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00618 to 0.00493, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 450ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00493 to 0.00420, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00420 to 0.00374, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_317\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1902 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_951 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_317 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1903 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_952 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1904 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_953 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1905 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_634 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1906 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_635 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1907 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3306\n",
      "Epoch 1: val_loss improved from inf to 0.29988, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 455ms/step - loss: 0.3306 - val_loss: 0.2999\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1890\n",
      "Epoch 2: val_loss improved from 0.29988 to 0.06648, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 443ms/step - loss: 0.1890 - val_loss: 0.0665\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 3: val_loss improved from 0.06648 to 0.03218, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0421 - val_loss: 0.0322\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0242\n",
      "Epoch 4: val_loss improved from 0.03218 to 0.01888, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.0242 - val_loss: 0.0189\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0144\n",
      "Epoch 5: val_loss improved from 0.01888 to 0.01200, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 6: val_loss improved from 0.01200 to 0.00779, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 7: val_loss improved from 0.00779 to 0.00590, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00590 to 0.00498, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00498 to 0.00436, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00436 to 0.00386, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 444ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_318\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1908 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_954 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_318 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1909 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_955 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1910 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_956 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1911 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_636 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1912 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_637 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1913 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2879\n",
      "Epoch 1: val_loss improved from inf to 0.20783, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 451ms/step - loss: 0.2879 - val_loss: 0.2078\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1196\n",
      "Epoch 2: val_loss improved from 0.20783 to 0.08390, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.1196 - val_loss: 0.0839\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0684\n",
      "Epoch 3: val_loss improved from 0.08390 to 0.05715, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0684 - val_loss: 0.0572\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 4: val_loss improved from 0.05715 to 0.03517, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.0436 - val_loss: 0.0352\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0280\n",
      "Epoch 5: val_loss improved from 0.03517 to 0.02352, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0280 - val_loss: 0.0235\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 6: val_loss improved from 0.02352 to 0.01457, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.0181 - val_loss: 0.0146\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 7: val_loss improved from 0.01457 to 0.00921, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 8: val_loss improved from 0.00921 to 0.00654, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 9: val_loss improved from 0.00654 to 0.00545, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 428ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 10: val_loss improved from 0.00545 to 0.00483, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "finished training\n",
      "15/15 [==============================] - 1s 58ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_319\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1914 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_957 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_319 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1915 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_958 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1916 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_959 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1917 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_638 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1918 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_639 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1919 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3108\n",
      "Epoch 1: val_loss improved from inf to 0.27445, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 453ms/step - loss: 0.3108 - val_loss: 0.2744\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1777\n",
      "Epoch 2: val_loss improved from 0.27445 to 0.09093, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.1777 - val_loss: 0.0909\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0663\n",
      "Epoch 3: val_loss improved from 0.09093 to 0.04882, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.0663 - val_loss: 0.0488\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 4: val_loss improved from 0.04882 to 0.02175, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 430ms/step - loss: 0.0328 - val_loss: 0.0217\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0159\n",
      "Epoch 5: val_loss improved from 0.02175 to 0.01286, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0159 - val_loss: 0.0129\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 6: val_loss improved from 0.01286 to 0.00868, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 431ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00868 to 0.00653, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 8: val_loss improved from 0.00653 to 0.00548, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00548 to 0.00474, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00474 to 0.00415, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_320\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1920 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_960 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_320 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1921 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_961 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1922 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_962 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1923 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_640 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1924 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_641 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1925 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2963\n",
      "Epoch 1: val_loss improved from inf to 0.20754, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 451ms/step - loss: 0.2963 - val_loss: 0.2075\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1052\n",
      "Epoch 2: val_loss improved from 0.20754 to 0.05862, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.1052 - val_loss: 0.0586\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0420\n",
      "Epoch 3: val_loss improved from 0.05862 to 0.03142, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 480ms/step - loss: 0.0420 - val_loss: 0.0314\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0236\n",
      "Epoch 4: val_loss improved from 0.03142 to 0.01927, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 487ms/step - loss: 0.0236 - val_loss: 0.0193\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 5: val_loss improved from 0.01927 to 0.01241, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 480ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01241 to 0.00846, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 482ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00846 to 0.00584, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 475ms/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 8: val_loss improved from 0.00584 to 0.00439, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 468ms/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00439 to 0.00387, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 460ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00387 to 0.00359, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 516ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 81ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_321\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1926 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_963 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_321 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1927 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_964 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1928 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_965 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1929 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_642 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1930 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_643 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1931 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3097\n",
      "Epoch 1: val_loss improved from inf to 0.27180, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 510ms/step - loss: 0.3097 - val_loss: 0.2718\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1670\n",
      "Epoch 2: val_loss improved from 0.27180 to 0.06270, saving model to best_weights.h5\n",
      "35/35 [==============================] - 38s 1s/step - loss: 0.1670 - val_loss: 0.0627\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 3: val_loss improved from 0.06270 to 0.03169, saving model to best_weights.h5\n",
      "35/35 [==============================] - 23s 652ms/step - loss: 0.0424 - val_loss: 0.0317\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 4: val_loss improved from 0.03169 to 0.01688, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 423ms/step - loss: 0.0224 - val_loss: 0.0169\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 5: val_loss improved from 0.01688 to 0.01166, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 427ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01166 to 0.00874, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 7: val_loss improved from 0.00874 to 0.00676, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 416ms/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00676 to 0.00552, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 422ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00552 to 0.00472, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 429ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00472 to 0.00419, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 419ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 57ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_322\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1932 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_966 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_322 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1933 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_967 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1934 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_968 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1935 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_644 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1936 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_645 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1937 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2818\n",
      "Epoch 1: val_loss improved from inf to 0.19802, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 423ms/step - loss: 0.2818 - val_loss: 0.1980\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1010\n",
      "Epoch 2: val_loss improved from 0.19802 to 0.05859, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.1010 - val_loss: 0.0586\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 3: val_loss improved from 0.05859 to 0.02497, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 425ms/step - loss: 0.0369 - val_loss: 0.0250\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0192\n",
      "Epoch 4: val_loss improved from 0.02497 to 0.01622, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 478ms/step - loss: 0.0192 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0132\n",
      "Epoch 5: val_loss improved from 0.01622 to 0.01161, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 548ms/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 6: val_loss improved from 0.01161 to 0.00862, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 480ms/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 7: val_loss improved from 0.00862 to 0.00635, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 555ms/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00635 to 0.00492, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 478ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00492 to 0.00414, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 465ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00414 to 0.00370, saving model to best_weights.h5\n",
      "35/35 [==============================] - 23s 660ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 3s 208ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_323\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1938 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_969 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_323 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1939 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_970 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1940 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_971 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1941 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_646 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1942 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_647 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1943 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3136\n",
      "Epoch 1: val_loss improved from inf to 0.27074, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 493ms/step - loss: 0.3136 - val_loss: 0.2707\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1652\n",
      "Epoch 2: val_loss improved from 0.27074 to 0.07859, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 463ms/step - loss: 0.1652 - val_loss: 0.0786\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0629\n",
      "Epoch 3: val_loss improved from 0.07859 to 0.05051, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0629 - val_loss: 0.0505\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0381\n",
      "Epoch 4: val_loss improved from 0.05051 to 0.03130, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.0381 - val_loss: 0.0313\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0250\n",
      "Epoch 5: val_loss improved from 0.03130 to 0.02112, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0250 - val_loss: 0.0211\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 6: val_loss improved from 0.02112 to 0.01358, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.0165 - val_loss: 0.0136\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 7: val_loss improved from 0.01358 to 0.00910, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 8: val_loss improved from 0.00910 to 0.00708, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 9: val_loss improved from 0.00708 to 0.00602, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 10: val_loss improved from 0.00602 to 0.00515, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_324\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1944 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_972 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_324 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1945 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_973 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1946 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_974 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1947 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_648 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1948 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_649 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1949 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2688\n",
      "Epoch 1: val_loss improved from inf to 0.17909, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 449ms/step - loss: 0.2688 - val_loss: 0.1791\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0935\n",
      "Epoch 2: val_loss improved from 0.17909 to 0.06007, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.0935 - val_loss: 0.0601\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 3: val_loss improved from 0.06007 to 0.03311, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0435 - val_loss: 0.0331\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Epoch 4: val_loss improved from 0.03311 to 0.01937, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0247 - val_loss: 0.0194\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 5: val_loss improved from 0.01937 to 0.01268, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0151 - val_loss: 0.0127\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 6: val_loss improved from 0.01268 to 0.00927, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 7: val_loss improved from 0.00927 to 0.00721, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00721 to 0.00579, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 443ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 9: val_loss improved from 0.00579 to 0.00489, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 444ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00489 to 0.00430, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_325\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1950 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_975 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_325 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1951 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_976 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1952 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_977 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1953 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_650 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1954 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_651 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1955 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3082\n",
      "Epoch 1: val_loss improved from inf to 0.25605, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 440ms/step - loss: 0.3082 - val_loss: 0.2561\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1413\n",
      "Epoch 2: val_loss improved from 0.25605 to 0.04569, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.1413 - val_loss: 0.0457\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0370\n",
      "Epoch 3: val_loss improved from 0.04569 to 0.02897, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.0370 - val_loss: 0.0290\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 4: val_loss improved from 0.02897 to 0.01843, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0220 - val_loss: 0.0184\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 5: val_loss improved from 0.01843 to 0.01337, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0151 - val_loss: 0.0134\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0109\n",
      "Epoch 6: val_loss improved from 0.01337 to 0.00971, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0081\n",
      "Epoch 7: val_loss improved from 0.00971 to 0.00745, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 8: val_loss improved from 0.00745 to 0.00621, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 9: val_loss improved from 0.00621 to 0.00538, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 10: val_loss improved from 0.00538 to 0.00470, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 524ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "finished training\n",
      "15/15 [==============================] - 1s 86ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_326\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1956 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_978 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_326 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1957 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_979 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1958 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_980 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1959 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_652 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1960 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_653 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1961 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3259\n",
      "Epoch 1: val_loss improved from inf to 0.27316, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 486ms/step - loss: 0.3259 - val_loss: 0.2732\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1656\n",
      "Epoch 2: val_loss improved from 0.27316 to 0.06322, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 483ms/step - loss: 0.1656 - val_loss: 0.0632\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0414\n",
      "Epoch 3: val_loss improved from 0.06322 to 0.03316, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 482ms/step - loss: 0.0414 - val_loss: 0.0332\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 4: val_loss improved from 0.03316 to 0.01969, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 480ms/step - loss: 0.0252 - val_loss: 0.0197\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 5: val_loss improved from 0.01969 to 0.01355, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 481ms/step - loss: 0.0155 - val_loss: 0.0135\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 6: val_loss improved from 0.01355 to 0.01025, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 482ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 7: val_loss improved from 0.01025 to 0.00808, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 487ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 8: val_loss improved from 0.00808 to 0.00638, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 482ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 9: val_loss improved from 0.00638 to 0.00516, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 500ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00516 to 0.00423, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 482ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 85ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_327\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1962 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_981 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_327 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1963 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_982 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1964 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_983 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1965 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_654 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1966 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_655 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1967 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2803\n",
      "Epoch 1: val_loss improved from inf to 0.20390, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 483ms/step - loss: 0.2803 - val_loss: 0.2039\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1273\n",
      "Epoch 2: val_loss improved from 0.20390 to 0.08989, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 476ms/step - loss: 0.1273 - val_loss: 0.0899\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0666\n",
      "Epoch 3: val_loss improved from 0.08989 to 0.04794, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 474ms/step - loss: 0.0666 - val_loss: 0.0479\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 4: val_loss improved from 0.04794 to 0.02705, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0342 - val_loss: 0.0271\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 5: val_loss improved from 0.02705 to 0.01825, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 447ms/step - loss: 0.0216 - val_loss: 0.0182\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0143\n",
      "Epoch 6: val_loss improved from 0.01825 to 0.01192, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 7: val_loss improved from 0.01192 to 0.00819, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 8: val_loss improved from 0.00819 to 0.00622, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 444ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00622 to 0.00514, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00514 to 0.00453, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 440ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_328\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1968 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_984 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_328 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1969 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_985 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1970 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_986 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1971 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_656 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1972 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_657 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1973 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3447\n",
      "Epoch 1: val_loss improved from inf to 0.33601, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 447ms/step - loss: 0.3447 - val_loss: 0.3360\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.2514\n",
      "Epoch 2: val_loss improved from 0.33601 to 0.14222, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.2514 - val_loss: 0.1422\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0702\n",
      "Epoch 3: val_loss improved from 0.14222 to 0.04630, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0702 - val_loss: 0.0463\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 4: val_loss improved from 0.04630 to 0.02342, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0330 - val_loss: 0.0234\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0183\n",
      "Epoch 5: val_loss improved from 0.02342 to 0.01550, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.0183 - val_loss: 0.0155\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0125\n",
      "Epoch 6: val_loss improved from 0.01550 to 0.01096, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 7: val_loss improved from 0.01096 to 0.00811, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 8: val_loss improved from 0.00811 to 0.00643, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 9: val_loss improved from 0.00643 to 0.00542, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 10: val_loss improved from 0.00542 to 0.00482, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_329\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1974 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_987 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_329 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1975 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_988 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1976 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_989 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1977 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_658 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1978 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_659 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1979 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2692\n",
      "Epoch 1: val_loss improved from inf to 0.18215, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 446ms/step - loss: 0.2692 - val_loss: 0.1822\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0906\n",
      "Epoch 2: val_loss improved from 0.18215 to 0.05017, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0906 - val_loss: 0.0502\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 3: val_loss improved from 0.05017 to 0.02481, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0342 - val_loss: 0.0248\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 4: val_loss improved from 0.02481 to 0.01695, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.0196 - val_loss: 0.0169\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.01695 to 0.01209, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 6: val_loss improved from 0.01209 to 0.00958, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 7: val_loss improved from 0.00958 to 0.00770, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 8: val_loss improved from 0.00770 to 0.00635, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 9: val_loss improved from 0.00635 to 0.00537, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 10: val_loss improved from 0.00537 to 0.00471, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 433ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_330\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1980 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_990 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_330 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1981 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_991 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1982 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_992 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1983 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_660 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1984 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_661 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1985 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2841\n",
      "Epoch 1: val_loss improved from inf to 0.20834, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 439ms/step - loss: 0.2841 - val_loss: 0.2083\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1138\n",
      "Epoch 2: val_loss improved from 0.20834 to 0.06473, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.1138 - val_loss: 0.0647\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0508\n",
      "Epoch 3: val_loss improved from 0.06473 to 0.03914, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.0508 - val_loss: 0.0391\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0277\n",
      "Epoch 4: val_loss improved from 0.03914 to 0.02086, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 432ms/step - loss: 0.0277 - val_loss: 0.0209\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Epoch 5: val_loss improved from 0.02086 to 0.01365, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 437ms/step - loss: 0.0161 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 6: val_loss improved from 0.01365 to 0.00990, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 7: val_loss improved from 0.00990 to 0.00756, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0082 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 8: val_loss improved from 0.00756 to 0.00586, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 434ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00586 to 0.00466, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 435ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00466 to 0.00382, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 439ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_331\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1986 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_993 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_331 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1987 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_994 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1988 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_995 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1989 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_662 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1990 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_663 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1991 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3181\n",
      "Epoch 1: val_loss improved from inf to 0.26033, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 442ms/step - loss: 0.3181 - val_loss: 0.2603\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1582\n",
      "Epoch 2: val_loss improved from 0.26033 to 0.06907, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 436ms/step - loss: 0.1582 - val_loss: 0.0691\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0522\n",
      "Epoch 3: val_loss improved from 0.06907 to 0.03971, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 438ms/step - loss: 0.0522 - val_loss: 0.0397\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0293\n",
      "Epoch 4: val_loss improved from 0.03971 to 0.02362, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0293 - val_loss: 0.0236\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0185\n",
      "Epoch 5: val_loss improved from 0.02362 to 0.01500, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 467ms/step - loss: 0.0185 - val_loss: 0.0150\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0113\n",
      "Epoch 6: val_loss improved from 0.01500 to 0.00916, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 449ms/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 7: val_loss improved from 0.00916 to 0.00640, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 452ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00640 to 0.00510, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 443ms/step - loss: 0.0054 - val_loss: 0.0051\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00510 to 0.00430, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 454ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00430 to 0.00377, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 442ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_332\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1992 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_996 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_332 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1993 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_997 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1994 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_998 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1995 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_664 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1996 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_665 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1997 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3505\n",
      "Epoch 1: val_loss improved from inf to 0.31887, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 486ms/step - loss: 0.3505 - val_loss: 0.3189\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.2148\n",
      "Epoch 2: val_loss improved from 0.31887 to 0.11392, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 507ms/step - loss: 0.2148 - val_loss: 0.1139\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0761\n",
      "Epoch 3: val_loss improved from 0.11392 to 0.06235, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 490ms/step - loss: 0.0761 - val_loss: 0.0624\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0495\n",
      "Epoch 4: val_loss improved from 0.06235 to 0.03957, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 467ms/step - loss: 0.0495 - val_loss: 0.0396\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 5: val_loss improved from 0.03957 to 0.02315, saving model to best_weights.h5\n",
      "35/35 [==============================] - 15s 441ms/step - loss: 0.0299 - val_loss: 0.0231\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 6: val_loss improved from 0.02315 to 0.01353, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 449ms/step - loss: 0.0173 - val_loss: 0.0135\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 7: val_loss improved from 0.01353 to 0.00825, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 471ms/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 8: val_loss improved from 0.00825 to 0.00611, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 467ms/step - loss: 0.0067 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00611 to 0.00494, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 461ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00494 to 0.00413, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 450ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 60ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_333\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1998 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_999 (MaxPooli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_333 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1999 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1000 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2000 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1001 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2001 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_666 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2002 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_667 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2003 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.2469\n",
      "Epoch 1: val_loss improved from inf to 0.16067, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 470ms/step - loss: 0.2469 - val_loss: 0.1607\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0799\n",
      "Epoch 2: val_loss improved from 0.16067 to 0.04441, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 463ms/step - loss: 0.0799 - val_loss: 0.0444\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0309\n",
      "Epoch 3: val_loss improved from 0.04441 to 0.02099, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 538ms/step - loss: 0.0309 - val_loss: 0.0210\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0153\n",
      "Epoch 4: val_loss improved from 0.02099 to 0.01227, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 493ms/step - loss: 0.0153 - val_loss: 0.0123\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 5: val_loss improved from 0.01227 to 0.00784, saving model to best_weights.h5\n",
      "35/35 [==============================] - 16s 468ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 6: val_loss improved from 0.00784 to 0.00579, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 539ms/step - loss: 0.0064 - val_loss: 0.0058\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 7: val_loss improved from 0.00579 to 0.00481, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 580ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 8: val_loss improved from 0.00481 to 0.00426, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 574ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 9: val_loss improved from 0.00426 to 0.00382, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 517ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 10: val_loss improved from 0.00382 to 0.00344, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 538ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "finished training\n",
      "15/15 [==============================] - 1s 72ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_334\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2004 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1002 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_334 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2005 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1003 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2006 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1004 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2007 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_668 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2008 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_669 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2009 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3279\n",
      "Epoch 1: val_loss improved from inf to 0.26749, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 558ms/step - loss: 0.3279 - val_loss: 0.2675\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1416\n",
      "Epoch 2: val_loss improved from 0.26749 to 0.05393, saving model to best_weights.h5\n",
      "35/35 [==============================] - 21s 592ms/step - loss: 0.1416 - val_loss: 0.0539\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0413\n",
      "Epoch 3: val_loss improved from 0.05393 to 0.03054, saving model to best_weights.h5\n",
      "35/35 [==============================] - 22s 626ms/step - loss: 0.0413 - val_loss: 0.0305\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Epoch 4: val_loss improved from 0.03054 to 0.01918, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 534ms/step - loss: 0.0233 - val_loss: 0.0192\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0150\n",
      "Epoch 5: val_loss improved from 0.01918 to 0.01241, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 502ms/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 6: val_loss improved from 0.01241 to 0.00858, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 536ms/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 7: val_loss improved from 0.00858 to 0.00668, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 519ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00668 to 0.00558, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 521ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00558 to 0.00488, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 533ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00488 to 0.00438, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 543ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "finished training\n",
      "15/15 [==============================] - 1s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_335\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2010 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1005 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_335 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2011 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1006 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2012 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1007 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2013 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_670 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2014 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_671 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2015 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3035\n",
      "Epoch 1: val_loss improved from inf to 0.23883, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 521ms/step - loss: 0.3035 - val_loss: 0.2388\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1304\n",
      "Epoch 2: val_loss improved from 0.23883 to 0.07557, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 509ms/step - loss: 0.1304 - val_loss: 0.0756\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0574\n",
      "Epoch 3: val_loss improved from 0.07557 to 0.04350, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 505ms/step - loss: 0.0574 - val_loss: 0.0435\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0331\n",
      "Epoch 4: val_loss improved from 0.04350 to 0.02806, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 533ms/step - loss: 0.0331 - val_loss: 0.0281\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 5: val_loss improved from 0.02806 to 0.01883, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 525ms/step - loss: 0.0225 - val_loss: 0.0188\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 6: val_loss improved from 0.01883 to 0.01198, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 499ms/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 7: val_loss improved from 0.01198 to 0.00805, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 525ms/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 8: val_loss improved from 0.00805 to 0.00610, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 557ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00610 to 0.00506, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 534ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00506 to 0.00434, saving model to best_weights.h5\n",
      "35/35 [==============================] - 21s 588ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 74ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_336\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2016 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1008 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_336 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2017 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1009 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2018 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1010 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2019 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_672 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2020 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_673 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2021 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3086\n",
      "Epoch 1: val_loss improved from inf to 0.24844, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 557ms/step - loss: 0.3086 - val_loss: 0.2484\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 2: val_loss improved from 0.24844 to 0.05363, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 564ms/step - loss: 0.1531 - val_loss: 0.0536\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0341\n",
      "Epoch 3: val_loss improved from 0.05363 to 0.02138, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 545ms/step - loss: 0.0341 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0148\n",
      "Epoch 4: val_loss improved from 0.02138 to 0.01164, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 569ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 5: val_loss improved from 0.01164 to 0.00868, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 546ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 6: val_loss improved from 0.00868 to 0.00698, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 517ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 7: val_loss improved from 0.00698 to 0.00566, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 492ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 8: val_loss improved from 0.00566 to 0.00483, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 578ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00483 to 0.00427, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 550ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00427 to 0.00385, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 509ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_337\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2022 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1011 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_337 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2023 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1012 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2024 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1013 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2025 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_674 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2026 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_675 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2027 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3276\n",
      "Epoch 1: val_loss improved from inf to 0.29063, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 515ms/step - loss: 0.3276 - val_loss: 0.2906\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1882\n",
      "Epoch 2: val_loss improved from 0.29063 to 0.07701, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 496ms/step - loss: 0.1882 - val_loss: 0.0770\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0476\n",
      "Epoch 3: val_loss improved from 0.07701 to 0.03601, saving model to best_weights.h5\n",
      "35/35 [==============================] - 21s 595ms/step - loss: 0.0476 - val_loss: 0.0360\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 4: val_loss improved from 0.03601 to 0.01843, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 551ms/step - loss: 0.0260 - val_loss: 0.0184\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0139\n",
      "Epoch 5: val_loss improved from 0.01843 to 0.01132, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 500ms/step - loss: 0.0139 - val_loss: 0.0113\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 6: val_loss improved from 0.01132 to 0.00800, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 494ms/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 7: val_loss improved from 0.00800 to 0.00617, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 495ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 8: val_loss improved from 0.00617 to 0.00497, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 500ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00497 to 0.00423, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 519ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 10: val_loss improved from 0.00423 to 0.00375, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 514ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_338\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2028 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1014 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_338 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2029 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1015 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2030 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1016 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2031 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_676 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2032 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_677 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2033 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - ETA: 0s - loss: 0.3174\n",
      "Epoch 1: val_loss improved from inf to 0.27338, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 506ms/step - loss: 0.3174 - val_loss: 0.2734\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.1604\n",
      "Epoch 2: val_loss improved from 0.27338 to 0.06677, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 503ms/step - loss: 0.1604 - val_loss: 0.0668\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0534\n",
      "Epoch 3: val_loss improved from 0.06677 to 0.03970, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 506ms/step - loss: 0.0534 - val_loss: 0.0397\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0280\n",
      "Epoch 4: val_loss improved from 0.03970 to 0.02108, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 498ms/step - loss: 0.0280 - val_loss: 0.0211\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0170\n",
      "Epoch 5: val_loss improved from 0.02108 to 0.01473, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 503ms/step - loss: 0.0170 - val_loss: 0.0147\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 6: val_loss improved from 0.01473 to 0.01080, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 504ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 7: val_loss improved from 0.01080 to 0.00793, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 500ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 8: val_loss improved from 0.00793 to 0.00618, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 509ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 9: val_loss improved from 0.00618 to 0.00521, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 510ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 10: val_loss improved from 0.00521 to 0.00459, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 512ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "finished training\n",
      "15/15 [==============================] - 1s 69ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_339\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2034 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1017 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_339 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2035 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1018 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2036 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1019 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2037 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_678 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2038 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_679 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2039 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/35 [============================>.] - ETA: 0s - loss: 0.3271\n",
      "Epoch 1: val_loss improved from inf to 0.27854, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 520ms/step - loss: 0.3270 - val_loss: 0.2785\n",
      "Epoch 2/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.1990\n",
      "Epoch 2: val_loss improved from 0.27854 to 0.11672, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 512ms/step - loss: 0.1989 - val_loss: 0.1167\n",
      "Epoch 3/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0755\n",
      "Epoch 3: val_loss improved from 0.11672 to 0.05642, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 512ms/step - loss: 0.0754 - val_loss: 0.0564\n",
      "Epoch 4/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0420\n",
      "Epoch 4: val_loss improved from 0.05642 to 0.03187, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 501ms/step - loss: 0.0420 - val_loss: 0.0319\n",
      "Epoch 5/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0240\n",
      "Epoch 5: val_loss improved from 0.03187 to 0.01932, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 504ms/step - loss: 0.0240 - val_loss: 0.0193\n",
      "Epoch 6/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0153\n",
      "Epoch 6: val_loss improved from 0.01932 to 0.01286, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 497ms/step - loss: 0.0153 - val_loss: 0.0129\n",
      "Epoch 7/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0103\n",
      "Epoch 7: val_loss improved from 0.01286 to 0.00898, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 532ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0074\n",
      "Epoch 8: val_loss improved from 0.00898 to 0.00662, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 499ms/step - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0056\n",
      "Epoch 9: val_loss improved from 0.00662 to 0.00531, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 566ms/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 10: val_loss improved from 0.00531 to 0.00460, saving model to best_weights.h5\n",
      "35/35 [==============================] - 20s 580ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "finished training\n",
      "15/15 [==============================] - 1s 77ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_340\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2040 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1020 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_340 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2041 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1021 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2042 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1022 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2043 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_680 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2044 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_681 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2045 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/35 [============================>.] - ETA: 0s - loss: 0.2914\n",
      "Epoch 1: val_loss improved from inf to 0.22065, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 503ms/step - loss: 0.2914 - val_loss: 0.2207\n",
      "Epoch 2/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.1094\n",
      "Epoch 2: val_loss improved from 0.22065 to 0.04993, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 518ms/step - loss: 0.1093 - val_loss: 0.0499\n",
      "Epoch 3/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0362\n",
      "Epoch 3: val_loss improved from 0.04993 to 0.02584, saving model to best_weights.h5\n",
      "35/35 [==============================] - 19s 553ms/step - loss: 0.0362 - val_loss: 0.0258\n",
      "Epoch 4/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0188\n",
      "Epoch 4: val_loss improved from 0.02584 to 0.01493, saving model to best_weights.h5\n",
      "35/35 [==============================] - 21s 593ms/step - loss: 0.0188 - val_loss: 0.0149\n",
      "Epoch 5/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0119\n",
      "Epoch 5: val_loss improved from 0.01493 to 0.01021, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 525ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 6/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0083\n",
      "Epoch 6: val_loss improved from 0.01021 to 0.00739, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 510ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 7/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0063\n",
      "Epoch 7: val_loss improved from 0.00739 to 0.00591, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 495ms/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 8/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00591 to 0.00485, saving model to best_weights.h5\n",
      "35/35 [==============================] - 17s 498ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00485 to 0.00410, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 525ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00410 to 0.00359, saving model to best_weights.h5\n",
      "35/35 [==============================] - 18s 522ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_341\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2046 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1023 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_341 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2047 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1024 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2048 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1025 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2049 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_682 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2050 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_683 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2051 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2994\n",
      "Epoch 1: val_loss improved from inf to 0.24632, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 568ms/step - loss: 0.2994 - val_loss: 0.2463\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1481\n",
      "Epoch 2: val_loss improved from 0.24632 to 0.07337, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 535ms/step - loss: 0.1481 - val_loss: 0.0734\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0577\n",
      "Epoch 3: val_loss improved from 0.07337 to 0.04759, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 552ms/step - loss: 0.0577 - val_loss: 0.0476\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 4: val_loss improved from 0.04759 to 0.02992, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 505ms/step - loss: 0.0369 - val_loss: 0.0299\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 5: val_loss improved from 0.02992 to 0.01993, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 0.0234 - val_loss: 0.0199\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 6: val_loss improved from 0.01993 to 0.01460, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 509ms/step - loss: 0.0164 - val_loss: 0.0146\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 7: val_loss improved from 0.01460 to 0.01037, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 508ms/step - loss: 0.0118 - val_loss: 0.0104\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 8: val_loss improved from 0.01037 to 0.00704, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 507ms/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 9: val_loss improved from 0.00704 to 0.00502, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 506ms/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00502 to 0.00428, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 504ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_342\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2052 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1026 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_342 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2053 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1027 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2054 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1028 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2055 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_684 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2056 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_685 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2057 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2888\n",
      "Epoch 1: val_loss improved from inf to 0.22955, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 542ms/step - loss: 0.2888 - val_loss: 0.2295\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1248\n",
      "Epoch 2: val_loss improved from 0.22955 to 0.06636, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 526ms/step - loss: 0.1248 - val_loss: 0.0664\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0510\n",
      "Epoch 3: val_loss improved from 0.06636 to 0.03983, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 519ms/step - loss: 0.0510 - val_loss: 0.0398\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0304\n",
      "Epoch 4: val_loss improved from 0.03983 to 0.02556, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 515ms/step - loss: 0.0304 - val_loss: 0.0256\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0205\n",
      "Epoch 5: val_loss improved from 0.02556 to 0.01773, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 531ms/step - loss: 0.0205 - val_loss: 0.0177\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0142\n",
      "Epoch 6: val_loss improved from 0.01773 to 0.01200, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 542ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 7: val_loss improved from 0.01200 to 0.00783, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 546ms/step - loss: 0.0093 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00783 to 0.00543, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 509ms/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 9: val_loss improved from 0.00543 to 0.00450, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 547ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 10: val_loss improved from 0.00450 to 0.00402, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 539ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "finished training\n",
      "15/15 [==============================] - 1s 67ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_343\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2058 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1029 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_343 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2059 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1030 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2060 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1031 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2061 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_686 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2062 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_687 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2063 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3683\n",
      "Epoch 1: val_loss improved from inf to 0.34567, saving model to best_weights.h5\n",
      "34/34 [==============================] - 21s 606ms/step - loss: 0.3683 - val_loss: 0.3457\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2827\n",
      "Epoch 2: val_loss improved from 0.34567 to 0.20529, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 579ms/step - loss: 0.2827 - val_loss: 0.2053\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0957\n",
      "Epoch 3: val_loss improved from 0.20529 to 0.05286, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 577ms/step - loss: 0.0957 - val_loss: 0.0529\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0374\n",
      "Epoch 4: val_loss improved from 0.05286 to 0.02743, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 597ms/step - loss: 0.0374 - val_loss: 0.0274\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0199\n",
      "Epoch 5: val_loss improved from 0.02743 to 0.01583, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 587ms/step - loss: 0.0199 - val_loss: 0.0158\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 6: val_loss improved from 0.01583 to 0.01179, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 586ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 7: val_loss improved from 0.01179 to 0.00945, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 603ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 8: val_loss improved from 0.00945 to 0.00791, saving model to best_weights.h5\n",
      "34/34 [==============================] - 21s 618ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 9: val_loss improved from 0.00791 to 0.00670, saving model to best_weights.h5\n",
      "34/34 [==============================] - 22s 641ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 10: val_loss improved from 0.00670 to 0.00574, saving model to best_weights.h5\n",
      "34/34 [==============================] - 23s 688ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "finished training\n",
      "15/15 [==============================] - 1s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_344\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2064 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1032 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_344 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2065 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1033 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2066 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1034 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2067 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_688 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2068 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_689 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2069 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3216\n",
      "Epoch 1: val_loss improved from inf to 0.29598, saving model to best_weights.h5\n",
      "34/34 [==============================] - 22s 627ms/step - loss: 0.3216 - val_loss: 0.2960\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1992\n",
      "Epoch 2: val_loss improved from 0.29598 to 0.10062, saving model to best_weights.h5\n",
      "34/34 [==============================] - 22s 639ms/step - loss: 0.1992 - val_loss: 0.1006\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0552\n",
      "Epoch 3: val_loss improved from 0.10062 to 0.04176, saving model to best_weights.h5\n",
      "34/34 [==============================] - 21s 607ms/step - loss: 0.0552 - val_loss: 0.0418\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 4: val_loss improved from 0.04176 to 0.02681, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 507ms/step - loss: 0.0328 - val_loss: 0.0268\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 5: val_loss improved from 0.02681 to 0.01600, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 540ms/step - loss: 0.0200 - val_loss: 0.0160\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 6: val_loss improved from 0.01600 to 0.01178, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 509ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 7: val_loss improved from 0.01178 to 0.00931, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 598ms/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0080\n",
      "Epoch 8: val_loss improved from 0.00931 to 0.00764, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 558ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 9: val_loss improved from 0.00764 to 0.00638, saving model to best_weights.h5\n",
      "34/34 [==============================] - 24s 717ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 10: val_loss improved from 0.00638 to 0.00546, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 564ms/step - loss: 0.0056 - val_loss: 0.0055\n",
      "finished training\n",
      "15/15 [==============================] - 1s 83ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_345\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2070 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1035 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_345 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2071 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1036 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2072 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1037 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2073 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_690 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2074 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_691 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2075 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3138\n",
      "Epoch 1: val_loss improved from inf to 0.24075, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 565ms/step - loss: 0.3138 - val_loss: 0.2408\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1426\n",
      "Epoch 2: val_loss improved from 0.24075 to 0.06651, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 525ms/step - loss: 0.1426 - val_loss: 0.0665\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0501\n",
      "Epoch 3: val_loss improved from 0.06651 to 0.03900, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 514ms/step - loss: 0.0501 - val_loss: 0.0390\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0272\n",
      "Epoch 4: val_loss improved from 0.03900 to 0.01922, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 544ms/step - loss: 0.0272 - val_loss: 0.0192\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 5: val_loss improved from 0.01922 to 0.01253, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 559ms/step - loss: 0.0146 - val_loss: 0.0125\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 6: val_loss improved from 0.01253 to 0.00930, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 547ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 7: val_loss improved from 0.00930 to 0.00729, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 545ms/step - loss: 0.0078 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 8: val_loss improved from 0.00729 to 0.00571, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 538ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00571 to 0.00467, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 512ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00467 to 0.00408, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 577ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_346\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2076 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1038 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_346 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2077 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1039 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2078 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1040 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2079 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_692 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2080 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_693 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2081 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3199\n",
      "Epoch 1: val_loss improved from inf to 0.28554, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 566ms/step - loss: 0.3199 - val_loss: 0.2855\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2001\n",
      "Epoch 2: val_loss improved from 0.28554 to 0.11374, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 538ms/step - loss: 0.2001 - val_loss: 0.1137\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0673\n",
      "Epoch 3: val_loss improved from 0.11374 to 0.04939, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 501ms/step - loss: 0.0673 - val_loss: 0.0494\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0352\n",
      "Epoch 4: val_loss improved from 0.04939 to 0.02531, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 547ms/step - loss: 0.0352 - val_loss: 0.0253\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0186\n",
      "Epoch 5: val_loss improved from 0.02531 to 0.01491, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 592ms/step - loss: 0.0186 - val_loss: 0.0149\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0117\n",
      "Epoch 6: val_loss improved from 0.01491 to 0.01010, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 513ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 7: val_loss improved from 0.01010 to 0.00782, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 527ms/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 8: val_loss improved from 0.00782 to 0.00660, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 493ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 9: val_loss improved from 0.00660 to 0.00587, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 495ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 10: val_loss improved from 0.00587 to 0.00532, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 527ms/step - loss: 0.0053 - val_loss: 0.0053\n",
      "finished training\n",
      "15/15 [==============================] - 1s 71ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_347\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2082 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1041 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_347 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2083 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1042 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2084 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1043 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2085 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_694 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2086 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_695 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2087 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2923\n",
      "Epoch 1: val_loss improved from inf to 0.23176, saving model to best_weights.h5\n",
      "34/34 [==============================] - 21s 596ms/step - loss: 0.2923 - val_loss: 0.2318\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1344\n",
      "Epoch 2: val_loss improved from 0.23176 to 0.08922, saving model to best_weights.h5\n",
      "34/34 [==============================] - 22s 658ms/step - loss: 0.1344 - val_loss: 0.0892\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0670\n",
      "Epoch 3: val_loss improved from 0.08922 to 0.05213, saving model to best_weights.h5\n",
      "34/34 [==============================] - 25s 730ms/step - loss: 0.0670 - val_loss: 0.0521\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 4: val_loss improved from 0.05213 to 0.03075, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 555ms/step - loss: 0.0386 - val_loss: 0.0307\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 5: val_loss improved from 0.03075 to 0.01981, saving model to best_weights.h5\n",
      "34/34 [==============================] - 20s 583ms/step - loss: 0.0239 - val_loss: 0.0198\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 6: val_loss improved from 0.01981 to 0.01300, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 508ms/step - loss: 0.0155 - val_loss: 0.0130\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 7: val_loss improved from 0.01300 to 0.00899, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 488ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 8: val_loss improved from 0.00899 to 0.00689, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 498ms/step - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 9: val_loss improved from 0.00689 to 0.00557, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 506ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 10: val_loss improved from 0.00557 to 0.00467, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 503ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "finished training\n",
      "15/15 [==============================] - 1s 66ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_348\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2088 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1044 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_348 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2089 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1045 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2090 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1046 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2091 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_696 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2092 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_697 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2093 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2822\n",
      "Epoch 1: val_loss improved from inf to 0.21744, saving model to best_weights.h5\n",
      "34/34 [==============================] - 22s 629ms/step - loss: 0.2822 - val_loss: 0.2174\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1273\n",
      "Epoch 2: val_loss improved from 0.21744 to 0.07983, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 532ms/step - loss: 0.1273 - val_loss: 0.0798\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0585\n",
      "Epoch 3: val_loss improved from 0.07983 to 0.04243, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 538ms/step - loss: 0.0585 - val_loss: 0.0424\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0298\n",
      "Epoch 4: val_loss improved from 0.04243 to 0.02190, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 552ms/step - loss: 0.0298 - val_loss: 0.0219\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0171\n",
      "Epoch 5: val_loss improved from 0.02190 to 0.01452, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 549ms/step - loss: 0.0171 - val_loss: 0.0145\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0115\n",
      "Epoch 6: val_loss improved from 0.01452 to 0.00970, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 509ms/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 7: val_loss improved from 0.00970 to 0.00686, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 512ms/step - loss: 0.0077 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00686 to 0.00554, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 516ms/step - loss: 0.0058 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00554 to 0.00472, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 539ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 10: val_loss improved from 0.00472 to 0.00411, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 487ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_349\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2094 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1047 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_349 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2095 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1048 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2096 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1049 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2097 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_698 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2098 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_699 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2099 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3314\n",
      "Epoch 1: val_loss improved from inf to 0.30569, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 540ms/step - loss: 0.3314 - val_loss: 0.3057\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2256\n",
      "Epoch 2: val_loss improved from 0.30569 to 0.14009, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 0.2256 - val_loss: 0.1401\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0855\n",
      "Epoch 3: val_loss improved from 0.14009 to 0.06814, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 515ms/step - loss: 0.0855 - val_loss: 0.0681\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0538\n",
      "Epoch 4: val_loss improved from 0.06814 to 0.04441, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 485ms/step - loss: 0.0538 - val_loss: 0.0444\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0344\n",
      "Epoch 5: val_loss improved from 0.04441 to 0.02819, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 504ms/step - loss: 0.0344 - val_loss: 0.0282\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 6: val_loss improved from 0.02819 to 0.01910, saving model to best_weights.h5\n",
      "34/34 [==============================] - 21s 621ms/step - loss: 0.0225 - val_loss: 0.0191\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 7: val_loss improved from 0.01910 to 0.01230, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 508ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 8: val_loss improved from 0.01230 to 0.00819, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 521ms/step - loss: 0.0096 - val_loss: 0.0082\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 9: val_loss improved from 0.00819 to 0.00623, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 544ms/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 10: val_loss improved from 0.00623 to 0.00517, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 520ms/step - loss: 0.0053 - val_loss: 0.0052\n",
      "finished training\n",
      "15/15 [==============================] - 1s 68ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_350\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2100 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1050 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_350 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2101 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1051 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2102 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1052 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2103 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_700 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2104 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_701 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2105 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2752\n",
      "Epoch 1: val_loss improved from inf to 0.21274, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 530ms/step - loss: 0.2752 - val_loss: 0.2127\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1162\n",
      "Epoch 2: val_loss improved from 0.21274 to 0.06459, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 519ms/step - loss: 0.1162 - val_loss: 0.0646\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0501\n",
      "Epoch 3: val_loss improved from 0.06459 to 0.03924, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 486ms/step - loss: 0.0501 - val_loss: 0.0392\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 4: val_loss improved from 0.03924 to 0.02463, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 507ms/step - loss: 0.0299 - val_loss: 0.0246\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0196\n",
      "Epoch 5: val_loss improved from 0.02463 to 0.01644, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 491ms/step - loss: 0.0196 - val_loss: 0.0164\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0129\n",
      "Epoch 6: val_loss improved from 0.01644 to 0.01083, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 485ms/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0085\n",
      "Epoch 7: val_loss improved from 0.01083 to 0.00727, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 506ms/step - loss: 0.0085 - val_loss: 0.0073\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 8: val_loss improved from 0.00727 to 0.00528, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 516ms/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 9: val_loss improved from 0.00528 to 0.00430, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 501ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00430 to 0.00382, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 477ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "finished training\n",
      "15/15 [==============================] - 1s 70ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_351\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2106 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1053 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_351 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2107 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1054 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2108 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1055 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2109 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_702 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2110 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_703 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2111 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3186\n",
      "Epoch 1: val_loss improved from inf to 0.28263, saving model to best_weights.h5\n",
      "34/34 [==============================] - 19s 535ms/step - loss: 0.3186 - val_loss: 0.2826\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1943\n",
      "Epoch 2: val_loss improved from 0.28263 to 0.09957, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 523ms/step - loss: 0.1943 - val_loss: 0.0996\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0699\n",
      "Epoch 3: val_loss improved from 0.09957 to 0.05562, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 488ms/step - loss: 0.0699 - val_loss: 0.0556\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0416\n",
      "Epoch 4: val_loss improved from 0.05562 to 0.03113, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.0416 - val_loss: 0.0311\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 5: val_loss improved from 0.03113 to 0.01706, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0225 - val_loss: 0.0171\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0127\n",
      "Epoch 6: val_loss improved from 0.01706 to 0.01031, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 512ms/step - loss: 0.0127 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 7: val_loss improved from 0.01031 to 0.00741, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 8: val_loss improved from 0.00741 to 0.00591, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 454ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00591 to 0.00495, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 530ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00495 to 0.00425, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 514ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 61ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_352\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2112 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1056 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_352 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2113 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1057 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2114 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1058 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2115 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_704 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2116 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_705 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2117 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3089\n",
      "Epoch 1: val_loss improved from inf to 0.26036, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 465ms/step - loss: 0.3089 - val_loss: 0.2604\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1605\n",
      "Epoch 2: val_loss improved from 0.26036 to 0.07970, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.1605 - val_loss: 0.0797\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0619\n",
      "Epoch 3: val_loss improved from 0.07970 to 0.04666, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 445ms/step - loss: 0.0619 - val_loss: 0.0467\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 4: val_loss improved from 0.04666 to 0.02236, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 450ms/step - loss: 0.0316 - val_loss: 0.0224\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0173\n",
      "Epoch 5: val_loss improved from 0.02236 to 0.01431, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0173 - val_loss: 0.0143\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 6: val_loss improved from 0.01431 to 0.00924, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 448ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 7: val_loss improved from 0.00924 to 0.00675, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0074 - val_loss: 0.0067\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 8: val_loss improved from 0.00675 to 0.00556, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 445ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 9: val_loss improved from 0.00556 to 0.00486, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 464ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 10: val_loss improved from 0.00486 to 0.00439, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 454ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_353\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2118 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1059 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_353 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2119 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1060 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2120 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1061 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2121 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_706 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2122 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_707 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2123 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3057\n",
      "Epoch 1: val_loss improved from inf to 0.25124, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 470ms/step - loss: 0.3057 - val_loss: 0.2512\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1516\n",
      "Epoch 2: val_loss improved from 0.25124 to 0.06809, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.1516 - val_loss: 0.0681\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 3: val_loss improved from 0.06809 to 0.03867, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 455ms/step - loss: 0.0525 - val_loss: 0.0387\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 4: val_loss improved from 0.03867 to 0.01787, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0260 - val_loss: 0.0179\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0136\n",
      "Epoch 5: val_loss improved from 0.01787 to 0.01144, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 459ms/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 6: val_loss improved from 0.01144 to 0.00852, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 467ms/step - loss: 0.0094 - val_loss: 0.0085\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 7: val_loss improved from 0.00852 to 0.00695, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 458ms/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 8: val_loss improved from 0.00695 to 0.00583, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 451ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 9: val_loss improved from 0.00583 to 0.00496, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 10: val_loss improved from 0.00496 to 0.00432, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_354\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2124 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1062 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_354 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2125 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1063 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2126 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1064 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2127 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_708 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2128 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_709 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2129 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2977\n",
      "Epoch 1: val_loss improved from inf to 0.24363, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 507ms/step - loss: 0.2977 - val_loss: 0.2436\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1291\n",
      "Epoch 2: val_loss improved from 0.24363 to 0.04231, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 470ms/step - loss: 0.1291 - val_loss: 0.0423\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0332\n",
      "Epoch 3: val_loss improved from 0.04231 to 0.02429, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 452ms/step - loss: 0.0332 - val_loss: 0.0243\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 4: val_loss improved from 0.02429 to 0.01526, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 452ms/step - loss: 0.0181 - val_loss: 0.0153\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0126\n",
      "Epoch 5: val_loss improved from 0.01526 to 0.01120, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 455ms/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 6: val_loss improved from 0.01120 to 0.00840, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 459ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 7: val_loss improved from 0.00840 to 0.00651, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 451ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 8: val_loss improved from 0.00651 to 0.00519, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0044\n",
      "Epoch 9: val_loss improved from 0.00519 to 0.00432, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 452ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 10: val_loss improved from 0.00432 to 0.00374, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_355\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2130 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1065 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_355 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2131 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1066 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2132 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1067 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2133 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_710 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2134 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_711 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2135 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2671\n",
      "Epoch 1: val_loss improved from inf to 0.18627, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 517ms/step - loss: 0.2671 - val_loss: 0.1863\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0986\n",
      "Epoch 2: val_loss improved from 0.18627 to 0.05761, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 502ms/step - loss: 0.0986 - val_loss: 0.0576\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0412\n",
      "Epoch 3: val_loss improved from 0.05761 to 0.02850, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 498ms/step - loss: 0.0412 - val_loss: 0.0285\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0201\n",
      "Epoch 4: val_loss improved from 0.02850 to 0.01572, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 497ms/step - loss: 0.0201 - val_loss: 0.0157\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 5: val_loss improved from 0.01572 to 0.01003, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 534ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0082\n",
      "Epoch 6: val_loss improved from 0.01003 to 0.00753, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 528ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 7: val_loss improved from 0.00753 to 0.00622, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 501ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0054\n",
      "Epoch 8: val_loss improved from 0.00622 to 0.00534, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 525ms/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 9: val_loss improved from 0.00534 to 0.00468, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 502ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00468 to 0.00419, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 513ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 1s 65ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_356\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2136 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1068 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_356 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2137 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1069 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2138 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1070 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2139 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_712 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2140 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_713 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2141 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2922\n",
      "Epoch 1: val_loss improved from inf to 0.23358, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 521ms/step - loss: 0.2922 - val_loss: 0.2336\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1283\n",
      "Epoch 2: val_loss improved from 0.23358 to 0.06662, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 510ms/step - loss: 0.1283 - val_loss: 0.0666\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0517\n",
      "Epoch 3: val_loss improved from 0.06662 to 0.03985, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 0.0517 - val_loss: 0.0399\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0298\n",
      "Epoch 4: val_loss improved from 0.03985 to 0.02437, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 525ms/step - loss: 0.0298 - val_loss: 0.0244\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0194\n",
      "Epoch 5: val_loss improved from 0.02437 to 0.01643, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 492ms/step - loss: 0.0194 - val_loss: 0.0164\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0130\n",
      "Epoch 6: val_loss improved from 0.01643 to 0.01111, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 527ms/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 7: val_loss improved from 0.01111 to 0.00744, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 514ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 8: val_loss improved from 0.00744 to 0.00518, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 529ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 9: val_loss improved from 0.00518 to 0.00404, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 10: val_loss improved from 0.00404 to 0.00354, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 515ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "finished training\n",
      "15/15 [==============================] - 1s 90ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_357\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2142 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1071 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_357 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2143 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1072 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2144 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1073 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2145 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_714 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2146 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_715 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2147 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2878\n",
      "Epoch 1: val_loss improved from inf to 0.23436, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 521ms/step - loss: 0.2878 - val_loss: 0.2344\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1353\n",
      "Epoch 2: val_loss improved from 0.23436 to 0.06206, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 515ms/step - loss: 0.1353 - val_loss: 0.0621\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0516\n",
      "Epoch 3: val_loss improved from 0.06206 to 0.04324, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 518ms/step - loss: 0.0516 - val_loss: 0.0432\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0341\n",
      "Epoch 4: val_loss improved from 0.04324 to 0.02778, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 524ms/step - loss: 0.0341 - val_loss: 0.0278\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 5: val_loss improved from 0.02778 to 0.01782, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 510ms/step - loss: 0.0215 - val_loss: 0.0178\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 6: val_loss improved from 0.01782 to 0.01185, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 482ms/step - loss: 0.0141 - val_loss: 0.0118\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 7: val_loss improved from 0.01185 to 0.00830, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 444ms/step - loss: 0.0094 - val_loss: 0.0083\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 8: val_loss improved from 0.00830 to 0.00651, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 450ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0056\n",
      "Epoch 9: val_loss improved from 0.00651 to 0.00542, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 455ms/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 10: val_loss improved from 0.00542 to 0.00466, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 451ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "finished training\n",
      "15/15 [==============================] - 1s 63ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_358\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2148 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1074 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_358 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2149 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1075 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2150 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1076 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2151 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_716 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2152 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_717 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2153 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3007\n",
      "Epoch 1: val_loss improved from inf to 0.22860, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 468ms/step - loss: 0.3007 - val_loss: 0.2286\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1250\n",
      "Epoch 2: val_loss improved from 0.22860 to 0.06552, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.1250 - val_loss: 0.0655\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0550\n",
      "Epoch 3: val_loss improved from 0.06552 to 0.04680, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 450ms/step - loss: 0.0550 - val_loss: 0.0468\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 4: val_loss improved from 0.04680 to 0.02860, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 446ms/step - loss: 0.0366 - val_loss: 0.0286\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 5: val_loss improved from 0.02860 to 0.01684, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0210 - val_loss: 0.0168\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0128\n",
      "Epoch 6: val_loss improved from 0.01684 to 0.01054, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 458ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 7: val_loss improved from 0.01054 to 0.00774, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 454ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 8: val_loss improved from 0.00774 to 0.00614, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 452ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 9: val_loss improved from 0.00614 to 0.00514, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 457ms/step - loss: 0.0053 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 10: val_loss improved from 0.00514 to 0.00450, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 456ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "finished training\n",
      "15/15 [==============================] - 1s 62ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_359\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2154 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1077 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_359 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2155 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1078 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2156 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1079 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2157 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_718 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2158 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_719 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2159 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.3254\n",
      "Epoch 1: val_loss improved from inf to 0.27801, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 473ms/step - loss: 0.3254 - val_loss: 0.2780\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1686\n",
      "Epoch 2: val_loss improved from 0.27801 to 0.08863, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 461ms/step - loss: 0.1686 - val_loss: 0.0886\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0717\n",
      "Epoch 3: val_loss improved from 0.08863 to 0.05736, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 459ms/step - loss: 0.0717 - val_loss: 0.0574\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0431\n",
      "Epoch 4: val_loss improved from 0.05736 to 0.03293, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.0431 - val_loss: 0.0329\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 5: val_loss improved from 0.03293 to 0.01939, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.0244 - val_loss: 0.0194\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0149\n",
      "Epoch 6: val_loss improved from 0.01939 to 0.01234, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 454ms/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 7: val_loss improved from 0.01234 to 0.00856, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0069\n",
      "Epoch 8: val_loss improved from 0.00856 to 0.00625, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 452ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 9: val_loss improved from 0.00625 to 0.00491, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 454ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00491 to 0.00407, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 451ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "finished training\n",
      "15/15 [==============================] - 1s 59ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_360\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2160 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1080 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_360 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2161 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1081 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2162 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1082 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2163 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_720 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2164 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_721 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2165 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2572\n",
      "Epoch 1: val_loss improved from inf to 0.17469, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 459ms/step - loss: 0.2572 - val_loss: 0.1747\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0855\n",
      "Epoch 2: val_loss improved from 0.17469 to 0.05122, saving model to best_weights.h5\n",
      "34/34 [==============================] - 15s 453ms/step - loss: 0.0855 - val_loss: 0.0512\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0376\n",
      "Epoch 3: val_loss improved from 0.05122 to 0.02963, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 509ms/step - loss: 0.0376 - val_loss: 0.0296\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0238\n",
      "Epoch 4: val_loss improved from 0.02963 to 0.02044, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 496ms/step - loss: 0.0238 - val_loss: 0.0204\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0164\n",
      "Epoch 5: val_loss improved from 0.02044 to 0.01401, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 467ms/step - loss: 0.0164 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0112\n",
      "Epoch 6: val_loss improved from 0.01401 to 0.00960, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 506ms/step - loss: 0.0112 - val_loss: 0.0096\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 7: val_loss improved from 0.00960 to 0.00698, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 530ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0059\n",
      "Epoch 8: val_loss improved from 0.00698 to 0.00552, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 544ms/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 9: val_loss improved from 0.00552 to 0.00470, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 10: val_loss improved from 0.00470 to 0.00420, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 541ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "finished training\n",
      "15/15 [==============================] - 2s 73ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_361\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2166 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1083 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_361 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2167 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1084 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2168 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1085 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2169 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_722 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2170 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_723 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2171 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2747\n",
      "Epoch 1: val_loss improved from inf to 0.22381, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 516ms/step - loss: 0.2747 - val_loss: 0.2238\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1325\n",
      "Epoch 2: val_loss improved from 0.22381 to 0.06674, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 482ms/step - loss: 0.1325 - val_loss: 0.0667\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0517\n",
      "Epoch 3: val_loss improved from 0.06674 to 0.03852, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 474ms/step - loss: 0.0517 - val_loss: 0.0385\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 4: val_loss improved from 0.03852 to 0.02217, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 495ms/step - loss: 0.0286 - val_loss: 0.0222\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0165\n",
      "Epoch 5: val_loss improved from 0.02217 to 0.01301, saving model to best_weights.h5\n",
      "34/34 [==============================] - 16s 476ms/step - loss: 0.0165 - val_loss: 0.0130\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 6: val_loss improved from 0.01301 to 0.00819, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 515ms/step - loss: 0.0098 - val_loss: 0.0082\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0066\n",
      "Epoch 7: val_loss improved from 0.00819 to 0.00607, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 502ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 8: val_loss improved from 0.00607 to 0.00489, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 531ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 9: val_loss improved from 0.00489 to 0.00415, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 513ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 10: val_loss improved from 0.00415 to 0.00364, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 513ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "finished training\n",
      "15/15 [==============================] - 1s 64ms/step\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_362\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2172 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_1086 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_362 (Dropout)       (None, 32, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2173 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1087 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2174 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1088 (MaxPool  (None, 32, 64, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2175 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_724 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2176 (Conv2D)        (None, 32, 64, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_725 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2177 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,721\n",
      "Trainable params: 66,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 0.2816\n",
      "Epoch 1: val_loss improved from inf to 0.19988, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 486ms/step - loss: 0.2816 - val_loss: 0.1999\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1075\n",
      "Epoch 2: val_loss improved from 0.19988 to 0.04800, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 528ms/step - loss: 0.1075 - val_loss: 0.0480\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0375\n",
      "Epoch 3: val_loss improved from 0.04800 to 0.02842, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 486ms/step - loss: 0.0375 - val_loss: 0.0284\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0201\n",
      "Epoch 4: val_loss improved from 0.02842 to 0.01478, saving model to best_weights.h5\n",
      "34/34 [==============================] - 18s 529ms/step - loss: 0.0201 - val_loss: 0.0148\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0118\n",
      "Epoch 5: val_loss improved from 0.01478 to 0.01053, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 508ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0088\n",
      "Epoch 6: val_loss improved from 0.01053 to 0.00811, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 492ms/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 7: val_loss improved from 0.00811 to 0.00630, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 488ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 8: val_loss improved from 0.00630 to 0.00502, saving model to best_weights.h5\n",
      "34/34 [==============================] - 17s 504ms/step - loss: 0.0053 - val_loss: 0.0050\n",
      "Epoch 9/10\n",
      "25/34 [=====================>........] - ETA: 4s - loss: 0.0044"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m         \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# just to make sure we use a lot of patience before stopping\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_weights.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# get best model from the training (based on validation loss),\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# this is neccessary because the early stopping callback saves the model \"patience\" epochs after the best one\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#model.load_weights('best_weights.h5')\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lead_time in range(0,361):\n",
    "    X_train,y_train, X_test, y_test = prepare_data(lead_time)\n",
    "    \n",
    "    ## The tuning process produced the best hyperparameters below.\n",
    "    params = {'conv_depth': 32, 'hidden_size': 500,\n",
    "              'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
    "\n",
    "    \n",
    "    print(params)\n",
    "    param_string = '_'.join([str(e) for e in (N_train,num_epochs,lead_time)])\n",
    "    \n",
    "    \n",
    "    #run the model\n",
    "    model = build_model(**params)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    \n",
    "    print('start training')\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                       batch_size = batch_size,\n",
    "             verbose=1, \n",
    "             epochs = num_epochs,\n",
    "             validation_data=(X_test,y_test),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                        min_delta=0,\n",
    "                                        patience=5, #To ensure a great deal of patience before ending\n",
    "                                        verbose=0, mode='auto'),\n",
    "                       keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', \n",
    "                                                    verbose=1, save_best_only=True, \n",
    "                                                    save_weights_only=True, mode='auto', period=1)]\n",
    "             )\n",
    "    \n",
    "    print('finished training')\n",
    "    \n",
    "    # To ensure the best model performance from the training based on learning curve,\n",
    "    # Because the early stopping callback saves the model's \"patience\" epochs after the best one, this is required.\n",
    "    model.load_weights('best_weights.h5')\n",
    "    \n",
    "    # delete the file generated by Model Checkppoint\n",
    "    os.system('rm best_weights.h5')\n",
    "    \n",
    "    \n",
    "    model.save_weights(outdir+'weights_tunedparams_leadtime'+str(lead_time)+'params_'+param_string+'.h5')\n",
    "  \n",
    "    # reformat history\n",
    "        \n",
    "    hist =  hist.history\n",
    "\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "\n",
    "    # compute accuracy\n",
    "    res = []\n",
    "    rmse = np.sqrt(np.mean((y_test_predicted - y_test)**2))\n",
    "    acc = acc_score(y_test_predicted, y_test)\n",
    "\n",
    "    res.append(dict(hist=hist,params=params, scores=[rmse,acc]))\n",
    "\n",
    "    pickle.dump(res,open(outdir+'training_result_sequential'+param_string+'.pkl','wb'))\n",
    "    \n",
    "    # plot loss value\n",
    "    plt.figure()\n",
    "    plt.title('a) Channel-wise-based CNN model', fontsize=14, x=0.0, y=1.05)\n",
    "    plt.xlabel('Epochs',fontsize=12)\n",
    "    plt.ylabel('Loss',fontsize=12)\n",
    "    plt.plot(hist['val_loss'], label='validation loss')\n",
    "    plt.plot(hist['loss'], label='train loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    #save loss to .png\n",
    "    plt.savefig(outdir+'cwcnn_history_tunedparams_leadtime'+str(lead_time)+'.png')\n",
    "\n",
    "    pd.DataFrame(hist).to_csv(outdir+'history_tunedparams_leadtime'+str(lead_time)+'.csv')\n",
    "\n",
    "    \n",
    "    '''y_test is a xarray dataarray, but y_test_predicted is now a numpy array.\n",
    "    Therefore, we convert it to an xarray with exactly the same coordinates and dims by using dim from y_test.'''\n",
    "    # save the validation\n",
    "    y_test_predicted_new = xr.DataArray(data=y_test_predicted, coords=y_test_size.coords, dims=y_test_size.dims)\n",
    "    y_test_new = xr.DataArray(data=y_test, coords=y_test_size.coords, dims=y_test_size.dims)\n",
    "    \n",
    "    # save the predictions\n",
    "    y_test_predicted_new.to_netcdf(outdir+'/predictions_tuned_leadtime'+str(lead_time)+'params_'+param_string+'.nc')\n",
    "    y_test_new.to_netcdf(outdir+'/truevalues_tuned_leadtime'+str(lead_time)+'params_'+param_string+'.nc')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f0bc3",
   "metadata": {},
   "source": [
    "# Prodicting PDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53633e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the average trend of global SST \n",
    "gsst = xr.open_dataarray('C:/Users/user/Research/Research Code/CNN/Data/'+'ersst_1854_2022_mech.nc')\n",
    "gclm = gsst.groupby('time.month').mean(dim='time')\n",
    "ganm = (gsst.groupby('time.month') - gclm)\n",
    "mglobal=ganm.mean((\"lon\", \"lat\"), skipna=True)\n",
    "plt.plot(mglobal)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03d6ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 23, 64, 1)\n",
      "<xarray.Dataset>\n",
      "Dimensions:                        (time: 480, lat: 23, lon: 64, lev: 1)\n",
      "Coordinates:\n",
      "  * time                           (time) datetime64[ns] 1983-01-01 ... 2022-...\n",
      "  * lat                            (lat) float32 64.0 62.0 60.0 ... 22.0 20.0\n",
      "  * lon                            (lon) float32 122.0 124.0 ... 246.0 248.0\n",
      "  * lev                            (lev) float64 0.0\n",
      "Data variables:\n",
      "    __xarray_dataarray_variable__  (time, lat, lon, lev) float32 ...\n"
     ]
    }
   ],
   "source": [
    "##Setup validation period\n",
    "ystr = 1983\n",
    "yend = 2022\n",
    "\n",
    "##Setup lat dimension\n",
    "lead_time = 359\n",
    "N_train = 1428\n",
    "\n",
    "##Imported ensemble training results used to transform land mask\n",
    "ncin = Dataset(ifile+'predictions_tuned_leadtime'+str(lead_time)+'params_'+str(N_train)+'_10_'+str(lead_time)+'.nc')\n",
    "\n",
    "\n",
    "sst  = ncin.variables['__xarray_dataarray_variable__'][:,:-9,:] \n",
    "time  = ncin.variables['time'][:]\n",
    "lat  = ncin.variables['lat'][:-9]\n",
    "lon  = ncin.variables['lon'][:]\n",
    "lev  = ncin.variables['lev'][:]\n",
    "ncin.close()\n",
    "\n",
    "nt,nlat,nlon,nlev = sst.shape    \n",
    "print(sst.shape )\n",
    "\n",
    "## Imported pred data\n",
    "ds = xr.open_dataset(ifile+'predictions_tuned_leadtime'+str(lead_time)+'params_'+str(N_train)+'_10_'+str(lead_time)+'.nc')\n",
    "ds = ds.sel(lat=slice(70, 20), lon=slice(122, 250))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0339e673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 23, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##import land mask\n",
    "lmfile = 'data\\lsmask.nc'\n",
    "lmset  = Dataset(lmfile)\n",
    "lsmask = lmset['mask'][0,24:70:2,122:250:2]# read land mask\n",
    "lsmask = lsmask-1\n",
    "\n",
    "num_repeats = nt\n",
    "lsm = np.stack([lsmask]*num_repeats,axis=-1).transpose((2,0,1))\n",
    "lsm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31cc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange('1983-01', '2023-01', dtype='datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44dcb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 23, 64)\n"
     ]
    }
   ],
   "source": [
    "# === Climatology and Anomalies \n",
    "sst = ds.__xarray_dataarray_variable__\n",
    "clm = sst.sel(time=slice(f'{ystr}-01-01',f'{yend}-12-01')).groupby('time.month').mean(dim='time')\n",
    "anm = (sst.groupby('time.month') - clm)\n",
    "\n",
    "# remove lev dimension\n",
    "anm=anm.isel(lev=0)\n",
    "\n",
    "##Prediction\n",
    "#detrend\n",
    "dpdo = detrend_dim(anm,mglobal,'time',1)\n",
    "\n",
    "#Mask out land\n",
    "sst_diff = dpdo\n",
    "sst_diff = np.ma.masked_array(sst_diff, mask=lsm)\n",
    "sst_diff[lsm<0] = np.nan\n",
    "#sst_diff=sst_diff.to_numpy()\n",
    "print(sst_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "733739c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To perform the EOF analysis, create an EOF solver.\n",
    "#Prior to computing the EOFs, latitude weights are applied with a cosine.\n",
    "wgts   = np.sqrt(np.cos(np.deg2rad(lat)))\n",
    "wgts   = wgts.reshape(len(wgts), 1)\n",
    "wgts.shape\n",
    "\n",
    "#Obtained the leading EOFs\n",
    "solver = Eof(sst_diff, weights=wgts)\n",
    "\n",
    "eof1 = solver.eofs(neofs=1)\n",
    "pc1  = solver.pcs(npcs=1, pcscaling=1)\n",
    "varfrac = solver.varianceFraction()\n",
    "lambdas = solver.eigenvalues()\n",
    "Covariance_eof1 = solver.eofsAsCovariance(neofs=1, pcscaling=0)\n",
    "\n",
    "leading_eof = solver.eofsAsCorrelation(neofs=1)\n",
    "eigenvalue1 = solver.eigenvalues(neigs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71fc2d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creat PDO index\n",
    "pc=pc1 [:,]\n",
    "pc_mean=pc1[:,].mean()\n",
    "pc_std=pc1[:,].std()\n",
    "\n",
    "#Normalised\n",
    "pcs = xr.apply_ufunc(\n",
    "\n",
    "lambda x, m, s: x  / s,\n",
    "pc,\n",
    "pc_mean,\n",
    "pc_std, dask = 'allowed', vectorize = True)\n",
    "pcs.shape\n",
    "PDO=pcs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "602206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothed with 10-year low pass\n",
    "cutoff = 0.05\n",
    "lw_pred = lowpass_filter(cutoff ,PDO)\n",
    "\n",
    "np.savetxt(outdir_smooth_pred+'Result_PDO index_pred_cwcnn_smoothed'+str(lead_time)+'.csv',lw_pred, delimiter=',', fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "447a1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot EOF map and PC Amplitude\n",
    "parallels = np.arange(-90,90,30.)\n",
    "meridians = np.arange(-180,180,30)\n",
    "\n",
    "for i in range(0,1):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    plt.subplot(211)\n",
    "    \n",
    "    m = Basemap(projection='cyl', llcrnrlon=min(lon), llcrnrlat=min(lat), urcrnrlon=max(lon), urcrnrlat=max(lat))   \n",
    "    x, y = m(*np.meshgrid(lon, lat))\n",
    "    clevs = np.linspace(np.min(eof1[i,:,:].squeeze()), np.max(eof1[i,:,:].squeeze()), 21)\n",
    "    cs = m.contourf(x, y, eof1[i,:,:].squeeze(), clevs, cmap=plt.cm.RdBu_r)\n",
    "    m.drawcoastlines()  \n",
    "    m.drawparallels(parallels, labels=[1,0,0,0])\n",
    "    m.drawmeridians(meridians, labels=[1,0,0,1])\n",
    "\n",
    "    cb = m.colorbar(cs, 'right', size='5%', pad='2%')\n",
    "    cb.set_label('EOF', fontsize=12)\n",
    "    plt.title('EOF ' + str(i+1), fontsize=16)\n",
    "\n",
    "    plt.subplot(212)\n",
    "    days = np.linspace(1983,2022,nt)\n",
    "    plt.plot(days, pc1[:,i], linewidth=2)\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('PC Amplitude')   \n",
    "    plt.ylim(np.min(pc1.squeeze()), np.max(pc1.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e633f422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2845: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2704: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2704: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n"
     ]
    }
   ],
   "source": [
    "##Calculate correlation\n",
    "\n",
    "##Import validation data from NCEI PDO index from 1983-2022 \n",
    "#https://www.ncei.noaa.gov/access/monitoring/pdo/\n",
    "cutoff = 0.05\n",
    "PDO_ncei = pd.read_excel(ifile_data+'NCEI PDO index _overall.xlsx',header=None,index_col=None,\n",
    "                      skiprows=985, skipfooter = 0,\n",
    "                      usecols=[1]  \n",
    "                     )\n",
    "\n",
    "PDO_ncei = adjust(PDO_ncei)\n",
    "lw_ncei = lowpass_filter(cutoff ,PDO_ncei)\n",
    "PDO_ncei=adjust(lw_ncei)\n",
    "\n",
    "\n",
    "##Calculate the average correlation over 30 years for lead forecasts.\n",
    "lead_Correlation_cnn = []\n",
    "\n",
    "for lead_time in range (0,360):\n",
    "    \n",
    "    Correlation_cnn = []\n",
    "    \n",
    "    PDO_cnn = np.loadtxt(outdir_smooth_pred+'Result_PDO index_pred_cwcnn_smoothed'+str(lead_time)+'.csv', dtype=float)\n",
    "    PDO_pred = adjust(PDO_cnn)\n",
    "\n",
    "    \n",
    "    for i in range (0,480): \n",
    "        correlation(PDO_pred,PDO_ncei,Correlation_cnn)\n",
    "\n",
    "    lead_Correlation_cnn.append(mean(Correlation_cnn[0:481]))\n",
    "\n",
    "print(mean(lead_Correlation_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa1c0b4",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanenv",
   "language": "python",
   "name": "oceanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
