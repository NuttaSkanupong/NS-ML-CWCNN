{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb50164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  #paths in the object-oriented filesystem\n",
    "import pandas as pd       #Python Data Analysis Library\n",
    "import wget               #a program for downloading content from web servers\n",
    "import time               #Module for time access and conversions \n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # plotting tool\n",
    "import cartopy.feature as cfeature # to add coastlines, land and ocean\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import array as arr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from tensorflow.keras.layers import Input, Convolution2D, Convolution1D, MaxPooling2D, Dense, Dropout, \\\n",
    "                          Flatten, concatenate, Activation, Reshape, \\\n",
    "                          UpSampling2D,ZeroPadding2D, Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from pylab import plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "from keras.applications import Xception\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "from keras import layers\n",
    "from keras.layers import Input, Convolution2D, Convolution1D, MaxPooling2D, Dense, Dropout, \\\n",
    "                          Flatten, concatenate, Activation, Reshape, \\\n",
    "                          UpSampling2D,ZeroPadding2D\n",
    "\n",
    "import keras\n",
    "from pylab import plt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot, figure\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from tsmoothie.smoother import *\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3902d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saved path\n",
    "outdir = 'C:/Users/user/Research/Research Code/CIMP6/CMIP6_model/Ensemble_CMIP6/'\n",
    "ifile = 'C:/Users/user/Research/Research Code/CIMP6/data/ensemble_train_overall_CMIP6/'\n",
    "testsizepath='C:/Users/user/Research/Research Code/Compare_CNN_LSTM/Evaluation/CNN/y_testsize_359_32_64_1.nc'\n",
    "y_test_size= xr.open_dataarray(testsizepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d1c9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (time: 1380, bnds: 2, lon: 128, lat: 64)\n",
       "Coordinates:\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
       "  * lat        (lat) float64 87.86 85.1 82.31 79.53 ... -82.31 -85.1 -87.86\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, bnds) float64 dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\n",
       "    tos        (time, lat, lon) float32 dask.array&lt;chunksize=(1, 64, 128), meta=np.ndarray&gt;\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-d99cb076-ee0e-4848-9253-2e33ff996301' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-d99cb076-ee0e-4848-9253-2e33ff996301' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 1380</li><li><span>bnds</span>: 2</li><li><span class='xr-has-index'>lon</span>: 128</li><li><span class='xr-has-index'>lat</span>: 64</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-a27ca293-5129-4117-a98c-1842d549c0d4' class='xr-section-summary-in' type='checkbox'  checked><label for='section-a27ca293-5129-4117-a98c-1842d549c0d4' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>15.5 45.0 ... 4.196e+04 4.199e+04</div><input id='attrs-3766befa-d085-464e-8ced-ac8b61a380c7' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-3766befa-d085-464e-8ced-ac8b61a380c7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-db4af23c-334d-4e15-b2a1-856c8a793b5c' class='xr-var-data-in' type='checkbox'><label for='data-db4af23c-334d-4e15-b2a1-856c8a793b5c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd><dt><span>bounds :</span></dt><dd>time_bnds</dd><dt><span>units :</span></dt><dd>days since 1850-01-01</dd><dt><span>calendar :</span></dt><dd>proleptic_gregorian</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([1.55000e+01, 4.50000e+01, 7.45000e+01, ..., 4.19265e+04, 4.19570e+04,\n",
       "       4.19875e+04])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 2.812 5.625 ... 354.4 357.2</div><input id='attrs-a653ffbd-217e-405d-b774-16dced4c7578' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a653ffbd-217e-405d-b774-16dced4c7578' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-85f97707-5c49-4768-ad80-7f0ead31d9c3' class='xr-var-data-in' type='checkbox'><label for='data-85f97707-5c49-4768-ad80-7f0ead31d9c3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([  0.    ,   2.8125,   5.625 ,   8.4375,  11.25  ,  14.0625,  16.875 ,\n",
       "        19.6875,  22.5   ,  25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "        39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,  53.4375,  56.25  ,\n",
       "        59.0625,  61.875 ,  64.6875,  67.5   ,  70.3125,  73.125 ,  75.9375,\n",
       "        78.75  ,  81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,  95.625 ,\n",
       "        98.4375, 101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125,\n",
       "       118.125 , 120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "       137.8125, 140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875,\n",
       "       157.5   , 160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 ,\n",
       "       177.1875, 180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625,\n",
       "       196.875 , 199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  ,\n",
       "       216.5625, 219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "       236.25  , 239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 ,\n",
       "       255.9375, 258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125,\n",
       "       275.625 , 278.4375, 281.25  , 284.0625, 286.875 , 289.6875, 292.5   ,\n",
       "       295.3125, 298.125 , 300.9375, 303.75  , 306.5625, 309.375 , 312.1875,\n",
       "       315.    , 317.8125, 320.625 , 323.4375, 326.25  , 329.0625, 331.875 ,\n",
       "       334.6875, 337.5   , 340.3125, 343.125 , 345.9375, 348.75  , 351.5625,\n",
       "       354.375 , 357.1875])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>87.86 85.1 82.31 ... -85.1 -87.86</div><input id='attrs-79d8f56d-af51-4aee-9475-423230a44f83' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-79d8f56d-af51-4aee-9475-423230a44f83' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-014b5ee4-1c5a-43a7-8b6f-6db03f78ba63' class='xr-var-data-in' type='checkbox'><label for='data-014b5ee4-1c5a-43a7-8b6f-6db03f78ba63' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([ 87.863799,  85.096527,  82.312913,  79.525607,  76.7369  ,  73.947515,\n",
       "        71.157752,  68.367756,  65.577607,  62.787352,  59.99702 ,  57.206632,\n",
       "        54.4162  ,  51.625734,  48.835241,  46.044727,  43.254195,  40.463648,\n",
       "        37.67309 ,  34.882521,  32.091944,  29.30136 ,  26.510769,  23.720174,\n",
       "        20.929574,  18.138971,  15.348365,  12.557756,   9.767146,   6.976534,\n",
       "         4.185921,   1.395307,  -1.395307,  -4.185921,  -6.976534,  -9.767146,\n",
       "       -12.557756, -15.348365, -18.138971, -20.929574, -23.720174, -26.510769,\n",
       "       -29.30136 , -32.091944, -34.882521, -37.67309 , -40.463648, -43.254195,\n",
       "       -46.044727, -48.835241, -51.625734, -54.4162  , -57.206632, -59.99702 ,\n",
       "       -62.787352, -65.577607, -68.367756, -71.157752, -73.947515, -76.7369  ,\n",
       "       -79.525607, -82.312913, -85.096527, -87.863799])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-14d8d222-f8e9-48ae-9194-eaf3b64fcf19' class='xr-section-summary-in' type='checkbox'  checked><label for='section-14d8d222-f8e9-48ae-9194-eaf3b64fcf19' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time_bnds</span></div><div class='xr-var-dims'>(time, bnds)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;</div><input id='attrs-0d19d5b3-50e8-49fc-8183-b4891ec15dd2' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0d19d5b3-50e8-49fc-8183-b4891ec15dd2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-06161080-1fa3-48a9-82fc-bf88e8ce8368' class='xr-var-data-in' type='checkbox'><label for='data-06161080-1fa3-48a9-82fc-bf88e8ce8368' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 21.56 kiB </td>\n",
       "                        <td> 16 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1380, 2) </td>\n",
       "                        <td> (1, 2) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1381 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"25\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"44\" x2=\"25\" y2=\"44\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"25\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"25\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"25\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"82\" x2=\"25\" y2=\"82\" />\n",
       "  <line x1=\"0\" y1=\"88\" x2=\"25\" y2=\"88\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"25\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"101\" x2=\"25\" y2=\"101\" />\n",
       "  <line x1=\"0\" y1=\"107\" x2=\"25\" y2=\"107\" />\n",
       "  <line x1=\"0\" y1=\"113\" x2=\"25\" y2=\"113\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">1380</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tos</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 64, 128), meta=np.ndarray&gt;</div><input id='attrs-a06ae0dd-dcb5-4fdd-adad-e584e3bd37ea' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a06ae0dd-dcb5-4fdd-adad-e584e3bd37ea' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e899c191-d1b2-432b-b058-bbb1555ea3c6' class='xr-var-data-in' type='checkbox'><label for='data-e899c191-d1b2-432b-b058-bbb1555ea3c6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_surface_temperature</dd><dt><span>long_name :</span></dt><dd>Sea Surface Temperature</dd><dt><span>units :</span></dt><dd>degC</dd><dt><span>CDI_grid_type :</span></dt><dd>gaussian</dd><dt><span>CDI_grid_num_LPE :</span></dt><dd>32</dd><dt><span>comment :</span></dt><dd>Temperature of upper boundary of the liquid ocean, including temperatures below sea-ice and floating ice shelves.</dd><dt><span>cell_methods :</span></dt><dd>area: mean where sea time: mean</dd><dt><span>cell_measures :</span></dt><dd>area: areacello</dd><dt><span>history :</span></dt><dd>2019-11-08T18:45:39Z altered by CMOR: replaced missing value flag (-1e+20) with standard missing value (1e+20).</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 43.12 MiB </td>\n",
       "                        <td> 32.00 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1380, 64, 128) </td>\n",
       "                        <td> (1, 64, 128) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1381 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"168\" height=\"154\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"34\" x2=\"80\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"34\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"37\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"41\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"45\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"48\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"52\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"56\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"60\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"63\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"67\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"71\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"50\" y2=\"74\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"78\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"58\" y2=\"82\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"86\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"65\" y2=\"89\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"69\" y2=\"93\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"73\" y2=\"97\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"100\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,104.62830694263232 10.0,34.04007164851467\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"48\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"51\" y2=\"3\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"55\" y2=\"7\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"59\" y2=\"11\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"63\" y2=\"14\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"66\" y2=\"18\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"70\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"74\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"77\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"81\" y2=\"33\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"85\" y2=\"37\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"88\" y2=\"40\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"92\" y2=\"44\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"96\" y2=\"48\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"100\" y2=\"51\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"103\" y2=\"55\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"107\" y2=\"59\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"111\" y2=\"63\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"115\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"118\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"118\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 48.17590727457826,0.0 118.76414256869592,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"118\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"104\" x2=\"118\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"118\" y1=\"70\" x2=\"118\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 118.76414256869592,70.58823529411765 118.76414256869592,104.62830694263232 80.58823529411765,104.62830694263232\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"99.676189\" y=\"124.628307\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >128</text>\n",
       "  <text x=\"138.764143\" y=\"87.608271\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,138.764143,87.608271)\">64</text>\n",
       "  <text x=\"35.294118\" y=\"89.334189\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,89.334189)\">1380</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-7c846047-4fd3-44dd-a5f6-4e1e09f8849a' class='xr-section-summary-in' type='checkbox'  ><label for='section-7c846047-4fd3-44dd-a5f6-4e1e09f8849a' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-25ec3b5a-1030-431d-bfd4-4af064e0a896' class='xr-index-data-in' type='checkbox'/><label for='index-25ec3b5a-1030-431d-bfd4-4af064e0a896' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([   15.5,    45.0,    74.5,   105.0,   135.5,   166.0,   196.5,\n",
       "                227.5,   258.0,   288.5,\n",
       "              ...\n",
       "              41712.5, 41743.0, 41773.5, 41804.0, 41834.5, 41865.5, 41896.0,\n",
       "              41926.5, 41957.0, 41987.5],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;, length=1380))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-c199ffc3-f3a9-45f8-82a3-d2de4c52731c' class='xr-index-data-in' type='checkbox'/><label for='index-c199ffc3-f3a9-45f8-82a3-d2de4c52731c' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([     0.0,   2.8125,    5.625,   8.4375,    11.25,  14.0625,\n",
       "                16.875,  19.6875,     22.5,  25.3125,\n",
       "              ...\n",
       "               331.875, 334.6875,    337.5, 340.3125,  343.125, 345.9375,\n",
       "                348.75, 351.5625,  354.375, 357.1875],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;, length=128))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-a67b3ec1-5eb8-47e3-bc47-00c9b25881f8' class='xr-index-data-in' type='checkbox'/><label for='index-a67b3ec1-5eb8-47e3-bc47-00c9b25881f8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([  87.86379883923263,   85.09652698831736,   82.31291294788629,\n",
       "                79.52560657265944,   76.73689968036832,   73.94751515398967,\n",
       "                71.15775201158733,   68.36775610831317,   65.57760701082782,\n",
       "                62.78735179896307,  59.997020108491306,  57.206631527643246,\n",
       "                54.41619952608621,  51.625733674938246,   48.83524096625058,\n",
       "               46.044726631101675,  43.254194665350944,   40.46364817811504,\n",
       "                37.67308962904533,   34.88252099377346,  32.091943881744015,\n",
       "                29.30135962176274,  26.510769325210987,  23.720173933534745,\n",
       "               20.929574254489523,  18.138970990239347,  15.348364759491494,\n",
       "               12.557756115230674,   9.767145559195573,   6.976533553948629,\n",
       "                4.185920533189151,  1.3953069108194966, -1.3953069108194966,\n",
       "               -4.185920533189151,  -6.976533553948629,  -9.767145559195573,\n",
       "              -12.557756115230674, -15.348364759491494, -18.138970990239347,\n",
       "              -20.929574254489523, -23.720173933534745, -26.510769325210987,\n",
       "               -29.30135962176274, -32.091943881744015,  -34.88252099377346,\n",
       "               -37.67308962904533,  -40.46364817811504, -43.254194665350944,\n",
       "              -46.044726631101675,  -48.83524096625058, -51.625733674938246,\n",
       "               -54.41619952608621, -57.206631527643246, -59.997020108491306,\n",
       "               -62.78735179896307,  -65.57760701082782,  -68.36775610831317,\n",
       "               -71.15775201158733,  -73.94751515398967,  -76.73689968036832,\n",
       "               -79.52560657265944,  -82.31291294788629,  -85.09652698831736,\n",
       "               -87.86379883923263],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c088ae45-16ab-4c13-a08e-0e12d46b37d2' class='xr-section-summary-in' type='checkbox'  ><label for='section-c088ae45-16ab-4c13-a08e-0e12d46b37d2' class='xr-section-summary' >Attributes: <span>(49)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>CDI :</span></dt><dd>Climate Data Interface version 2.0.4 (https://mpimet.mpg.de/cdi)</dd><dt><span>source :</span></dt><dd>ACCESS-CM2 (2019): \n",
       "aerosol: UKCA-GLOMAP-mode\n",
       "atmos: MetUM-HadGEM3-GA7.1 (N96; 192 x 144 longitude/latitude; 85 levels; top level 85 km)\n",
       "atmosChem: none\n",
       "land: CABLE2.5\n",
       "landIce: none\n",
       "ocean: ACCESS-OM2 (GFDL-MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\n",
       "ocnBgchem: none\n",
       "seaIce: CICE5.1.2 (same grid as ocean)</dd><dt><span>institution :</span></dt><dd>CSIRO (Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia), ARCCSS (Australian Research Council Centre of Excellence for Climate System Science)</dd><dt><span>Conventions :</span></dt><dd>CF-1.7 CMIP-6.2</dd><dt><span>activity_id :</span></dt><dd>CMIP</dd><dt><span>branch_method :</span></dt><dd>standard</dd><dt><span>branch_time_in_child :</span></dt><dd>0.0</dd><dt><span>branch_time_in_parent :</span></dt><dd>0.0</dd><dt><span>creation_date :</span></dt><dd>2019-11-08T18:45:44Z</dd><dt><span>data_specs_version :</span></dt><dd>01.00.30</dd><dt><span>experiment :</span></dt><dd>all-forcing simulation of the recent past</dd><dt><span>experiment_id :</span></dt><dd>historical</dd><dt><span>external_variables :</span></dt><dd>areacello</dd><dt><span>forcing_index :</span></dt><dd>1</dd><dt><span>frequency :</span></dt><dd>mon</dd><dt><span>further_info_url :</span></dt><dd>https://furtherinfo.es-doc.org/CMIP6.CSIRO-ARCCSS.ACCESS-CM2.historical.none.r1i1p1f1</dd><dt><span>grid :</span></dt><dd>native atmosphere N96 grid (144x192 latxlon)</dd><dt><span>grid_label :</span></dt><dd>gn</dd><dt><span>history :</span></dt><dd>Tue Jan 24 01:06:45 2023: cdo ensmean Regrid_ACCESS-CM2.nc Regrid_ACCESS-ESM1-5.nc Regrid_CAMS-CSM1-0.nc Regrid_CanESM5-CanOE.nc Regrid_CanESM5.nc Regrid_CMCC-CM2-SR5.nc Regrid_CMCC-ESM2.nc Regrid_CNRM-CM6-1.nc Regrid_CNRM-ESM2-1.nc Regrid_E3SM-1-0.nc Regrid_E3SM-1-1-ECA.nc Regrid_FGOALS-f3-L.nc Regrid_FGOALS-g3.nc Regrid_FIO-ESM-2-0.nc Regrid_GFDL-ESM4.nc Regrid_GISS-E2-1-H.nc Regrid_HadGEM3-GC31-LL.nc Regrid_IITM-ESM.nc Regrid_INM-CM4-8.nc Regrid_INM-CM5-0.nc Regrid_KIOST-ESM.nc Regrid_MCM-UA-1-0.nc Regrid_MIROC6.nc Regrid_MIROC-ES2L.nc Regrid_MRI-ESM2-0.nc Regrid_NESM3.nc Regrid_NorCPM1.nc ensemble_CMIP6.nc\n",
       "Mon Jan 23 23:06:23 2023: cdo -remap,n32,weights.nc tos_Omon_ACCESS-CM2_historical_r1i1p1f1_gn_18500116-20141216_v20191108.nc Regrid_ACCESS-CM2.nc\n",
       "2019-11-08T18:45:44Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.</dd><dt><span>initialization_index :</span></dt><dd>1</dd><dt><span>institution_id :</span></dt><dd>CSIRO-ARCCSS</dd><dt><span>mip_era :</span></dt><dd>CMIP6</dd><dt><span>nominal_resolution :</span></dt><dd>250 km</dd><dt><span>notes :</span></dt><dd>Exp: CM2-historical; Local ID: bj594; Variable: tos ([&#x27;sst&#x27;])</dd><dt><span>parent_activity_id :</span></dt><dd>CMIP</dd><dt><span>parent_experiment_id :</span></dt><dd>piControl</dd><dt><span>parent_mip_era :</span></dt><dd>CMIP6</dd><dt><span>parent_source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>parent_time_units :</span></dt><dd>days since 0950-01-01</dd><dt><span>parent_variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>physics_index :</span></dt><dd>1</dd><dt><span>product :</span></dt><dd>model-output</dd><dt><span>realization_index :</span></dt><dd>1</dd><dt><span>realm :</span></dt><dd>ocean</dd><dt><span>run_variant :</span></dt><dd>forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)</dd><dt><span>source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>source_type :</span></dt><dd>AOGCM</dd><dt><span>sub_experiment :</span></dt><dd>none</dd><dt><span>sub_experiment_id :</span></dt><dd>none</dd><dt><span>table_id :</span></dt><dd>Omon</dd><dt><span>table_info :</span></dt><dd>Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371</dd><dt><span>title :</span></dt><dd>ACCESS-CM2 output prepared for CMIP6</dd><dt><span>variable_id :</span></dt><dd>tos</dd><dt><span>variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>version :</span></dt><dd>v20191108</dd><dt><span>cmor_version :</span></dt><dd>3.4.0</dd><dt><span>tracking_id :</span></dt><dd>hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5</dd><dt><span>license :</span></dt><dd>CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.</dd><dt><span>CDO :</span></dt><dd>Climate Data Operators version 2.0.4 (https://mpimet.mpg.de/cdo)</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (time: 1380, bnds: 2, lon: 128, lat: 64)\n",
       "Coordinates:\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
       "  * lat        (lat) float64 87.86 85.1 82.31 79.53 ... -82.31 -85.1 -87.86\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, bnds) float64 dask.array<chunksize=(1, 2), meta=np.ndarray>\n",
       "    tos        (time, lat, lon) float32 dask.array<chunksize=(1, 64, 128), meta=np.ndarray>\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "ds = xr.open_dataset(ifile+'ensemble_CMIP6.nc', chunks={'time':1},decode_times=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5bd0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add lev dimension\n",
    "lev_coords = np.zeros(1)\n",
    "ds_add_lev = ds.expand_dims({\"lev\": lev_coords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f2bb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (lev: 1, time: 1380, bnds: 2, lon: 128, lat: 64)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
       "  * lat        (lat) float64 87.86 85.1 82.31 79.53 ... -82.31 -85.1 -87.86\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (lev, time, bnds) float64 dask.array&lt;chunksize=(1, 1, 2), meta=np.ndarray&gt;\n",
       "    tos        (lev, time, lat, lon) float32 dask.array&lt;chunksize=(1, 1, 64, 128), meta=np.ndarray&gt;\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-d05f8f44-b865-431b-a357-a3762eb5c6bc' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-d05f8f44-b865-431b-a357-a3762eb5c6bc' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lev</span>: 1</li><li><span class='xr-has-index'>time</span>: 1380</li><li><span>bnds</span>: 2</li><li><span class='xr-has-index'>lon</span>: 128</li><li><span class='xr-has-index'>lat</span>: 64</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-89ed99e6-0581-46b8-a413-ff204efacc65' class='xr-section-summary-in' type='checkbox'  checked><label for='section-89ed99e6-0581-46b8-a413-ff204efacc65' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lev</span></div><div class='xr-var-dims'>(lev)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0</div><input id='attrs-ea0ad040-92ac-4f53-a13e-0a1fab1f4df7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ea0ad040-92ac-4f53-a13e-0a1fab1f4df7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d7bab372-aca8-4e42-97e0-c57bae052d56' class='xr-var-data-in' type='checkbox'><label for='data-d7bab372-aca8-4e42-97e0-c57bae052d56' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>15.5 45.0 ... 4.196e+04 4.199e+04</div><input id='attrs-5f6ad00d-1e0d-4133-b73f-1d3bd210c0a2' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-5f6ad00d-1e0d-4133-b73f-1d3bd210c0a2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f3eda221-ad7b-4d85-8479-5fc34b01d5f7' class='xr-var-data-in' type='checkbox'><label for='data-f3eda221-ad7b-4d85-8479-5fc34b01d5f7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd><dt><span>bounds :</span></dt><dd>time_bnds</dd><dt><span>units :</span></dt><dd>days since 1850-01-01</dd><dt><span>calendar :</span></dt><dd>proleptic_gregorian</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([1.55000e+01, 4.50000e+01, 7.45000e+01, ..., 4.19265e+04, 4.19570e+04,\n",
       "       4.19875e+04])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 2.812 5.625 ... 354.4 357.2</div><input id='attrs-ad2daa09-54d6-4011-9e26-c971fdf237ad' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-ad2daa09-54d6-4011-9e26-c971fdf237ad' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3a1d90cb-4b12-47bc-88dd-8a995f5f01c6' class='xr-var-data-in' type='checkbox'><label for='data-3a1d90cb-4b12-47bc-88dd-8a995f5f01c6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([  0.    ,   2.8125,   5.625 ,   8.4375,  11.25  ,  14.0625,  16.875 ,\n",
       "        19.6875,  22.5   ,  25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "        39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,  53.4375,  56.25  ,\n",
       "        59.0625,  61.875 ,  64.6875,  67.5   ,  70.3125,  73.125 ,  75.9375,\n",
       "        78.75  ,  81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,  95.625 ,\n",
       "        98.4375, 101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125,\n",
       "       118.125 , 120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "       137.8125, 140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875,\n",
       "       157.5   , 160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 ,\n",
       "       177.1875, 180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625,\n",
       "       196.875 , 199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  ,\n",
       "       216.5625, 219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "       236.25  , 239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 ,\n",
       "       255.9375, 258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125,\n",
       "       275.625 , 278.4375, 281.25  , 284.0625, 286.875 , 289.6875, 292.5   ,\n",
       "       295.3125, 298.125 , 300.9375, 303.75  , 306.5625, 309.375 , 312.1875,\n",
       "       315.    , 317.8125, 320.625 , 323.4375, 326.25  , 329.0625, 331.875 ,\n",
       "       334.6875, 337.5   , 340.3125, 343.125 , 345.9375, 348.75  , 351.5625,\n",
       "       354.375 , 357.1875])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>87.86 85.1 82.31 ... -85.1 -87.86</div><input id='attrs-a68fee13-e98e-4ce9-a06c-2f9908bb5476' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a68fee13-e98e-4ce9-a06c-2f9908bb5476' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b1609632-2a84-42e1-b7d9-efd263e4609b' class='xr-var-data-in' type='checkbox'><label for='data-b1609632-2a84-42e1-b7d9-efd263e4609b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([ 87.863799,  85.096527,  82.312913,  79.525607,  76.7369  ,  73.947515,\n",
       "        71.157752,  68.367756,  65.577607,  62.787352,  59.99702 ,  57.206632,\n",
       "        54.4162  ,  51.625734,  48.835241,  46.044727,  43.254195,  40.463648,\n",
       "        37.67309 ,  34.882521,  32.091944,  29.30136 ,  26.510769,  23.720174,\n",
       "        20.929574,  18.138971,  15.348365,  12.557756,   9.767146,   6.976534,\n",
       "         4.185921,   1.395307,  -1.395307,  -4.185921,  -6.976534,  -9.767146,\n",
       "       -12.557756, -15.348365, -18.138971, -20.929574, -23.720174, -26.510769,\n",
       "       -29.30136 , -32.091944, -34.882521, -37.67309 , -40.463648, -43.254195,\n",
       "       -46.044727, -48.835241, -51.625734, -54.4162  , -57.206632, -59.99702 ,\n",
       "       -62.787352, -65.577607, -68.367756, -71.157752, -73.947515, -76.7369  ,\n",
       "       -79.525607, -82.312913, -85.096527, -87.863799])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-4dee7569-b2dc-461f-8030-1a59fc5c5784' class='xr-section-summary-in' type='checkbox'  checked><label for='section-4dee7569-b2dc-461f-8030-1a59fc5c5784' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time_bnds</span></div><div class='xr-var-dims'>(lev, time, bnds)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1, 2), meta=np.ndarray&gt;</div><input id='attrs-a3cfae3c-fb75-461b-8760-777f5273f619' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a3cfae3c-fb75-461b-8760-777f5273f619' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1d18daed-2906-4903-93e1-be531754859a' class='xr-var-data-in' type='checkbox'><label for='data-1d18daed-2906-4903-93e1-be531754859a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 21.56 kiB </td>\n",
       "                        <td> 16 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1380, 2) </td>\n",
       "                        <td> (1, 1, 2) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2761 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"100\" height=\"184\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"6\" x2=\"24\" y2=\"21\" />\n",
       "  <line x1=\"10\" y1=\"12\" x2=\"24\" y2=\"27\" />\n",
       "  <line x1=\"10\" y1=\"18\" x2=\"24\" y2=\"33\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"10\" y1=\"31\" x2=\"24\" y2=\"46\" />\n",
       "  <line x1=\"10\" y1=\"37\" x2=\"24\" y2=\"52\" />\n",
       "  <line x1=\"10\" y1=\"44\" x2=\"24\" y2=\"59\" />\n",
       "  <line x1=\"10\" y1=\"50\" x2=\"24\" y2=\"65\" />\n",
       "  <line x1=\"10\" y1=\"56\" x2=\"24\" y2=\"71\" />\n",
       "  <line x1=\"10\" y1=\"63\" x2=\"24\" y2=\"78\" />\n",
       "  <line x1=\"10\" y1=\"69\" x2=\"24\" y2=\"84\" />\n",
       "  <line x1=\"10\" y1=\"75\" x2=\"24\" y2=\"90\" />\n",
       "  <line x1=\"10\" y1=\"82\" x2=\"24\" y2=\"97\" />\n",
       "  <line x1=\"10\" y1=\"88\" x2=\"24\" y2=\"103\" />\n",
       "  <line x1=\"10\" y1=\"94\" x2=\"24\" y2=\"109\" />\n",
       "  <line x1=\"10\" y1=\"101\" x2=\"24\" y2=\"115\" />\n",
       "  <line x1=\"10\" y1=\"107\" x2=\"24\" y2=\"122\" />\n",
       "  <line x1=\"10\" y1=\"113\" x2=\"24\" y2=\"128\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"24\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 24.9485979497544,14.948597949754403 24.9485979497544,134.9485979497544 10.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"24\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"50\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 50.36121446433688,14.948597949754403 24.9485979497544,14.948597949754403\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"21\" x2=\"50\" y2=\"21\" />\n",
       "  <line x1=\"24\" y1=\"27\" x2=\"50\" y2=\"27\" />\n",
       "  <line x1=\"24\" y1=\"33\" x2=\"50\" y2=\"33\" />\n",
       "  <line x1=\"24\" y1=\"40\" x2=\"50\" y2=\"40\" />\n",
       "  <line x1=\"24\" y1=\"46\" x2=\"50\" y2=\"46\" />\n",
       "  <line x1=\"24\" y1=\"52\" x2=\"50\" y2=\"52\" />\n",
       "  <line x1=\"24\" y1=\"59\" x2=\"50\" y2=\"59\" />\n",
       "  <line x1=\"24\" y1=\"65\" x2=\"50\" y2=\"65\" />\n",
       "  <line x1=\"24\" y1=\"71\" x2=\"50\" y2=\"71\" />\n",
       "  <line x1=\"24\" y1=\"78\" x2=\"50\" y2=\"78\" />\n",
       "  <line x1=\"24\" y1=\"84\" x2=\"50\" y2=\"84\" />\n",
       "  <line x1=\"24\" y1=\"90\" x2=\"50\" y2=\"90\" />\n",
       "  <line x1=\"24\" y1=\"97\" x2=\"50\" y2=\"97\" />\n",
       "  <line x1=\"24\" y1=\"103\" x2=\"50\" y2=\"103\" />\n",
       "  <line x1=\"24\" y1=\"109\" x2=\"50\" y2=\"109\" />\n",
       "  <line x1=\"24\" y1=\"115\" x2=\"50\" y2=\"115\" />\n",
       "  <line x1=\"24\" y1=\"122\" x2=\"50\" y2=\"122\" />\n",
       "  <line x1=\"24\" y1=\"128\" x2=\"50\" y2=\"128\" />\n",
       "  <line x1=\"24\" y1=\"134\" x2=\"50\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"50\" y1=\"14\" x2=\"50\" y2=\"134\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"24.9485979497544,14.948597949754403 50.36121446433688,14.948597949754403 50.36121446433688,134.9485979497544 24.9485979497544,134.9485979497544\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"37.654906\" y=\"154.948598\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2</text>\n",
       "  <text x=\"70.361214\" y=\"74.948598\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,70.361214,74.948598)\">1380</text>\n",
       "  <text x=\"7.474299\" y=\"147.474299\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,7.474299,147.474299)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tos</span></div><div class='xr-var-dims'>(lev, time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1, 64, 128), meta=np.ndarray&gt;</div><input id='attrs-41f8d8ab-0f45-458f-9d6f-ea06047b5f68' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-41f8d8ab-0f45-458f-9d6f-ea06047b5f68' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-759f2dcd-e0af-41c7-970c-5438dc5fa394' class='xr-var-data-in' type='checkbox'><label for='data-759f2dcd-e0af-41c7-970c-5438dc5fa394' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_surface_temperature</dd><dt><span>long_name :</span></dt><dd>Sea Surface Temperature</dd><dt><span>units :</span></dt><dd>degC</dd><dt><span>CDI_grid_type :</span></dt><dd>gaussian</dd><dt><span>CDI_grid_num_LPE :</span></dt><dd>32</dd><dt><span>comment :</span></dt><dd>Temperature of upper boundary of the liquid ocean, including temperatures below sea-ice and floating ice shelves.</dd><dt><span>cell_methods :</span></dt><dd>area: mean where sea time: mean</dd><dt><span>cell_measures :</span></dt><dd>area: areacello</dd><dt><span>history :</span></dt><dd>2019-11-08T18:45:39Z altered by CMOR: replaced missing value flag (-1e+20) with standard missing value (1e+20).</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 43.12 MiB </td>\n",
       "                        <td> 32.00 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, 1380, 64, 128) </td>\n",
       "                        <td> (1, 1, 64, 128) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 2761 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"348\" height=\"154\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1</text>\n",
       "  <text x=\"45.412617\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,45.412617,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"165\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"95\" y1=\"34\" x2=\"165\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"95\" y2=\"34\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"97\" y1=\"2\" x2=\"97\" y2=\"36\" />\n",
       "  <line x1=\"99\" y1=\"4\" x2=\"99\" y2=\"38\" />\n",
       "  <line x1=\"101\" y1=\"6\" x2=\"101\" y2=\"40\" />\n",
       "  <line x1=\"103\" y1=\"8\" x2=\"103\" y2=\"42\" />\n",
       "  <line x1=\"105\" y1=\"10\" x2=\"105\" y2=\"45\" />\n",
       "  <line x1=\"108\" y1=\"13\" x2=\"108\" y2=\"47\" />\n",
       "  <line x1=\"110\" y1=\"15\" x2=\"110\" y2=\"49\" />\n",
       "  <line x1=\"112\" y1=\"17\" x2=\"112\" y2=\"51\" />\n",
       "  <line x1=\"114\" y1=\"19\" x2=\"114\" y2=\"53\" />\n",
       "  <line x1=\"117\" y1=\"22\" x2=\"117\" y2=\"56\" />\n",
       "  <line x1=\"119\" y1=\"24\" x2=\"119\" y2=\"58\" />\n",
       "  <line x1=\"121\" y1=\"26\" x2=\"121\" y2=\"60\" />\n",
       "  <line x1=\"123\" y1=\"28\" x2=\"123\" y2=\"62\" />\n",
       "  <line x1=\"125\" y1=\"30\" x2=\"125\" y2=\"64\" />\n",
       "  <line x1=\"128\" y1=\"33\" x2=\"128\" y2=\"67\" />\n",
       "  <line x1=\"130\" y1=\"35\" x2=\"130\" y2=\"69\" />\n",
       "  <line x1=\"132\" y1=\"37\" x2=\"132\" y2=\"71\" />\n",
       "  <line x1=\"134\" y1=\"39\" x2=\"134\" y2=\"73\" />\n",
       "  <line x1=\"136\" y1=\"41\" x2=\"136\" y2=\"75\" />\n",
       "  <line x1=\"139\" y1=\"44\" x2=\"139\" y2=\"78\" />\n",
       "  <line x1=\"141\" y1=\"46\" x2=\"141\" y2=\"80\" />\n",
       "  <line x1=\"143\" y1=\"48\" x2=\"143\" y2=\"82\" />\n",
       "  <line x1=\"145\" y1=\"50\" x2=\"145\" y2=\"84\" />\n",
       "  <line x1=\"147\" y1=\"52\" x2=\"147\" y2=\"86\" />\n",
       "  <line x1=\"150\" y1=\"55\" x2=\"150\" y2=\"89\" />\n",
       "  <line x1=\"152\" y1=\"57\" x2=\"152\" y2=\"91\" />\n",
       "  <line x1=\"154\" y1=\"59\" x2=\"154\" y2=\"93\" />\n",
       "  <line x1=\"156\" y1=\"61\" x2=\"156\" y2=\"95\" />\n",
       "  <line x1=\"158\" y1=\"63\" x2=\"158\" y2=\"97\" />\n",
       "  <line x1=\"161\" y1=\"66\" x2=\"161\" y2=\"100\" />\n",
       "  <line x1=\"163\" y1=\"68\" x2=\"163\" y2=\"102\" />\n",
       "  <line x1=\"165\" y1=\"70\" x2=\"165\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 165.58823529411765,70.58823529411765 165.58823529411765,104.62830694263232 95.0,34.04007164851467\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"133\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"97\" y1=\"2\" x2=\"135\" y2=\"2\" />\n",
       "  <line x1=\"99\" y1=\"4\" x2=\"137\" y2=\"4\" />\n",
       "  <line x1=\"101\" y1=\"6\" x2=\"139\" y2=\"6\" />\n",
       "  <line x1=\"103\" y1=\"8\" x2=\"141\" y2=\"8\" />\n",
       "  <line x1=\"105\" y1=\"10\" x2=\"144\" y2=\"10\" />\n",
       "  <line x1=\"108\" y1=\"13\" x2=\"146\" y2=\"13\" />\n",
       "  <line x1=\"110\" y1=\"15\" x2=\"148\" y2=\"15\" />\n",
       "  <line x1=\"112\" y1=\"17\" x2=\"150\" y2=\"17\" />\n",
       "  <line x1=\"114\" y1=\"19\" x2=\"153\" y2=\"19\" />\n",
       "  <line x1=\"117\" y1=\"22\" x2=\"155\" y2=\"22\" />\n",
       "  <line x1=\"119\" y1=\"24\" x2=\"157\" y2=\"24\" />\n",
       "  <line x1=\"121\" y1=\"26\" x2=\"159\" y2=\"26\" />\n",
       "  <line x1=\"123\" y1=\"28\" x2=\"161\" y2=\"28\" />\n",
       "  <line x1=\"125\" y1=\"30\" x2=\"164\" y2=\"30\" />\n",
       "  <line x1=\"128\" y1=\"33\" x2=\"166\" y2=\"33\" />\n",
       "  <line x1=\"130\" y1=\"35\" x2=\"168\" y2=\"35\" />\n",
       "  <line x1=\"132\" y1=\"37\" x2=\"170\" y2=\"37\" />\n",
       "  <line x1=\"134\" y1=\"39\" x2=\"172\" y2=\"39\" />\n",
       "  <line x1=\"136\" y1=\"41\" x2=\"175\" y2=\"41\" />\n",
       "  <line x1=\"139\" y1=\"44\" x2=\"177\" y2=\"44\" />\n",
       "  <line x1=\"141\" y1=\"46\" x2=\"179\" y2=\"46\" />\n",
       "  <line x1=\"143\" y1=\"48\" x2=\"181\" y2=\"48\" />\n",
       "  <line x1=\"145\" y1=\"50\" x2=\"183\" y2=\"50\" />\n",
       "  <line x1=\"147\" y1=\"52\" x2=\"186\" y2=\"52\" />\n",
       "  <line x1=\"150\" y1=\"55\" x2=\"188\" y2=\"55\" />\n",
       "  <line x1=\"152\" y1=\"57\" x2=\"190\" y2=\"57\" />\n",
       "  <line x1=\"154\" y1=\"59\" x2=\"192\" y2=\"59\" />\n",
       "  <line x1=\"156\" y1=\"61\" x2=\"194\" y2=\"61\" />\n",
       "  <line x1=\"158\" y1=\"63\" x2=\"197\" y2=\"63\" />\n",
       "  <line x1=\"161\" y1=\"66\" x2=\"199\" y2=\"66\" />\n",
       "  <line x1=\"163\" y1=\"68\" x2=\"201\" y2=\"68\" />\n",
       "  <line x1=\"165\" y1=\"70\" x2=\"203\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"95\" y1=\"0\" x2=\"165\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"133\" y1=\"0\" x2=\"203\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"95.0,0.0 133.17590727457826,0.0 203.76414256869592,70.58823529411765 165.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"165\" y1=\"70\" x2=\"203\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"165\" y1=\"104\" x2=\"203\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"165\" y1=\"70\" x2=\"165\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"203\" y1=\"70\" x2=\"203\" y2=\"104\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"165.58823529411765,70.58823529411765 203.76414256869592,70.58823529411765 203.76414256869592,104.62830694263232 165.58823529411765,104.62830694263232\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"184.676189\" y=\"124.628307\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >128</text>\n",
       "  <text x=\"223.764143\" y=\"87.608271\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,223.764143,87.608271)\">64</text>\n",
       "  <text x=\"120.294118\" y=\"89.334189\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,120.294118,89.334189)\">1380</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-c192ca55-042c-44ba-bbd5-4cb2b79d81aa' class='xr-section-summary-in' type='checkbox'  ><label for='section-c192ca55-042c-44ba-bbd5-4cb2b79d81aa' class='xr-section-summary' >Indexes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-14e4bad0-2fc0-4a9d-aeb2-79decc5266ea' class='xr-index-data-in' type='checkbox'/><label for='index-14e4bad0-2fc0-4a9d-aeb2-79decc5266ea' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([   15.5,    45.0,    74.5,   105.0,   135.5,   166.0,   196.5,\n",
       "                227.5,   258.0,   288.5,\n",
       "              ...\n",
       "              41712.5, 41743.0, 41773.5, 41804.0, 41834.5, 41865.5, 41896.0,\n",
       "              41926.5, 41957.0, 41987.5],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;, length=1380))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-ee6f9ef0-5d5e-44f0-b3e3-bce3abfe444a' class='xr-index-data-in' type='checkbox'/><label for='index-ee6f9ef0-5d5e-44f0-b3e3-bce3abfe444a' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([     0.0,   2.8125,    5.625,   8.4375,    11.25,  14.0625,\n",
       "                16.875,  19.6875,     22.5,  25.3125,\n",
       "              ...\n",
       "               331.875, 334.6875,    337.5, 340.3125,  343.125, 345.9375,\n",
       "                348.75, 351.5625,  354.375, 357.1875],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;, length=128))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-32efec1a-f5cd-4cd9-a9ea-ec5aa6ad6779' class='xr-index-data-in' type='checkbox'/><label for='index-32efec1a-f5cd-4cd9-a9ea-ec5aa6ad6779' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([  87.86379883923263,   85.09652698831736,   82.31291294788629,\n",
       "                79.52560657265944,   76.73689968036832,   73.94751515398967,\n",
       "                71.15775201158733,   68.36775610831317,   65.57760701082782,\n",
       "                62.78735179896307,  59.997020108491306,  57.206631527643246,\n",
       "                54.41619952608621,  51.625733674938246,   48.83524096625058,\n",
       "               46.044726631101675,  43.254194665350944,   40.46364817811504,\n",
       "                37.67308962904533,   34.88252099377346,  32.091943881744015,\n",
       "                29.30135962176274,  26.510769325210987,  23.720173933534745,\n",
       "               20.929574254489523,  18.138970990239347,  15.348364759491494,\n",
       "               12.557756115230674,   9.767145559195573,   6.976533553948629,\n",
       "                4.185920533189151,  1.3953069108194966, -1.3953069108194966,\n",
       "               -4.185920533189151,  -6.976533553948629,  -9.767145559195573,\n",
       "              -12.557756115230674, -15.348364759491494, -18.138970990239347,\n",
       "              -20.929574254489523, -23.720173933534745, -26.510769325210987,\n",
       "               -29.30135962176274, -32.091943881744015,  -34.88252099377346,\n",
       "               -37.67308962904533,  -40.46364817811504, -43.254194665350944,\n",
       "              -46.044726631101675,  -48.83524096625058, -51.625733674938246,\n",
       "               -54.41619952608621, -57.206631527643246, -59.997020108491306,\n",
       "               -62.78735179896307,  -65.57760701082782,  -68.36775610831317,\n",
       "               -71.15775201158733,  -73.94751515398967,  -76.73689968036832,\n",
       "               -79.52560657265944,  -82.31291294788629,  -85.09652698831736,\n",
       "               -87.86379883923263],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lev</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-a9c36096-a7cb-466c-9306-272729d1bfc0' class='xr-index-data-in' type='checkbox'/><label for='index-a9c36096-a7cb-466c-9306-272729d1bfc0' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([0.0], dtype=&#x27;float64&#x27;, name=&#x27;lev&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-025a08fd-4034-44b8-9bc0-0dbd8d052288' class='xr-section-summary-in' type='checkbox'  ><label for='section-025a08fd-4034-44b8-9bc0-0dbd8d052288' class='xr-section-summary' >Attributes: <span>(49)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>CDI :</span></dt><dd>Climate Data Interface version 2.0.4 (https://mpimet.mpg.de/cdi)</dd><dt><span>source :</span></dt><dd>ACCESS-CM2 (2019): \n",
       "aerosol: UKCA-GLOMAP-mode\n",
       "atmos: MetUM-HadGEM3-GA7.1 (N96; 192 x 144 longitude/latitude; 85 levels; top level 85 km)\n",
       "atmosChem: none\n",
       "land: CABLE2.5\n",
       "landIce: none\n",
       "ocean: ACCESS-OM2 (GFDL-MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\n",
       "ocnBgchem: none\n",
       "seaIce: CICE5.1.2 (same grid as ocean)</dd><dt><span>institution :</span></dt><dd>CSIRO (Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia), ARCCSS (Australian Research Council Centre of Excellence for Climate System Science)</dd><dt><span>Conventions :</span></dt><dd>CF-1.7 CMIP-6.2</dd><dt><span>activity_id :</span></dt><dd>CMIP</dd><dt><span>branch_method :</span></dt><dd>standard</dd><dt><span>branch_time_in_child :</span></dt><dd>0.0</dd><dt><span>branch_time_in_parent :</span></dt><dd>0.0</dd><dt><span>creation_date :</span></dt><dd>2019-11-08T18:45:44Z</dd><dt><span>data_specs_version :</span></dt><dd>01.00.30</dd><dt><span>experiment :</span></dt><dd>all-forcing simulation of the recent past</dd><dt><span>experiment_id :</span></dt><dd>historical</dd><dt><span>external_variables :</span></dt><dd>areacello</dd><dt><span>forcing_index :</span></dt><dd>1</dd><dt><span>frequency :</span></dt><dd>mon</dd><dt><span>further_info_url :</span></dt><dd>https://furtherinfo.es-doc.org/CMIP6.CSIRO-ARCCSS.ACCESS-CM2.historical.none.r1i1p1f1</dd><dt><span>grid :</span></dt><dd>native atmosphere N96 grid (144x192 latxlon)</dd><dt><span>grid_label :</span></dt><dd>gn</dd><dt><span>history :</span></dt><dd>Tue Jan 24 01:06:45 2023: cdo ensmean Regrid_ACCESS-CM2.nc Regrid_ACCESS-ESM1-5.nc Regrid_CAMS-CSM1-0.nc Regrid_CanESM5-CanOE.nc Regrid_CanESM5.nc Regrid_CMCC-CM2-SR5.nc Regrid_CMCC-ESM2.nc Regrid_CNRM-CM6-1.nc Regrid_CNRM-ESM2-1.nc Regrid_E3SM-1-0.nc Regrid_E3SM-1-1-ECA.nc Regrid_FGOALS-f3-L.nc Regrid_FGOALS-g3.nc Regrid_FIO-ESM-2-0.nc Regrid_GFDL-ESM4.nc Regrid_GISS-E2-1-H.nc Regrid_HadGEM3-GC31-LL.nc Regrid_IITM-ESM.nc Regrid_INM-CM4-8.nc Regrid_INM-CM5-0.nc Regrid_KIOST-ESM.nc Regrid_MCM-UA-1-0.nc Regrid_MIROC6.nc Regrid_MIROC-ES2L.nc Regrid_MRI-ESM2-0.nc Regrid_NESM3.nc Regrid_NorCPM1.nc ensemble_CMIP6.nc\n",
       "Mon Jan 23 23:06:23 2023: cdo -remap,n32,weights.nc tos_Omon_ACCESS-CM2_historical_r1i1p1f1_gn_18500116-20141216_v20191108.nc Regrid_ACCESS-CM2.nc\n",
       "2019-11-08T18:45:44Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.</dd><dt><span>initialization_index :</span></dt><dd>1</dd><dt><span>institution_id :</span></dt><dd>CSIRO-ARCCSS</dd><dt><span>mip_era :</span></dt><dd>CMIP6</dd><dt><span>nominal_resolution :</span></dt><dd>250 km</dd><dt><span>notes :</span></dt><dd>Exp: CM2-historical; Local ID: bj594; Variable: tos ([&#x27;sst&#x27;])</dd><dt><span>parent_activity_id :</span></dt><dd>CMIP</dd><dt><span>parent_experiment_id :</span></dt><dd>piControl</dd><dt><span>parent_mip_era :</span></dt><dd>CMIP6</dd><dt><span>parent_source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>parent_time_units :</span></dt><dd>days since 0950-01-01</dd><dt><span>parent_variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>physics_index :</span></dt><dd>1</dd><dt><span>product :</span></dt><dd>model-output</dd><dt><span>realization_index :</span></dt><dd>1</dd><dt><span>realm :</span></dt><dd>ocean</dd><dt><span>run_variant :</span></dt><dd>forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)</dd><dt><span>source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>source_type :</span></dt><dd>AOGCM</dd><dt><span>sub_experiment :</span></dt><dd>none</dd><dt><span>sub_experiment_id :</span></dt><dd>none</dd><dt><span>table_id :</span></dt><dd>Omon</dd><dt><span>table_info :</span></dt><dd>Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371</dd><dt><span>title :</span></dt><dd>ACCESS-CM2 output prepared for CMIP6</dd><dt><span>variable_id :</span></dt><dd>tos</dd><dt><span>variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>version :</span></dt><dd>v20191108</dd><dt><span>cmor_version :</span></dt><dd>3.4.0</dd><dt><span>tracking_id :</span></dt><dd>hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5</dd><dt><span>license :</span></dt><dd>CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.</dd><dt><span>CDO :</span></dt><dd>Climate Data Operators version 2.0.4 (https://mpimet.mpg.de/cdo)</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (lev: 1, time: 1380, bnds: 2, lon: 128, lat: 64)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
       "  * lat        (lat) float64 87.86 85.1 82.31 79.53 ... -82.31 -85.1 -87.86\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (lev, time, bnds) float64 dask.array<chunksize=(1, 1, 2), meta=np.ndarray>\n",
       "    tos        (lev, time, lat, lon) float32 dask.array<chunksize=(1, 1, 64, 128), meta=np.ndarray>\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_add_lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b85e87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (lev: 1, time: 1380, bnds: 2, lon: 128, lat: 64)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
       "  * lat        (lat) float64 87.86 85.1 82.31 79.53 ... -82.31 -85.1 -87.86\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, lev, bnds) float64 dask.array&lt;chunksize=(1, 1, 2), meta=np.ndarray&gt;\n",
       "    tos        (time, lat, lon, lev) float32 dask.array&lt;chunksize=(1, 64, 128, 1), meta=np.ndarray&gt;\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-4f1bb508-0083-42d9-88fa-097991c1ff0a' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-4f1bb508-0083-42d9-88fa-097991c1ff0a' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lev</span>: 1</li><li><span class='xr-has-index'>time</span>: 1380</li><li><span>bnds</span>: 2</li><li><span class='xr-has-index'>lon</span>: 128</li><li><span class='xr-has-index'>lat</span>: 64</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-c990a141-1fb8-464c-8513-2ae881ca78e7' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c990a141-1fb8-464c-8513-2ae881ca78e7' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lev</span></div><div class='xr-var-dims'>(lev)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0</div><input id='attrs-f737d4e7-6c98-4a83-a5f5-df572e12eae5' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f737d4e7-6c98-4a83-a5f5-df572e12eae5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c33ace2b-8929-4776-9a6e-bc2159dc38c2' class='xr-var-data-in' type='checkbox'><label for='data-c33ace2b-8929-4776-9a6e-bc2159dc38c2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>15.5 45.0 ... 4.196e+04 4.199e+04</div><input id='attrs-e8ee14f0-df8e-4444-ae3b-c68a1c13922e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e8ee14f0-df8e-4444-ae3b-c68a1c13922e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a61b38cd-bda4-4d2c-9386-0c75ce5aabec' class='xr-var-data-in' type='checkbox'><label for='data-a61b38cd-bda4-4d2c-9386-0c75ce5aabec' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd><dt><span>bounds :</span></dt><dd>time_bnds</dd><dt><span>units :</span></dt><dd>days since 1850-01-01</dd><dt><span>calendar :</span></dt><dd>proleptic_gregorian</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([1.55000e+01, 4.50000e+01, 7.45000e+01, ..., 4.19265e+04, 4.19570e+04,\n",
       "       4.19875e+04])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 2.812 5.625 ... 354.4 357.2</div><input id='attrs-dcc96035-93ac-4372-96ce-0d7e0d6f73b4' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-dcc96035-93ac-4372-96ce-0d7e0d6f73b4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-67171462-617e-4185-b28f-47980bb7936a' class='xr-var-data-in' type='checkbox'><label for='data-67171462-617e-4185-b28f-47980bb7936a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([  0.    ,   2.8125,   5.625 ,   8.4375,  11.25  ,  14.0625,  16.875 ,\n",
       "        19.6875,  22.5   ,  25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "        39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,  53.4375,  56.25  ,\n",
       "        59.0625,  61.875 ,  64.6875,  67.5   ,  70.3125,  73.125 ,  75.9375,\n",
       "        78.75  ,  81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,  95.625 ,\n",
       "        98.4375, 101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125,\n",
       "       118.125 , 120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "       137.8125, 140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875,\n",
       "       157.5   , 160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 ,\n",
       "       177.1875, 180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625,\n",
       "       196.875 , 199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  ,\n",
       "       216.5625, 219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "       236.25  , 239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 ,\n",
       "       255.9375, 258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125,\n",
       "       275.625 , 278.4375, 281.25  , 284.0625, 286.875 , 289.6875, 292.5   ,\n",
       "       295.3125, 298.125 , 300.9375, 303.75  , 306.5625, 309.375 , 312.1875,\n",
       "       315.    , 317.8125, 320.625 , 323.4375, 326.25  , 329.0625, 331.875 ,\n",
       "       334.6875, 337.5   , 340.3125, 343.125 , 345.9375, 348.75  , 351.5625,\n",
       "       354.375 , 357.1875])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>87.86 85.1 82.31 ... -85.1 -87.86</div><input id='attrs-b3b7713b-9b62-40bd-85dd-484c55733af8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b3b7713b-9b62-40bd-85dd-484c55733af8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-163bcd1a-7d4e-40f0-be52-7c8480839348' class='xr-var-data-in' type='checkbox'><label for='data-163bcd1a-7d4e-40f0-be52-7c8480839348' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([ 87.863799,  85.096527,  82.312913,  79.525607,  76.7369  ,  73.947515,\n",
       "        71.157752,  68.367756,  65.577607,  62.787352,  59.99702 ,  57.206632,\n",
       "        54.4162  ,  51.625734,  48.835241,  46.044727,  43.254195,  40.463648,\n",
       "        37.67309 ,  34.882521,  32.091944,  29.30136 ,  26.510769,  23.720174,\n",
       "        20.929574,  18.138971,  15.348365,  12.557756,   9.767146,   6.976534,\n",
       "         4.185921,   1.395307,  -1.395307,  -4.185921,  -6.976534,  -9.767146,\n",
       "       -12.557756, -15.348365, -18.138971, -20.929574, -23.720174, -26.510769,\n",
       "       -29.30136 , -32.091944, -34.882521, -37.67309 , -40.463648, -43.254195,\n",
       "       -46.044727, -48.835241, -51.625734, -54.4162  , -57.206632, -59.99702 ,\n",
       "       -62.787352, -65.577607, -68.367756, -71.157752, -73.947515, -76.7369  ,\n",
       "       -79.525607, -82.312913, -85.096527, -87.863799])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-838c8ce2-bb3d-4fa6-a247-bd4a91f3ab5c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-838c8ce2-bb3d-4fa6-a247-bd4a91f3ab5c' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time_bnds</span></div><div class='xr-var-dims'>(time, lev, bnds)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1, 2), meta=np.ndarray&gt;</div><input id='attrs-fa2c37cb-7e04-4233-a0a3-7b81ac3b9ef6' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-fa2c37cb-7e04-4233-a0a3-7b81ac3b9ef6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fb408aff-07e8-48d4-b0ab-e19290fb1713' class='xr-var-data-in' type='checkbox'><label for='data-fb408aff-07e8-48d4-b0ab-e19290fb1713' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 21.56 kiB </td>\n",
       "                        <td> 16 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1380, 1, 2) </td>\n",
       "                        <td> (1, 1, 2) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 4141 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"29\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"36\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"51\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"55\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"58\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"62\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"50\" y2=\"66\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"58\" y2=\"73\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"77\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"65\" y2=\"81\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"69\" y2=\"84\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"73\" y2=\"88\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"92\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"39\" y2=\"3\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"46\" y2=\"11\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"53\" y2=\"18\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"61\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"65\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"68\" y2=\"33\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"72\" y2=\"37\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"76\" y2=\"40\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"83\" y2=\"48\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"87\" y2=\"51\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"91\" y2=\"55\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"94\" y2=\"59\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"98\" y2=\"63\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"102\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">1</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">1380</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tos</span></div><div class='xr-var-dims'>(time, lat, lon, lev)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 64, 128, 1), meta=np.ndarray&gt;</div><input id='attrs-816a343a-16db-4906-972c-0153a82fe4b1' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-816a343a-16db-4906-972c-0153a82fe4b1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b3819743-0422-46d0-9b27-99e2017c69b0' class='xr-var-data-in' type='checkbox'><label for='data-b3819743-0422-46d0-9b27-99e2017c69b0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_surface_temperature</dd><dt><span>long_name :</span></dt><dd>Sea Surface Temperature</dd><dt><span>units :</span></dt><dd>degC</dd><dt><span>CDI_grid_type :</span></dt><dd>gaussian</dd><dt><span>CDI_grid_num_LPE :</span></dt><dd>32</dd><dt><span>comment :</span></dt><dd>Temperature of upper boundary of the liquid ocean, including temperatures below sea-ice and floating ice shelves.</dd><dt><span>cell_methods :</span></dt><dd>area: mean where sea time: mean</dd><dt><span>cell_measures :</span></dt><dd>area: areacello</dd><dt><span>history :</span></dt><dd>2019-11-08T18:45:39Z altered by CMOR: replaced missing value flag (-1e+20) with standard missing value (1e+20).</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 43.12 MiB </td>\n",
       "                        <td> 32.00 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1380, 64, 128, 1) </td>\n",
       "                        <td> (1, 64, 128, 1) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 4141 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"475\" height=\"108\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"3\" y1=\"0\" x2=\"3\" y2=\"25\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"11\" y1=\"0\" x2=\"11\" y2=\"25\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"14\" y2=\"25\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"26\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"33\" y1=\"0\" x2=\"33\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"41\" y1=\"0\" x2=\"41\" y2=\"25\" />\n",
       "  <line x1=\"44\" y1=\"0\" x2=\"44\" y2=\"25\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"63\" y1=\"0\" x2=\"63\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"71\" y1=\"0\" x2=\"71\" y2=\"25\" />\n",
       "  <line x1=\"74\" y1=\"0\" x2=\"74\" y2=\"25\" />\n",
       "  <line x1=\"78\" y1=\"0\" x2=\"78\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"86\" y1=\"0\" x2=\"86\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"93\" y1=\"0\" x2=\"93\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"101\" y1=\"0\" x2=\"101\" y2=\"25\" />\n",
       "  <line x1=\"104\" y1=\"0\" x2=\"104\" y2=\"25\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"116\" y1=\"0\" x2=\"116\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1380</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"210\" y2=\"20\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"190\" y1=\"38\" x2=\"210\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"190\" y2=\"38\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"210\" y1=\"20\" x2=\"210\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.0,0.0 210.0235715579498,20.023571557949804 210.0235715579498,58.19947883252806 190.0,38.17590727457826\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"210\" y1=\"20\" x2=\"235\" y2=\"20\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"210\" y2=\"20\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"215\" y1=\"0\" x2=\"235\" y2=\"20\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.0,0.0 215.41261651458248,0.0 235.43618807253227,20.023571557949804 210.0235715579498,20.023571557949804\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"210\" y1=\"20\" x2=\"235\" y2=\"20\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"210\" y1=\"58\" x2=\"235\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"210\" y1=\"20\" x2=\"210\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"235\" y1=\"20\" x2=\"235\" y2=\"58\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"210.0235715579498,20.023571557949804 235.43618807253227,20.023571557949804 235.43618807253227,58.19947883252806 210.0235715579498,58.19947883252806\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"222.729880\" y=\"78.199479\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1</text>\n",
       "  <text x=\"255.436188\" y=\"39.111525\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,255.436188,39.111525)\">128</text>\n",
       "  <text x=\"190.011786\" y=\"68.187693\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,190.011786,68.187693)\">64</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-f6c5e573-69a8-4942-aa1e-5773cc98a409' class='xr-section-summary-in' type='checkbox'  ><label for='section-f6c5e573-69a8-4942-aa1e-5773cc98a409' class='xr-section-summary' >Indexes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-a9fca9d3-175d-4852-973a-79b9bc74d88d' class='xr-index-data-in' type='checkbox'/><label for='index-a9fca9d3-175d-4852-973a-79b9bc74d88d' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([   15.5,    45.0,    74.5,   105.0,   135.5,   166.0,   196.5,\n",
       "                227.5,   258.0,   288.5,\n",
       "              ...\n",
       "              41712.5, 41743.0, 41773.5, 41804.0, 41834.5, 41865.5, 41896.0,\n",
       "              41926.5, 41957.0, 41987.5],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;, length=1380))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-cf1ef2e0-9e3a-44cc-b691-0e53eb523497' class='xr-index-data-in' type='checkbox'/><label for='index-cf1ef2e0-9e3a-44cc-b691-0e53eb523497' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([     0.0,   2.8125,    5.625,   8.4375,    11.25,  14.0625,\n",
       "                16.875,  19.6875,     22.5,  25.3125,\n",
       "              ...\n",
       "               331.875, 334.6875,    337.5, 340.3125,  343.125, 345.9375,\n",
       "                348.75, 351.5625,  354.375, 357.1875],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;, length=128))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-5485c15b-c289-4825-bfd9-f45ca9739880' class='xr-index-data-in' type='checkbox'/><label for='index-5485c15b-c289-4825-bfd9-f45ca9739880' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([  87.86379883923263,   85.09652698831736,   82.31291294788629,\n",
       "                79.52560657265944,   76.73689968036832,   73.94751515398967,\n",
       "                71.15775201158733,   68.36775610831317,   65.57760701082782,\n",
       "                62.78735179896307,  59.997020108491306,  57.206631527643246,\n",
       "                54.41619952608621,  51.625733674938246,   48.83524096625058,\n",
       "               46.044726631101675,  43.254194665350944,   40.46364817811504,\n",
       "                37.67308962904533,   34.88252099377346,  32.091943881744015,\n",
       "                29.30135962176274,  26.510769325210987,  23.720173933534745,\n",
       "               20.929574254489523,  18.138970990239347,  15.348364759491494,\n",
       "               12.557756115230674,   9.767145559195573,   6.976533553948629,\n",
       "                4.185920533189151,  1.3953069108194966, -1.3953069108194966,\n",
       "               -4.185920533189151,  -6.976533553948629,  -9.767145559195573,\n",
       "              -12.557756115230674, -15.348364759491494, -18.138970990239347,\n",
       "              -20.929574254489523, -23.720173933534745, -26.510769325210987,\n",
       "               -29.30135962176274, -32.091943881744015,  -34.88252099377346,\n",
       "               -37.67308962904533,  -40.46364817811504, -43.254194665350944,\n",
       "              -46.044726631101675,  -48.83524096625058, -51.625733674938246,\n",
       "               -54.41619952608621, -57.206631527643246, -59.997020108491306,\n",
       "               -62.78735179896307,  -65.57760701082782,  -68.36775610831317,\n",
       "               -71.15775201158733,  -73.94751515398967,  -76.73689968036832,\n",
       "               -79.52560657265944,  -82.31291294788629,  -85.09652698831736,\n",
       "               -87.86379883923263],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lev</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-95d67df4-72db-48be-8afb-30461d95d974' class='xr-index-data-in' type='checkbox'/><label for='index-95d67df4-72db-48be-8afb-30461d95d974' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([0.0], dtype=&#x27;float64&#x27;, name=&#x27;lev&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-94bbaab9-7c5c-4c1a-80fc-ce58158ae125' class='xr-section-summary-in' type='checkbox'  ><label for='section-94bbaab9-7c5c-4c1a-80fc-ce58158ae125' class='xr-section-summary' >Attributes: <span>(49)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>CDI :</span></dt><dd>Climate Data Interface version 2.0.4 (https://mpimet.mpg.de/cdi)</dd><dt><span>source :</span></dt><dd>ACCESS-CM2 (2019): \n",
       "aerosol: UKCA-GLOMAP-mode\n",
       "atmos: MetUM-HadGEM3-GA7.1 (N96; 192 x 144 longitude/latitude; 85 levels; top level 85 km)\n",
       "atmosChem: none\n",
       "land: CABLE2.5\n",
       "landIce: none\n",
       "ocean: ACCESS-OM2 (GFDL-MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\n",
       "ocnBgchem: none\n",
       "seaIce: CICE5.1.2 (same grid as ocean)</dd><dt><span>institution :</span></dt><dd>CSIRO (Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia), ARCCSS (Australian Research Council Centre of Excellence for Climate System Science)</dd><dt><span>Conventions :</span></dt><dd>CF-1.7 CMIP-6.2</dd><dt><span>activity_id :</span></dt><dd>CMIP</dd><dt><span>branch_method :</span></dt><dd>standard</dd><dt><span>branch_time_in_child :</span></dt><dd>0.0</dd><dt><span>branch_time_in_parent :</span></dt><dd>0.0</dd><dt><span>creation_date :</span></dt><dd>2019-11-08T18:45:44Z</dd><dt><span>data_specs_version :</span></dt><dd>01.00.30</dd><dt><span>experiment :</span></dt><dd>all-forcing simulation of the recent past</dd><dt><span>experiment_id :</span></dt><dd>historical</dd><dt><span>external_variables :</span></dt><dd>areacello</dd><dt><span>forcing_index :</span></dt><dd>1</dd><dt><span>frequency :</span></dt><dd>mon</dd><dt><span>further_info_url :</span></dt><dd>https://furtherinfo.es-doc.org/CMIP6.CSIRO-ARCCSS.ACCESS-CM2.historical.none.r1i1p1f1</dd><dt><span>grid :</span></dt><dd>native atmosphere N96 grid (144x192 latxlon)</dd><dt><span>grid_label :</span></dt><dd>gn</dd><dt><span>history :</span></dt><dd>Tue Jan 24 01:06:45 2023: cdo ensmean Regrid_ACCESS-CM2.nc Regrid_ACCESS-ESM1-5.nc Regrid_CAMS-CSM1-0.nc Regrid_CanESM5-CanOE.nc Regrid_CanESM5.nc Regrid_CMCC-CM2-SR5.nc Regrid_CMCC-ESM2.nc Regrid_CNRM-CM6-1.nc Regrid_CNRM-ESM2-1.nc Regrid_E3SM-1-0.nc Regrid_E3SM-1-1-ECA.nc Regrid_FGOALS-f3-L.nc Regrid_FGOALS-g3.nc Regrid_FIO-ESM-2-0.nc Regrid_GFDL-ESM4.nc Regrid_GISS-E2-1-H.nc Regrid_HadGEM3-GC31-LL.nc Regrid_IITM-ESM.nc Regrid_INM-CM4-8.nc Regrid_INM-CM5-0.nc Regrid_KIOST-ESM.nc Regrid_MCM-UA-1-0.nc Regrid_MIROC6.nc Regrid_MIROC-ES2L.nc Regrid_MRI-ESM2-0.nc Regrid_NESM3.nc Regrid_NorCPM1.nc ensemble_CMIP6.nc\n",
       "Mon Jan 23 23:06:23 2023: cdo -remap,n32,weights.nc tos_Omon_ACCESS-CM2_historical_r1i1p1f1_gn_18500116-20141216_v20191108.nc Regrid_ACCESS-CM2.nc\n",
       "2019-11-08T18:45:44Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.</dd><dt><span>initialization_index :</span></dt><dd>1</dd><dt><span>institution_id :</span></dt><dd>CSIRO-ARCCSS</dd><dt><span>mip_era :</span></dt><dd>CMIP6</dd><dt><span>nominal_resolution :</span></dt><dd>250 km</dd><dt><span>notes :</span></dt><dd>Exp: CM2-historical; Local ID: bj594; Variable: tos ([&#x27;sst&#x27;])</dd><dt><span>parent_activity_id :</span></dt><dd>CMIP</dd><dt><span>parent_experiment_id :</span></dt><dd>piControl</dd><dt><span>parent_mip_era :</span></dt><dd>CMIP6</dd><dt><span>parent_source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>parent_time_units :</span></dt><dd>days since 0950-01-01</dd><dt><span>parent_variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>physics_index :</span></dt><dd>1</dd><dt><span>product :</span></dt><dd>model-output</dd><dt><span>realization_index :</span></dt><dd>1</dd><dt><span>realm :</span></dt><dd>ocean</dd><dt><span>run_variant :</span></dt><dd>forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)</dd><dt><span>source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>source_type :</span></dt><dd>AOGCM</dd><dt><span>sub_experiment :</span></dt><dd>none</dd><dt><span>sub_experiment_id :</span></dt><dd>none</dd><dt><span>table_id :</span></dt><dd>Omon</dd><dt><span>table_info :</span></dt><dd>Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371</dd><dt><span>title :</span></dt><dd>ACCESS-CM2 output prepared for CMIP6</dd><dt><span>variable_id :</span></dt><dd>tos</dd><dt><span>variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>version :</span></dt><dd>v20191108</dd><dt><span>cmor_version :</span></dt><dd>3.4.0</dd><dt><span>tracking_id :</span></dt><dd>hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5</dd><dt><span>license :</span></dt><dd>CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.</dd><dt><span>CDO :</span></dt><dd>Climate Data Operators version 2.0.4 (https://mpimet.mpg.de/cdo)</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (lev: 1, time: 1380, bnds: 2, lon: 128, lat: 64)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
       "  * lat        (lat) float64 87.86 85.1 82.31 79.53 ... -82.31 -85.1 -87.86\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, lev, bnds) float64 dask.array<chunksize=(1, 1, 2), meta=np.ndarray>\n",
       "    tos        (time, lat, lon, lev) float32 dask.array<chunksize=(1, 64, 128, 1), meta=np.ndarray>\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Transpose dimensions before feeding them into the model\n",
    "x = ds_add_lev.transpose('time','lat','lon','lev','bnds')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45b94fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (lev: 1, time: 1380, bnds: 2, lon: 64, lat: 32)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 101.2 104.1 106.9 109.7 ... 270.0 272.8 275.6 278.4\n",
       "  * lat        (lat) float64 85.1 82.31 79.53 76.74 ... 6.977 4.186 1.395 -1.395\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, lev, bnds) float64 dask.array&lt;chunksize=(1, 1, 2), meta=np.ndarray&gt;\n",
       "    tos        (time, lat, lon, lev) float32 dask.array&lt;chunksize=(1, 32, 64, 1), meta=np.ndarray&gt;\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-04d8cf74-7473-4c88-922b-6f588a4878bc' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-04d8cf74-7473-4c88-922b-6f588a4878bc' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lev</span>: 1</li><li><span class='xr-has-index'>time</span>: 1380</li><li><span>bnds</span>: 2</li><li><span class='xr-has-index'>lon</span>: 64</li><li><span class='xr-has-index'>lat</span>: 32</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-a3eceaad-d635-4630-8f9e-b8d77901f1e8' class='xr-section-summary-in' type='checkbox'  checked><label for='section-a3eceaad-d635-4630-8f9e-b8d77901f1e8' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lev</span></div><div class='xr-var-dims'>(lev)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0</div><input id='attrs-5c98be0d-c34f-411a-ad70-e88d300c949d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-5c98be0d-c34f-411a-ad70-e88d300c949d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-38d1a454-78f4-40ee-8a7d-4d33bbcaef1e' class='xr-var-data-in' type='checkbox'><label for='data-38d1a454-78f4-40ee-8a7d-4d33bbcaef1e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>15.5 45.0 ... 4.196e+04 4.199e+04</div><input id='attrs-ddc989f0-eeb7-409a-a031-a538dd16923c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-ddc989f0-eeb7-409a-a031-a538dd16923c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-874fea97-bac4-47ec-9490-4fec9d6e522b' class='xr-var-data-in' type='checkbox'><label for='data-874fea97-bac4-47ec-9490-4fec9d6e522b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd><dt><span>bounds :</span></dt><dd>time_bnds</dd><dt><span>units :</span></dt><dd>days since 1850-01-01</dd><dt><span>calendar :</span></dt><dd>proleptic_gregorian</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([1.55000e+01, 4.50000e+01, 7.45000e+01, ..., 4.19265e+04, 4.19570e+04,\n",
       "       4.19875e+04])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>101.2 104.1 106.9 ... 275.6 278.4</div><input id='attrs-9eb1bcb7-01c1-47ff-8522-6c0319e1c77c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9eb1bcb7-01c1-47ff-8522-6c0319e1c77c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d6060931-932e-4685-9b10-b5cf4fd1fe7a' class='xr-var-data-in' type='checkbox'><label for='data-d6060931-932e-4685-9b10-b5cf4fd1fe7a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125, 118.125 ,\n",
       "       120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    , 137.8125,\n",
       "       140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875, 157.5   ,\n",
       "       160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 , 177.1875,\n",
       "       180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625, 196.875 ,\n",
       "       199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  , 216.5625,\n",
       "       219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375, 236.25  ,\n",
       "       239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 , 255.9375,\n",
       "       258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125, 275.625 ,\n",
       "       278.4375])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>85.1 82.31 79.53 ... 1.395 -1.395</div><input id='attrs-22eb9b8a-993e-4d4a-a31b-1504685cba54' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-22eb9b8a-993e-4d4a-a31b-1504685cba54' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bdbbb142-9c4c-4fac-8c80-065166be8a18' class='xr-var-data-in' type='checkbox'><label for='data-bdbbb142-9c4c-4fac-8c80-065166be8a18' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([85.096527, 82.312913, 79.525607, 76.7369  , 73.947515, 71.157752,\n",
       "       68.367756, 65.577607, 62.787352, 59.99702 , 57.206632, 54.4162  ,\n",
       "       51.625734, 48.835241, 46.044727, 43.254195, 40.463648, 37.67309 ,\n",
       "       34.882521, 32.091944, 29.30136 , 26.510769, 23.720174, 20.929574,\n",
       "       18.138971, 15.348365, 12.557756,  9.767146,  6.976534,  4.185921,\n",
       "        1.395307, -1.395307])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c1dffb9a-661e-41ed-bf50-ad282dc42e85' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c1dffb9a-661e-41ed-bf50-ad282dc42e85' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time_bnds</span></div><div class='xr-var-dims'>(time, lev, bnds)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 1, 2), meta=np.ndarray&gt;</div><input id='attrs-cde400f6-e507-4e72-96ab-473a2f145aa1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-cde400f6-e507-4e72-96ab-473a2f145aa1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-efb33581-d765-4fa2-bd03-85861678420d' class='xr-var-data-in' type='checkbox'><label for='data-efb33581-d765-4fa2-bd03-85861678420d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 21.56 kiB </td>\n",
       "                        <td> 16 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1380, 1, 2) </td>\n",
       "                        <td> (1, 1, 2) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 4141 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"156\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"29\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"32\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"36\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"40\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"43\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"47\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"51\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"55\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"58\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"62\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"50\" y2=\"66\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"69\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"58\" y2=\"73\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"77\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"65\" y2=\"81\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"69\" y2=\"84\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"73\" y2=\"88\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"92\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,96.00085180870013 10.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"39\" y2=\"3\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"42\" y2=\"7\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"46\" y2=\"11\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"50\" y2=\"14\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"53\" y2=\"18\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"57\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"61\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"65\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"68\" y2=\"33\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"72\" y2=\"37\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"76\" y2=\"40\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"79\" y2=\"44\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"83\" y2=\"48\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"87\" y2=\"51\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"91\" y2=\"55\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"94\" y2=\"59\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"98\" y2=\"63\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"102\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.41261651458248,0.0 106.00085180870013,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"106\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"96\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"106\" y1=\"70\" x2=\"106\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 106.00085180870013,70.58823529411765 106.00085180870013,96.00085180870013 80.58823529411765,96.00085180870013\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"93.294544\" y=\"116.000852\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2</text>\n",
       "  <text x=\"126.000852\" y=\"83.294544\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,126.000852,83.294544)\">1</text>\n",
       "  <text x=\"35.294118\" y=\"80.706734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,80.706734)\">1380</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tos</span></div><div class='xr-var-dims'>(time, lat, lon, lev)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>dask.array&lt;chunksize=(1, 32, 64, 1), meta=np.ndarray&gt;</div><input id='attrs-76d6fe77-1386-4f43-9703-2df18d3c54bd' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-76d6fe77-1386-4f43-9703-2df18d3c54bd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-961d1144-8810-4220-9e83-6b5a7be2852c' class='xr-var-data-in' type='checkbox'><label for='data-961d1144-8810-4220-9e83-6b5a7be2852c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>sea_surface_temperature</dd><dt><span>long_name :</span></dt><dd>Sea Surface Temperature</dd><dt><span>units :</span></dt><dd>degC</dd><dt><span>CDI_grid_type :</span></dt><dd>gaussian</dd><dt><span>CDI_grid_num_LPE :</span></dt><dd>32</dd><dt><span>comment :</span></dt><dd>Temperature of upper boundary of the liquid ocean, including temperatures below sea-ice and floating ice shelves.</dd><dt><span>cell_methods :</span></dt><dd>area: mean where sea time: mean</dd><dt><span>cell_measures :</span></dt><dd>area: areacello</dd><dt><span>history :</span></dt><dd>2019-11-08T18:45:39Z altered by CMOR: replaced missing value flag (-1e+20) with standard missing value (1e+20).</dd></dl></div><div class='xr-var-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 10.78 MiB </td>\n",
       "                        <td> 8.00 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1380, 32, 64, 1) </td>\n",
       "                        <td> (1, 32, 64, 1) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 5521 Tasks </td>\n",
       "                        <td> 1380 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"472\" height=\"101\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"3\" y1=\"0\" x2=\"3\" y2=\"25\" />\n",
       "  <line x1=\"7\" y1=\"0\" x2=\"7\" y2=\"25\" />\n",
       "  <line x1=\"11\" y1=\"0\" x2=\"11\" y2=\"25\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"14\" y2=\"25\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"26\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"33\" y1=\"0\" x2=\"33\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"41\" y1=\"0\" x2=\"41\" y2=\"25\" />\n",
       "  <line x1=\"44\" y1=\"0\" x2=\"44\" y2=\"25\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"63\" y1=\"0\" x2=\"63\" y2=\"25\" />\n",
       "  <line x1=\"67\" y1=\"0\" x2=\"67\" y2=\"25\" />\n",
       "  <line x1=\"71\" y1=\"0\" x2=\"71\" y2=\"25\" />\n",
       "  <line x1=\"74\" y1=\"0\" x2=\"74\" y2=\"25\" />\n",
       "  <line x1=\"78\" y1=\"0\" x2=\"78\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"86\" y1=\"0\" x2=\"86\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"93\" y1=\"0\" x2=\"93\" y2=\"25\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"97\" y2=\"25\" />\n",
       "  <line x1=\"101\" y1=\"0\" x2=\"101\" y2=\"25\" />\n",
       "  <line x1=\"104\" y1=\"0\" x2=\"104\" y2=\"25\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"116\" y1=\"0\" x2=\"116\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1380</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"207\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"190\" y1=\"34\" x2=\"207\" y2=\"51\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"190\" y2=\"34\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"207\" y1=\"17\" x2=\"207\" y2=\"51\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.0,0.0 207.57310517911156,17.57310517911155 207.57310517911156,51.61317682762622 190.0,34.04007164851467\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"207\" y1=\"17\" x2=\"232\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"207\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"215\" y1=\"0\" x2=\"232\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.0,0.0 215.41261651458248,0.0 232.98572169369402,17.57310517911155 207.57310517911156,17.57310517911155\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"207\" y1=\"17\" x2=\"232\" y2=\"17\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"207\" y1=\"51\" x2=\"232\" y2=\"51\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"207\" y1=\"17\" x2=\"207\" y2=\"51\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"232\" y1=\"17\" x2=\"232\" y2=\"51\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"207.57310517911156,17.57310517911155 232.98572169369405,17.57310517911155 232.98572169369405,51.61317682762622 207.57310517911156,51.61317682762622\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"220.279413\" y=\"71.613177\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1</text>\n",
       "  <text x=\"252.985722\" y=\"34.593141\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,252.985722,34.593141)\">64</text>\n",
       "  <text x=\"188.786553\" y=\"62.826624\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,188.786553,62.826624)\">32</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></li></ul></div></li><li class='xr-section-item'><input id='section-fa9c99a7-ebcb-47c8-aa5d-07f61e65d7d0' class='xr-section-summary-in' type='checkbox'  ><label for='section-fa9c99a7-ebcb-47c8-aa5d-07f61e65d7d0' class='xr-section-summary' >Indexes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-79e9b7ec-ccf0-4170-ad19-c772363eac03' class='xr-index-data-in' type='checkbox'/><label for='index-79e9b7ec-ccf0-4170-ad19-c772363eac03' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([   15.5,    45.0,    74.5,   105.0,   135.5,   166.0,   196.5,\n",
       "                227.5,   258.0,   288.5,\n",
       "              ...\n",
       "              41712.5, 41743.0, 41773.5, 41804.0, 41834.5, 41865.5, 41896.0,\n",
       "              41926.5, 41957.0, 41987.5],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;, length=1380))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b5d04a00-abf1-40ea-aa8d-8de1d55f3989' class='xr-index-data-in' type='checkbox'/><label for='index-b5d04a00-abf1-40ea-aa8d-8de1d55f3989' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([  101.25, 104.0625,  106.875, 109.6875,    112.5, 115.3125,\n",
       "               118.125, 120.9375,   123.75, 126.5625,  129.375, 132.1875,\n",
       "                 135.0, 137.8125,  140.625, 143.4375,   146.25, 149.0625,\n",
       "               151.875, 154.6875,    157.5, 160.3125,  163.125, 165.9375,\n",
       "                168.75, 171.5625,  174.375, 177.1875,    180.0, 182.8125,\n",
       "               185.625, 188.4375,   191.25, 194.0625,  196.875, 199.6875,\n",
       "                 202.5, 205.3125,  208.125, 210.9375,   213.75, 216.5625,\n",
       "               219.375, 222.1875,    225.0, 227.8125,  230.625, 233.4375,\n",
       "                236.25, 239.0625,  241.875, 244.6875,    247.5, 250.3125,\n",
       "               253.125, 255.9375,   258.75, 261.5625,  264.375, 267.1875,\n",
       "                 270.0, 272.8125,  275.625, 278.4375],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-d363255d-59d9-4e11-bb19-746b14269cc9' class='xr-index-data-in' type='checkbox'/><label for='index-d363255d-59d9-4e11-bb19-746b14269cc9' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([  85.09652698831736,   82.31291294788629,   79.52560657265944,\n",
       "                76.73689968036832,   73.94751515398967,   71.15775201158733,\n",
       "                68.36775610831317,   65.57760701082782,   62.78735179896307,\n",
       "               59.997020108491306,  57.206631527643246,   54.41619952608621,\n",
       "               51.625733674938246,   48.83524096625058,  46.044726631101675,\n",
       "               43.254194665350944,   40.46364817811504,   37.67308962904533,\n",
       "                34.88252099377346,  32.091943881744015,   29.30135962176274,\n",
       "               26.510769325210987,  23.720173933534745,  20.929574254489523,\n",
       "               18.138970990239347,  15.348364759491494,  12.557756115230674,\n",
       "                9.767145559195573,   6.976533553948629,   4.185920533189151,\n",
       "               1.3953069108194966, -1.3953069108194966],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lev</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-fca947b8-ae73-44e5-92fa-bc21b78ae238' class='xr-index-data-in' type='checkbox'/><label for='index-fca947b8-ae73-44e5-92fa-bc21b78ae238' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([0.0], dtype=&#x27;float64&#x27;, name=&#x27;lev&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-32107faf-faaf-411d-abe0-19c144baadf3' class='xr-section-summary-in' type='checkbox'  ><label for='section-32107faf-faaf-411d-abe0-19c144baadf3' class='xr-section-summary' >Attributes: <span>(49)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>CDI :</span></dt><dd>Climate Data Interface version 2.0.4 (https://mpimet.mpg.de/cdi)</dd><dt><span>source :</span></dt><dd>ACCESS-CM2 (2019): \n",
       "aerosol: UKCA-GLOMAP-mode\n",
       "atmos: MetUM-HadGEM3-GA7.1 (N96; 192 x 144 longitude/latitude; 85 levels; top level 85 km)\n",
       "atmosChem: none\n",
       "land: CABLE2.5\n",
       "landIce: none\n",
       "ocean: ACCESS-OM2 (GFDL-MOM5, tripolar primarily 1deg; 360 x 300 longitude/latitude; 50 levels; top grid cell 0-10 m)\n",
       "ocnBgchem: none\n",
       "seaIce: CICE5.1.2 (same grid as ocean)</dd><dt><span>institution :</span></dt><dd>CSIRO (Commonwealth Scientific and Industrial Research Organisation, Aspendale, Victoria 3195, Australia), ARCCSS (Australian Research Council Centre of Excellence for Climate System Science)</dd><dt><span>Conventions :</span></dt><dd>CF-1.7 CMIP-6.2</dd><dt><span>activity_id :</span></dt><dd>CMIP</dd><dt><span>branch_method :</span></dt><dd>standard</dd><dt><span>branch_time_in_child :</span></dt><dd>0.0</dd><dt><span>branch_time_in_parent :</span></dt><dd>0.0</dd><dt><span>creation_date :</span></dt><dd>2019-11-08T18:45:44Z</dd><dt><span>data_specs_version :</span></dt><dd>01.00.30</dd><dt><span>experiment :</span></dt><dd>all-forcing simulation of the recent past</dd><dt><span>experiment_id :</span></dt><dd>historical</dd><dt><span>external_variables :</span></dt><dd>areacello</dd><dt><span>forcing_index :</span></dt><dd>1</dd><dt><span>frequency :</span></dt><dd>mon</dd><dt><span>further_info_url :</span></dt><dd>https://furtherinfo.es-doc.org/CMIP6.CSIRO-ARCCSS.ACCESS-CM2.historical.none.r1i1p1f1</dd><dt><span>grid :</span></dt><dd>native atmosphere N96 grid (144x192 latxlon)</dd><dt><span>grid_label :</span></dt><dd>gn</dd><dt><span>history :</span></dt><dd>Tue Jan 24 01:06:45 2023: cdo ensmean Regrid_ACCESS-CM2.nc Regrid_ACCESS-ESM1-5.nc Regrid_CAMS-CSM1-0.nc Regrid_CanESM5-CanOE.nc Regrid_CanESM5.nc Regrid_CMCC-CM2-SR5.nc Regrid_CMCC-ESM2.nc Regrid_CNRM-CM6-1.nc Regrid_CNRM-ESM2-1.nc Regrid_E3SM-1-0.nc Regrid_E3SM-1-1-ECA.nc Regrid_FGOALS-f3-L.nc Regrid_FGOALS-g3.nc Regrid_FIO-ESM-2-0.nc Regrid_GFDL-ESM4.nc Regrid_GISS-E2-1-H.nc Regrid_HadGEM3-GC31-LL.nc Regrid_IITM-ESM.nc Regrid_INM-CM4-8.nc Regrid_INM-CM5-0.nc Regrid_KIOST-ESM.nc Regrid_MCM-UA-1-0.nc Regrid_MIROC6.nc Regrid_MIROC-ES2L.nc Regrid_MRI-ESM2-0.nc Regrid_NESM3.nc Regrid_NorCPM1.nc ensemble_CMIP6.nc\n",
       "Mon Jan 23 23:06:23 2023: cdo -remap,n32,weights.nc tos_Omon_ACCESS-CM2_historical_r1i1p1f1_gn_18500116-20141216_v20191108.nc Regrid_ACCESS-CM2.nc\n",
       "2019-11-08T18:45:44Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.</dd><dt><span>initialization_index :</span></dt><dd>1</dd><dt><span>institution_id :</span></dt><dd>CSIRO-ARCCSS</dd><dt><span>mip_era :</span></dt><dd>CMIP6</dd><dt><span>nominal_resolution :</span></dt><dd>250 km</dd><dt><span>notes :</span></dt><dd>Exp: CM2-historical; Local ID: bj594; Variable: tos ([&#x27;sst&#x27;])</dd><dt><span>parent_activity_id :</span></dt><dd>CMIP</dd><dt><span>parent_experiment_id :</span></dt><dd>piControl</dd><dt><span>parent_mip_era :</span></dt><dd>CMIP6</dd><dt><span>parent_source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>parent_time_units :</span></dt><dd>days since 0950-01-01</dd><dt><span>parent_variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>physics_index :</span></dt><dd>1</dd><dt><span>product :</span></dt><dd>model-output</dd><dt><span>realization_index :</span></dt><dd>1</dd><dt><span>realm :</span></dt><dd>ocean</dd><dt><span>run_variant :</span></dt><dd>forcing: GHG, Oz, SA, Sl, Vl, BC, OC, (GHG = CO2, N2O, CH4, CFC11, CFC12, CFC113, HCFC22, HFC125, HFC134a)</dd><dt><span>source_id :</span></dt><dd>ACCESS-CM2</dd><dt><span>source_type :</span></dt><dd>AOGCM</dd><dt><span>sub_experiment :</span></dt><dd>none</dd><dt><span>sub_experiment_id :</span></dt><dd>none</dd><dt><span>table_id :</span></dt><dd>Omon</dd><dt><span>table_info :</span></dt><dd>Creation Date:(30 April 2019) MD5:e14f55f257cceafb2523e41244962371</dd><dt><span>title :</span></dt><dd>ACCESS-CM2 output prepared for CMIP6</dd><dt><span>variable_id :</span></dt><dd>tos</dd><dt><span>variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>version :</span></dt><dd>v20191108</dd><dt><span>cmor_version :</span></dt><dd>3.4.0</dd><dt><span>tracking_id :</span></dt><dd>hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5</dd><dt><span>license :</span></dt><dd>CMIP6 model data produced by CSIRO is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License (https://creativecommons.org/licenses/).  Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment.  Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file).  The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.</dd><dt><span>CDO :</span></dt><dd>Climate Data Operators version 2.0.4 (https://mpimet.mpg.de/cdo)</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (lev: 1, time: 1380, bnds: 2, lon: 64, lat: 32)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) float64 15.5 45.0 74.5 ... 4.193e+04 4.196e+04 4.199e+04\n",
       "  * lon        (lon) float64 101.2 104.1 106.9 109.7 ... 270.0 272.8 275.6 278.4\n",
       "  * lat        (lat) float64 85.1 82.31 79.53 76.74 ... 6.977 4.186 1.395 -1.395\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, lev, bnds) float64 dask.array<chunksize=(1, 1, 2), meta=np.ndarray>\n",
       "    tos        (time, lat, lon, lev) float32 dask.array<chunksize=(1, 32, 64, 1), meta=np.ndarray>\n",
       "Attributes: (12/49)\n",
       "    CDI:                    Climate Data Interface version 2.0.4 (https://mpi...\n",
       "    source:                 ACCESS-CM2 (2019): \\naerosol: UKCA-GLOMAP-mode\\na...\n",
       "    institution:            CSIRO (Commonwealth Scientific and Industrial Res...\n",
       "    Conventions:            CF-1.7 CMIP-6.2\n",
       "    activity_id:            CMIP\n",
       "    branch_method:          standard\n",
       "    ...                     ...\n",
       "    variant_label:          r1i1p1f1\n",
       "    version:                v20191108\n",
       "    cmor_version:           3.4.0\n",
       "    tracking_id:            hdl:21.14100/0bcaaa74-aedb-4d45-a5e5-cb3ab467f2b5\n",
       "    license:                CMIP6 model data produced by CSIRO is licensed un...\n",
       "    CDO:                    Climate Data Operators version 2.0.4 (https://mpi..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sliced the area\n",
    "data=x\n",
    "data = data.sel(lat=slice(87,-2,1),lon=slice(100, 280,1))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6018e5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  6.0s\n",
      "[########################################] | 100% Completed |  6.0s\n",
      "[########################################] | 100% Completed |  6.7s\n",
      "[########################################] | 100% Completed |  6.8s\n",
      "[########################################] | 100% Completed |  8.1s\n",
      "[########################################] | 100% Completed |  8.1s\n"
     ]
    }
   ],
   "source": [
    "#Normalized the data\n",
    "mm = data.mean(('time','lat','lon'))\n",
    "std = data.std(('time','lat','lon'))\n",
    "\n",
    "mm.load()\n",
    "std.load()\n",
    "\n",
    "normalized = (data - mm) / std\n",
    "\n",
    "normalized.to_netcdf(outdir + 'normalized_Ensemble_CMIP6.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c5eaf",
   "metadata": {},
   "source": [
    "# Start tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba5d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported data\n",
    "ds = xr.open_dataset(outdir + 'normalized_Ensemble_CMIP6.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78091ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (lev: 1, time: 1380, lon: 64, lat: 32, bnds: 2)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) datetime64[ns] 1850-01-16T12:00:00 ... 1964-12-16T12:00:00\n",
       "  * lon        (lon) float64 101.2 104.1 106.9 109.7 ... 270.0 272.8 275.6 278.4\n",
       "  * lat        (lat) float64 85.1 82.31 79.53 76.74 ... 6.977 4.186 1.395 -1.395\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, lev, bnds) datetime64[ns] ...\n",
       "    tos        (time, lat, lon, lev) float32 ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-7742b95b-88a4-4555-9104-bccdef2c0b21' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-7742b95b-88a4-4555-9104-bccdef2c0b21' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lev</span>: 1</li><li><span class='xr-has-index'>time</span>: 1380</li><li><span class='xr-has-index'>lon</span>: 64</li><li><span class='xr-has-index'>lat</span>: 32</li><li><span>bnds</span>: 2</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-24a646c7-3e8e-454f-a343-93d348aa74aa' class='xr-section-summary-in' type='checkbox'  checked><label for='section-24a646c7-3e8e-454f-a343-93d348aa74aa' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lev</span></div><div class='xr-var-dims'>(lev)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0</div><input id='attrs-66b70e0b-4abe-441c-9208-d71191725825' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-66b70e0b-4abe-441c-9208-d71191725825' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-32f6c7e7-29e3-4621-bd33-d8ddfd8e978a' class='xr-var-data-in' type='checkbox'><label for='data-32f6c7e7-29e3-4621-bd33-d8ddfd8e978a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([0.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1850-01-16T12:00:00 ... 1964-12-...</div><input id='attrs-0f7e3a25-6306-4e75-8e6c-5a30bf0856c0' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0f7e3a25-6306-4e75-8e6c-5a30bf0856c0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-16457911-ebe1-4fdd-9f3a-4ae70d1a989f' class='xr-var-data-in' type='checkbox'><label for='data-16457911-ebe1-4fdd-9f3a-4ae70d1a989f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>long_name :</span></dt><dd>time</dd><dt><span>bounds :</span></dt><dd>time_bnds</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1850-01-16T12:00:00.000000000&#x27;, &#x27;1850-02-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;1850-03-16T12:00:00.000000000&#x27;, ..., &#x27;1964-10-16T12:00:00.000000000&#x27;,\n",
       "       &#x27;1964-11-16T00:00:00.000000000&#x27;, &#x27;1964-12-16T12:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>101.2 104.1 106.9 ... 275.6 278.4</div><input id='attrs-93a5d638-4498-4b38-b208-5d2f3cc75bb0' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-93a5d638-4498-4b38-b208-5d2f3cc75bb0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5f72e5c4-2738-4f39-9d19-7603daaf2e5e' class='xr-var-data-in' type='checkbox'><label for='data-5f72e5c4-2738-4f39-9d19-7603daaf2e5e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([101.25  , 104.0625, 106.875 , 109.6875, 112.5   , 115.3125, 118.125 ,\n",
       "       120.9375, 123.75  , 126.5625, 129.375 , 132.1875, 135.    , 137.8125,\n",
       "       140.625 , 143.4375, 146.25  , 149.0625, 151.875 , 154.6875, 157.5   ,\n",
       "       160.3125, 163.125 , 165.9375, 168.75  , 171.5625, 174.375 , 177.1875,\n",
       "       180.    , 182.8125, 185.625 , 188.4375, 191.25  , 194.0625, 196.875 ,\n",
       "       199.6875, 202.5   , 205.3125, 208.125 , 210.9375, 213.75  , 216.5625,\n",
       "       219.375 , 222.1875, 225.    , 227.8125, 230.625 , 233.4375, 236.25  ,\n",
       "       239.0625, 241.875 , 244.6875, 247.5   , 250.3125, 253.125 , 255.9375,\n",
       "       258.75  , 261.5625, 264.375 , 267.1875, 270.    , 272.8125, 275.625 ,\n",
       "       278.4375])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>85.1 82.31 79.53 ... 1.395 -1.395</div><input id='attrs-1ff398ff-06a4-48b0-ab19-a70d78e1904c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-1ff398ff-06a4-48b0-ab19-a70d78e1904c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-72f0ef32-ea52-43dd-a093-28f44bb606a3' class='xr-var-data-in' type='checkbox'><label for='data-72f0ef32-ea52-43dd-a093-28f44bb606a3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([85.096527, 82.312913, 79.525607, 76.7369  , 73.947515, 71.157752,\n",
       "       68.367756, 65.577607, 62.787352, 59.99702 , 57.206632, 54.4162  ,\n",
       "       51.625734, 48.835241, 46.044727, 43.254195, 40.463648, 37.67309 ,\n",
       "       34.882521, 32.091944, 29.30136 , 26.510769, 23.720174, 20.929574,\n",
       "       18.138971, 15.348365, 12.557756,  9.767146,  6.976534,  4.185921,\n",
       "        1.395307, -1.395307])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-07aad32f-d318-43c1-9f10-ef44c959c550' class='xr-section-summary-in' type='checkbox'  checked><label for='section-07aad32f-d318-43c1-9f10-ef44c959c550' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>time_bnds</span></div><div class='xr-var-dims'>(time, lev, bnds)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-14753c69-634d-4338-bef2-0e5b6b8176e0' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-14753c69-634d-4338-bef2-0e5b6b8176e0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ed9c91bc-e1b7-4342-9fa7-7e1470adb373' class='xr-var-data-in' type='checkbox'><label for='data-ed9c91bc-e1b7-4342-9fa7-7e1470adb373' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2760 values with dtype=datetime64[ns]]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tos</span></div><div class='xr-var-dims'>(time, lat, lon, lev)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-7b179d08-4f30-4a7f-a1af-fb09e375b710' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7b179d08-4f30-4a7f-a1af-fb09e375b710' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7488dc0e-10cc-4883-b209-b65f8066d2ee' class='xr-var-data-in' type='checkbox'><label for='data-7488dc0e-10cc-4883-b209-b65f8066d2ee' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2826240 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-0419b830-4abb-4e3e-bc6a-b2acec753597' class='xr-section-summary-in' type='checkbox'  ><label for='section-0419b830-4abb-4e3e-bc6a-b2acec753597' class='xr-section-summary' >Indexes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lev</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-6967658c-b72c-4d28-a181-2d609a79973e' class='xr-index-data-in' type='checkbox'/><label for='index-6967658c-b72c-4d28-a181-2d609a79973e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([0.0], dtype=&#x27;float64&#x27;, name=&#x27;lev&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-83a1fcbb-d864-4705-b2f0-58c1c64c801b' class='xr-index-data-in' type='checkbox'/><label for='index-83a1fcbb-d864-4705-b2f0-58c1c64c801b' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;1850-01-16 12:00:00&#x27;, &#x27;1850-02-15 00:00:00&#x27;,\n",
       "               &#x27;1850-03-16 12:00:00&#x27;, &#x27;1850-04-16 00:00:00&#x27;,\n",
       "               &#x27;1850-05-16 12:00:00&#x27;, &#x27;1850-06-16 00:00:00&#x27;,\n",
       "               &#x27;1850-07-16 12:00:00&#x27;, &#x27;1850-08-16 12:00:00&#x27;,\n",
       "               &#x27;1850-09-16 00:00:00&#x27;, &#x27;1850-10-16 12:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;1964-03-16 12:00:00&#x27;, &#x27;1964-04-16 00:00:00&#x27;,\n",
       "               &#x27;1964-05-16 12:00:00&#x27;, &#x27;1964-06-16 00:00:00&#x27;,\n",
       "               &#x27;1964-07-16 12:00:00&#x27;, &#x27;1964-08-16 12:00:00&#x27;,\n",
       "               &#x27;1964-09-16 00:00:00&#x27;, &#x27;1964-10-16 12:00:00&#x27;,\n",
       "               &#x27;1964-11-16 00:00:00&#x27;, &#x27;1964-12-16 12:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=1380, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b5650891-c81c-4eb3-ab29-eb9bcdd96bee' class='xr-index-data-in' type='checkbox'/><label for='index-b5650891-c81c-4eb3-ab29-eb9bcdd96bee' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([  101.25, 104.0625,  106.875, 109.6875,    112.5, 115.3125,\n",
       "               118.125, 120.9375,   123.75, 126.5625,  129.375, 132.1875,\n",
       "                 135.0, 137.8125,  140.625, 143.4375,   146.25, 149.0625,\n",
       "               151.875, 154.6875,    157.5, 160.3125,  163.125, 165.9375,\n",
       "                168.75, 171.5625,  174.375, 177.1875,    180.0, 182.8125,\n",
       "               185.625, 188.4375,   191.25, 194.0625,  196.875, 199.6875,\n",
       "                 202.5, 205.3125,  208.125, 210.9375,   213.75, 216.5625,\n",
       "               219.375, 222.1875,    225.0, 227.8125,  230.625, 233.4375,\n",
       "                236.25, 239.0625,  241.875, 244.6875,    247.5, 250.3125,\n",
       "               253.125, 255.9375,   258.75, 261.5625,  264.375, 267.1875,\n",
       "                 270.0, 272.8125,  275.625, 278.4375],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-fe32851c-4626-4267-9d72-ffa8b6fe3c91' class='xr-index-data-in' type='checkbox'/><label for='index-fe32851c-4626-4267-9d72-ffa8b6fe3c91' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([  85.09652698831736,   82.31291294788629,   79.52560657265944,\n",
       "                76.73689968036832,   73.94751515398967,   71.15775201158733,\n",
       "                68.36775610831317,   65.57760701082782,   62.78735179896307,\n",
       "               59.997020108491306,  57.206631527643246,   54.41619952608621,\n",
       "               51.625733674938246,   48.83524096625058,  46.044726631101675,\n",
       "               43.254194665350944,   40.46364817811504,   37.67308962904533,\n",
       "                34.88252099377346,  32.091943881744015,   29.30135962176274,\n",
       "               26.510769325210987,  23.720173933534745,  20.929574254489523,\n",
       "               18.138970990239347,  15.348364759491494,  12.557756115230674,\n",
       "                9.767145559195573,   6.976533553948629,   4.185920533189151,\n",
       "               1.3953069108194966, -1.3953069108194966],\n",
       "             dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-6450781a-8688-4a17-b8e0-d5cdf6dd8d3c' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-6450781a-8688-4a17-b8e0-d5cdf6dd8d3c' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (lev: 1, time: 1380, lon: 64, lat: 32, bnds: 2)\n",
       "Coordinates:\n",
       "  * lev        (lev) float64 0.0\n",
       "  * time       (time) datetime64[ns] 1850-01-16T12:00:00 ... 1964-12-16T12:00:00\n",
       "  * lon        (lon) float64 101.2 104.1 106.9 109.7 ... 270.0 272.8 275.6 278.4\n",
       "  * lat        (lat) float64 85.1 82.31 79.53 76.74 ... 6.977 4.186 1.395 -1.395\n",
       "Dimensions without coordinates: bnds\n",
       "Data variables:\n",
       "    time_bnds  (time, lev, bnds) datetime64[ns] ...\n",
       "    tos        (time, lat, lon, lev) float32 ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0687bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepared data\n",
    "ds=ds['tos'].data #extra data array\n",
    "ds[ds<0]=0 #treat nan values as 0\n",
    "np.nan_to_num(ds,copy=False)\n",
    "ds=ds/(np.nanmax(ds)) \n",
    "dates=pd.date_range(start='1855-01-01',periods=len(ds))\n",
    "label=np.array(dates.month)\n",
    "label=label-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0333e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1380"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_N = len(ds)\n",
    "total_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc56bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splited the data\n",
    "\n",
    "N_tune = 900\n",
    "N_gab =120\n",
    "N_dev = 360\n",
    "N_test = 0\n",
    "N_train = 0\n",
    "N_spinup = total_N-(N_tune+N_gab+N_dev+N_test+N_train)\n",
    "\n",
    "lead_time=1\n",
    "x = ds\n",
    "\n",
    "x = x.astype('float32')\n",
    "x = x[:N_spinup+N_train+N_tune+N_gab+N_dev+N_test]\n",
    "\n",
    "lat,lon,lev=x.shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edf20aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(lead_time):\n",
    "    ''' Shift the data based on the lead time and \n",
    "    divide it into a predictor set and a predictant set. \n",
    "    Then divide it into a tuning set, training set, development set, and a test set.'''\n",
    "    if lead_time == 0:\n",
    "        X = x\n",
    "        y = X[:]\n",
    "    else:\n",
    "\n",
    "        X = x[:-lead_time]\n",
    "        y = x[lead_time:]\n",
    "\n",
    "    X_train = X[N_spinup+N_tune+N_dev+N_test:]\n",
    "    y_train = y[N_spinup+N_tune+N_dev+N_test:]\n",
    "    \n",
    "    X_tune = X[N_spinup:N_spinup+N_tune]\n",
    "    y_tune = y[N_spinup:N_spinup+N_tune]\n",
    "    \n",
    "    X_dev = X[N_spinup+N_tune+N_gab:N_spinup+N_tune+N_gab+N_dev]\n",
    "    y_dev = y[N_spinup+N_tune+N_gab:N_spinup+N_tune+N_gab+N_dev]\n",
    "    \n",
    "    X_test = X[N_spinup+N_tune+N_dev:N_spinup+N_tune+N_dev+N_test]\n",
    "    y_test = y[N_spinup+N_tune+N_dev:N_spinup+N_tune+N_dev+N_test]\n",
    "    \n",
    "       \n",
    "    return X_tune,y_tune, X_dev, y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c907c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed (not-tuned params)\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "pool_size = 2\n",
    "drop_prob=0\n",
    "conv_activation='relu'\n",
    "\n",
    "param_string = '_'.join([str(e) for e in (N_train,lead_time,batch_size,num_epochs,pool_size,drop_prob)])\n",
    "\n",
    "N_gpu = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f59d9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_score(x,y):\n",
    "    '''timestepwise anomaly correlation coefficient, averaged over time\n",
    "        (simple version without seasonal climatoloty)'''\n",
    "    assert(x.shape==y.shape)\n",
    "    return np.mean([np.corrcoef(x[i].flatten(),y[i].flatten())[0,1] for i in range(len(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3409f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(conv_depth, kernel_size, hidden_size, n_hidden_layers, lr):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "            \n",
    "            ## Convolution which involves dimensionality reduction (similar to Encoder in an autoencoder)\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation, input_shape=(lat,lon,lev)),\n",
    "            layers.MaxPooling2D(pool_size=pool_size),\n",
    "            Dropout(drop_prob),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.MaxPooling2D(pool_size=pool_size),\n",
    "            # end \"encoder\"\n",
    "            \n",
    "            \n",
    "            # dense layers (Automatic flattening and reshaping occurs.)\n",
    "            ] + [layers.Dense(hidden_size, activation='sigmoid') for i in range(n_hidden_layers)] +\n",
    "             \n",
    "            [\n",
    "            \n",
    "            \n",
    "            # start \"Decoder\" (upsampling of the encoder above)\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.UpSampling2D(size=pool_size),\n",
    "            Convolution2D(conv_depth, kernel_size, padding='same', activation=conv_activation),\n",
    "            layers.UpSampling2D(size=pool_size),\n",
    "            layers.Convolution2D(lev, kernel_size, padding='same', activation=None)\n",
    "            ]\n",
    "            )\n",
    "    \n",
    "    \n",
    "    optimizer= keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "\n",
    "            \n",
    "             \n",
    "    #model.compile(loss='mean_squared_error', optimizer = optimizer)\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "     optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "     #)\n",
    "     metrics=[])\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8be6d388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 32, 64, 1) (359, 32, 64, 1)\n",
      "(900, 32, 64, 1) (359, 32, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "##See the data\n",
    "X_tune,y_tune, X_dev, y_dev = prepare_data(lead_time)\n",
    "print(X_tune.shape,X_dev.shape);\n",
    "print(y_tune.shape,y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258999a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "##Hyperparameters\n",
    "tunable_params = dict(\n",
    "                  lr=[0.00001,0.00003,0.0001],\n",
    "                  n_hidden_layers = [0,1,2],\n",
    "                  kernel_size = [2,4,6],\n",
    "                  hidden_size=[50,100,300,500],\n",
    "                  conv_depth = [16,32]\n",
    "        )\n",
    "\n",
    "    \n",
    "print(lead_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ebf9328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nutta\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying  216  combinations\n",
      "training on param set  0\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 32, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 16, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 16, 32, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 32, 64, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.0211\n",
      "Epoch 1: val_loss improved from inf to 0.56446, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 44ms/step - loss: 1.0038 - val_loss: 0.5645\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4820\n",
      "Epoch 2: val_loss improved from 0.56446 to 0.39754, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.4786 - val_loss: 0.3975\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3615\n",
      "Epoch 3: val_loss improved from 0.39754 to 0.32085, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 39ms/step - loss: 0.3601 - val_loss: 0.3208\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3062\n",
      "Epoch 4: val_loss improved from 0.32085 to 0.29334, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.3062 - val_loss: 0.2933\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2892\n",
      "Epoch 5: val_loss improved from 0.29334 to 0.28108, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 39ms/step - loss: 0.2888 - val_loss: 0.2811\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  1\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 16, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 16, 16)         3216      \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 32, 64, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,291\n",
      "Trainable params: 6,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 2.3624\n",
      "Epoch 1: val_loss improved from inf to 1.51749, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 41ms/step - loss: 2.3274 - val_loss: 1.5175\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.9365\n",
      "Epoch 2: val_loss improved from 1.51749 to 0.62897, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 0.9241 - val_loss: 0.6290\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5899\n",
      "Epoch 3: val_loss improved from 0.62897 to 0.55047, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.5883 - val_loss: 0.5505\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5072\n",
      "Epoch 4: val_loss improved from 0.55047 to 0.46702, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.5054 - val_loss: 0.4670\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4346\n",
      "Epoch 5: val_loss improved from 0.46702 to 0.40883, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.4337 - val_loss: 0.4088\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  2\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 16, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 8, 16, 16)         3216      \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 32, 64, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,841\n",
      "Trainable params: 8,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 3.8502\n",
      "Epoch 1: val_loss improved from inf to 3.87583, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 46ms/step - loss: 3.8449 - val_loss: 3.8758\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 2.0755\n",
      "Epoch 2: val_loss improved from 3.87583 to 0.53381, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 2.0153 - val_loss: 0.5338\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5192\n",
      "Epoch 3: val_loss improved from 0.53381 to 0.50021, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.5187 - val_loss: 0.5002\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4715\n",
      "Epoch 4: val_loss improved from 0.50021 to 0.44685, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.4707 - val_loss: 0.4468\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4068\n",
      "Epoch 5: val_loss improved from 0.44685 to 0.36578, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.4053 - val_loss: 0.3658\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "training on param set  3\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 16, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 32, 64, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.0733\n",
      "Epoch 1: val_loss improved from inf to 0.48457, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 39ms/step - loss: 1.0504 - val_loss: 0.4846\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4040\n",
      "Epoch 2: val_loss improved from 0.48457 to 0.33303, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.4013 - val_loss: 0.3330\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3131\n",
      "Epoch 3: val_loss improved from 0.33303 to 0.29770, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.3125 - val_loss: 0.2977\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2935\n",
      "Epoch 4: val_loss improved from 0.29770 to 0.28431, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 34ms/step - loss: 0.2931 - val_loss: 0.2843\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2817\n",
      "Epoch 5: val_loss improved from 0.28431 to 0.27442, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.2815 - val_loss: 0.2744\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  4\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 8, 16, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 8, 16, 16)         3216      \n",
      "                                                                 \n",
      " up_sampling2d_8 (UpSampling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 32, 64, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,291\n",
      "Trainable params: 6,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.6126\n",
      "Epoch 1: val_loss improved from inf to 0.52082, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 47ms/step - loss: 1.5705 - val_loss: 0.5208\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4870\n",
      "Epoch 2: val_loss improved from 0.52082 to 0.45704, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 0.4857 - val_loss: 0.4570\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4233\n",
      "Epoch 3: val_loss improved from 0.45704 to 0.38021, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.4219 - val_loss: 0.3802\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3384\n",
      "Epoch 4: val_loss improved from 0.38021 to 0.30948, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.3376 - val_loss: 0.3095\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2969\n",
      "Epoch 5: val_loss improved from 0.30948 to 0.28357, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.2965 - val_loss: 0.2836\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  5\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 8, 16, 16)         3216      \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,841\n",
      "Trainable params: 8,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.7550\n",
      "Epoch 1: val_loss improved from inf to 0.45302, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 49ms/step - loss: 0.7425 - val_loss: 0.4530\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4422\n",
      "Epoch 2: val_loss improved from 0.45302 to 0.43758, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 44ms/step - loss: 0.4418 - val_loss: 0.4376\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4290\n",
      "Epoch 3: val_loss improved from 0.43758 to 0.42041, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.4289 - val_loss: 0.4204\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3853\n",
      "Epoch 4: val_loss improved from 0.42041 to 0.32497, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.3831 - val_loss: 0.3250\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3150\n",
      "Epoch 5: val_loss improved from 0.32497 to 0.30273, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 45ms/step - loss: 0.3144 - val_loss: 0.3027\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  6\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.0333\n",
      "Epoch 1: val_loss improved from inf to 0.57547, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 42ms/step - loss: 1.0148 - val_loss: 0.5755\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4788\n",
      "Epoch 2: val_loss improved from 0.57547 to 0.37262, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.4749 - val_loss: 0.3726\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3268\n",
      "Epoch 3: val_loss improved from 0.37262 to 0.30422, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.3258 - val_loss: 0.3042\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2966\n",
      "Epoch 4: val_loss improved from 0.30422 to 0.28627, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.2964 - val_loss: 0.2863\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2842\n",
      "Epoch 5: val_loss improved from 0.28627 to 0.27942, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 39ms/step - loss: 0.2841 - val_loss: 0.2794\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  7\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_35 (Conv2D)          (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 8, 16, 16)         3216      \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_15 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,291\n",
      "Trainable params: 6,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 2.4276\n",
      "Epoch 1: val_loss improved from inf to 0.74634, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 43ms/step - loss: 2.3601 - val_loss: 0.7463\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.6881\n",
      "Epoch 2: val_loss improved from 0.74634 to 0.61786, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.6850 - val_loss: 0.6179\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5712\n",
      "Epoch 3: val_loss improved from 0.61786 to 0.53124, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.5694 - val_loss: 0.5312\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4831\n",
      "Epoch 4: val_loss improved from 0.53124 to 0.42401, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.4810 - val_loss: 0.4240\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3739\n",
      "Epoch 5: val_loss improved from 0.42401 to 0.33350, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 44ms/step - loss: 0.3728 - val_loss: 0.3335\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "training on param set  8\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 8, 16, 16)         3216      \n",
      "                                                                 \n",
      " up_sampling2d_16 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_17 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,841\n",
      "Trainable params: 8,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5470\n",
      "Epoch 1: val_loss improved from inf to 0.44041, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 49ms/step - loss: 0.5427 - val_loss: 0.4404\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4106\n",
      "Epoch 2: val_loss improved from 0.44041 to 0.35098, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.4087 - val_loss: 0.3510\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3230\n",
      "Epoch 3: val_loss did not improve from 0.35098\n",
      "29/29 [==============================] - 1s 41ms/step - loss: 0.3226 - val_loss: 0.4046\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3189\n",
      "Epoch 4: val_loss improved from 0.35098 to 0.30039, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.3181 - val_loss: 0.3004\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2985\n",
      "Epoch 5: val_loss improved from 0.30039 to 0.29218, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 44ms/step - loss: 0.2985 - val_loss: 0.2922\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  9\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_45 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_18 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_19 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5702\n",
      "Epoch 1: val_loss improved from inf to 0.29973, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 81ms/step - loss: 0.5691 - val_loss: 0.2997\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2872\n",
      "Epoch 2: val_loss improved from 0.29973 to 0.27271, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.2871 - val_loss: 0.2727\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2716\n",
      "Epoch 3: val_loss improved from 0.27271 to 0.26340, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.2715 - val_loss: 0.2634\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2645\n",
      "Epoch 4: val_loss improved from 0.26340 to 0.25954, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.2644 - val_loss: 0.2595\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2615\n",
      "Epoch 5: val_loss improved from 0.25954 to 0.25759, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.2614 - val_loss: 0.2576\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  10\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_50 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 8, 16, 16)         12816     \n",
      "                                                                 \n",
      " up_sampling2d_20 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_21 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,419\n",
      "Trainable params: 22,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0908\n",
      "Epoch 1: val_loss improved from inf to 0.52279, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 73ms/step - loss: 1.0885 - val_loss: 0.5228\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3916\n",
      "Epoch 2: val_loss improved from 0.52279 to 0.31550, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 0.3911 - val_loss: 0.3155\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3299\n",
      "Epoch 3: val_loss did not improve from 0.31550\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.3304 - val_loss: 0.3181\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3303\n",
      "Epoch 4: val_loss did not improve from 0.31550\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.3303 - val_loss: 0.3463\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2988\n",
      "Epoch 5: val_loss improved from 0.31550 to 0.28166, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.2988 - val_loss: 0.2817\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  11\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_55 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 8, 16, 16)         12816     \n",
      "                                                                 \n",
      " up_sampling2d_22 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_23 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,969\n",
      "Trainable params: 24,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7976\n",
      "Epoch 1: val_loss improved from inf to 0.52792, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 78ms/step - loss: 0.7968 - val_loss: 0.5279\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7219\n",
      "Epoch 2: val_loss improved from 0.52792 to 0.46065, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.7208 - val_loss: 0.4607\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3917\n",
      "Epoch 3: val_loss improved from 0.46065 to 0.35630, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.3915 - val_loss: 0.3563\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3442\n",
      "Epoch 4: val_loss improved from 0.35630 to 0.33233, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.3441 - val_loss: 0.3323\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3259\n",
      "Epoch 5: val_loss improved from 0.33233 to 0.32854, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.3257 - val_loss: 0.3285\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "training on param set  12\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_24 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_25 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6037\n",
      "Epoch 1: val_loss improved from inf to 0.29991, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 68ms/step - loss: 0.6023 - val_loss: 0.2999\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2905\n",
      "Epoch 2: val_loss improved from 0.29991 to 0.27659, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.2904 - val_loss: 0.2766\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2738\n",
      "Epoch 3: val_loss improved from 0.27659 to 0.26851, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.2738 - val_loss: 0.2685\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2676\n",
      "Epoch 4: val_loss improved from 0.26851 to 0.26209, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 64ms/step - loss: 0.2676 - val_loss: 0.2621\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2637\n",
      "Epoch 5: val_loss improved from 0.26209 to 0.25887, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.2636 - val_loss: 0.2589\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  13\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_65 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 8, 16, 16)         12816     \n",
      "                                                                 \n",
      " up_sampling2d_26 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_27 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,419\n",
      "Trainable params: 22,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2059\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 77ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2060\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2061\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2050\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2063\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  14\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_70 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 8, 16, 16)         12816     \n",
      "                                                                 \n",
      " up_sampling2d_28 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_29 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,969\n",
      "Trainable params: 24,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.4829\n",
      "Epoch 1: val_loss improved from inf to 0.90340, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 80ms/step - loss: 1.4813 - val_loss: 0.9034\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6325\n",
      "Epoch 2: val_loss improved from 0.90340 to 0.40786, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.6315 - val_loss: 0.4079\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3642\n",
      "Epoch 3: val_loss improved from 0.40786 to 0.32756, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.3641 - val_loss: 0.3276\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3176\n",
      "Epoch 4: val_loss improved from 0.32756 to 0.30827, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.3175 - val_loss: 0.3083\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3049\n",
      "Epoch 5: val_loss improved from 0.30827 to 0.29998, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.3048 - val_loss: 0.3000\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  15\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_75 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_30 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_31 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4800\n",
      "Epoch 1: val_loss improved from inf to 0.31084, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 69ms/step - loss: 0.4793 - val_loss: 0.3108\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2840\n",
      "Epoch 2: val_loss improved from 0.31084 to 0.26737, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.2840 - val_loss: 0.2674\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2666\n",
      "Epoch 3: val_loss improved from 0.26737 to 0.26000, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.2665 - val_loss: 0.2600\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2615\n",
      "Epoch 4: val_loss improved from 0.26000 to 0.25541, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.2614 - val_loss: 0.2554\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2575\n",
      "Epoch 5: val_loss improved from 0.25541 to 0.25418, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.2575 - val_loss: 0.2542\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  16\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_80 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 8, 16, 16)         12816     \n",
      "                                                                 \n",
      " up_sampling2d_32 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_33 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,419\n",
      "Trainable params: 22,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4469\n",
      "Epoch 1: val_loss improved from inf to 0.42224, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 77ms/step - loss: 0.4468 - val_loss: 0.4222\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3911\n",
      "Epoch 2: val_loss improved from 0.42224 to 0.31019, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.3907 - val_loss: 0.3102\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2974\n",
      "Epoch 3: val_loss improved from 0.31019 to 0.28955, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.2973 - val_loss: 0.2896\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2949\n",
      "Epoch 4: val_loss improved from 0.28955 to 0.27604, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.2950 - val_loss: 0.2760\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2771\n",
      "Epoch 5: val_loss improved from 0.27604 to 0.27140, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.2772 - val_loss: 0.2714\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  17\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_85 (Conv2D)          (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 8, 16, 16)         12816     \n",
      "                                                                 \n",
      " up_sampling2d_34 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_35 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,969\n",
      "Trainable params: 24,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4598\n",
      "Epoch 1: val_loss improved from inf to 0.40255, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 79ms/step - loss: 0.4595 - val_loss: 0.4026\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4540\n",
      "Epoch 2: val_loss did not improve from 0.40255\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.4540 - val_loss: 0.4475\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3423\n",
      "Epoch 3: val_loss improved from 0.40255 to 0.29945, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.3422 - val_loss: 0.2995\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2906\n",
      "Epoch 4: val_loss improved from 0.29945 to 0.28778, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.2906 - val_loss: 0.2878\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2802\n",
      "Epoch 5: val_loss improved from 0.28778 to 0.27085, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.2802 - val_loss: 0.2709\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  18\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_90 (Conv2D)          (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_36 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_37 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4569\n",
      "Epoch 1: val_loss improved from inf to 0.30835, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 129ms/step - loss: 0.4563 - val_loss: 0.3084\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2918\n",
      "Epoch 2: val_loss improved from 0.30835 to 0.27867, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 122ms/step - loss: 0.2918 - val_loss: 0.2787\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2756\n",
      "Epoch 3: val_loss improved from 0.27867 to 0.26900, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 121ms/step - loss: 0.2756 - val_loss: 0.2690\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2707\n",
      "Epoch 4: val_loss did not improve from 0.26900\n",
      "29/29 [==============================] - 3s 117ms/step - loss: 0.2707 - val_loss: 0.2707\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2709\n",
      "Epoch 5: val_loss improved from 0.26900 to 0.26300, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 116ms/step - loss: 0.2709 - val_loss: 0.2630\n",
      "finished training\n",
      "12/12 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  19\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_95 (Conv2D)          (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 8, 16, 16)         28816     \n",
      "                                                                 \n",
      " up_sampling2d_38 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_39 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,299\n",
      "Trainable params: 49,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3413\n",
      "Epoch 1: val_loss improved from inf to 0.53807, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 125ms/step - loss: 1.3377 - val_loss: 0.5381\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5577\n",
      "Epoch 2: val_loss did not improve from 0.53807\n",
      "29/29 [==============================] - 4s 127ms/step - loss: 0.5581 - val_loss: 0.5843\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4689\n",
      "Epoch 3: val_loss improved from 0.53807 to 0.40208, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.4687 - val_loss: 0.4021\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3439\n",
      "Epoch 4: val_loss improved from 0.40208 to 0.31099, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.3437 - val_loss: 0.3110\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3193\n",
      "Epoch 5: val_loss did not improve from 0.31099\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.3191 - val_loss: 0.3197\n",
      "finished training\n",
      "12/12 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  20\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_100 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_102 (Conv2D)         (None, 8, 16, 16)         28816     \n",
      "                                                                 \n",
      " up_sampling2d_40 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_41 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,849\n",
      "Trainable params: 51,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3912\n",
      "Epoch 1: val_loss improved from inf to 0.42140, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 139ms/step - loss: 1.3868 - val_loss: 0.4214\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3612\n",
      "Epoch 2: val_loss improved from 0.42140 to 0.31106, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.3609 - val_loss: 0.3111\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3038\n",
      "Epoch 3: val_loss improved from 0.31106 to 0.29628, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 0.3038 - val_loss: 0.2963\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2964\n",
      "Epoch 4: val_loss improved from 0.29628 to 0.29252, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 0.2964 - val_loss: 0.2925\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2914\n",
      "Epoch 5: val_loss improved from 0.29252 to 0.28798, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.2914 - val_loss: 0.2880\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n",
      "training on param set  21\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nutta\\AppData\\Local\\Temp\\ipykernel_6076\\2570716441.py:63: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure()\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_105 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_42 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_43 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2041\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 121ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2049\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2059\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2060\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 3s 119ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2081\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 3s 113ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n",
      "training on param set  22\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_110 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 8, 16, 16)         28816     \n",
      "                                                                 \n",
      " up_sampling2d_44 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_45 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,299\n",
      "Trainable params: 49,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6313\n",
      "Epoch 1: val_loss improved from inf to 0.46453, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 136ms/step - loss: 0.6310 - val_loss: 0.4645\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3664\n",
      "Epoch 2: val_loss improved from 0.46453 to 0.31896, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 143ms/step - loss: 0.3662 - val_loss: 0.3190\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3074\n",
      "Epoch 3: val_loss improved from 0.31896 to 0.29391, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.3074 - val_loss: 0.2939\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2914\n",
      "Epoch 4: val_loss improved from 0.29391 to 0.28595, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 0.2914 - val_loss: 0.2860\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2877\n",
      "Epoch 5: val_loss improved from 0.28595 to 0.28373, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 139ms/step - loss: 0.2877 - val_loss: 0.2837\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  23\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_115 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 8, 16, 16)         28816     \n",
      "                                                                 \n",
      " up_sampling2d_46 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_47 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,849\n",
      "Trainable params: 51,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2063\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 137ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2050\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2064\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 128ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2068\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2056\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 134ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  24\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_120 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_48 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_49 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4208\n",
      "Epoch 1: val_loss improved from inf to 0.29340, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 0.4202 - val_loss: 0.2934\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2850\n",
      "Epoch 2: val_loss improved from 0.29340 to 0.27063, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 127ms/step - loss: 0.2850 - val_loss: 0.2706\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2761\n",
      "Epoch 3: val_loss did not improve from 0.27063\n",
      "29/29 [==============================] - 4s 123ms/step - loss: 0.2761 - val_loss: 0.2750\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2684\n",
      "Epoch 4: val_loss improved from 0.27063 to 0.26056, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 115ms/step - loss: 0.2684 - val_loss: 0.2606\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2612\n",
      "Epoch 5: val_loss improved from 0.26056 to 0.25552, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 0.2612 - val_loss: 0.2555\n",
      "finished training\n",
      "12/12 [==============================] - 0s 16ms/step\n",
      "training on param set  25\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_125 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " conv2d_127 (Conv2D)         (None, 8, 16, 16)         28816     \n",
      "                                                                 \n",
      " up_sampling2d_50 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_128 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_51 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_129 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,299\n",
      "Trainable params: 49,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4853\n",
      "Epoch 1: val_loss improved from inf to 0.31615, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 133ms/step - loss: 0.4847 - val_loss: 0.3161\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3113\n",
      "Epoch 2: val_loss improved from 0.31615 to 0.30047, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.3113 - val_loss: 0.3005\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3001\n",
      "Epoch 3: val_loss improved from 0.30047 to 0.28260, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.3001 - val_loss: 0.2826\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2843\n",
      "Epoch 4: val_loss did not improve from 0.28260\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.2842 - val_loss: 0.2841\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2851\n",
      "Epoch 5: val_loss improved from 0.28260 to 0.27670, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.2851 - val_loss: 0.2767\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  26\n",
      "{'conv_depth': 16, 'hidden_size': 50, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_130 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_131 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 8, 16, 50)         850       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_132 (Conv2D)         (None, 8, 16, 16)         28816     \n",
      "                                                                 \n",
      " up_sampling2d_52 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_133 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_53 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,849\n",
      "Trainable params: 51,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3743\n",
      "Epoch 1: val_loss improved from inf to 0.29132, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 136ms/step - loss: 0.3740 - val_loss: 0.2913\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2833\n",
      "Epoch 2: val_loss improved from 0.29132 to 0.27220, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.2832 - val_loss: 0.2722\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2717\n",
      "Epoch 3: val_loss improved from 0.27220 to 0.26502, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 128ms/step - loss: 0.2717 - val_loss: 0.2650\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2657\n",
      "Epoch 4: val_loss improved from 0.26502 to 0.26048, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 134ms/step - loss: 0.2657 - val_loss: 0.2605\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2623\n",
      "Epoch 5: val_loss improved from 0.26048 to 0.25750, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.2623 - val_loss: 0.2575\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  27\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_135 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_54 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_138 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_55 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.1431\n",
      "Epoch 1: val_loss improved from inf to 0.44434, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 40ms/step - loss: 1.1152 - val_loss: 0.4443\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3974\n",
      "Epoch 2: val_loss improved from 0.44434 to 0.35449, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.3957 - val_loss: 0.3545\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3347\n",
      "Epoch 3: val_loss improved from 0.35449 to 0.31417, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.3342 - val_loss: 0.3142\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3023\n",
      "Epoch 4: val_loss improved from 0.31417 to 0.28947, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.3017 - val_loss: 0.2895\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2879\n",
      "Epoch 5: val_loss improved from 0.28947 to 0.28060, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.2877 - val_loss: 0.2806\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  28\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_140 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_141 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_142 (Conv2D)         (None, 8, 16, 16)         6416      \n",
      "                                                                 \n",
      " up_sampling2d_56 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_143 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_57 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_144 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,341\n",
      "Trainable params: 10,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.2857\n",
      "Epoch 1: val_loss improved from inf to 0.46854, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 46ms/step - loss: 1.2528 - val_loss: 0.4685\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4493\n",
      "Epoch 2: val_loss improved from 0.46854 to 0.42467, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 41ms/step - loss: 0.4484 - val_loss: 0.4247\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3678\n",
      "Epoch 3: val_loss improved from 0.42467 to 0.31183, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 0.3656 - val_loss: 0.3118\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3005\n",
      "Epoch 4: val_loss improved from 0.31183 to 0.29208, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 41ms/step - loss: 0.3005 - val_loss: 0.2921\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2877\n",
      "Epoch 5: val_loss improved from 0.29208 to 0.27724, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 0.2876 - val_loss: 0.2772\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "training on param set  29\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_145 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_146 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_147 (Conv2D)         (None, 8, 16, 16)         6416      \n",
      "                                                                 \n",
      " up_sampling2d_58 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_59 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,441\n",
      "Trainable params: 20,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 4.2006\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 47ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 4.2014\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 4.2039\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 1s 41ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 4.2042\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "training on param set  30\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_150 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_151 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_152 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_60 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_153 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_61 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_154 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.9824\n",
      "Epoch 1: val_loss improved from inf to 0.61145, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 43ms/step - loss: 0.9669 - val_loss: 0.6115\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5262\n",
      "Epoch 2: val_loss improved from 0.61145 to 0.43974, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 0.5229 - val_loss: 0.4397\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3724\n",
      "Epoch 3: val_loss improved from 0.43974 to 0.31412, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 41ms/step - loss: 0.3703 - val_loss: 0.3141\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3051\n",
      "Epoch 4: val_loss improved from 0.31412 to 0.29214, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 39ms/step - loss: 0.3043 - val_loss: 0.2921\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2928\n",
      "Epoch 5: val_loss improved from 0.29214 to 0.28460, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 39ms/step - loss: 0.2926 - val_loss: 0.2846\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  31\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_155 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_156 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_157 (Conv2D)         (None, 8, 16, 16)         6416      \n",
      "                                                                 \n",
      " up_sampling2d_62 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_158 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_63 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_159 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,341\n",
      "Trainable params: 10,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.7681\n",
      "Epoch 1: val_loss improved from inf to 0.60167, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 48ms/step - loss: 0.7619 - val_loss: 0.6017\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5817\n",
      "Epoch 2: val_loss improved from 0.60167 to 0.52761, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.5796 - val_loss: 0.5276\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5427\n",
      "Epoch 3: val_loss improved from 0.52761 to 0.47568, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.5427 - val_loss: 0.4757\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4234\n",
      "Epoch 4: val_loss improved from 0.47568 to 0.35878, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.4211 - val_loss: 0.3588\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3566\n",
      "Epoch 5: val_loss improved from 0.35878 to 0.33615, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.3559 - val_loss: 0.3361\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "training on param set  32\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_160 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_161 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_162 (Conv2D)         (None, 8, 16, 16)         6416      \n",
      "                                                                 \n",
      " up_sampling2d_64 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_163 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_65 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_164 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,441\n",
      "Trainable params: 20,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5080\n",
      "Epoch 1: val_loss improved from inf to 0.48068, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 48ms/step - loss: 0.5071 - val_loss: 0.4807\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4452\n",
      "Epoch 2: val_loss improved from 0.48068 to 0.42046, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.4439 - val_loss: 0.4205\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3644\n",
      "Epoch 3: val_loss improved from 0.42046 to 0.31536, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.3625 - val_loss: 0.3154\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3111\n",
      "Epoch 4: val_loss improved from 0.31536 to 0.29974, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 45ms/step - loss: 0.3110 - val_loss: 0.2997\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3336\n",
      "Epoch 5: val_loss did not improve from 0.29974\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.3328 - val_loss: 0.3029\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "training on param set  33\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_165 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_66 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_168 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_67 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_169 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.8616\n",
      "Epoch 1: val_loss improved from inf to 0.41678, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 39ms/step - loss: 0.8441 - val_loss: 0.4168\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3704\n",
      "Epoch 2: val_loss improved from 0.41678 to 0.33743, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 35ms/step - loss: 0.3694 - val_loss: 0.3374\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3280\n",
      "Epoch 3: val_loss improved from 0.33743 to 0.31071, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.3273 - val_loss: 0.3107\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3036\n",
      "Epoch 4: val_loss improved from 0.31071 to 0.29459, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.3031 - val_loss: 0.2946\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2908\n",
      "Epoch 5: val_loss improved from 0.29459 to 0.28431, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.2905 - val_loss: 0.2843\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  34\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_170 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_69 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_172 (Conv2D)         (None, 8, 16, 16)         6416      \n",
      "                                                                 \n",
      " up_sampling2d_68 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_173 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_69 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_174 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,341\n",
      "Trainable params: 10,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.7871\n",
      "Epoch 1: val_loss improved from inf to 0.51516, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 46ms/step - loss: 0.7748 - val_loss: 0.5152\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4721\n",
      "Epoch 2: val_loss improved from 0.51516 to 0.44900, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.4707 - val_loss: 0.4490\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4293\n",
      "Epoch 3: val_loss improved from 0.44900 to 0.40755, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 42ms/step - loss: 0.4288 - val_loss: 0.4076\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3710\n",
      "Epoch 4: val_loss improved from 0.40755 to 0.33578, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 41ms/step - loss: 0.3694 - val_loss: 0.3358\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3222\n",
      "Epoch 5: val_loss improved from 0.33578 to 0.30781, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 43ms/step - loss: 0.3214 - val_loss: 0.3078\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  35\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_175 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_70 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_71 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_177 (Conv2D)         (None, 8, 16, 16)         6416      \n",
      "                                                                 \n",
      " up_sampling2d_70 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_178 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_71 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_179 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,441\n",
      "Trainable params: 20,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.6072\n",
      "Epoch 1: val_loss improved from inf to 0.45662, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 50ms/step - loss: 0.6072 - val_loss: 0.4566\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4284\n",
      "Epoch 2: val_loss improved from 0.45662 to 0.37632, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 45ms/step - loss: 0.4267 - val_loss: 0.3763\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3343\n",
      "Epoch 3: val_loss improved from 0.37632 to 0.31079, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 46ms/step - loss: 0.3343 - val_loss: 0.3108\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3127\n",
      "Epoch 4: val_loss improved from 0.31079 to 0.30128, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 44ms/step - loss: 0.3119 - val_loss: 0.3013\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3019\n",
      "Epoch 5: val_loss improved from 0.30128 to 0.29510, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 44ms/step - loss: 0.3021 - val_loss: 0.2951\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  36\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_180 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_72 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_183 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_73 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_184 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5719\n",
      "Epoch 1: val_loss improved from inf to 0.32160, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 70ms/step - loss: 0.5708 - val_loss: 0.3216\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3005\n",
      "Epoch 2: val_loss improved from 0.32160 to 0.28930, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.3005 - val_loss: 0.2893\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2842\n",
      "Epoch 3: val_loss improved from 0.28930 to 0.27323, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.2841 - val_loss: 0.2732\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2685\n",
      "Epoch 4: val_loss improved from 0.27323 to 0.26021, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.2685 - val_loss: 0.2602\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2619\n",
      "Epoch 5: val_loss improved from 0.26021 to 0.25674, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.2618 - val_loss: 0.2567\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  37\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_185 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_186 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_187 (Conv2D)         (None, 8, 16, 16)         25616     \n",
      "                                                                 \n",
      " up_sampling2d_74 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_188 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_75 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_189 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,069\n",
      "Trainable params: 36,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5761\n",
      "Epoch 1: val_loss improved from inf to 0.52839, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 88ms/step - loss: 0.5751 - val_loss: 0.5284\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3571\n",
      "Epoch 2: val_loss improved from 0.52839 to 0.39387, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 1.3528 - val_loss: 0.3939\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3733\n",
      "Epoch 3: val_loss improved from 0.39387 to 0.31419, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 85ms/step - loss: 0.3730 - val_loss: 0.3142\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3058\n",
      "Epoch 4: val_loss improved from 0.31419 to 0.29527, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 86ms/step - loss: 0.3058 - val_loss: 0.2953\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2911\n",
      "Epoch 5: val_loss improved from 0.29527 to 0.28724, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 87ms/step - loss: 0.2911 - val_loss: 0.2872\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  38\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_190 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_77 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_192 (Conv2D)         (None, 8, 16, 16)         25616     \n",
      "                                                                 \n",
      " up_sampling2d_76 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_77 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,169\n",
      "Trainable params: 46,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8453\n",
      "Epoch 1: val_loss improved from inf to 0.35753, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 106ms/step - loss: 1.8390 - val_loss: 0.3575\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3908\n",
      "Epoch 2: val_loss improved from 0.35753 to 0.34006, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 100ms/step - loss: 0.3906 - val_loss: 0.3401\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3379\n",
      "Epoch 3: val_loss improved from 0.34006 to 0.29671, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 99ms/step - loss: 0.3377 - val_loss: 0.2967\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2907\n",
      "Epoch 4: val_loss improved from 0.29671 to 0.28178, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 95ms/step - loss: 0.2907 - val_loss: 0.2818\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2817\n",
      "Epoch 5: val_loss improved from 0.28178 to 0.27654, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 99ms/step - loss: 0.2817 - val_loss: 0.2765\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  39\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_195 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_78 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_198 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_79 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_199 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3674\n",
      "Epoch 1: val_loss improved from inf to 0.28265, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 80ms/step - loss: 0.3670 - val_loss: 0.2826\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2790\n",
      "Epoch 2: val_loss improved from 0.28265 to 0.26845, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.2789 - val_loss: 0.2684\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2679\n",
      "Epoch 3: val_loss improved from 0.26845 to 0.26144, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.2678 - val_loss: 0.2614\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2629\n",
      "Epoch 4: val_loss improved from 0.26144 to 0.26090, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.2629 - val_loss: 0.2609\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2603\n",
      "Epoch 5: val_loss improved from 0.26090 to 0.25491, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.2603 - val_loss: 0.2549\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  40\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_200 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_201 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_202 (Conv2D)         (None, 8, 16, 16)         25616     \n",
      "                                                                 \n",
      " up_sampling2d_80 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_203 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_81 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_204 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,069\n",
      "Trainable params: 36,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.0992\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 92ms/step - loss: 4.1003 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2047\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 83ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2051\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 81ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2056\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 81ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2032\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 83ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "training on param set  41\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_205 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_206 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_207 (Conv2D)         (None, 8, 16, 16)         25616     \n",
      "                                                                 \n",
      " up_sampling2d_82 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_208 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_83 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_209 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,169\n",
      "Trainable params: 46,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9403\n",
      "Epoch 1: val_loss improved from inf to 0.63077, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 92ms/step - loss: 0.9408 - val_loss: 0.6308\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6586\n",
      "Epoch 2: val_loss improved from 0.63077 to 0.51582, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 89ms/step - loss: 0.6580 - val_loss: 0.5158\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4552\n",
      "Epoch 3: val_loss improved from 0.51582 to 0.49239, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.4554 - val_loss: 0.4924\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4595\n",
      "Epoch 4: val_loss improved from 0.49239 to 0.36244, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.4591 - val_loss: 0.3624\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3451\n",
      "Epoch 5: val_loss improved from 0.36244 to 0.31412, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 88ms/step - loss: 0.3449 - val_loss: 0.3141\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  42\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_210 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_84 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_211 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_85 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_212 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_84 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_213 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_85 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_214 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6960\n",
      "Epoch 1: val_loss improved from inf to 0.29780, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 73ms/step - loss: 0.6943 - val_loss: 0.2978\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2854\n",
      "Epoch 2: val_loss improved from 0.29780 to 0.27338, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.2854 - val_loss: 0.2734\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2715\n",
      "Epoch 3: val_loss improved from 0.27338 to 0.26452, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.2714 - val_loss: 0.2645\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2652\n",
      "Epoch 4: val_loss improved from 0.26452 to 0.26118, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.2653 - val_loss: 0.2612\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2689\n",
      "Epoch 5: val_loss did not improve from 0.26118\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.2689 - val_loss: 0.2619\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "training on param set  43\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_215 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_86 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_216 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_217 (Conv2D)         (None, 8, 16, 16)         25616     \n",
      "                                                                 \n",
      " up_sampling2d_86 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_218 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_87 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_219 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,069\n",
      "Trainable params: 36,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7854\n",
      "Epoch 1: val_loss improved from inf to 0.52244, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 84ms/step - loss: 0.7850 - val_loss: 0.5224\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4639\n",
      "Epoch 2: val_loss improved from 0.52244 to 0.34168, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 0.4634 - val_loss: 0.3417\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4671\n",
      "Epoch 3: val_loss did not improve from 0.34168\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 0.4665 - val_loss: 0.3634\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3169\n",
      "Epoch 4: val_loss improved from 0.34168 to 0.29376, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 85ms/step - loss: 0.3169 - val_loss: 0.2938\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2880\n",
      "Epoch 5: val_loss improved from 0.29376 to 0.28029, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 82ms/step - loss: 0.2879 - val_loss: 0.2803\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  44\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_220 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_221 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_222 (Conv2D)         (None, 8, 16, 16)         25616     \n",
      "                                                                 \n",
      " up_sampling2d_88 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_223 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_89 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_224 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,169\n",
      "Trainable params: 46,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.0080\n",
      "Epoch 1: val_loss improved from inf to 0.59262, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 97ms/step - loss: 1.0080 - val_loss: 0.5926\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4847\n",
      "Epoch 2: val_loss improved from 0.59262 to 0.32073, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.4840 - val_loss: 0.3207\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3135\n",
      "Epoch 3: val_loss improved from 0.32073 to 0.29896, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 95ms/step - loss: 0.3135 - val_loss: 0.2990\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2961\n",
      "Epoch 4: val_loss improved from 0.29896 to 0.28793, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.2961 - val_loss: 0.2879\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2866\n",
      "Epoch 5: val_loss improved from 0.28793 to 0.28354, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 92ms/step - loss: 0.2865 - val_loss: 0.2835\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  45\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_225 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_90 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_226 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_91 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_227 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_90 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_228 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_91 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_229 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3614\n",
      "Epoch 1: val_loss improved from inf to 0.28354, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 134ms/step - loss: 0.3612 - val_loss: 0.2835\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2861\n",
      "Epoch 2: val_loss improved from 0.28354 to 0.26999, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.2861 - val_loss: 0.2700\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2686\n",
      "Epoch 3: val_loss improved from 0.26999 to 0.26144, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 128ms/step - loss: 0.2686 - val_loss: 0.2614\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2620\n",
      "Epoch 4: val_loss improved from 0.26144 to 0.25801, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 124ms/step - loss: 0.2620 - val_loss: 0.2580\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2585\n",
      "Epoch 5: val_loss improved from 0.25801 to 0.25349, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 123ms/step - loss: 0.2585 - val_loss: 0.2535\n",
      "finished training\n",
      "12/12 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  46\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_230 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_92 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_231 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_93 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_232 (Conv2D)         (None, 8, 16, 16)         57616     \n",
      "                                                                 \n",
      " up_sampling2d_92 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_233 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_93 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_234 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,949\n",
      "Trainable params: 78,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 6.1597\n",
      "Epoch 1: val_loss improved from inf to 1.89808, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 152ms/step - loss: 6.1395 - val_loss: 1.8981\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1112\n",
      "Epoch 2: val_loss did not improve from 1.89808\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 2.1119 - val_loss: 2.3803\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0921\n",
      "Epoch 3: val_loss did not improve from 1.89808\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 2.0928 - val_loss: 2.3638\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3109\n",
      "Epoch 4: val_loss did not improve from 1.89808\n",
      "29/29 [==============================] - 4s 140ms/step - loss: 2.3110 - val_loss: 2.2438\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3550\n",
      "Epoch 5: val_loss did not improve from 1.89808\n",
      "29/29 [==============================] - 4s 149ms/step - loss: 2.3537 - val_loss: 1.9320\n",
      "finished training\n",
      "12/12 [==============================] - 0s 21ms/step\n",
      "training on param set  47\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_235 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_94 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_236 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_237 (Conv2D)         (None, 8, 16, 16)         57616     \n",
      "                                                                 \n",
      " up_sampling2d_94 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_238 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_95 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,049\n",
      "Trainable params: 89,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9866\n",
      "Epoch 1: val_loss improved from inf to 0.37769, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 173ms/step - loss: 0.9838 - val_loss: 0.3777\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4888\n",
      "Epoch 2: val_loss did not improve from 0.37769\n",
      "29/29 [==============================] - 5s 171ms/step - loss: 0.4887 - val_loss: 0.4371\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3730\n",
      "Epoch 3: val_loss improved from 0.37769 to 0.32933, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 161ms/step - loss: 0.3728 - val_loss: 0.3293\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3135\n",
      "Epoch 4: val_loss improved from 0.32933 to 0.30278, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 165ms/step - loss: 0.3134 - val_loss: 0.3028\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2972\n",
      "Epoch 5: val_loss improved from 0.30278 to 0.29110, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 163ms/step - loss: 0.2971 - val_loss: 0.2911\n",
      "finished training\n",
      "12/12 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  48\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_240 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_96 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_97 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5581\n",
      "Epoch 1: val_loss improved from inf to 0.28954, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 139ms/step - loss: 0.5569 - val_loss: 0.2895\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2805\n",
      "Epoch 2: val_loss improved from 0.28954 to 0.26874, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.2805 - val_loss: 0.2687\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2716\n",
      "Epoch 3: val_loss improved from 0.26874 to 0.26699, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.2715 - val_loss: 0.2670\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2667\n",
      "Epoch 4: val_loss improved from 0.26699 to 0.26038, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 128ms/step - loss: 0.2667 - val_loss: 0.2604\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2601\n",
      "Epoch 5: val_loss improved from 0.26038 to 0.25434, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 125ms/step - loss: 0.2601 - val_loss: 0.2543\n",
      "finished training\n",
      "12/12 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  49\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_245 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_98 (MaxPoolin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_246 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_99 (MaxPoolin  (None, 8, 16, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_247 (Conv2D)         (None, 8, 16, 16)         57616     \n",
      "                                                                 \n",
      " up_sampling2d_98 (UpSamplin  (None, 16, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_248 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_99 (UpSamplin  (None, 32, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_249 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,949\n",
      "Trainable params: 78,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7220\n",
      "Epoch 1: val_loss improved from inf to 0.41637, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 148ms/step - loss: 0.7207 - val_loss: 0.4164\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3725\n",
      "Epoch 2: val_loss improved from 0.41637 to 0.32761, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 155ms/step - loss: 0.3724 - val_loss: 0.3276\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3162\n",
      "Epoch 3: val_loss improved from 0.32761 to 0.31349, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 158ms/step - loss: 0.3162 - val_loss: 0.3135\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3170\n",
      "Epoch 4: val_loss improved from 0.31349 to 0.31035, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 153ms/step - loss: 0.3170 - val_loss: 0.3104\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2999\n",
      "Epoch 5: val_loss improved from 0.31035 to 0.29176, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 153ms/step - loss: 0.2999 - val_loss: 0.2918\n",
      "finished training\n",
      "12/12 [==============================] - 0s 27ms/step\n",
      "training on param set  50\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_250 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_100 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_251 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_101 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_252 (Conv2D)         (None, 8, 16, 16)         57616     \n",
      "                                                                 \n",
      " up_sampling2d_100 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_253 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_101 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_254 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,049\n",
      "Trainable params: 89,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9109\n",
      "Epoch 1: val_loss improved from inf to 0.39853, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 153ms/step - loss: 0.9086 - val_loss: 0.3985\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3425\n",
      "Epoch 2: val_loss improved from 0.39853 to 0.29610, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 150ms/step - loss: 0.3424 - val_loss: 0.2961\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2968\n",
      "Epoch 3: val_loss improved from 0.29610 to 0.29477, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 150ms/step - loss: 0.2967 - val_loss: 0.2948\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2957\n",
      "Epoch 4: val_loss improved from 0.29477 to 0.28612, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 157ms/step - loss: 0.2956 - val_loss: 0.2861\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2853\n",
      "Epoch 5: val_loss improved from 0.28612 to 0.27850, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 164ms/step - loss: 0.2853 - val_loss: 0.2785\n",
      "finished training\n",
      "12/12 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  51\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_255 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_102 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_256 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_103 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_257 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_102 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_258 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_103 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_259 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5413\n",
      "Epoch 1: val_loss improved from inf to 0.29266, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 136ms/step - loss: 0.5401 - val_loss: 0.2927\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2821\n",
      "Epoch 2: val_loss improved from 0.29266 to 0.27174, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 128ms/step - loss: 0.2821 - val_loss: 0.2717\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2670\n",
      "Epoch 3: val_loss improved from 0.27174 to 0.25986, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 0.2670 - val_loss: 0.2599\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2614\n",
      "Epoch 4: val_loss improved from 0.25986 to 0.25631, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 121ms/step - loss: 0.2614 - val_loss: 0.2563\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2585\n",
      "Epoch 5: val_loss improved from 0.25631 to 0.25460, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.2585 - val_loss: 0.2546\n",
      "finished training\n",
      "12/12 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  52\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_260 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_104 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_261 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_105 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " conv2d_262 (Conv2D)         (None, 8, 16, 16)         57616     \n",
      "                                                                 \n",
      " up_sampling2d_104 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_263 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_105 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_264 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,949\n",
      "Trainable params: 78,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.3886\n",
      "Epoch 1: val_loss improved from inf to 0.64988, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 161ms/step - loss: 3.3768 - val_loss: 0.6499\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4908\n",
      "Epoch 2: val_loss improved from 0.64988 to 0.33880, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 165ms/step - loss: 0.4902 - val_loss: 0.3388\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3132\n",
      "Epoch 3: val_loss improved from 0.33880 to 0.29579, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 159ms/step - loss: 0.3131 - val_loss: 0.2958\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2917\n",
      "Epoch 4: val_loss improved from 0.29579 to 0.28456, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 156ms/step - loss: 0.2919 - val_loss: 0.2846\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2839\n",
      "Epoch 5: val_loss improved from 0.28456 to 0.27960, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.2839 - val_loss: 0.2796\n",
      "finished training\n",
      "12/12 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  53\n",
      "{'conv_depth': 16, 'hidden_size': 100, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_265 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_106 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_266 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_107 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 8, 16, 100)        1700      \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_267 (Conv2D)         (None, 8, 16, 16)         57616     \n",
      "                                                                 \n",
      " up_sampling2d_106 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_268 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_107 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_269 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,049\n",
      "Trainable params: 89,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8607\n",
      "Epoch 1: val_loss improved from inf to 2.63136, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 155ms/step - loss: 1.8655 - val_loss: 2.6314\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.5484\n",
      "Epoch 2: val_loss improved from 2.63136 to 1.00065, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 161ms/step - loss: 1.5457 - val_loss: 1.0007\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7618\n",
      "Epoch 3: val_loss improved from 1.00065 to 0.63823, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 158ms/step - loss: 0.7612 - val_loss: 0.6382\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6037\n",
      "Epoch 4: val_loss improved from 0.63823 to 0.59886, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 151ms/step - loss: 0.6036 - val_loss: 0.5989\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5856\n",
      "Epoch 5: val_loss improved from 0.59886 to 0.58545, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 154ms/step - loss: 0.5856 - val_loss: 0.5854\n",
      "finished training\n",
      "12/12 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  54\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_270 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_108 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_271 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_109 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_272 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_108 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_273 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_109 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_274 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4849\n",
      "Epoch 1: val_loss improved from inf to 0.34305, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 39ms/step - loss: 0.4792 - val_loss: 0.3431\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3272\n",
      "Epoch 2: val_loss improved from 0.34305 to 0.30858, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.3265 - val_loss: 0.3086\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2991\n",
      "Epoch 3: val_loss improved from 0.30858 to 0.28762, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.2989 - val_loss: 0.2876\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2834\n",
      "Epoch 4: val_loss improved from 0.28762 to 0.27446, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.2832 - val_loss: 0.2745\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2733\n",
      "Epoch 5: val_loss improved from 0.27446 to 0.26702, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.2733 - val_loss: 0.2670\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  55\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_275 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_110 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_276 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_111 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_277 (Conv2D)         (None, 8, 16, 16)         19216     \n",
      "                                                                 \n",
      " up_sampling2d_110 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_278 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_111 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_279 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,541\n",
      "Trainable params: 26,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.0516\n",
      "Epoch 1: val_loss improved from inf to 0.87723, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 57ms/step - loss: 1.0516 - val_loss: 0.8772\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8792\n",
      "Epoch 2: val_loss improved from 0.87723 to 0.82849, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 53ms/step - loss: 0.8791 - val_loss: 0.8285\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.8110\n",
      "Epoch 3: val_loss improved from 0.82849 to 0.75087, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 54ms/step - loss: 0.8110 - val_loss: 0.7509\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7130\n",
      "Epoch 4: val_loss improved from 0.75087 to 0.63006, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 0.7129 - val_loss: 0.6301\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6397\n",
      "Epoch 5: val_loss improved from 0.63006 to 0.60085, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 0.6396 - val_loss: 0.6008\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  56\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_280 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_112 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_281 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_113 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_282 (Conv2D)         (None, 8, 16, 16)         19216     \n",
      "                                                                 \n",
      " up_sampling2d_112 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_283 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_113 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_284 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,841\n",
      "Trainable params: 116,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.3103\n",
      "Epoch 1: val_loss improved from inf to 0.51115, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 82ms/step - loss: 4.2933 - val_loss: 0.5112\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5421\n",
      "Epoch 2: val_loss did not improve from 0.51115\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.5420 - val_loss: 0.5295\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5255\n",
      "Epoch 3: val_loss did not improve from 0.51115\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.5256 - val_loss: 0.5113\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4898\n",
      "Epoch 4: val_loss improved from 0.51115 to 0.43385, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.4895 - val_loss: 0.4339\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3409\n",
      "Epoch 5: val_loss improved from 0.43385 to 0.30250, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.3407 - val_loss: 0.3025\n",
      "finished training\n",
      "12/12 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  57\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_285 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_114 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_286 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_115 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_287 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_114 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_288 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_115 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_289 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.4302\n",
      "Epoch 1: val_loss improved from inf to 0.61996, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 40ms/step - loss: 1.3977 - val_loss: 0.6200\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5431\n",
      "Epoch 2: val_loss improved from 0.61996 to 0.47955, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.5404 - val_loss: 0.4796\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4248\n",
      "Epoch 3: val_loss improved from 0.47955 to 0.37377, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.4228 - val_loss: 0.3738\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3435\n",
      "Epoch 4: val_loss improved from 0.37377 to 0.32063, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.3427 - val_loss: 0.3206\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3083\n",
      "Epoch 5: val_loss improved from 0.32063 to 0.29444, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.3081 - val_loss: 0.2944\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  58\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_290 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_116 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_291 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_117 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_292 (Conv2D)         (None, 8, 16, 16)         19216     \n",
      "                                                                 \n",
      " up_sampling2d_116 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_293 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_117 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_294 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,541\n",
      "Trainable params: 26,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6061\n",
      "Epoch 1: val_loss improved from inf to 0.45012, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 59ms/step - loss: 0.6055 - val_loss: 0.4501\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3934\n",
      "Epoch 2: val_loss improved from 0.45012 to 0.34636, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 0.3933 - val_loss: 0.3464\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4313\n",
      "Epoch 3: val_loss did not improve from 0.34636\n",
      "29/29 [==============================] - 2s 54ms/step - loss: 0.4314 - val_loss: 0.4134\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3318\n",
      "Epoch 4: val_loss improved from 0.34636 to 0.30621, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.3318 - val_loss: 0.3062\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3014\n",
      "Epoch 5: val_loss improved from 0.30621 to 0.29494, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 56ms/step - loss: 0.3012 - val_loss: 0.2949\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  59\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_295 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_118 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_296 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_119 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_297 (Conv2D)         (None, 8, 16, 16)         19216     \n",
      "                                                                 \n",
      " up_sampling2d_118 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_298 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_119 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_299 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,841\n",
      "Trainable params: 116,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.1509\n",
      "Epoch 1: val_loss improved from inf to 0.81355, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 83ms/step - loss: 1.1495 - val_loss: 0.8135\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8367\n",
      "Epoch 2: val_loss improved from 0.81355 to 0.80888, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.8366 - val_loss: 0.8089\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8294\n",
      "Epoch 3: val_loss improved from 0.80888 to 0.79850, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.8294 - val_loss: 0.7985\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8126\n",
      "Epoch 4: val_loss improved from 0.79850 to 0.76881, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.8123 - val_loss: 0.7688\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7656\n",
      "Epoch 5: val_loss improved from 0.76881 to 0.70775, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 0.7654 - val_loss: 0.7077\n",
      "finished training\n",
      "12/12 [==============================] - 0s 18ms/step\n",
      "training on param set  60\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_300 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_120 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_301 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_121 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_302 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_120 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_303 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_121 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_304 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.5207\n",
      "Epoch 1: val_loss improved from inf to 0.66478, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 44ms/step - loss: 1.4869 - val_loss: 0.6648\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5727\n",
      "Epoch 2: val_loss improved from 0.66478 to 0.49223, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.5698 - val_loss: 0.4922\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.4385\n",
      "Epoch 3: val_loss improved from 0.49223 to 0.39119, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.4367 - val_loss: 0.3912\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3605\n",
      "Epoch 4: val_loss did not improve from 0.39119\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.3622 - val_loss: 0.4329\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3801\n",
      "Epoch 5: val_loss improved from 0.39119 to 0.33458, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.3786 - val_loss: 0.3346\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n",
      "training on param set  61\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_305 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_122 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_306 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_123 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_307 (Conv2D)         (None, 8, 16, 16)         19216     \n",
      "                                                                 \n",
      " up_sampling2d_122 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_308 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_123 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_309 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,541\n",
      "Trainable params: 26,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0744\n",
      "Epoch 1: val_loss improved from inf to 0.53521, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 61ms/step - loss: 1.0721 - val_loss: 0.5352\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5207\n",
      "Epoch 2: val_loss improved from 0.53521 to 0.48573, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 0.5205 - val_loss: 0.4857\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4478\n",
      "Epoch 3: val_loss improved from 0.48573 to 0.39453, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 0.4477 - val_loss: 0.3945\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3859\n",
      "Epoch 4: val_loss improved from 0.39453 to 0.36576, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 0.3859 - val_loss: 0.3658\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3747\n",
      "Epoch 5: val_loss improved from 0.36576 to 0.36086, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 0.3750 - val_loss: 0.3609\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  62\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_310 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_124 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_311 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_125 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_312 (Conv2D)         (None, 8, 16, 16)         19216     \n",
      "                                                                 \n",
      " up_sampling2d_124 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_313 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_125 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_314 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 116,841\n",
      "Trainable params: 116,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0794\n",
      "Epoch 1: val_loss improved from inf to 0.47595, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 74ms/step - loss: 1.0766 - val_loss: 0.4759\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4532\n",
      "Epoch 2: val_loss improved from 0.47595 to 0.43574, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.4531 - val_loss: 0.4357\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3914\n",
      "Epoch 3: val_loss improved from 0.43574 to 0.32416, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.3911 - val_loss: 0.3242\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3127\n",
      "Epoch 4: val_loss improved from 0.32416 to 0.30454, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 82ms/step - loss: 0.3126 - val_loss: 0.3045\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3021\n",
      "Epoch 5: val_loss improved from 0.30454 to 0.29804, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.3021 - val_loss: 0.2980\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  63\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_315 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_126 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_316 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_127 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_317 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_126 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_318 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_127 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_319 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5959\n",
      "Epoch 1: val_loss improved from inf to 0.30963, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 69ms/step - loss: 0.5946 - val_loss: 0.3096\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3379\n",
      "Epoch 2: val_loss did not improve from 0.30963\n",
      "29/29 [==============================] - 2s 64ms/step - loss: 0.3377 - val_loss: 0.3191\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2882\n",
      "Epoch 3: val_loss improved from 0.30963 to 0.27423, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.2881 - val_loss: 0.2742\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2717\n",
      "Epoch 4: val_loss improved from 0.27423 to 0.26464, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.2717 - val_loss: 0.2646\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2658\n",
      "Epoch 5: val_loss improved from 0.26464 to 0.26143, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.2658 - val_loss: 0.2614\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  64\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_320 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_128 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_321 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_129 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_322 (Conv2D)         (None, 8, 16, 16)         76816     \n",
      "                                                                 \n",
      " up_sampling2d_128 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_323 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_129 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_324 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,669\n",
      "Trainable params: 90,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0859\n",
      "Epoch 1: val_loss improved from inf to 0.48121, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 112ms/step - loss: 1.0833 - val_loss: 0.4812\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.2808\n",
      "Epoch 2: val_loss did not improve from 0.48121\n",
      "29/29 [==============================] - 3s 105ms/step - loss: 1.2804 - val_loss: 1.1068\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9801\n",
      "Epoch 3: val_loss did not improve from 0.48121\n",
      "29/29 [==============================] - 3s 104ms/step - loss: 0.9796 - val_loss: 0.8960\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8383\n",
      "Epoch 4: val_loss did not improve from 0.48121\n",
      "29/29 [==============================] - 3s 104ms/step - loss: 0.8384 - val_loss: 1.2369\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7056\n",
      "Epoch 5: val_loss did not improve from 0.48121\n",
      "29/29 [==============================] - 3s 105ms/step - loss: 0.7049 - val_loss: 0.5327\n",
      "finished training\n",
      "12/12 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  65\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_325 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_130 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_326 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_131 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_327 (Conv2D)         (None, 8, 16, 16)         76816     \n",
      "                                                                 \n",
      " up_sampling2d_130 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_328 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_131 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_329 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,969\n",
      "Trainable params: 180,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7930\n",
      "Epoch 1: val_loss improved from inf to 2.62000, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 128ms/step - loss: 3.7884 - val_loss: 2.6200\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2158\n",
      "Epoch 2: val_loss improved from 2.62000 to 2.13478, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 118ms/step - loss: 2.2141 - val_loss: 2.1348\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.7430\n",
      "Epoch 3: val_loss improved from 2.13478 to 1.00392, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 115ms/step - loss: 1.7391 - val_loss: 1.0039\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3979\n",
      "Epoch 4: val_loss did not improve from 1.00392\n",
      "29/29 [==============================] - 3s 113ms/step - loss: 1.3953 - val_loss: 1.0367\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9177\n",
      "Epoch 5: val_loss did not improve from 1.00392\n",
      "29/29 [==============================] - 3s 111ms/step - loss: 0.9250 - val_loss: 2.5243\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  66\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_330 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_132 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_331 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_133 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_332 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_132 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_333 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_133 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_334 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3749\n",
      "Epoch 1: val_loss improved from inf to 0.28304, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 76ms/step - loss: 0.3745 - val_loss: 0.2830\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2764\n",
      "Epoch 2: val_loss improved from 0.28304 to 0.26754, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 0.2764 - val_loss: 0.2675\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2663\n",
      "Epoch 3: val_loss improved from 0.26754 to 0.26038, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.2663 - val_loss: 0.2604\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2617\n",
      "Epoch 4: val_loss improved from 0.26038 to 0.25600, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.2617 - val_loss: 0.2560\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2578\n",
      "Epoch 5: val_loss improved from 0.25600 to 0.25266, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.2578 - val_loss: 0.2527\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "training on param set  67\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_335 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_134 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_336 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_135 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_337 (Conv2D)         (None, 8, 16, 16)         76816     \n",
      "                                                                 \n",
      " up_sampling2d_134 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_338 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_135 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_339 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,669\n",
      "Trainable params: 90,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.1890\n",
      "Epoch 1: val_loss improved from inf to 1.42568, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 110ms/step - loss: 3.1830 - val_loss: 1.4257\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9164\n",
      "Epoch 2: val_loss did not improve from 1.42568\n",
      "29/29 [==============================] - 3s 107ms/step - loss: 1.9159 - val_loss: 1.7066\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.8183\n",
      "Epoch 3: val_loss did not improve from 1.42568\n",
      "29/29 [==============================] - 3s 110ms/step - loss: 4.8460 - val_loss: 10.6893\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.6256\n",
      "Epoch 4: val_loss did not improve from 1.42568\n",
      "29/29 [==============================] - 3s 112ms/step - loss: 10.6240 - val_loss: 9.5155\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.6012\n",
      "Epoch 5: val_loss did not improve from 1.42568\n",
      "29/29 [==============================] - 3s 110ms/step - loss: 3.5939 - val_loss: 1.9828\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  68\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_340 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_136 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_341 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_137 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_342 (Conv2D)         (None, 8, 16, 16)         76816     \n",
      "                                                                 \n",
      " up_sampling2d_136 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_343 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_137 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_344 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,969\n",
      "Trainable params: 180,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1219\n",
      "Epoch 1: val_loss improved from inf to 2.90353, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 142ms/step - loss: 2.1239 - val_loss: 2.9035\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 7.7173\n",
      "Epoch 2: val_loss did not improve from 2.90353\n",
      "29/29 [==============================] - 4s 143ms/step - loss: 7.7327 - val_loss: 10.9676\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 11.0667\n",
      "Epoch 3: val_loss did not improve from 2.90353\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 11.0671 - val_loss: 10.9612\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 11.0629\n",
      "Epoch 4: val_loss did not improve from 2.90353\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 11.0634 - val_loss: 10.9608\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 11.0632\n",
      "Epoch 5: val_loss did not improve from 2.90353\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 11.0631 - val_loss: 10.9606\n",
      "finished training\n",
      "12/12 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  69\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_345 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_138 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_346 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_139 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_347 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_138 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_348 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_139 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_349 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5948\n",
      "Epoch 1: val_loss improved from inf to 0.37005, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 84ms/step - loss: 0.5938 - val_loss: 0.3700\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3120\n",
      "Epoch 2: val_loss improved from 0.37005 to 0.28768, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.3119 - val_loss: 0.2877\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2752\n",
      "Epoch 3: val_loss improved from 0.28768 to 0.26544, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.2752 - val_loss: 0.2654\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2669\n",
      "Epoch 4: val_loss improved from 0.26544 to 0.26135, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 0.2668 - val_loss: 0.2614\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2633\n",
      "Epoch 5: val_loss improved from 0.26135 to 0.25845, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.2634 - val_loss: 0.2584\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  70\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_350 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_140 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_351 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_141 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_352 (Conv2D)         (None, 8, 16, 16)         76816     \n",
      "                                                                 \n",
      " up_sampling2d_140 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_353 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_141 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_354 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,669\n",
      "Trainable params: 90,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.8849\n",
      "Epoch 1: val_loss improved from inf to 2.33909, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 115ms/step - loss: 2.8838 - val_loss: 2.3391\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3731\n",
      "Epoch 2: val_loss did not improve from 2.33909\n",
      "29/29 [==============================] - 3s 110ms/step - loss: 2.3748 - val_loss: 2.5525\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1670\n",
      "Epoch 3: val_loss improved from 2.33909 to 1.71468, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 110ms/step - loss: 2.1658 - val_loss: 1.7147\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0682\n",
      "Epoch 4: val_loss did not improve from 1.71468\n",
      "29/29 [==============================] - 3s 109ms/step - loss: 2.0690 - val_loss: 2.1263\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8933\n",
      "Epoch 5: val_loss did not improve from 1.71468\n",
      "29/29 [==============================] - 3s 109ms/step - loss: 1.8929 - val_loss: 1.8371\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  71\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_355 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_142 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_356 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_143 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_357 (Conv2D)         (None, 8, 16, 16)         76816     \n",
      "                                                                 \n",
      " up_sampling2d_142 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_358 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_143 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_359 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,969\n",
      "Trainable params: 180,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2226\n",
      "Epoch 1: val_loss improved from inf to 2.03641, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 135ms/step - loss: 2.2215 - val_loss: 2.0364\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7602\n",
      "Epoch 2: val_loss did not improve from 2.03641\n",
      "29/29 [==============================] - 3s 120ms/step - loss: 2.7594 - val_loss: 2.4140\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3814\n",
      "Epoch 3: val_loss did not improve from 2.03641\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 2.3837 - val_loss: 2.9277\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.6815\n",
      "Epoch 4: val_loss did not improve from 2.03641\n",
      "29/29 [==============================] - 4s 155ms/step - loss: 2.6799 - val_loss: 2.3377\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2445\n",
      "Epoch 5: val_loss did not improve from 2.03641\n",
      "29/29 [==============================] - 5s 158ms/step - loss: 2.2446 - val_loss: 2.2002\n",
      "finished training\n",
      "12/12 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  72\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_360 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_144 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_361 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_145 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_362 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_144 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_363 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_145 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_364 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4783\n",
      "Epoch 1: val_loss improved from inf to 0.31028, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 144ms/step - loss: 0.4775 - val_loss: 0.3103\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2914\n",
      "Epoch 2: val_loss improved from 0.31028 to 0.27772, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 145ms/step - loss: 0.2913 - val_loss: 0.2777\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2747\n",
      "Epoch 3: val_loss improved from 0.27772 to 0.26733, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.2747 - val_loss: 0.2673\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2677\n",
      "Epoch 4: val_loss improved from 0.26733 to 0.26166, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 145ms/step - loss: 0.2677 - val_loss: 0.2617\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2631\n",
      "Epoch 5: val_loss improved from 0.26166 to 0.25758, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 0.2630 - val_loss: 0.2576\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n",
      "training on param set  73\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_365 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_146 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_366 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_147 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_367 (Conv2D)         (None, 8, 16, 16)         172816    \n",
      "                                                                 \n",
      " up_sampling2d_146 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_368 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_147 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_369 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,549\n",
      "Trainable params: 197,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.2222\n",
      "Epoch 1: val_loss improved from inf to 4.02858, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 198ms/step - loss: 3.2250 - val_loss: 4.0286\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7225\n",
      "Epoch 2: val_loss improved from 4.02858 to 3.17791, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 192ms/step - loss: 3.7228 - val_loss: 3.1779\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.5594\n",
      "Epoch 3: val_loss did not improve from 3.17791\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 3.5615 - val_loss: 3.7644\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.6529\n",
      "Epoch 4: val_loss did not improve from 3.17791\n",
      "29/29 [==============================] - 5s 184ms/step - loss: 3.6521 - val_loss: 3.7308\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.6447\n",
      "Epoch 5: val_loss did not improve from 3.17791\n",
      "29/29 [==============================] - 6s 201ms/step - loss: 3.6447 - val_loss: 3.7297\n",
      "finished training\n",
      "12/12 [==============================] - 1s 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  74\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_370 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_148 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_371 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_149 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_372 (Conv2D)         (None, 8, 16, 16)         172816    \n",
      "                                                                 \n",
      " up_sampling2d_148 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_373 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_149 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_374 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,849\n",
      "Trainable params: 287,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2072\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 246ms/step - loss: 4.2053 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2055\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 7s 233ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2044\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2062\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 7s 230ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2045\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  75\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_375 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_150 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_376 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_151 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_377 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_150 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_378 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_151 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_379 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5674\n",
      "Epoch 1: val_loss improved from inf to 0.28072, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 143ms/step - loss: 0.5661 - val_loss: 0.2807\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2737\n",
      "Epoch 2: val_loss improved from 0.28072 to 0.26330, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.2736 - val_loss: 0.2633\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2626\n",
      "Epoch 3: val_loss improved from 0.26330 to 0.25711, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.2625 - val_loss: 0.2571\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2577\n",
      "Epoch 4: val_loss did not improve from 0.25711\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.2577 - val_loss: 0.2572\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2544\n",
      "Epoch 5: val_loss improved from 0.25711 to 0.24824, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 119ms/step - loss: 0.2543 - val_loss: 0.2482\n",
      "finished training\n",
      "12/12 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  76\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_380 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_152 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_381 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_153 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_382 (Conv2D)         (None, 8, 16, 16)         172816    \n",
      "                                                                 \n",
      " up_sampling2d_152 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_383 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_153 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_384 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,549\n",
      "Trainable params: 197,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5382\n",
      "Epoch 1: val_loss improved from inf to 2.15504, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 244ms/step - loss: 2.5356 - val_loss: 2.1550\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5406\n",
      "Epoch 2: val_loss improved from 2.15504 to 2.00114, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 229ms/step - loss: 2.5388 - val_loss: 2.0011\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1556\n",
      "Epoch 3: val_loss did not improve from 2.00114\n",
      "29/29 [==============================] - 7s 228ms/step - loss: 2.1576 - val_loss: 2.6454\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5589\n",
      "Epoch 4: val_loss did not improve from 2.00114\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 2.5557 - val_loss: 2.1133\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0932\n",
      "Epoch 5: val_loss did not improve from 2.00114\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 2.0926 - val_loss: 2.0644\n",
      "finished training\n",
      "12/12 [==============================] - 1s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  77\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_385 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_154 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_386 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_155 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_387 (Conv2D)         (None, 8, 16, 16)         172816    \n",
      "                                                                 \n",
      " up_sampling2d_154 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_388 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_155 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_389 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,849\n",
      "Trainable params: 287,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.8672\n",
      "Epoch 1: val_loss improved from inf to 3.48212, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 265ms/step - loss: 3.8665 - val_loss: 3.4821\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.9235\n",
      "Epoch 2: val_loss improved from 3.48212 to 3.45665, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 2.9252 - val_loss: 3.4566\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7290\n",
      "Epoch 3: val_loss improved from 3.45665 to 2.07095, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 2.7261 - val_loss: 2.0710\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0990\n",
      "Epoch 4: val_loss improved from 2.07095 to 2.03064, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 2.0989 - val_loss: 2.0306\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3087\n",
      "Epoch 5: val_loss did not improve from 2.03064\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 2.3093 - val_loss: 2.1973\n",
      "finished training\n",
      "12/12 [==============================] - 1s 48ms/step\n",
      "training on param set  78\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_390 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_156 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_391 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_157 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_392 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_156 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_393 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_157 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_394 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6186\n",
      "Epoch 1: val_loss improved from inf to 0.30153, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 134ms/step - loss: 0.6172 - val_loss: 0.3015\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2915\n",
      "Epoch 2: val_loss improved from 0.30153 to 0.27554, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 149ms/step - loss: 0.2914 - val_loss: 0.2755\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2707\n",
      "Epoch 3: val_loss improved from 0.27554 to 0.26509, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 142ms/step - loss: 0.2706 - val_loss: 0.2651\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2650\n",
      "Epoch 4: val_loss improved from 0.26509 to 0.25965, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.2650 - val_loss: 0.2597\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2608\n",
      "Epoch 5: val_loss improved from 0.25965 to 0.25561, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 141ms/step - loss: 0.2608 - val_loss: 0.2556\n",
      "finished training\n",
      "12/12 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  79\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_395 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_158 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_396 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_159 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " conv2d_397 (Conv2D)         (None, 8, 16, 16)         172816    \n",
      "                                                                 \n",
      " up_sampling2d_158 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_398 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_159 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_399 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,549\n",
      "Trainable params: 197,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7450\n",
      "Epoch 1: val_loss improved from inf to 2.58119, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 235ms/step - loss: 2.7441 - val_loss: 2.5812\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.6687\n",
      "Epoch 2: val_loss improved from 2.58119 to 2.09281, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 2.6664 - val_loss: 2.0928\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2849\n",
      "Epoch 3: val_loss did not improve from 2.09281\n",
      "29/29 [==============================] - 7s 233ms/step - loss: 2.2842 - val_loss: 2.2666\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.4667\n",
      "Epoch 4: val_loss did not improve from 2.09281\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 2.4666 - val_loss: 2.3295\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5073\n",
      "Epoch 5: val_loss improved from 2.09281 to 2.04365, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 2.5052 - val_loss: 2.0437\n",
      "finished training\n",
      "12/12 [==============================] - 1s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  80\n",
      "{'conv_depth': 16, 'hidden_size': 300, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_400 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_160 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_401 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_161 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 8, 16, 300)        5100      \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_402 (Conv2D)         (None, 8, 16, 16)         172816    \n",
      "                                                                 \n",
      " up_sampling2d_160 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_403 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_161 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_404 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,849\n",
      "Trainable params: 287,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5714\n",
      "Epoch 1: val_loss improved from inf to 2.65106, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 256ms/step - loss: 2.5732 - val_loss: 2.6511\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.6494\n",
      "Epoch 2: val_loss improved from 2.65106 to 2.64893, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 2.6494 - val_loss: 2.6489\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.0160\n",
      "Epoch 3: val_loss did not improve from 2.64893\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 3.0181 - val_loss: 3.2003\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.1547\n",
      "Epoch 4: val_loss did not improve from 2.64893\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 3.1560 - val_loss: 3.1888\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.1480\n",
      "Epoch 5: val_loss did not improve from 2.64893\n",
      "29/29 [==============================] - 6s 217ms/step - loss: 3.1470 - val_loss: 3.1886\n",
      "finished training\n",
      "12/12 [==============================] - 1s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  81\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_405 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_162 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_406 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_163 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_407 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_162 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_408 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_163 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_409 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 1.4964\n",
      "Epoch 1: val_loss improved from inf to 1.03401, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 39ms/step - loss: 1.4776 - val_loss: 1.0340\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.9211\n",
      "Epoch 2: val_loss improved from 1.03401 to 0.83836, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.9172 - val_loss: 0.8384\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.7567\n",
      "Epoch 3: val_loss improved from 0.83836 to 0.70381, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.7542 - val_loss: 0.7038\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.6549\n",
      "Epoch 4: val_loss improved from 0.70381 to 0.62312, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.6535 - val_loss: 0.6231\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.5651\n",
      "Epoch 5: val_loss improved from 0.62312 to 0.33134, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 37ms/step - loss: 0.5558 - val_loss: 0.3313\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  82\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_410 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_164 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_411 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_165 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_412 (Conv2D)         (None, 8, 16, 16)         32016     \n",
      "                                                                 \n",
      " up_sampling2d_164 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_413 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_165 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_414 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,741\n",
      "Trainable params: 42,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.3481\n",
      "Epoch 1: val_loss improved from inf to 3.56066, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 70ms/step - loss: 3.3490 - val_loss: 3.5607\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8171\n",
      "Epoch 2: val_loss improved from 3.56066 to 1.07586, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 1.8133 - val_loss: 1.0759\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6045\n",
      "Epoch 3: val_loss improved from 1.07586 to 0.49629, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.6040 - val_loss: 0.4963\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4531\n",
      "Epoch 4: val_loss improved from 0.49629 to 0.40458, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.4530 - val_loss: 0.4046\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3775\n",
      "Epoch 5: val_loss improved from 0.40458 to 0.35851, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.3775 - val_loss: 0.3585\n",
      "finished training\n",
      "12/12 [==============================] - 0s 14ms/step\n",
      "training on param set  83\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_415 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_166 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_416 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_167 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_417 (Conv2D)         (None, 8, 16, 16)         32016     \n",
      "                                                                 \n",
      " up_sampling2d_166 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_418 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_167 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_419 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 293,241\n",
      "Trainable params: 293,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2045\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 91ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2059\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 3s 88ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2049\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 3s 87ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2053\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2038\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 85ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  84\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_420 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_168 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_421 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_169 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_422 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_168 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_423 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_169 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_424 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.6213\n",
      "Epoch 1: val_loss improved from inf to 0.39979, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 39ms/step - loss: 0.6128 - val_loss: 0.3998\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3556\n",
      "Epoch 2: val_loss improved from 0.39979 to 0.32601, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.3549 - val_loss: 0.3260\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3111\n",
      "Epoch 3: val_loss improved from 0.32601 to 0.29458, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.3106 - val_loss: 0.2946\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2887\n",
      "Epoch 4: val_loss improved from 0.29458 to 0.27462, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.2882 - val_loss: 0.2746\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2740\n",
      "Epoch 5: val_loss improved from 0.27462 to 0.26777, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 36ms/step - loss: 0.2739 - val_loss: 0.2678\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  85\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_425 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_170 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_426 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_171 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_427 (Conv2D)         (None, 8, 16, 16)         32016     \n",
      "                                                                 \n",
      " up_sampling2d_170 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_428 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_171 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_429 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,741\n",
      "Trainable params: 42,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7397\n",
      "Epoch 1: val_loss improved from inf to 0.46441, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 66ms/step - loss: 0.7385 - val_loss: 0.4644\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4366\n",
      "Epoch 2: val_loss improved from 0.46441 to 0.40231, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.4365 - val_loss: 0.4023\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3526\n",
      "Epoch 3: val_loss improved from 0.40231 to 0.31417, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 63ms/step - loss: 0.3523 - val_loss: 0.3142\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3118\n",
      "Epoch 4: val_loss improved from 0.31417 to 0.30171, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 63ms/step - loss: 0.3117 - val_loss: 0.3017\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2977\n",
      "Epoch 5: val_loss improved from 0.30171 to 0.28837, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.2978 - val_loss: 0.2884\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  86\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_430 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_172 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_431 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_173 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_432 (Conv2D)         (None, 8, 16, 16)         32016     \n",
      "                                                                 \n",
      " up_sampling2d_172 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_433 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_173 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_434 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 293,241\n",
      "Trainable params: 293,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0609\n",
      "Epoch 1: val_loss improved from inf to 0.51036, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 90ms/step - loss: 1.0584 - val_loss: 0.5104\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4618\n",
      "Epoch 2: val_loss improved from 0.51036 to 0.43305, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.4616 - val_loss: 0.4331\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3822\n",
      "Epoch 3: val_loss improved from 0.43305 to 0.32337, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 88ms/step - loss: 0.3819 - val_loss: 0.3234\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3122\n",
      "Epoch 4: val_loss improved from 0.32337 to 0.30225, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 89ms/step - loss: 0.3120 - val_loss: 0.3023\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3075\n",
      "Epoch 5: val_loss improved from 0.30225 to 0.30094, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.3077 - val_loss: 0.3009\n",
      "finished training\n",
      "12/12 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  87\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_435 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_174 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_436 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_175 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_437 (Conv2D)         (None, 8, 16, 16)         1040      \n",
      "                                                                 \n",
      " up_sampling2d_174 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_438 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_175 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_439 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,265\n",
      "Trainable params: 3,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.6505\n",
      "Epoch 1: val_loss improved from inf to 0.42997, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 41ms/step - loss: 0.6421 - val_loss: 0.4300\n",
      "Epoch 2/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.3597\n",
      "Epoch 2: val_loss improved from 0.42997 to 0.31614, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 39ms/step - loss: 0.3583 - val_loss: 0.3161\n",
      "Epoch 3/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2973\n",
      "Epoch 3: val_loss improved from 0.31614 to 0.28012, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 38ms/step - loss: 0.2966 - val_loss: 0.2801\n",
      "Epoch 4/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2766\n",
      "Epoch 4: val_loss improved from 0.28012 to 0.26944, saving model to best_weights.h5\n",
      "29/29 [==============================] - 1s 39ms/step - loss: 0.2763 - val_loss: 0.2694\n",
      "Epoch 5/5\n",
      "27/29 [==========================>...] - ETA: 0s - loss: 0.2732\n",
      "Epoch 5: val_loss did not improve from 0.26944\n",
      "29/29 [==============================] - 1s 40ms/step - loss: 0.2735 - val_loss: 0.2742\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  88\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_440 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_176 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_441 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_177 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_442 (Conv2D)         (None, 8, 16, 16)         32016     \n",
      "                                                                 \n",
      " up_sampling2d_176 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_443 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_177 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_444 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,741\n",
      "Trainable params: 42,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9724\n",
      "Epoch 1: val_loss improved from inf to 0.82800, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 73ms/step - loss: 0.9717 - val_loss: 0.8280\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7602\n",
      "Epoch 2: val_loss improved from 0.82800 to 0.73031, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.7600 - val_loss: 0.7303\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6912\n",
      "Epoch 3: val_loss improved from 0.73031 to 0.65990, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.6912 - val_loss: 0.6599\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6418\n",
      "Epoch 4: val_loss did not improve from 0.65990\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.6418 - val_loss: 0.6865\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6272\n",
      "Epoch 5: val_loss improved from 0.65990 to 0.63248, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.6271 - val_loss: 0.6325\n",
      "finished training\n",
      "12/12 [==============================] - 0s 14ms/step\n",
      "training on param set  89\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_445 (Conv2D)         (None, 32, 64, 16)        80        \n",
      "                                                                 \n",
      " max_pooling2d_178 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_446 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_179 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_447 (Conv2D)         (None, 8, 16, 16)         32016     \n",
      "                                                                 \n",
      " up_sampling2d_178 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_448 (Conv2D)         (None, 16, 32, 16)        1040      \n",
      "                                                                 \n",
      " up_sampling2d_179 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_449 (Conv2D)         (None, 32, 64, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 293,241\n",
      "Trainable params: 293,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 9.9337\n",
      "Epoch 1: val_loss improved from inf to 10.13100, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 98ms/step - loss: 9.9349 - val_loss: 10.1310\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 7.8626\n",
      "Epoch 2: val_loss improved from 10.13100 to 1.35131, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 92ms/step - loss: 7.8353 - val_loss: 1.3513\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7880\n",
      "Epoch 3: val_loss improved from 1.35131 to 0.70885, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 97ms/step - loss: 0.7875 - val_loss: 0.7089\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6951\n",
      "Epoch 4: val_loss improved from 0.70885 to 0.68701, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 98ms/step - loss: 0.6951 - val_loss: 0.6870\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6705\n",
      "Epoch 5: val_loss improved from 0.68701 to 0.66259, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 98ms/step - loss: 0.6705 - val_loss: 0.6626\n",
      "finished training\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "training on param set  90\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_450 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_180 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_451 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_181 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_452 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_180 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_453 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_181 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_454 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4008\n",
      "Epoch 1: val_loss improved from inf to 0.29989, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 70ms/step - loss: 0.4004 - val_loss: 0.2999\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2878\n",
      "Epoch 2: val_loss improved from 0.29989 to 0.27307, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.2876 - val_loss: 0.2731\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2707\n",
      "Epoch 3: val_loss improved from 0.27307 to 0.26354, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.2707 - val_loss: 0.2635\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2634\n",
      "Epoch 4: val_loss improved from 0.26354 to 0.25738, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.2634 - val_loss: 0.2574\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2589\n",
      "Epoch 5: val_loss improved from 0.25738 to 0.25372, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.2589 - val_loss: 0.2537\n",
      "finished training\n",
      "12/12 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  91\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_455 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_182 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_456 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_183 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_457 (Conv2D)         (None, 8, 16, 16)         128016    \n",
      "                                                                 \n",
      " up_sampling2d_182 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_458 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_183 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_459 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,269\n",
      "Trainable params: 145,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7474\n",
      "Epoch 1: val_loss improved from inf to 2.89492, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 129ms/step - loss: 2.7505 - val_loss: 2.8949\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2665\n",
      "Epoch 2: val_loss improved from 2.89492 to 1.94013, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 127ms/step - loss: 2.2654 - val_loss: 1.9401\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8811\n",
      "Epoch 3: val_loss did not improve from 1.94013\n",
      "29/29 [==============================] - 4s 127ms/step - loss: 1.8824 - val_loss: 2.2828\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3072\n",
      "Epoch 4: val_loss did not improve from 1.94013\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 2.3068 - val_loss: 2.1953\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0794\n",
      "Epoch 5: val_loss improved from 1.94013 to 1.93667, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 2.0797 - val_loss: 1.9367\n",
      "finished training\n",
      "12/12 [==============================] - 0s 22ms/step\n",
      "training on param set  92\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_460 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_184 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_461 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_185 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_462 (Conv2D)         (None, 8, 16, 16)         128016    \n",
      "                                                                 \n",
      " up_sampling2d_184 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_463 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_185 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_464 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 395,769\n",
      "Trainable params: 395,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7399\n",
      "Epoch 1: val_loss improved from inf to 2.55901, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 166ms/step - loss: 2.7385 - val_loss: 2.5590\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3062\n",
      "Epoch 2: val_loss did not improve from 2.55901\n",
      "29/29 [==============================] - 5s 161ms/step - loss: 2.3114 - val_loss: 4.0913\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.0143\n",
      "Epoch 3: val_loss did not improve from 2.55901\n",
      "29/29 [==============================] - 4s 154ms/step - loss: 4.0134 - val_loss: 4.1010\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.0085\n",
      "Epoch 4: val_loss did not improve from 2.55901\n",
      "29/29 [==============================] - 5s 163ms/step - loss: 4.0061 - val_loss: 4.0962\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.0032\n",
      "Epoch 5: val_loss did not improve from 2.55901\n",
      "29/29 [==============================] - 5s 158ms/step - loss: 4.0056 - val_loss: 4.0961\n",
      "finished training\n",
      "12/12 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  93\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_465 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_186 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_466 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_187 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_467 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_186 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_468 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_187 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_469 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4688\n",
      "Epoch 1: val_loss improved from inf to 0.31605, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 73ms/step - loss: 0.4681 - val_loss: 0.3160\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3014\n",
      "Epoch 2: val_loss improved from 0.31605 to 0.28306, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.3014 - val_loss: 0.2831\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2762\n",
      "Epoch 3: val_loss improved from 0.28306 to 0.26766, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.2761 - val_loss: 0.2677\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2677\n",
      "Epoch 4: val_loss improved from 0.26766 to 0.26243, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.2678 - val_loss: 0.2624\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2632\n",
      "Epoch 5: val_loss improved from 0.26243 to 0.25734, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.2632 - val_loss: 0.2573\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  94\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_470 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_188 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_471 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_189 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_472 (Conv2D)         (None, 8, 16, 16)         128016    \n",
      "                                                                 \n",
      " up_sampling2d_188 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_473 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_189 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_474 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,269\n",
      "Trainable params: 145,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.6762\n",
      "Epoch 1: val_loss improved from inf to 1.94778, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 145ms/step - loss: 2.6722 - val_loss: 1.9478\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2902\n",
      "Epoch 2: val_loss did not improve from 1.94778\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 2.2891 - val_loss: 2.2226\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0123\n",
      "Epoch 3: val_loss improved from 1.94778 to 1.87794, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 125ms/step - loss: 2.0123 - val_loss: 1.8779\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9200\n",
      "Epoch 4: val_loss improved from 1.87794 to 1.87284, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 153ms/step - loss: 1.9200 - val_loss: 1.8728\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9177\n",
      "Epoch 5: val_loss improved from 1.87284 to 1.87180, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 1.9177 - val_loss: 1.8718\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  95\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_475 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_190 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_476 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_191 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_477 (Conv2D)         (None, 8, 16, 16)         128016    \n",
      "                                                                 \n",
      " up_sampling2d_190 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_478 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_191 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_479 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 395,769\n",
      "Trainable params: 395,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.8706\n",
      "Epoch 1: val_loss improved from inf to 2.95678, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 157ms/step - loss: 2.8692 - val_loss: 2.9568\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.6366\n",
      "Epoch 2: val_loss did not improve from 2.95678\n",
      "29/29 [==============================] - 5s 163ms/step - loss: 3.6393 - val_loss: 4.2460\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1380\n",
      "Epoch 3: val_loss did not improve from 2.95678\n",
      "29/29 [==============================] - 5s 160ms/step - loss: 4.1392 - val_loss: 4.2356\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1340\n",
      "Epoch 4: val_loss did not improve from 2.95678\n",
      "29/29 [==============================] - 5s 160ms/step - loss: 4.1327 - val_loss: 4.2346\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1310\n",
      "Epoch 5: val_loss did not improve from 2.95678\n",
      "29/29 [==============================] - 5s 182ms/step - loss: 4.1320 - val_loss: 4.2340\n",
      "finished training\n",
      "12/12 [==============================] - 1s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  96\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_480 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_192 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_481 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_193 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_482 (Conv2D)         (None, 8, 16, 16)         4112      \n",
      "                                                                 \n",
      " up_sampling2d_192 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_483 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_193 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_484 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,865\n",
      "Trainable params: 12,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5800\n",
      "Epoch 1: val_loss improved from inf to 0.30920, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 77ms/step - loss: 0.5788 - val_loss: 0.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2878\n",
      "Epoch 2: val_loss improved from 0.30920 to 0.27294, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 0.2878 - val_loss: 0.2729\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2711\n",
      "Epoch 3: val_loss improved from 0.27294 to 0.26422, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.2711 - val_loss: 0.2642\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2653\n",
      "Epoch 4: val_loss improved from 0.26422 to 0.25975, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.2653 - val_loss: 0.2598\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2613\n",
      "Epoch 5: val_loss improved from 0.25975 to 0.25674, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.2613 - val_loss: 0.2567\n",
      "finished training\n",
      "12/12 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  97\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_485 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_194 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_486 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_195 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_487 (Conv2D)         (None, 8, 16, 16)         128016    \n",
      "                                                                 \n",
      " up_sampling2d_194 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_488 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_195 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_489 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,269\n",
      "Trainable params: 145,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.2265\n",
      "Epoch 1: val_loss improved from inf to 9.39161, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 145ms/step - loss: 10.2227 - val_loss: 9.3916\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.4369\n",
      "Epoch 2: val_loss improved from 9.39161 to 2.27945, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 154ms/step - loss: 3.4321 - val_loss: 2.2794\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5569\n",
      "Epoch 3: val_loss did not improve from 2.27945\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 2.5570 - val_loss: 2.9382\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7629\n",
      "Epoch 4: val_loss did not improve from 2.27945\n",
      "29/29 [==============================] - 4s 134ms/step - loss: 2.7634 - val_loss: 2.6077\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5436\n",
      "Epoch 5: val_loss did not improve from 2.27945\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 2.5420 - val_loss: 2.3070\n",
      "finished training\n",
      "12/12 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  98\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_490 (Conv2D)         (None, 32, 64, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_196 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_491 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " max_pooling2d_197 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_492 (Conv2D)         (None, 8, 16, 16)         128016    \n",
      "                                                                 \n",
      " up_sampling2d_196 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_493 (Conv2D)         (None, 16, 32, 16)        4112      \n",
      "                                                                 \n",
      " up_sampling2d_197 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_494 (Conv2D)         (None, 32, 64, 1)         257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 395,769\n",
      "Trainable params: 395,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5924\n",
      "Epoch 1: val_loss improved from inf to 2.37726, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 221ms/step - loss: 2.5916 - val_loss: 2.3773\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3625\n",
      "Epoch 2: val_loss improved from 2.37726 to 2.34368, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 2.3632 - val_loss: 2.3437\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2968\n",
      "Epoch 3: val_loss improved from 2.34368 to 2.21752, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 2.2955 - val_loss: 2.2175\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2315\n",
      "Epoch 4: val_loss did not improve from 2.21752\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 2.2339 - val_loss: 3.1224\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1878\n",
      "Epoch 5: val_loss improved from 2.21752 to 1.94304, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 2.1873 - val_loss: 1.9430\n",
      "finished training\n",
      "12/12 [==============================] - 1s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  99\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_495 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_198 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_496 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_199 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_497 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_198 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_498 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_199 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_499 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3802\n",
      "Epoch 1: val_loss improved from inf to 0.28930, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 146ms/step - loss: 0.3798 - val_loss: 0.2893\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2788\n",
      "Epoch 2: val_loss improved from 0.28930 to 0.26818, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 0.2787 - val_loss: 0.2682\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2678\n",
      "Epoch 3: val_loss improved from 0.26818 to 0.26299, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.2678 - val_loss: 0.2630\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2632\n",
      "Epoch 4: val_loss improved from 0.26299 to 0.25782, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.2632 - val_loss: 0.2578\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2602\n",
      "Epoch 5: val_loss did not improve from 0.25782\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 0.2603 - val_loss: 0.2578\n",
      "finished training\n",
      "12/12 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  100\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_500 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_200 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_501 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_201 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_502 (Conv2D)         (None, 8, 16, 16)         288016    \n",
      "                                                                 \n",
      " up_sampling2d_200 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_503 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_201 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_504 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316,149\n",
      "Trainable params: 316,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7354\n",
      "Epoch 1: val_loss improved from inf to 4.05024, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 320ms/step - loss: 3.7384 - val_loss: 4.0502\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.8520\n",
      "Epoch 2: val_loss improved from 4.05024 to 3.74441, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 3.8504 - val_loss: 3.7444\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.0791\n",
      "Epoch 3: val_loss did not improve from 3.74441\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 4.0795 - val_loss: 4.2564\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1533\n",
      "Epoch 4: val_loss did not improve from 3.74441\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 4.1537 - val_loss: 4.2539\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1521\n",
      "Epoch 5: val_loss did not improve from 3.74441\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 4.1534 - val_loss: 4.2539\n",
      "finished training\n",
      "12/12 [==============================] - 1s 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  101\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_505 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_202 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_506 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_203 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_507 (Conv2D)         (None, 8, 16, 16)         288016    \n",
      "                                                                 \n",
      " up_sampling2d_202 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_508 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_203 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_509 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 566,649\n",
      "Trainable params: 566,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.9125\n",
      "Epoch 1: val_loss improved from inf to 3.11530, saving model to best_weights.h5\n",
      "29/29 [==============================] - 11s 336ms/step - loss: 2.9125 - val_loss: 3.1153\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.1392\n",
      "Epoch 2: val_loss did not improve from 3.11530\n",
      "29/29 [==============================] - 11s 384ms/step - loss: 3.1392 - val_loss: 3.1635\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.1282\n",
      "Epoch 3: val_loss did not improve from 3.11530\n",
      "29/29 [==============================] - 11s 372ms/step - loss: 3.1282 - val_loss: 3.1742\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.1420\n",
      "Epoch 4: val_loss did not improve from 3.11530\n",
      "29/29 [==============================] - 11s 364ms/step - loss: 3.1420 - val_loss: 3.1932\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.6876\n",
      "Epoch 5: val_loss did not improve from 3.11530\n",
      "29/29 [==============================] - 11s 372ms/step - loss: 4.6876 - val_loss: 10.4250\n",
      "finished training\n",
      "12/12 [==============================] - 1s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  102\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_510 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_204 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_511 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_205 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_512 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_204 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_513 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_205 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_514 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5554\n",
      "Epoch 1: val_loss improved from inf to 0.30299, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 152ms/step - loss: 0.5542 - val_loss: 0.3030\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2902\n",
      "Epoch 2: val_loss improved from 0.30299 to 0.29821, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 146ms/step - loss: 0.2902 - val_loss: 0.2982\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2800\n",
      "Epoch 3: val_loss improved from 0.29821 to 0.26662, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.2800 - val_loss: 0.2666\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2670\n",
      "Epoch 4: val_loss improved from 0.26662 to 0.26212, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.2669 - val_loss: 0.2621\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2630\n",
      "Epoch 5: val_loss improved from 0.26212 to 0.25785, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 148ms/step - loss: 0.2630 - val_loss: 0.2579\n",
      "finished training\n",
      "12/12 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  103\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_515 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_206 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_516 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_207 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_517 (Conv2D)         (None, 8, 16, 16)         288016    \n",
      "                                                                 \n",
      " up_sampling2d_206 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_518 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_207 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_519 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316,149\n",
      "Trainable params: 316,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.6064\n",
      "Epoch 1: val_loss improved from inf to 3.31915, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 295ms/step - loss: 2.6064 - val_loss: 3.3192\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.3064\n",
      "Epoch 2: val_loss improved from 3.31915 to 3.14194, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 286ms/step - loss: 3.3065 - val_loss: 3.1419\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7930\n",
      "Epoch 3: val_loss did not improve from 3.14194\n",
      "29/29 [==============================] - 8s 277ms/step - loss: 2.7972 - val_loss: 3.7453\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7041\n",
      "Epoch 4: val_loss did not improve from 3.14194\n",
      "29/29 [==============================] - 8s 275ms/step - loss: 3.7039 - val_loss: 3.7770\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.7049\n",
      "Epoch 5: val_loss did not improve from 3.14194\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 3.7049 - val_loss: 3.7757\n",
      "finished training\n",
      "12/12 [==============================] - 1s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  104\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_520 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_208 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_521 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_209 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_522 (Conv2D)         (None, 8, 16, 16)         288016    \n",
      "                                                                 \n",
      " up_sampling2d_208 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_523 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_209 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_524 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 566,649\n",
      "Trainable params: 566,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.0205\n",
      "Epoch 1: val_loss improved from inf to 2.43648, saving model to best_weights.h5\n",
      "29/29 [==============================] - 11s 322ms/step - loss: 4.0205 - val_loss: 2.4365\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.2143\n",
      "Epoch 2: val_loss improved from 2.43648 to 2.14573, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 2.2143 - val_loss: 2.1457\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1443\n",
      "Epoch 3: val_loss improved from 2.14573 to 2.02335, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 2.1438 - val_loss: 2.0234\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7875\n",
      "Epoch 4: val_loss did not improve from 2.02335\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 2.7841 - val_loss: 2.0306\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.2646\n",
      "Epoch 5: val_loss did not improve from 2.02335\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 2.2646 - val_loss: 2.2714\n",
      "finished training\n",
      "12/12 [==============================] - 1s 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  105\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_525 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_210 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_526 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_211 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_527 (Conv2D)         (None, 8, 16, 16)         9232      \n",
      "                                                                 \n",
      " up_sampling2d_210 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_528 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_211 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_529 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,865\n",
      "Trainable params: 28,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4635\n",
      "Epoch 1: val_loss improved from inf to 0.29093, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 129ms/step - loss: 0.4627 - val_loss: 0.2909\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2799\n",
      "Epoch 2: val_loss improved from 0.29093 to 0.26857, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.2799 - val_loss: 0.2686\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2669\n",
      "Epoch 3: val_loss improved from 0.26857 to 0.26038, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 127ms/step - loss: 0.2669 - val_loss: 0.2604\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2610\n",
      "Epoch 4: val_loss improved from 0.26038 to 0.25508, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 122ms/step - loss: 0.2610 - val_loss: 0.2551\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2572\n",
      "Epoch 5: val_loss improved from 0.25508 to 0.25202, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 123ms/step - loss: 0.2571 - val_loss: 0.2520\n",
      "finished training\n",
      "12/12 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  106\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_530 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_212 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_531 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_213 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " conv2d_532 (Conv2D)         (None, 8, 16, 16)         288016    \n",
      "                                                                 \n",
      " up_sampling2d_212 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_533 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_213 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_534 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316,149\n",
      "Trainable params: 316,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.5233\n",
      "Epoch 1: val_loss improved from inf to 4.27683, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 262ms/step - loss: 3.5255 - val_loss: 4.2768\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1810\n",
      "Epoch 2: val_loss did not improve from 4.27683\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 4.1805 - val_loss: 4.2837\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1303\n",
      "Epoch 3: val_loss improved from 4.27683 to 4.18891, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 257ms/step - loss: 4.1286 - val_loss: 4.1889\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.8598\n",
      "Epoch 4: val_loss improved from 4.18891 to 2.70378, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 3.8548 - val_loss: 2.7038\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5610\n",
      "Epoch 5: val_loss did not improve from 2.70378\n",
      "29/29 [==============================] - 8s 259ms/step - loss: 2.5658 - val_loss: 4.1433\n",
      "finished training\n",
      "12/12 [==============================] - 1s 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  107\n",
      "{'conv_depth': 16, 'hidden_size': 500, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_535 (Conv2D)         (None, 32, 64, 16)        592       \n",
      "                                                                 \n",
      " max_pooling2d_214 (MaxPooli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 16, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_536 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " max_pooling2d_215 (MaxPooli  (None, 8, 16, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 8, 16, 500)        8500      \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_537 (Conv2D)         (None, 8, 16, 16)         288016    \n",
      "                                                                 \n",
      " up_sampling2d_214 (UpSampli  (None, 16, 32, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_538 (Conv2D)         (None, 16, 32, 16)        9232      \n",
      "                                                                 \n",
      " up_sampling2d_215 (UpSampli  (None, 32, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_539 (Conv2D)         (None, 32, 64, 1)         577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 566,649\n",
      "Trainable params: 566,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5795\n",
      "Epoch 1: val_loss improved from inf to 1.92692, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 300ms/step - loss: 2.5768 - val_loss: 1.9269\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.2103\n",
      "Epoch 2: val_loss did not improve from 1.92692\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 3.2058 - val_loss: 2.0853\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3401\n",
      "Epoch 3: val_loss did not improve from 1.92692\n",
      "29/29 [==============================] - 8s 269ms/step - loss: 2.3387 - val_loss: 2.3205\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7424\n",
      "Epoch 4: val_loss did not improve from 1.92692\n",
      "29/29 [==============================] - 8s 280ms/step - loss: 3.7432 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2059\n",
      "Epoch 5: val_loss did not improve from 1.92692\n",
      "29/29 [==============================] - 8s 279ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  108\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_540 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_216 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_541 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_217 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_542 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_216 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_543 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_217 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_544 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.4913\n",
      "Epoch 1: val_loss improved from inf to 0.33126, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 58ms/step - loss: 0.4913 - val_loss: 0.3313\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3076\n",
      "Epoch 2: val_loss improved from 0.33126 to 0.29056, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 54ms/step - loss: 0.3076 - val_loss: 0.2906\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2825\n",
      "Epoch 3: val_loss improved from 0.29056 to 0.27268, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 55ms/step - loss: 0.2825 - val_loss: 0.2727\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2703\n",
      "Epoch 4: val_loss improved from 0.27268 to 0.26342, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 54ms/step - loss: 0.2703 - val_loss: 0.2634\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2668\n",
      "Epoch 5: val_loss improved from 0.26342 to 0.26037, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 0.2668 - val_loss: 0.2604\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  109\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_545 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_218 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_546 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_219 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_547 (Conv2D)         (None, 8, 16, 32)         6432      \n",
      "                                                                 \n",
      " up_sampling2d_218 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_548 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_219 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_549 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,627\n",
      "Trainable params: 16,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6819\n",
      "Epoch 1: val_loss improved from inf to 0.42760, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 64ms/step - loss: 0.6807 - val_loss: 0.4276\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3833\n",
      "Epoch 2: val_loss improved from 0.42760 to 0.32742, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 0.3832 - val_loss: 0.3274\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3062\n",
      "Epoch 3: val_loss improved from 0.32742 to 0.29545, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.3061 - val_loss: 0.2955\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2887\n",
      "Epoch 4: val_loss improved from 0.29545 to 0.28100, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2887 - val_loss: 0.2810\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3570\n",
      "Epoch 5: val_loss did not improve from 0.28100\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 0.3571 - val_loss: 0.3949\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "training on param set  110\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_550 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_220 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_551 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_221 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_552 (Conv2D)         (None, 8, 16, 32)         6432      \n",
      "                                                                 \n",
      " up_sampling2d_220 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_553 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_221 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_554 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,177\n",
      "Trainable params: 19,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9412\n",
      "Epoch 1: val_loss improved from inf to 0.46633, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 69ms/step - loss: 0.9391 - val_loss: 0.4663\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4312\n",
      "Epoch 2: val_loss improved from 0.46633 to 0.38857, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 64ms/step - loss: 0.4312 - val_loss: 0.3886\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3327\n",
      "Epoch 3: val_loss improved from 0.38857 to 0.29903, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.3326 - val_loss: 0.2990\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2929\n",
      "Epoch 4: val_loss improved from 0.29903 to 0.27950, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.2928 - val_loss: 0.2795\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2780\n",
      "Epoch 5: val_loss improved from 0.27950 to 0.27406, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 64ms/step - loss: 0.2781 - val_loss: 0.2741\n",
      "finished training\n",
      "12/12 [==============================] - 0s 14ms/step\n",
      "training on param set  111\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_555 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_222 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_556 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_223 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_557 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_222 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_558 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_223 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_559 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6136\n",
      "Epoch 1: val_loss improved from inf to 0.32001, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 61ms/step - loss: 0.6123 - val_loss: 0.3200\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3072\n",
      "Epoch 2: val_loss improved from 0.32001 to 0.28340, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 56ms/step - loss: 0.3071 - val_loss: 0.2834\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2761\n",
      "Epoch 3: val_loss improved from 0.28340 to 0.26516, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 0.2760 - val_loss: 0.2652\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2655\n",
      "Epoch 4: val_loss improved from 0.26516 to 0.25977, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 0.2655 - val_loss: 0.2598\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2615\n",
      "Epoch 5: val_loss improved from 0.25977 to 0.25617, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.2615 - val_loss: 0.2562\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  112\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_560 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_224 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_561 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_225 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_562 (Conv2D)         (None, 8, 16, 32)         6432      \n",
      "                                                                 \n",
      " up_sampling2d_224 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_563 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_225 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_564 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,627\n",
      "Trainable params: 16,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6376\n",
      "Epoch 1: val_loss improved from inf to 0.34506, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 66ms/step - loss: 0.6364 - val_loss: 0.3451\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3150\n",
      "Epoch 2: val_loss improved from 0.34506 to 0.29486, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.3150 - val_loss: 0.2949\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2897\n",
      "Epoch 3: val_loss improved from 0.29486 to 0.27826, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 63ms/step - loss: 0.2898 - val_loss: 0.2783\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2780\n",
      "Epoch 4: val_loss improved from 0.27826 to 0.26893, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 63ms/step - loss: 0.2779 - val_loss: 0.2689\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7694\n",
      "Epoch 5: val_loss did not improve from 0.26893\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 0.7672 - val_loss: 0.4130\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  113\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_565 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_226 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_566 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_227 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_567 (Conv2D)         (None, 8, 16, 32)         6432      \n",
      "                                                                 \n",
      " up_sampling2d_226 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_568 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_227 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_569 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,177\n",
      "Trainable params: 19,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2044\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 66ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2042\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2060\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2038\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2034\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "training on param set  114\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_570 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_228 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_571 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_229 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_572 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_228 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_573 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_229 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_574 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3793\n",
      "Epoch 1: val_loss improved from inf to 0.30350, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 61ms/step - loss: 0.3790 - val_loss: 0.3035\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2889\n",
      "Epoch 2: val_loss improved from 0.30350 to 0.27310, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 56ms/step - loss: 0.2888 - val_loss: 0.2731\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2692\n",
      "Epoch 3: val_loss improved from 0.27310 to 0.26286, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 0.2693 - val_loss: 0.2629\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2623\n",
      "Epoch 4: val_loss improved from 0.26286 to 0.25638, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2623 - val_loss: 0.2564\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2583\n",
      "Epoch 5: val_loss improved from 0.25638 to 0.25311, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2583 - val_loss: 0.2531\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  115\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_575 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_230 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_576 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_231 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_577 (Conv2D)         (None, 8, 16, 32)         6432      \n",
      "                                                                 \n",
      " up_sampling2d_230 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_578 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_231 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_579 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,627\n",
      "Trainable params: 16,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4062\n",
      "Epoch 1: val_loss improved from inf to 0.31341, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 66ms/step - loss: 0.4058 - val_loss: 0.3134\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3043\n",
      "Epoch 2: val_loss improved from 0.31341 to 0.29350, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 0.3044 - val_loss: 0.2935\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2874\n",
      "Epoch 3: val_loss improved from 0.29350 to 0.27586, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.2873 - val_loss: 0.2759\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2743\n",
      "Epoch 4: val_loss did not improve from 0.27586\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2742 - val_loss: 0.2788\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2708\n",
      "Epoch 5: val_loss improved from 0.27586 to 0.26790, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.2707 - val_loss: 0.2679\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "training on param set  116\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_580 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_232 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_581 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_233 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_582 (Conv2D)         (None, 8, 16, 32)         6432      \n",
      "                                                                 \n",
      " up_sampling2d_232 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_583 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_233 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_584 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,177\n",
      "Trainable params: 19,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4711\n",
      "Epoch 1: val_loss improved from inf to 0.40152, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 61ms/step - loss: 0.4707 - val_loss: 0.4015\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3526\n",
      "Epoch 2: val_loss improved from 0.40152 to 0.32031, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 0.3524 - val_loss: 0.3203\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3139\n",
      "Epoch 3: val_loss improved from 0.32031 to 0.31437, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 0.3139 - val_loss: 0.3144\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3048\n",
      "Epoch 4: val_loss improved from 0.31437 to 0.29780, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.3049 - val_loss: 0.2978\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2926\n",
      "Epoch 5: val_loss improved from 0.29780 to 0.28893, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.2926 - val_loss: 0.2889\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  117\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_585 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_234 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_586 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_235 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_587 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_234 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_588 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_235 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_589 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5409\n",
      "Epoch 1: val_loss improved from inf to 0.27897, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 130ms/step - loss: 0.5397 - val_loss: 0.2790\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2774\n",
      "Epoch 2: val_loss improved from 0.27897 to 0.26460, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 134ms/step - loss: 0.2773 - val_loss: 0.2646\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2649\n",
      "Epoch 3: val_loss improved from 0.26460 to 0.25919, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.2649 - val_loss: 0.2592\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2617\n",
      "Epoch 4: val_loss improved from 0.25919 to 0.25569, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.2617 - val_loss: 0.2557\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2599\n",
      "Epoch 5: val_loss did not improve from 0.25569\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.2599 - val_loss: 0.2568\n",
      "finished training\n",
      "12/12 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  118\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_590 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_236 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_591 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_237 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_592 (Conv2D)         (None, 8, 16, 32)         25632     \n",
      "                                                                 \n",
      " up_sampling2d_236 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_593 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_237 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_594 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,171\n",
      "Trainable params: 61,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5824\n",
      "Epoch 1: val_loss improved from inf to 0.55764, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 136ms/step - loss: 0.5819 - val_loss: 0.5576\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4094\n",
      "Epoch 2: val_loss improved from 0.55764 to 0.31029, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 152ms/step - loss: 0.4090 - val_loss: 0.3103\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3892\n",
      "Epoch 3: val_loss did not improve from 0.31029\n",
      "29/29 [==============================] - 5s 162ms/step - loss: 0.3890 - val_loss: 0.3340\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3193\n",
      "Epoch 4: val_loss improved from 0.31029 to 0.28483, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 159ms/step - loss: 0.3192 - val_loss: 0.2848\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2772\n",
      "Epoch 5: val_loss improved from 0.28483 to 0.26975, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 149ms/step - loss: 0.2772 - val_loss: 0.2697\n",
      "finished training\n",
      "12/12 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  119\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_595 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_238 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_596 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_239 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_597 (Conv2D)         (None, 8, 16, 32)         25632     \n",
      "                                                                 \n",
      " up_sampling2d_238 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_598 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_239 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_599 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,721\n",
      "Trainable params: 63,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0112\n",
      "Epoch 1: val_loss improved from inf to 0.45494, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 175ms/step - loss: 1.0092 - val_loss: 0.4549\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5995\n",
      "Epoch 2: val_loss did not improve from 0.45494\n",
      "29/29 [==============================] - 5s 162ms/step - loss: 0.5992 - val_loss: 0.6070\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5911\n",
      "Epoch 3: val_loss improved from 0.45494 to 0.43934, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 150ms/step - loss: 0.5905 - val_loss: 0.4393\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6562\n",
      "Epoch 4: val_loss did not improve from 0.43934\n",
      "29/29 [==============================] - 4s 142ms/step - loss: 0.6566 - val_loss: 0.4816\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6565\n",
      "Epoch 5: val_loss improved from 0.43934 to 0.33602, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 156ms/step - loss: 0.6553 - val_loss: 0.3360\n",
      "finished training\n",
      "12/12 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  120\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_600 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_240 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_601 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_241 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_602 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_240 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_603 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_241 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_604 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3703\n",
      "Epoch 1: val_loss improved from inf to 0.30408, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 165ms/step - loss: 0.3700 - val_loss: 0.3041\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2795\n",
      "Epoch 2: val_loss improved from 0.30408 to 0.26229, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 157ms/step - loss: 0.2795 - val_loss: 0.2623\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2628\n",
      "Epoch 3: val_loss improved from 0.26229 to 0.25928, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 156ms/step - loss: 0.2627 - val_loss: 0.2593\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2591\n",
      "Epoch 4: val_loss improved from 0.25928 to 0.25341, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 154ms/step - loss: 0.2590 - val_loss: 0.2534\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2575\n",
      "Epoch 5: val_loss improved from 0.25341 to 0.25168, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 163ms/step - loss: 0.2575 - val_loss: 0.2517\n",
      "finished training\n",
      "12/12 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  121\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_605 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_242 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_606 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_243 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_607 (Conv2D)         (None, 8, 16, 32)         25632     \n",
      "                                                                 \n",
      " up_sampling2d_242 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_608 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_243 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_609 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,171\n",
      "Trainable params: 61,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2061\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 153ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2026\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 5s 160ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2059\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 139ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2058\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2059\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 145ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "training on param set  122\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_610 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_244 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_611 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_245 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_612 (Conv2D)         (None, 8, 16, 32)         25632     \n",
      "                                                                 \n",
      " up_sampling2d_244 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_613 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_245 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_614 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,721\n",
      "Trainable params: 63,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7197\n",
      "Epoch 1: val_loss improved from inf to 0.74821, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 169ms/step - loss: 0.7281 - val_loss: 0.7482\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.2455\n",
      "Epoch 2: val_loss did not improve from 0.74821\n",
      "29/29 [==============================] - 5s 175ms/step - loss: 1.2447 - val_loss: 0.9926\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4780\n",
      "Epoch 3: val_loss improved from 0.74821 to 0.34531, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 177ms/step - loss: 0.4774 - val_loss: 0.3453\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3188\n",
      "Epoch 4: val_loss improved from 0.34531 to 0.29657, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 171ms/step - loss: 0.3188 - val_loss: 0.2966\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2943\n",
      "Epoch 5: val_loss improved from 0.29657 to 0.28964, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 190ms/step - loss: 0.2943 - val_loss: 0.2896\n",
      "finished training\n",
      "12/12 [==============================] - 0s 29ms/step\n",
      "training on param set  123\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_615 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_246 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_616 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_247 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_617 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_246 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_618 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_247 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_619 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5065\n",
      "Epoch 1: val_loss improved from inf to 0.29245, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 155ms/step - loss: 0.5055 - val_loss: 0.2925\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2803\n",
      "Epoch 2: val_loss improved from 0.29245 to 0.26578, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 158ms/step - loss: 0.2802 - val_loss: 0.2658\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2655\n",
      "Epoch 3: val_loss improved from 0.26578 to 0.25857, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 158ms/step - loss: 0.2654 - val_loss: 0.2586\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2601\n",
      "Epoch 4: val_loss improved from 0.25857 to 0.25701, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 156ms/step - loss: 0.2601 - val_loss: 0.2570\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2573\n",
      "Epoch 5: val_loss improved from 0.25701 to 0.25225, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 156ms/step - loss: 0.2573 - val_loss: 0.2522\n",
      "finished training\n",
      "12/12 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  124\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_620 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_248 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_621 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_249 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_622 (Conv2D)         (None, 8, 16, 32)         25632     \n",
      "                                                                 \n",
      " up_sampling2d_248 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_623 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_249 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_624 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,171\n",
      "Trainable params: 61,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6088\n",
      "Epoch 1: val_loss improved from inf to 0.47013, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 162ms/step - loss: 0.6082 - val_loss: 0.4701\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3844\n",
      "Epoch 2: val_loss improved from 0.47013 to 0.32335, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 156ms/step - loss: 0.3842 - val_loss: 0.3234\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3012\n",
      "Epoch 3: val_loss improved from 0.32335 to 0.28437, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 160ms/step - loss: 0.3012 - val_loss: 0.2844\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2798\n",
      "Epoch 4: val_loss improved from 0.28437 to 0.27412, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 180ms/step - loss: 0.2798 - val_loss: 0.2741\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2732\n",
      "Epoch 5: val_loss improved from 0.27412 to 0.27264, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 167ms/step - loss: 0.2733 - val_loss: 0.2726\n",
      "finished training\n",
      "12/12 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  125\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_625 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_250 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_626 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_251 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_627 (Conv2D)         (None, 8, 16, 32)         25632     \n",
      "                                                                 \n",
      " up_sampling2d_250 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_628 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_251 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_629 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,721\n",
      "Trainable params: 63,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.5728\n",
      "Epoch 1: val_loss improved from inf to 1.56788, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 191ms/step - loss: 1.5721 - val_loss: 1.5679\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9800\n",
      "Epoch 2: val_loss did not improve from 1.56788\n",
      "29/29 [==============================] - 5s 167ms/step - loss: 0.9833 - val_loss: 1.7188\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1251\n",
      "Epoch 3: val_loss did not improve from 1.56788\n",
      "29/29 [==============================] - 5s 158ms/step - loss: 4.1513 - val_loss: 10.3899\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.3254\n",
      "Epoch 4: val_loss did not improve from 1.56788\n",
      "29/29 [==============================] - 5s 174ms/step - loss: 4.3161 - val_loss: 2.2807\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9224\n",
      "Epoch 5: val_loss did not improve from 1.56788\n",
      "29/29 [==============================] - 5s 178ms/step - loss: 1.9222 - val_loss: 1.8023\n",
      "finished training\n",
      "12/12 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  126\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_630 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_252 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_631 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_253 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_632 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_252 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_633 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_253 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_634 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4283\n",
      "Epoch 1: val_loss improved from inf to 0.30137, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 273ms/step - loss: 0.4278 - val_loss: 0.3014\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2849\n",
      "Epoch 2: val_loss improved from 0.30137 to 0.26841, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 237ms/step - loss: 0.2848 - val_loss: 0.2684\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2657\n",
      "Epoch 3: val_loss improved from 0.26841 to 0.25811, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.2657 - val_loss: 0.2581\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2598\n",
      "Epoch 4: val_loss improved from 0.25811 to 0.25434, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.2598 - val_loss: 0.2543\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2566\n",
      "Epoch 5: val_loss improved from 0.25434 to 0.25148, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 264ms/step - loss: 0.2566 - val_loss: 0.2515\n",
      "finished training\n",
      "12/12 [==============================] - 1s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  127\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_635 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_254 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_636 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_255 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_637 (Conv2D)         (None, 8, 16, 32)         57632     \n",
      "                                                                 \n",
      " up_sampling2d_254 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_638 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_255 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_639 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,411\n",
      "Trainable params: 135,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7329\n",
      "Epoch 1: val_loss improved from inf to 0.34735, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 260ms/step - loss: 0.7312 - val_loss: 0.3474\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3142\n",
      "Epoch 2: val_loss improved from 0.34735 to 0.29011, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.3141 - val_loss: 0.2901\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4965\n",
      "Epoch 3: val_loss did not improve from 0.29011\n",
      "29/29 [==============================] - 7s 252ms/step - loss: 0.4971 - val_loss: 0.6862\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4829\n",
      "Epoch 4: val_loss did not improve from 0.29011\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.4828 - val_loss: 0.3667\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3479\n",
      "Epoch 5: val_loss did not improve from 0.29011\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 0.3480 - val_loss: 0.3556\n",
      "finished training\n",
      "12/12 [==============================] - 1s 38ms/step\n",
      "training on param set  128\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_640 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_256 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_641 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_257 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_642 (Conv2D)         (None, 8, 16, 32)         57632     \n",
      "                                                                 \n",
      " up_sampling2d_256 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_643 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_257 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_644 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,961\n",
      "Trainable params: 137,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3122\n",
      "Epoch 1: val_loss improved from inf to 0.57904, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 248ms/step - loss: 1.3090 - val_loss: 0.5790\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3307\n",
      "Epoch 2: val_loss improved from 0.57904 to 0.28672, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.3305 - val_loss: 0.2867\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2837\n",
      "Epoch 3: val_loss improved from 0.28672 to 0.27865, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.2837 - val_loss: 0.2786\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2776\n",
      "Epoch 4: val_loss improved from 0.27865 to 0.27506, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 233ms/step - loss: 0.2776 - val_loss: 0.2751\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2743\n",
      "Epoch 5: val_loss improved from 0.27506 to 0.27150, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.2743 - val_loss: 0.2715\n",
      "finished training\n",
      "12/12 [==============================] - 1s 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  129\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_645 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_258 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_646 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_259 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_647 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_258 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_648 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_259 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_649 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5032\n",
      "Epoch 1: val_loss improved from inf to 0.31975, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 238ms/step - loss: 0.5023 - val_loss: 0.3198\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2947\n",
      "Epoch 2: val_loss improved from 0.31975 to 0.27682, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.2947 - val_loss: 0.2768\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2736\n",
      "Epoch 3: val_loss improved from 0.27682 to 0.26422, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.2735 - val_loss: 0.2642\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2658\n",
      "Epoch 4: val_loss improved from 0.26422 to 0.25989, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.2658 - val_loss: 0.2599\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2622\n",
      "Epoch 5: val_loss improved from 0.25989 to 0.25671, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.2622 - val_loss: 0.2567\n",
      "finished training\n",
      "12/12 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  130\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_650 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_260 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_651 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_261 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_652 (Conv2D)         (None, 8, 16, 32)         57632     \n",
      "                                                                 \n",
      " up_sampling2d_260 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_653 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_261 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_654 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,411\n",
      "Trainable params: 135,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6220\n",
      "Epoch 1: val_loss improved from inf to 0.35430, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 270ms/step - loss: 0.6206 - val_loss: 0.3543\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3020\n",
      "Epoch 2: val_loss improved from 0.35430 to 0.28354, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.3019 - val_loss: 0.2835\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2812\n",
      "Epoch 3: val_loss improved from 0.28354 to 0.27551, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 245ms/step - loss: 0.2813 - val_loss: 0.2755\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2784\n",
      "Epoch 4: val_loss improved from 0.27551 to 0.27158, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.2784 - val_loss: 0.2716\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2694\n",
      "Epoch 5: val_loss improved from 0.27158 to 0.26578, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 0.2694 - val_loss: 0.2658\n",
      "finished training\n",
      "12/12 [==============================] - 1s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  131\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_655 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_262 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_656 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_263 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_657 (Conv2D)         (None, 8, 16, 32)         57632     \n",
      "                                                                 \n",
      " up_sampling2d_262 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_658 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_263 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_659 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,961\n",
      "Trainable params: 137,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3611\n",
      "Epoch 1: val_loss improved from inf to 0.36242, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 235ms/step - loss: 1.3567 - val_loss: 0.3624\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.1434\n",
      "Epoch 2: val_loss did not improve from 0.36242\n",
      "29/29 [==============================] - 7s 230ms/step - loss: 1.1434 - val_loss: 0.4968\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4456\n",
      "Epoch 3: val_loss improved from 0.36242 to 0.35131, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 0.4451 - val_loss: 0.3513\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3136\n",
      "Epoch 4: val_loss improved from 0.35131 to 0.30044, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 234ms/step - loss: 0.3135 - val_loss: 0.3004\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2952\n",
      "Epoch 5: val_loss improved from 0.30044 to 0.29170, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 234ms/step - loss: 0.2952 - val_loss: 0.2917\n",
      "finished training\n",
      "12/12 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  132\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_660 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_264 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_661 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_265 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_662 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_264 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_663 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_265 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_664 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4330\n",
      "Epoch 1: val_loss improved from inf to 0.27309, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.4324 - val_loss: 0.2731\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2687\n",
      "Epoch 2: val_loss improved from 0.27309 to 0.26052, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 226ms/step - loss: 0.2687 - val_loss: 0.2605\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2676\n",
      "Epoch 3: val_loss improved from 0.26052 to 0.25957, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 224ms/step - loss: 0.2677 - val_loss: 0.2596\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2603\n",
      "Epoch 4: val_loss improved from 0.25957 to 0.25392, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 0.2603 - val_loss: 0.2539\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2578\n",
      "Epoch 5: val_loss did not improve from 0.25392\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 0.2578 - val_loss: 0.2557\n",
      "finished training\n",
      "12/12 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  133\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_665 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_266 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_666 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_267 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " conv2d_667 (Conv2D)         (None, 8, 16, 32)         57632     \n",
      "                                                                 \n",
      " up_sampling2d_266 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_668 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_267 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_669 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,411\n",
      "Trainable params: 135,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3932\n",
      "Epoch 1: val_loss improved from inf to 0.29728, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 237ms/step - loss: 0.3930 - val_loss: 0.2973\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2999\n",
      "Epoch 2: val_loss improved from 0.29728 to 0.28796, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 0.2999 - val_loss: 0.2880\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2798\n",
      "Epoch 3: val_loss improved from 0.28796 to 0.27024, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 232ms/step - loss: 0.2797 - val_loss: 0.2702\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2731\n",
      "Epoch 4: val_loss improved from 0.27024 to 0.26955, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.2731 - val_loss: 0.2696\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2872\n",
      "Epoch 5: val_loss did not improve from 0.26955\n",
      "29/29 [==============================] - 7s 224ms/step - loss: 0.2873 - val_loss: 0.2934\n",
      "finished training\n",
      "12/12 [==============================] - 1s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  134\n",
      "{'conv_depth': 32, 'hidden_size': 50, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_670 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_268 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_671 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_269 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 8, 16, 50)         1650      \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 8, 16, 50)         2550      \n",
      "                                                                 \n",
      " conv2d_672 (Conv2D)         (None, 8, 16, 32)         57632     \n",
      "                                                                 \n",
      " up_sampling2d_268 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_673 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_269 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_674 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,961\n",
      "Trainable params: 137,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.5442\n",
      "Epoch 1: val_loss improved from inf to 2.84045, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 254ms/step - loss: 2.5442 - val_loss: 2.8405\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3647\n",
      "Epoch 2: val_loss improved from 2.84045 to 0.87631, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 1.3636 - val_loss: 0.8763\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5062\n",
      "Epoch 3: val_loss improved from 0.87631 to 0.34760, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 222ms/step - loss: 0.5055 - val_loss: 0.3476\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3358\n",
      "Epoch 4: val_loss improved from 0.34760 to 0.31012, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.3358 - val_loss: 0.3101\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2979\n",
      "Epoch 5: val_loss improved from 0.31012 to 0.28890, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 234ms/step - loss: 0.2979 - val_loss: 0.2889\n",
      "finished training\n",
      "12/12 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  135\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_675 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_270 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_676 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_271 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_677 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_270 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_678 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_271 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_679 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6506\n",
      "Epoch 1: val_loss improved from inf to 0.33758, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 70ms/step - loss: 0.6492 - val_loss: 0.3376\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3212\n",
      "Epoch 2: val_loss improved from 0.33758 to 0.30980, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.3211 - val_loss: 0.3098\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2985\n",
      "Epoch 3: val_loss improved from 0.30980 to 0.28127, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.2985 - val_loss: 0.2813\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2750\n",
      "Epoch 4: val_loss improved from 0.28127 to 0.26827, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 64ms/step - loss: 0.2750 - val_loss: 0.2683\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2679\n",
      "Epoch 5: val_loss improved from 0.26827 to 0.26260, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.2679 - val_loss: 0.2626\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "training on param set  136\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_680 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_272 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_681 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_273 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_682 (Conv2D)         (None, 8, 16, 32)         12832     \n",
      "                                                                 \n",
      " up_sampling2d_272 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_683 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_273 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_684 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,677\n",
      "Trainable params: 24,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8811\n",
      "Epoch 1: val_loss improved from inf to 0.46375, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 76ms/step - loss: 0.8791 - val_loss: 0.4638\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4392\n",
      "Epoch 2: val_loss improved from 0.46375 to 0.41445, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.4389 - val_loss: 0.4144\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3745\n",
      "Epoch 3: val_loss improved from 0.41445 to 0.32362, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.3743 - val_loss: 0.3236\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3047\n",
      "Epoch 4: val_loss improved from 0.32362 to 0.28602, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.3046 - val_loss: 0.2860\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2817\n",
      "Epoch 5: val_loss improved from 0.28602 to 0.27260, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 0.2817 - val_loss: 0.2726\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  137\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_685 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_274 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_686 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_275 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_687 (Conv2D)         (None, 8, 16, 32)         12832     \n",
      "                                                                 \n",
      " up_sampling2d_274 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_688 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_275 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_689 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,777\n",
      "Trainable params: 34,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7305\n",
      "Epoch 1: val_loss improved from inf to 0.52397, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 82ms/step - loss: 0.7296 - val_loss: 0.5240\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4655\n",
      "Epoch 2: val_loss improved from 0.52397 to 0.39779, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.4653 - val_loss: 0.3978\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3468\n",
      "Epoch 3: val_loss improved from 0.39779 to 0.31695, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 0.3467 - val_loss: 0.3169\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3097\n",
      "Epoch 4: val_loss improved from 0.31695 to 0.29962, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.3096 - val_loss: 0.2996\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2989\n",
      "Epoch 5: val_loss improved from 0.29962 to 0.29253, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.2989 - val_loss: 0.2925\n",
      "finished training\n",
      "12/12 [==============================] - 0s 16ms/step\n",
      "training on param set  138\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_690 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_276 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_691 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_277 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_692 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_276 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_693 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_277 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_694 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.0565\n",
      "Epoch 1: val_loss improved from inf to 0.44890, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 63ms/step - loss: 1.0539 - val_loss: 0.4489\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3599\n",
      "Epoch 2: val_loss improved from 0.44890 to 0.30686, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.3597 - val_loss: 0.3069\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2939\n",
      "Epoch 3: val_loss improved from 0.30686 to 0.28014, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 0.2939 - val_loss: 0.2801\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2772\n",
      "Epoch 4: val_loss improved from 0.28014 to 0.27073, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2772 - val_loss: 0.2707\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2715\n",
      "Epoch 5: val_loss improved from 0.27073 to 0.26494, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 61ms/step - loss: 0.2715 - val_loss: 0.2649\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  139\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_695 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_278 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_696 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_279 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_697 (Conv2D)         (None, 8, 16, 32)         12832     \n",
      "                                                                 \n",
      " up_sampling2d_278 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_698 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_279 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_699 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,677\n",
      "Trainable params: 24,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8474\n",
      "Epoch 1: val_loss improved from inf to 0.40304, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 71ms/step - loss: 0.8454 - val_loss: 0.4030\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3527\n",
      "Epoch 2: val_loss improved from 0.40304 to 0.31424, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.3526 - val_loss: 0.3142\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3114\n",
      "Epoch 3: val_loss improved from 0.31424 to 0.29714, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.3113 - val_loss: 0.2971\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3136\n",
      "Epoch 4: val_loss did not improve from 0.29714\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.3136 - val_loss: 0.3043\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2974\n",
      "Epoch 5: val_loss improved from 0.29714 to 0.28273, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 0.2973 - val_loss: 0.2827\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  140\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_700 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_280 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_701 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_281 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_702 (Conv2D)         (None, 8, 16, 32)         12832     \n",
      "                                                                 \n",
      " up_sampling2d_280 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_703 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_281 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_704 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,777\n",
      "Trainable params: 34,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5665\n",
      "Epoch 1: val_loss improved from inf to 0.47780, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 79ms/step - loss: 0.5662 - val_loss: 0.4778\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4487\n",
      "Epoch 2: val_loss improved from 0.47780 to 0.42796, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 0.4485 - val_loss: 0.4280\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3679\n",
      "Epoch 3: val_loss improved from 0.42796 to 0.32755, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.3676 - val_loss: 0.3276\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3067\n",
      "Epoch 4: val_loss improved from 0.32755 to 0.29619, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.3067 - val_loss: 0.2962\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2918\n",
      "Epoch 5: val_loss improved from 0.29619 to 0.28721, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 69ms/step - loss: 0.2917 - val_loss: 0.2872\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n",
      "training on param set  141\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_705 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_282 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_706 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_283 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_707 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_282 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_708 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_283 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_709 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5777\n",
      "Epoch 1: val_loss improved from inf to 0.32769, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 60ms/step - loss: 0.5766 - val_loss: 0.3277\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3114\n",
      "Epoch 2: val_loss improved from 0.32769 to 0.29148, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 57ms/step - loss: 0.3113 - val_loss: 0.2915\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2835\n",
      "Epoch 3: val_loss improved from 0.29148 to 0.27152, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2835 - val_loss: 0.2715\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2684\n",
      "Epoch 4: val_loss improved from 0.27152 to 0.26154, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 60ms/step - loss: 0.2685 - val_loss: 0.2615\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2629\n",
      "Epoch 5: val_loss improved from 0.26154 to 0.25789, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 63ms/step - loss: 0.2628 - val_loss: 0.2579\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  142\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_710 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_284 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_711 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_285 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_712 (Conv2D)         (None, 8, 16, 32)         12832     \n",
      "                                                                 \n",
      " up_sampling2d_284 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_713 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_285 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_714 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,677\n",
      "Trainable params: 24,677\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.1402\n",
      "Epoch 1: val_loss improved from inf to 1.88094, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 70ms/step - loss: 1.1439 - val_loss: 1.8809\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.7265\n",
      "Epoch 2: val_loss improved from 1.88094 to 1.72489, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 1.7269 - val_loss: 1.7249\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.6682\n",
      "Epoch 3: val_loss improved from 1.72489 to 1.70358, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 1.6695 - val_loss: 1.7036\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.6547\n",
      "Epoch 4: val_loss improved from 1.70358 to 1.69194, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 1.6545 - val_loss: 1.6919\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.6456\n",
      "Epoch 5: val_loss improved from 1.69194 to 1.68450, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 1.6451 - val_loss: 1.6845\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  143\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_715 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_286 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_716 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_287 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_717 (Conv2D)         (None, 8, 16, 32)         12832     \n",
      "                                                                 \n",
      " up_sampling2d_286 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_718 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_287 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_719 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,777\n",
      "Trainable params: 34,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6911\n",
      "Epoch 1: val_loss improved from inf to 0.45977, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 80ms/step - loss: 0.6900 - val_loss: 0.4598\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4368\n",
      "Epoch 2: val_loss improved from 0.45977 to 0.41409, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 0.4367 - val_loss: 0.4141\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3632\n",
      "Epoch 3: val_loss improved from 0.41409 to 0.32338, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 0.3632 - val_loss: 0.3234\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3070\n",
      "Epoch 4: val_loss improved from 0.32338 to 0.29655, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.3070 - val_loss: 0.2966\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3070\n",
      "Epoch 5: val_loss did not improve from 0.29655\n",
      "29/29 [==============================] - 2s 68ms/step - loss: 0.3071 - val_loss: 0.3103\n",
      "finished training\n",
      "12/12 [==============================] - 0s 14ms/step\n",
      "training on param set  144\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_720 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_288 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_721 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_289 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_722 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_288 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_723 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_289 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_724 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5119\n",
      "Epoch 1: val_loss improved from inf to 0.28579, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 137ms/step - loss: 0.5110 - val_loss: 0.2858\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2801\n",
      "Epoch 2: val_loss improved from 0.28579 to 0.26608, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.2800 - val_loss: 0.2661\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2655\n",
      "Epoch 3: val_loss improved from 0.26608 to 0.25896, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 0.2655 - val_loss: 0.2590\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2606\n",
      "Epoch 4: val_loss improved from 0.25896 to 0.25493, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 136ms/step - loss: 0.2606 - val_loss: 0.2549\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2573\n",
      "Epoch 5: val_loss improved from 0.25493 to 0.25143, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 135ms/step - loss: 0.2573 - val_loss: 0.2514\n",
      "finished training\n",
      "12/12 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  145\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_725 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_290 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_726 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_291 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_727 (Conv2D)         (None, 8, 16, 32)         51232     \n",
      "                                                                 \n",
      " up_sampling2d_290 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_728 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_291 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_729 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,421\n",
      "Trainable params: 88,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.6354\n",
      "Epoch 1: val_loss improved from inf to 0.94142, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 152ms/step - loss: 1.6333 - val_loss: 0.9414\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4810\n",
      "Epoch 2: val_loss improved from 0.94142 to 0.41289, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 146ms/step - loss: 0.4805 - val_loss: 0.4129\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3356\n",
      "Epoch 3: val_loss improved from 0.41289 to 0.32086, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 0.3356 - val_loss: 0.3209\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3419\n",
      "Epoch 4: val_loss did not improve from 0.32086\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 0.3427 - val_loss: 0.4995\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3535\n",
      "Epoch 5: val_loss improved from 0.32086 to 0.30118, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 0.3532 - val_loss: 0.3012\n",
      "finished training\n",
      "12/12 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  146\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_730 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_292 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_731 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_293 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_732 (Conv2D)         (None, 8, 16, 32)         51232     \n",
      "                                                                 \n",
      " up_sampling2d_292 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_733 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_293 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_734 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,521\n",
      "Trainable params: 98,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.6028\n",
      "Epoch 1: val_loss improved from inf to 1.12416, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 162ms/step - loss: 1.6005 - val_loss: 1.1242\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.1195\n",
      "Epoch 2: val_loss improved from 1.12416 to 0.33536, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 154ms/step - loss: 1.1161 - val_loss: 0.3354\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4593\n",
      "Epoch 3: val_loss did not improve from 0.33536\n",
      "29/29 [==============================] - 4s 146ms/step - loss: 0.4591 - val_loss: 0.4290\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4420\n",
      "Epoch 4: val_loss did not improve from 0.33536\n",
      "29/29 [==============================] - 4s 145ms/step - loss: 0.4421 - val_loss: 0.4215\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4052\n",
      "Epoch 5: val_loss improved from 0.33536 to 0.31577, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 152ms/step - loss: 0.4048 - val_loss: 0.3158\n",
      "finished training\n",
      "12/12 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  147\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_735 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_294 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_736 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_295 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_737 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_294 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_738 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_295 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_739 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6101\n",
      "Epoch 1: val_loss improved from inf to 0.30227, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 137ms/step - loss: 0.6087 - val_loss: 0.3023\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2861\n",
      "Epoch 2: val_loss improved from 0.30227 to 0.27058, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.2860 - val_loss: 0.2706\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2718\n",
      "Epoch 3: val_loss improved from 0.27058 to 0.26424, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.2718 - val_loss: 0.2642\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2658\n",
      "Epoch 4: val_loss improved from 0.26424 to 0.26013, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 133ms/step - loss: 0.2658 - val_loss: 0.2601\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2780\n",
      "Epoch 5: val_loss did not improve from 0.26013\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 0.2780 - val_loss: 0.2627\n",
      "finished training\n",
      "12/12 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  148\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_740 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_296 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_741 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_297 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_742 (Conv2D)         (None, 8, 16, 32)         51232     \n",
      "                                                                 \n",
      " up_sampling2d_296 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_743 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_297 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_744 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,421\n",
      "Trainable params: 88,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5770\n",
      "Epoch 1: val_loss improved from inf to 2.78151, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 147ms/step - loss: 2.5778 - val_loss: 2.7815\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.4556\n",
      "Epoch 2: val_loss improved from 2.78151 to 0.63402, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 154ms/step - loss: 1.4517 - val_loss: 0.6340\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7908\n",
      "Epoch 3: val_loss did not improve from 0.63402\n",
      "29/29 [==============================] - 4s 150ms/step - loss: 0.7894 - val_loss: 0.9645\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4609\n",
      "Epoch 4: val_loss improved from 0.63402 to 0.34551, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 150ms/step - loss: 0.4604 - val_loss: 0.3455\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3281\n",
      "Epoch 5: val_loss did not improve from 0.34551\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 0.3281 - val_loss: 0.3562\n",
      "finished training\n",
      "12/12 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  149\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_745 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_298 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_746 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_299 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_747 (Conv2D)         (None, 8, 16, 32)         51232     \n",
      "                                                                 \n",
      " up_sampling2d_298 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_748 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_299 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_749 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,521\n",
      "Trainable params: 98,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9443\n",
      "Epoch 1: val_loss improved from inf to 0.74190, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 175ms/step - loss: 1.9392 - val_loss: 0.7419\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9465\n",
      "Epoch 2: val_loss did not improve from 0.74190\n",
      "29/29 [==============================] - 5s 176ms/step - loss: 0.9456 - val_loss: 0.8894\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6402\n",
      "Epoch 3: val_loss improved from 0.74190 to 0.41816, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 181ms/step - loss: 0.6392 - val_loss: 0.4182\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3577\n",
      "Epoch 4: val_loss improved from 0.41816 to 0.31573, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 182ms/step - loss: 0.3574 - val_loss: 0.3157\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3105\n",
      "Epoch 5: val_loss improved from 0.31573 to 0.30519, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 185ms/step - loss: 0.3105 - val_loss: 0.3052\n",
      "finished training\n",
      "12/12 [==============================] - 1s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  150\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_750 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_300 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_751 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_301 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_752 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_300 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_753 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_301 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_754 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2052\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 174ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2049\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 5s 171ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2061\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 5s 161ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2069\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 5s 163ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2064\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 5s 159ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 29ms/step\n",
      "training on param set  151\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_755 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_302 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_756 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_303 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_757 (Conv2D)         (None, 8, 16, 32)         51232     \n",
      "                                                                 \n",
      " up_sampling2d_302 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_758 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_303 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_759 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,421\n",
      "Trainable params: 88,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.7393\n",
      "Epoch 1: val_loss improved from inf to 1.11364, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 186ms/step - loss: 1.7370 - val_loss: 1.1136\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.9841\n",
      "Epoch 2: val_loss improved from 1.11364 to 0.98127, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 175ms/step - loss: 0.9842 - val_loss: 0.9813\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.7733\n",
      "Epoch 3: val_loss did not improve from 0.98127\n",
      "29/29 [==============================] - 5s 173ms/step - loss: 1.7816 - val_loss: 3.2948\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8524\n",
      "Epoch 4: val_loss did not improve from 0.98127\n",
      "29/29 [==============================] - 6s 199ms/step - loss: 1.8511 - val_loss: 1.3930\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2960\n",
      "Epoch 5: val_loss did not improve from 0.98127\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 2.2945 - val_loss: 1.6988\n",
      "finished training\n",
      "12/12 [==============================] - 1s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  152\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_760 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_304 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_761 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_305 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_762 (Conv2D)         (None, 8, 16, 32)         51232     \n",
      "                                                                 \n",
      " up_sampling2d_304 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_763 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_305 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_764 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,521\n",
      "Trainable params: 98,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 5.3482\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 218ms/step - loss: 5.3431 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2065\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 5s 186ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2032\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2045\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2050\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 5s 183ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  153\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_765 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_306 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_766 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_307 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_767 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_306 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_768 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_307 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_769 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5496\n",
      "Epoch 1: val_loss improved from inf to 0.35923, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 265ms/step - loss: 0.5496 - val_loss: 0.3592\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3032\n",
      "Epoch 2: val_loss improved from 0.35923 to 0.28635, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.3032 - val_loss: 0.2863\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2783\n",
      "Epoch 3: val_loss improved from 0.28635 to 0.26883, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 0.2783 - val_loss: 0.2688\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2659\n",
      "Epoch 4: val_loss improved from 0.26883 to 0.25743, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 0.2659 - val_loss: 0.2574\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2594\n",
      "Epoch 5: val_loss improved from 0.25743 to 0.25646, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.2594 - val_loss: 0.2565\n",
      "finished training\n",
      "12/12 [==============================] - 1s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  154\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_770 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_308 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_771 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_309 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_772 (Conv2D)         (None, 8, 16, 32)         115232    \n",
      "                                                                 \n",
      " up_sampling2d_308 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_773 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_309 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_774 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,661\n",
      "Trainable params: 194,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.6426\n",
      "Epoch 1: val_loss improved from inf to 4.95284, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 293ms/step - loss: 3.6541 - val_loss: 4.9528\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.8247\n",
      "Epoch 2: val_loss improved from 4.95284 to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 3.8248 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2052\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 281ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2054\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  155\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_775 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_310 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_776 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_311 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_777 (Conv2D)         (None, 8, 16, 32)         115232    \n",
      "                                                                 \n",
      " up_sampling2d_310 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_778 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_311 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_779 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,761\n",
      "Trainable params: 204,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.0854\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 283ms/step - loss: 4.0850 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2044\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 7s 258ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2036\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 279ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2065\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  156\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_780 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_312 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_781 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_313 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_782 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_312 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_783 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_313 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_784 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4718\n",
      "Epoch 1: val_loss improved from inf to 0.28442, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 257ms/step - loss: 0.4710 - val_loss: 0.2844\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2766\n",
      "Epoch 2: val_loss improved from 0.28442 to 0.26581, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.2766 - val_loss: 0.2658\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2636\n",
      "Epoch 3: val_loss improved from 0.26581 to 0.25913, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 253ms/step - loss: 0.2635 - val_loss: 0.2591\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2589\n",
      "Epoch 4: val_loss improved from 0.25913 to 0.25100, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 290ms/step - loss: 0.2589 - val_loss: 0.2510\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2530\n",
      "Epoch 5: val_loss improved from 0.25100 to 0.24784, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 0.2530 - val_loss: 0.2478\n",
      "finished training\n",
      "12/12 [==============================] - 1s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  157\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_785 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_314 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_786 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_315 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_787 (Conv2D)         (None, 8, 16, 32)         115232    \n",
      "                                                                 \n",
      " up_sampling2d_314 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_788 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_315 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_789 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,661\n",
      "Trainable params: 194,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.5965\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 271ms/step - loss: 4.5943 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 263ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2063\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2052\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 286ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  158\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_790 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_316 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_791 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_317 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_792 (Conv2D)         (None, 8, 16, 32)         115232    \n",
      "                                                                 \n",
      " up_sampling2d_316 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_793 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_317 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_794 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,761\n",
      "Trainable params: 204,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7082\n",
      "Epoch 1: val_loss improved from inf to 1.75055, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 278ms/step - loss: 2.7044 - val_loss: 1.7505\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0074\n",
      "Epoch 2: val_loss did not improve from 1.75055\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 2.0097 - val_loss: 2.3349\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1928\n",
      "Epoch 3: val_loss improved from 1.75055 to 1.40757, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 277ms/step - loss: 2.1894 - val_loss: 1.4076\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.0748\n",
      "Epoch 4: val_loss improved from 1.40757 to 0.75386, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 278ms/step - loss: 1.0748 - val_loss: 0.7539\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8056\n",
      "Epoch 5: val_loss improved from 0.75386 to 0.39260, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 282ms/step - loss: 0.8037 - val_loss: 0.3926\n",
      "finished training\n",
      "12/12 [==============================] - 1s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  159\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_795 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_318 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_796 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_319 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_797 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_318 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_798 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_319 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_799 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4004\n",
      "Epoch 1: val_loss improved from inf to 0.27386, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 245ms/step - loss: 0.3998 - val_loss: 0.2739\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2694\n",
      "Epoch 2: val_loss improved from 0.27386 to 0.25971, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 0.2694 - val_loss: 0.2597\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2600\n",
      "Epoch 3: val_loss improved from 0.25971 to 0.25787, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.2600 - val_loss: 0.2579\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2549\n",
      "Epoch 4: val_loss improved from 0.25787 to 0.24836, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 243ms/step - loss: 0.2548 - val_loss: 0.2484\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2598\n",
      "Epoch 5: val_loss did not improve from 0.24836\n",
      "29/29 [==============================] - 7s 230ms/step - loss: 0.2598 - val_loss: 0.2892\n",
      "finished training\n",
      "12/12 [==============================] - 1s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  160\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_800 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_320 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_801 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_321 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " conv2d_802 (Conv2D)         (None, 8, 16, 32)         115232    \n",
      "                                                                 \n",
      " up_sampling2d_320 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_803 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_321 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_804 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,661\n",
      "Trainable params: 194,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.1723\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 276ms/step - loss: 4.1723 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2056\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 266ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 7s 246ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2041\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 8s 268ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  161\n",
      "{'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_805 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_322 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_806 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_323 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 8, 16, 100)        3300      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 8, 16, 100)        10100     \n",
      "                                                                 \n",
      " conv2d_807 (Conv2D)         (None, 8, 16, 32)         115232    \n",
      "                                                                 \n",
      " up_sampling2d_322 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_808 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_323 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_809 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,761\n",
      "Trainable params: 204,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.3722\n",
      "Epoch 1: val_loss improved from inf to 0.37111, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 279ms/step - loss: 1.3682 - val_loss: 0.3711\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3371\n",
      "Epoch 2: val_loss improved from 0.37111 to 0.36797, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 240ms/step - loss: 0.3372 - val_loss: 0.3680\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2996\n",
      "Epoch 3: val_loss improved from 0.36797 to 0.27784, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 261ms/step - loss: 0.2996 - val_loss: 0.2778\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2779\n",
      "Epoch 4: val_loss improved from 0.27784 to 0.27232, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 247ms/step - loss: 0.2779 - val_loss: 0.2723\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2750\n",
      "Epoch 5: val_loss did not improve from 0.27232\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.2749 - val_loss: 0.2726\n",
      "finished training\n",
      "12/12 [==============================] - 1s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  162\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_810 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_324 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_811 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_325 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_812 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_324 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_813 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_325 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_814 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6101\n",
      "Epoch 1: val_loss improved from inf to 0.32621, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 65ms/step - loss: 0.6090 - val_loss: 0.3262\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3003\n",
      "Epoch 2: val_loss improved from 0.32621 to 0.28445, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.3003 - val_loss: 0.2845\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2853\n",
      "Epoch 3: val_loss improved from 0.28445 to 0.26866, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2852 - val_loss: 0.2687\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2684\n",
      "Epoch 4: val_loss improved from 0.26866 to 0.26193, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 63ms/step - loss: 0.2684 - val_loss: 0.2619\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2639\n",
      "Epoch 5: val_loss improved from 0.26193 to 0.25918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 64ms/step - loss: 0.2639 - val_loss: 0.2592\n",
      "finished training\n",
      "12/12 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  163\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_815 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_326 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_816 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_327 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_817 (Conv2D)         (None, 8, 16, 32)         38432     \n",
      "                                                                 \n",
      " up_sampling2d_326 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_818 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_327 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_819 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,877\n",
      "Trainable params: 56,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2056\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 83ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2074\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2061\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2048\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2065\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 14ms/step\n",
      "training on param set  164\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_820 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_328 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_821 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_329 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_822 (Conv2D)         (None, 8, 16, 32)         38432     \n",
      "                                                                 \n",
      " up_sampling2d_328 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_823 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_329 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_824 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,177\n",
      "Trainable params: 147,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.5094\n",
      "Epoch 1: val_loss improved from inf to 2.19130, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 107ms/step - loss: 4.4946 - val_loss: 2.1913\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.8969\n",
      "Epoch 2: val_loss did not improve from 2.19130\n",
      "29/29 [==============================] - 3s 106ms/step - loss: 2.8981 - val_loss: 3.2398\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.1364\n",
      "Epoch 3: val_loss did not improve from 2.19130\n",
      "29/29 [==============================] - 3s 103ms/step - loss: 3.1365 - val_loss: 3.2071\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.1278\n",
      "Epoch 4: val_loss did not improve from 2.19130\n",
      "29/29 [==============================] - 3s 105ms/step - loss: 3.1286 - val_loss: 3.2062\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.1274\n",
      "Epoch 5: val_loss did not improve from 2.19130\n",
      "29/29 [==============================] - 3s 112ms/step - loss: 3.1281 - val_loss: 3.2059\n",
      "finished training\n",
      "12/12 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  165\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_825 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_330 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_826 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_331 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_827 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_330 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_828 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_331 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_829 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7482\n",
      "Epoch 1: val_loss improved from inf to 0.41148, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 72ms/step - loss: 0.7467 - val_loss: 0.4115\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3450\n",
      "Epoch 2: val_loss improved from 0.41148 to 0.30446, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.3448 - val_loss: 0.3045\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2928\n",
      "Epoch 3: val_loss improved from 0.30446 to 0.28144, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 66ms/step - loss: 0.2927 - val_loss: 0.2814\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2780\n",
      "Epoch 4: val_loss improved from 0.28144 to 0.26996, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.2780 - val_loss: 0.2700\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2699\n",
      "Epoch 5: val_loss improved from 0.26996 to 0.26407, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 67ms/step - loss: 0.2698 - val_loss: 0.2641\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  166\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_830 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_332 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_831 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_333 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_832 (Conv2D)         (None, 8, 16, 32)         38432     \n",
      "                                                                 \n",
      " up_sampling2d_332 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_833 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_333 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_834 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,877\n",
      "Trainable params: 56,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.0801\n",
      "Epoch 1: val_loss improved from inf to 2.34107, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 85ms/step - loss: 2.0813 - val_loss: 2.3411\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.3280\n",
      "Epoch 2: val_loss did not improve from 2.34107\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 2.3244 - val_loss: 2.6492\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.3720\n",
      "Epoch 3: val_loss did not improve from 2.34107\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 10.3733 - val_loss: 10.5451\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.6240\n",
      "Epoch 4: val_loss did not improve from 2.34107\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 10.6227 - val_loss: 10.5421\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.6189\n",
      "Epoch 5: val_loss did not improve from 2.34107\n",
      "29/29 [==============================] - 3s 88ms/step - loss: 10.6201 - val_loss: 10.5399\n",
      "finished training\n",
      "12/12 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  167\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_835 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_334 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_836 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_335 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_837 (Conv2D)         (None, 8, 16, 32)         38432     \n",
      "                                                                 \n",
      " up_sampling2d_334 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_838 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_335 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_839 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,177\n",
      "Trainable params: 147,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7565\n",
      "Epoch 1: val_loss improved from inf to 1.17579, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 118ms/step - loss: 0.7567 - val_loss: 1.1758\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7751\n",
      "Epoch 2: val_loss improved from 1.17579 to 0.65061, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 105ms/step - loss: 0.7748 - val_loss: 0.6506\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6455\n",
      "Epoch 3: val_loss improved from 0.65061 to 0.60906, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 102ms/step - loss: 0.6455 - val_loss: 0.6091\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5938\n",
      "Epoch 4: val_loss improved from 0.60906 to 0.53248, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 99ms/step - loss: 0.5936 - val_loss: 0.5325\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5174\n",
      "Epoch 5: val_loss improved from 0.53248 to 0.48202, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 99ms/step - loss: 0.5173 - val_loss: 0.4820\n",
      "finished training\n",
      "12/12 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  168\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_840 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_336 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_841 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_337 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_842 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_336 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_843 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_337 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_844 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5365\n",
      "Epoch 1: val_loss improved from inf to 0.31592, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 60ms/step - loss: 0.5356 - val_loss: 0.3159\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2985\n",
      "Epoch 2: val_loss improved from 0.31592 to 0.28623, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 59ms/step - loss: 0.2985 - val_loss: 0.2862\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2793\n",
      "Epoch 3: val_loss improved from 0.28623 to 0.26750, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 58ms/step - loss: 0.2793 - val_loss: 0.2675\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2681\n",
      "Epoch 4: val_loss improved from 0.26750 to 0.26213, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 0.2680 - val_loss: 0.2621\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2640\n",
      "Epoch 5: val_loss improved from 0.26213 to 0.25941, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 64ms/step - loss: 0.2640 - val_loss: 0.2594\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  169\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_845 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_338 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_846 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_339 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_847 (Conv2D)         (None, 8, 16, 32)         38432     \n",
      "                                                                 \n",
      " up_sampling2d_338 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_848 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_339 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_849 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,877\n",
      "Trainable params: 56,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6615\n",
      "Epoch 1: val_loss improved from inf to 0.42794, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 86ms/step - loss: 0.6606 - val_loss: 0.4279\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3623\n",
      "Epoch 2: val_loss improved from 0.42794 to 0.30727, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 84ms/step - loss: 0.3621 - val_loss: 0.3073\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3193\n",
      "Epoch 3: val_loss did not improve from 0.30727\n",
      "29/29 [==============================] - 3s 94ms/step - loss: 0.3193 - val_loss: 0.3246\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3079\n",
      "Epoch 4: val_loss improved from 0.30727 to 0.29173, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 110ms/step - loss: 0.3078 - val_loss: 0.2917\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2881\n",
      "Epoch 5: val_loss improved from 0.29173 to 0.28261, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 97ms/step - loss: 0.2882 - val_loss: 0.2826\n",
      "finished training\n",
      "12/12 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  170\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_850 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_340 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_851 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_341 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_852 (Conv2D)         (None, 8, 16, 32)         38432     \n",
      "                                                                 \n",
      " up_sampling2d_340 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_853 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_341 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_854 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,177\n",
      "Trainable params: 147,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7588\n",
      "Epoch 1: val_loss improved from inf to 0.55319, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 99ms/step - loss: 0.7579 - val_loss: 0.5532\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4972\n",
      "Epoch 2: val_loss improved from 0.55319 to 0.46020, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 108ms/step - loss: 0.4970 - val_loss: 0.4602\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4480\n",
      "Epoch 3: val_loss improved from 0.46020 to 0.44112, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 100ms/step - loss: 0.4478 - val_loss: 0.4411\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4279\n",
      "Epoch 4: val_loss improved from 0.44112 to 0.41166, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 103ms/step - loss: 0.4279 - val_loss: 0.4117\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3717\n",
      "Epoch 5: val_loss improved from 0.41166 to 0.32824, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 90ms/step - loss: 0.3716 - val_loss: 0.3282\n",
      "finished training\n",
      "12/12 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  171\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_855 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_342 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_856 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_343 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_857 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_342 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_858 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_343 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_859 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5596\n",
      "Epoch 1: val_loss improved from inf to 0.29133, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 181ms/step - loss: 0.5583 - val_loss: 0.2913\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2779\n",
      "Epoch 2: val_loss improved from 0.29133 to 0.26834, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 151ms/step - loss: 0.2779 - val_loss: 0.2683\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2710\n",
      "Epoch 3: val_loss improved from 0.26834 to 0.26086, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 141ms/step - loss: 0.2709 - val_loss: 0.2609\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2627\n",
      "Epoch 4: val_loss improved from 0.26086 to 0.25639, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 142ms/step - loss: 0.2627 - val_loss: 0.2564\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2596\n",
      "Epoch 5: val_loss improved from 0.25639 to 0.25467, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 138ms/step - loss: 0.2596 - val_loss: 0.2547\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  172\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_860 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_344 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_861 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_345 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_862 (Conv2D)         (None, 8, 16, 32)         153632    \n",
      "                                                                 \n",
      " up_sampling2d_344 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_863 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_345 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_864 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,421\n",
      "Trainable params: 197,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.2546\n",
      "Epoch 1: val_loss improved from inf to 0.55364, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 175ms/step - loss: 1.2515 - val_loss: 0.5536\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7640\n",
      "Epoch 2: val_loss improved from 0.55364 to 0.37705, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 178ms/step - loss: 0.7623 - val_loss: 0.3771\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3374\n",
      "Epoch 3: val_loss improved from 0.37705 to 0.31585, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 177ms/step - loss: 0.3372 - val_loss: 0.3159\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3092\n",
      "Epoch 4: val_loss improved from 0.31585 to 0.30280, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 177ms/step - loss: 0.3093 - val_loss: 0.3028\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2991\n",
      "Epoch 5: val_loss improved from 0.30280 to 0.29304, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 179ms/step - loss: 0.2991 - val_loss: 0.2930\n",
      "finished training\n",
      "12/12 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  173\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_865 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_346 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_866 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_347 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_867 (Conv2D)         (None, 8, 16, 32)         153632    \n",
      "                                                                 \n",
      " up_sampling2d_346 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_868 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_347 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_869 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,721\n",
      "Trainable params: 287,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 5.5349\n",
      "Epoch 1: val_loss improved from inf to 10.48728, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 188ms/step - loss: 5.5580 - val_loss: 10.4873\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.5479\n",
      "Epoch 2: val_loss improved from 10.48728 to 9.81549, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 192ms/step - loss: 10.5473 - val_loss: 9.8155\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.8657\n",
      "Epoch 3: val_loss improved from 9.81549 to 2.14262, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 200ms/step - loss: 3.8602 - val_loss: 2.1426\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1142\n",
      "Epoch 4: val_loss improved from 2.14262 to 1.89927, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 2.1144 - val_loss: 1.8993\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1196\n",
      "Epoch 5: val_loss did not improve from 1.89927\n",
      "29/29 [==============================] - 7s 225ms/step - loss: 2.1192 - val_loss: 2.1006\n",
      "finished training\n",
      "12/12 [==============================] - 1s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  174\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_870 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_348 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_871 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_349 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_872 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_348 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_873 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_349 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_874 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3317\n",
      "Epoch 1: val_loss improved from inf to 0.27077, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 173ms/step - loss: 0.3314 - val_loss: 0.2708\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2651\n",
      "Epoch 2: val_loss improved from 0.27077 to 0.25688, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 171ms/step - loss: 0.2650 - val_loss: 0.2569\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2572\n",
      "Epoch 3: val_loss improved from 0.25688 to 0.24993, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 174ms/step - loss: 0.2572 - val_loss: 0.2499\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2512\n",
      "Epoch 4: val_loss improved from 0.24993 to 0.24688, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 156ms/step - loss: 0.2513 - val_loss: 0.2469\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2497\n",
      "Epoch 5: val_loss did not improve from 0.24688\n",
      "29/29 [==============================] - 5s 168ms/step - loss: 0.2498 - val_loss: 0.2800\n",
      "finished training\n",
      "12/12 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  175\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_875 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_350 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_876 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_351 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_877 (Conv2D)         (None, 8, 16, 32)         153632    \n",
      "                                                                 \n",
      " up_sampling2d_350 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_878 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_351 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_879 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,421\n",
      "Trainable params: 197,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7211\n",
      "Epoch 1: val_loss improved from inf to 2.15895, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 215ms/step - loss: 3.7135 - val_loss: 2.1590\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.2276\n",
      "Epoch 2: val_loss did not improve from 2.15895\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 3.2266 - val_loss: 3.1790\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.0304\n",
      "Epoch 3: val_loss did not improve from 2.15895\n",
      "29/29 [==============================] - 6s 219ms/step - loss: 3.0278 - val_loss: 2.6166\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1863\n",
      "Epoch 4: val_loss improved from 2.15895 to 2.07178, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 228ms/step - loss: 2.1867 - val_loss: 2.0718\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.8448\n",
      "Epoch 5: val_loss did not improve from 2.07178\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 2.8425 - val_loss: 2.6988\n",
      "finished training\n",
      "12/12 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  176\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_880 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_352 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_881 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_353 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_882 (Conv2D)         (None, 8, 16, 32)         153632    \n",
      "                                                                 \n",
      " up_sampling2d_352 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_883 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_353 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_884 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,721\n",
      "Trainable params: 287,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7470\n",
      "Epoch 1: val_loss improved from inf to 3.69105, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 209ms/step - loss: 3.7462 - val_loss: 3.6910\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.4125\n",
      "Epoch 2: val_loss improved from 3.69105 to 3.09042, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 3.4117 - val_loss: 3.0904\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5111\n",
      "Epoch 3: val_loss improved from 3.09042 to 2.58796, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 2.5135 - val_loss: 2.5880\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.0774\n",
      "Epoch 4: val_loss did not improve from 2.58796\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 3.0802 - val_loss: 3.8478\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.7710\n",
      "Epoch 5: val_loss did not improve from 2.58796\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 3.7707 - val_loss: 3.8010\n",
      "finished training\n",
      "12/12 [==============================] - 1s 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  177\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_885 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_354 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_886 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_355 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_887 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_354 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_888 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_355 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_889 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4440\n",
      "Epoch 1: val_loss improved from inf to 0.29126, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 216ms/step - loss: 0.4434 - val_loss: 0.2913\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2779\n",
      "Epoch 2: val_loss improved from 0.29126 to 0.26684, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 171ms/step - loss: 0.2779 - val_loss: 0.2668\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2675\n",
      "Epoch 3: val_loss improved from 0.26684 to 0.26057, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 0.2675 - val_loss: 0.2606\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2616\n",
      "Epoch 4: val_loss improved from 0.26057 to 0.25601, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 144ms/step - loss: 0.2616 - val_loss: 0.2560\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2584\n",
      "Epoch 5: val_loss improved from 0.25601 to 0.25519, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 147ms/step - loss: 0.2584 - val_loss: 0.2552\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  178\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_890 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_356 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_891 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_357 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_892 (Conv2D)         (None, 8, 16, 32)         153632    \n",
      "                                                                 \n",
      " up_sampling2d_356 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_893 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_357 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_894 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,421\n",
      "Trainable params: 197,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.4625\n",
      "Epoch 1: val_loss improved from inf to 3.58018, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 190ms/step - loss: 2.4676 - val_loss: 3.5802\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7604\n",
      "Epoch 2: val_loss improved from 3.58018 to 2.02280, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 229ms/step - loss: 2.7566 - val_loss: 2.0228\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.8596\n",
      "Epoch 3: val_loss did not improve from 2.02280\n",
      "29/29 [==============================] - 5s 181ms/step - loss: 3.8603 - val_loss: 3.7183\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.3233\n",
      "Epoch 4: val_loss did not improve from 2.02280\n",
      "29/29 [==============================] - 5s 177ms/step - loss: 3.3235 - val_loss: 3.3692\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.3029\n",
      "Epoch 5: val_loss did not improve from 2.02280\n",
      "29/29 [==============================] - 5s 170ms/step - loss: 3.3029 - val_loss: 3.3713\n",
      "finished training\n",
      "12/12 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  179\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_895 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_358 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_896 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_359 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_897 (Conv2D)         (None, 8, 16, 32)         153632    \n",
      "                                                                 \n",
      " up_sampling2d_358 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_898 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_359 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_899 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,721\n",
      "Trainable params: 287,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.4474\n",
      "Epoch 1: val_loss improved from inf to 1.34730, saving model to best_weights.h5\n",
      "29/29 [==============================] - 12s 300ms/step - loss: 2.4474 - val_loss: 1.3473\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.6189\n",
      "Epoch 2: val_loss did not improve from 1.34730\n",
      "29/29 [==============================] - 8s 288ms/step - loss: 1.6189 - val_loss: 1.5639\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.7302\n",
      "Epoch 3: val_loss did not improve from 1.34730\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 1.7306 - val_loss: 2.0248\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9326\n",
      "Epoch 4: val_loss did not improve from 1.34730\n",
      "29/29 [==============================] - 8s 265ms/step - loss: 1.9326 - val_loss: 1.8224\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.5668\n",
      "Epoch 5: val_loss did not improve from 1.34730\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 1.5662 - val_loss: 1.4438\n",
      "finished training\n",
      "12/12 [==============================] - 1s 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  180\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_900 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_360 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_901 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_361 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_902 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_360 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_903 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_361 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_904 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4651\n",
      "Epoch 1: val_loss improved from inf to 0.34651, saving model to best_weights.h5\n",
      "29/29 [==============================] - 11s 346ms/step - loss: 0.4644 - val_loss: 0.3465\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3691\n",
      "Epoch 2: val_loss improved from 0.34651 to 0.29364, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 0.3691 - val_loss: 0.2936\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2837\n",
      "Epoch 3: val_loss improved from 0.29364 to 0.27544, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2837 - val_loss: 0.2754\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2705\n",
      "Epoch 4: val_loss improved from 0.27544 to 0.26408, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2704 - val_loss: 0.2641\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2656\n",
      "Epoch 5: val_loss improved from 0.26408 to 0.25990, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 332ms/step - loss: 0.2656 - val_loss: 0.2599\n",
      "finished training\n",
      "12/12 [==============================] - 1s 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  181\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_905 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_362 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_906 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_363 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_907 (Conv2D)         (None, 8, 16, 32)         345632    \n",
      "                                                                 \n",
      " up_sampling2d_362 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_908 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_363 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_909 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,661\n",
      "Trainable params: 431,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3919\n",
      "Epoch 1: val_loss improved from inf to 2.23463, saving model to best_weights.h5\n",
      "29/29 [==============================] - 16s 519ms/step - loss: 2.3919 - val_loss: 2.2346\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.7122\n",
      "Epoch 2: val_loss did not improve from 2.23463\n",
      "29/29 [==============================] - 16s 556ms/step - loss: 2.7122 - val_loss: 3.1965\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.1475\n",
      "Epoch 3: val_loss did not improve from 2.23463\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 3.1475 - val_loss: 3.1776\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.1377\n",
      "Epoch 4: val_loss did not improve from 2.23463\n",
      "29/29 [==============================] - 17s 575ms/step - loss: 3.1377 - val_loss: 3.1451\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.2485\n",
      "Epoch 5: val_loss improved from 2.23463 to 2.01209, saving model to best_weights.h5\n",
      "29/29 [==============================] - 15s 516ms/step - loss: 2.2485 - val_loss: 2.0121\n",
      "finished training\n",
      "12/12 [==============================] - 1s 116ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  182\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_910 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_364 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_911 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_365 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_912 (Conv2D)         (None, 8, 16, 32)         345632    \n",
      "                                                                 \n",
      " up_sampling2d_364 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_913 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_365 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_914 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,961\n",
      "Trainable params: 521,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.5141\n",
      "Epoch 1: val_loss improved from inf to 2.85995, saving model to best_weights.h5\n",
      "29/29 [==============================] - 18s 569ms/step - loss: 3.5141 - val_loss: 2.8599\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.4645\n",
      "Epoch 2: val_loss improved from 2.85995 to 2.28010, saving model to best_weights.h5\n",
      "29/29 [==============================] - 15s 513ms/step - loss: 2.4645 - val_loss: 2.2801\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3044\n",
      "Epoch 3: val_loss improved from 2.28010 to 2.13618, saving model to best_weights.h5\n",
      "29/29 [==============================] - 15s 526ms/step - loss: 2.3044 - val_loss: 2.1362\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 9.2255\n",
      "Epoch 4: val_loss did not improve from 2.13618\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 9.2255 - val_loss: 10.9892\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 11.0918\n",
      "Epoch 5: val_loss did not improve from 2.13618\n",
      "29/29 [==============================] - 16s 553ms/step - loss: 11.0918 - val_loss: 10.9892\n",
      "finished training\n",
      "12/12 [==============================] - 1s 103ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  183\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_915 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_366 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_916 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_367 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_917 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_366 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_918 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_367 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_919 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5528\n",
      "Epoch 1: val_loss improved from inf to 0.29729, saving model to best_weights.h5\n",
      "29/29 [==============================] - 11s 349ms/step - loss: 0.5528 - val_loss: 0.2973\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2761\n",
      "Epoch 2: val_loss improved from 0.29729 to 0.26602, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2761 - val_loss: 0.2660\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2650\n",
      "Epoch 3: val_loss improved from 0.26602 to 0.25715, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2650 - val_loss: 0.2571\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2583\n",
      "Epoch 4: val_loss improved from 0.25715 to 0.25235, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.2583 - val_loss: 0.2524\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2545\n",
      "Epoch 5: val_loss improved from 0.25235 to 0.24996, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2545 - val_loss: 0.2500\n",
      "finished training\n",
      "12/12 [==============================] - 1s 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  184\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_920 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_368 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_921 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_369 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_922 (Conv2D)         (None, 8, 16, 32)         345632    \n",
      "                                                                 \n",
      " up_sampling2d_368 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_923 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_369 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_924 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,661\n",
      "Trainable params: 431,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.8648\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 14s 444ms/step - loss: 4.8648 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 13s 462ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 13s 456ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 13s 458ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 13s 454ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 83ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  185\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_925 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_370 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_926 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_371 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_927 (Conv2D)         (None, 8, 16, 32)         345632    \n",
      "                                                                 \n",
      " up_sampling2d_370 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_928 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_371 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_929 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,961\n",
      "Trainable params: 521,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.6341\n",
      "Epoch 1: val_loss improved from inf to 2.17871, saving model to best_weights.h5\n",
      "29/29 [==============================] - 17s 536ms/step - loss: 2.6341 - val_loss: 2.1787\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.5134\n",
      "Epoch 2: val_loss improved from 2.17871 to 2.09932, saving model to best_weights.h5\n",
      "29/29 [==============================] - 14s 493ms/step - loss: 2.5134 - val_loss: 2.0993\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.2501\n",
      "Epoch 3: val_loss did not improve from 2.09932\n",
      "29/29 [==============================] - 13s 462ms/step - loss: 2.2501 - val_loss: 2.4040\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3659\n",
      "Epoch 4: val_loss did not improve from 2.09932\n",
      "29/29 [==============================] - 14s 495ms/step - loss: 2.3659 - val_loss: 2.4089\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.4784\n",
      "Epoch 5: val_loss did not improve from 2.09932\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 2.4784 - val_loss: 2.3993\n",
      "finished training\n",
      "12/12 [==============================] - 2s 117ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  186\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_930 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_372 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_931 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_373 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_932 (Conv2D)         (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_372 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_933 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_373 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_934 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.4953\n",
      "Epoch 1: val_loss improved from inf to 0.28882, saving model to best_weights.h5\n",
      "29/29 [==============================] - 11s 358ms/step - loss: 0.4953 - val_loss: 0.2888\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2981\n",
      "Epoch 2: val_loss improved from 0.28882 to 0.28422, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2979 - val_loss: 0.2842\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2840\n",
      "Epoch 3: val_loss improved from 0.28422 to 0.27222, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.2838 - val_loss: 0.2722\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2683\n",
      "Epoch 4: val_loss improved from 0.27222 to 0.26015, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.2682 - val_loss: 0.2602\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2610\n",
      "Epoch 5: val_loss improved from 0.26015 to 0.25482, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2610 - val_loss: 0.2548\n",
      "finished training\n",
      "12/12 [==============================] - 1s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  187\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_935 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_374 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_936 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_375 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " conv2d_937 (Conv2D)         (None, 8, 16, 32)         345632    \n",
      "                                                                 \n",
      " up_sampling2d_374 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_938 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_375 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_939 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 431,661\n",
      "Trainable params: 431,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.4870\n",
      "Epoch 1: val_loss improved from inf to 2.96495, saving model to best_weights.h5\n",
      "29/29 [==============================] - 14s 446ms/step - loss: 4.4870 - val_loss: 2.9650\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.5423\n",
      "Epoch 2: val_loss improved from 2.96495 to 2.90497, saving model to best_weights.h5\n",
      "29/29 [==============================] - 14s 472ms/step - loss: 2.5423 - val_loss: 2.9050\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3857\n",
      "Epoch 3: val_loss improved from 2.90497 to 2.06170, saving model to best_weights.h5\n",
      "29/29 [==============================] - 13s 449ms/step - loss: 2.3857 - val_loss: 2.0617\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.1695\n",
      "Epoch 4: val_loss did not improve from 2.06170\n",
      "29/29 [==============================] - 14s 474ms/step - loss: 2.1695 - val_loss: 2.1327\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.1591\n",
      "Epoch 5: val_loss did not improve from 2.06170\n",
      "29/29 [==============================] - 13s 455ms/step - loss: 2.1591 - val_loss: 2.1287\n",
      "finished training\n",
      "12/12 [==============================] - 1s 83ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  188\n",
      "{'conv_depth': 32, 'hidden_size': 300, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_940 (Conv2D)         (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_376 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_941 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_377 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 8, 16, 300)        9900      \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 8, 16, 300)        90300     \n",
      "                                                                 \n",
      " conv2d_942 (Conv2D)         (None, 8, 16, 32)         345632    \n",
      "                                                                 \n",
      " up_sampling2d_376 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_943 (Conv2D)         (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_377 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_944 (Conv2D)         (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,961\n",
      "Trainable params: 521,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.0010\n",
      "Epoch 1: val_loss improved from inf to 4.30024, saving model to best_weights.h5\n",
      "29/29 [==============================] - 15s 460ms/step - loss: 4.0010 - val_loss: 4.3002\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.1973\n",
      "Epoch 2: val_loss improved from 4.30024 to 4.30023, saving model to best_weights.h5\n",
      "29/29 [==============================] - 13s 441ms/step - loss: 4.1973 - val_loss: 4.3002\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.1970\n",
      "Epoch 3: val_loss did not improve from 4.30023\n",
      "29/29 [==============================] - 13s 459ms/step - loss: 4.1970 - val_loss: 4.3002\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.1970\n",
      "Epoch 4: val_loss improved from 4.30023 to 4.30023, saving model to best_weights.h5\n",
      "29/29 [==============================] - 14s 500ms/step - loss: 4.1970 - val_loss: 4.3002\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.1970\n",
      "Epoch 5: val_loss did not improve from 4.30023\n",
      "29/29 [==============================] - 14s 472ms/step - loss: 4.1970 - val_loss: 4.3002\n",
      "finished training\n",
      "12/12 [==============================] - 1s 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  189\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_945 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_378 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_946 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_379 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_947 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_378 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_948 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_379 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_949 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.7588\n",
      "Epoch 1: val_loss improved from inf to 0.40827, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 79ms/step - loss: 0.7572 - val_loss: 0.4083\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3344\n",
      "Epoch 2: val_loss improved from 0.40827 to 0.30074, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.3342 - val_loss: 0.3007\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2928\n",
      "Epoch 3: val_loss improved from 0.30074 to 0.27999, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 82ms/step - loss: 0.2927 - val_loss: 0.2800\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2754\n",
      "Epoch 4: val_loss improved from 0.27999 to 0.26664, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.2754 - val_loss: 0.2666\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2679\n",
      "Epoch 5: val_loss improved from 0.26664 to 0.26296, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.2679 - val_loss: 0.2630\n",
      "finished training\n",
      "12/12 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  190\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_950 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_380 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_951 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_381 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_952 (Conv2D)         (None, 8, 16, 32)         64032     \n",
      "                                                                 \n",
      " up_sampling2d_380 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_953 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_381 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_954 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,077\n",
      "Trainable params: 89,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9045\n",
      "Epoch 1: val_loss improved from inf to 1.87562, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 103ms/step - loss: 1.9055 - val_loss: 1.8756\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8169\n",
      "Epoch 2: val_loss improved from 1.87562 to 1.84320, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 123ms/step - loss: 1.8173 - val_loss: 1.8432\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.8040\n",
      "Epoch 3: val_loss improved from 1.84320 to 1.84028, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 122ms/step - loss: 1.8029 - val_loss: 1.8403\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5873\n",
      "Epoch 4: val_loss did not improve from 1.84028\n",
      "29/29 [==============================] - 3s 95ms/step - loss: 2.6214 - val_loss: 10.2769\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 6.3412\n",
      "Epoch 5: val_loss did not improve from 1.84028\n",
      "29/29 [==============================] - 3s 119ms/step - loss: 6.3206 - val_loss: 2.0253\n",
      "finished training\n",
      "12/12 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  191\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_955 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_382 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_956 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_383 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_957 (Conv2D)         (None, 8, 16, 32)         64032     \n",
      "                                                                 \n",
      " up_sampling2d_382 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_958 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_383 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_959 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 339,577\n",
      "Trainable params: 339,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.9101\n",
      "Epoch 1: val_loss improved from inf to 10.41213, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 171ms/step - loss: 1.9487 - val_loss: 10.4121\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.9092\n",
      "Epoch 2: val_loss did not improve from 10.41213\n",
      "29/29 [==============================] - 4s 155ms/step - loss: 10.9085 - val_loss: 10.8551\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 7.8712\n",
      "Epoch 3: val_loss improved from 10.41213 to 3.34389, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 165ms/step - loss: 7.8503 - val_loss: 3.3439\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 3.0678\n",
      "Epoch 4: val_loss improved from 3.34389 to 3.03648, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 148ms/step - loss: 3.0692 - val_loss: 3.0365\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.9775\n",
      "Epoch 5: val_loss improved from 3.03648 to 3.03511, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 2.9773 - val_loss: 3.0351\n",
      "finished training\n",
      "12/12 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  192\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_960 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_384 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_961 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_385 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_962 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_384 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_963 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_385 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_964 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6267\n",
      "Epoch 1: val_loss improved from inf to 0.35980, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 79ms/step - loss: 0.6255 - val_loss: 0.3598\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3087\n",
      "Epoch 2: val_loss improved from 0.35980 to 0.28493, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 80ms/step - loss: 0.3086 - val_loss: 0.2849\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2777\n",
      "Epoch 3: val_loss improved from 0.28493 to 0.26727, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.2777 - val_loss: 0.2673\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2677\n",
      "Epoch 4: val_loss improved from 0.26727 to 0.26357, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 0.2677 - val_loss: 0.2636\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2654\n",
      "Epoch 5: val_loss improved from 0.26357 to 0.25945, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 65ms/step - loss: 0.2654 - val_loss: 0.2594\n",
      "finished training\n",
      "12/12 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  193\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_965 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_386 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_966 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_387 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_967 (Conv2D)         (None, 8, 16, 32)         64032     \n",
      "                                                                 \n",
      " up_sampling2d_386 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_968 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_387 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_969 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,077\n",
      "Trainable params: 89,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 1.4290\n",
      "Epoch 1: val_loss improved from inf to 0.55802, saving model to best_weights.h5\n",
      "29/29 [==============================] - 4s 108ms/step - loss: 1.4250 - val_loss: 0.5580\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.5062\n",
      "Epoch 2: val_loss improved from 0.55802 to 0.45390, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 109ms/step - loss: 0.5059 - val_loss: 0.4539\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4644\n",
      "Epoch 3: val_loss improved from 0.45390 to 0.41688, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 92ms/step - loss: 0.4641 - val_loss: 0.4169\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4033\n",
      "Epoch 4: val_loss improved from 0.41688 to 0.32688, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 112ms/step - loss: 0.4030 - val_loss: 0.3269\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3133\n",
      "Epoch 5: val_loss improved from 0.32688 to 0.29982, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 97ms/step - loss: 0.3133 - val_loss: 0.2998\n",
      "finished training\n",
      "12/12 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  194\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_970 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_388 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_971 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_389 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_972 (Conv2D)         (None, 8, 16, 32)         64032     \n",
      "                                                                 \n",
      " up_sampling2d_388 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_973 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_389 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_974 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 339,577\n",
      "Trainable params: 339,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2035\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 168ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2067\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 154ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2045\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 137ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2069\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 155ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2049\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 143ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  195\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_975 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_390 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_976 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_391 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_977 (Conv2D)         (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " up_sampling2d_390 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_978 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_391 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_979 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.8181\n",
      "Epoch 1: val_loss improved from inf to 0.36724, saving model to best_weights.h5\n",
      "29/29 [==============================] - 3s 67ms/step - loss: 0.8161 - val_loss: 0.3672\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.3167\n",
      "Epoch 2: val_loss improved from 0.36724 to 0.29058, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 0.3166 - val_loss: 0.2906\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2810\n",
      "Epoch 3: val_loss improved from 0.29058 to 0.27013, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.2810 - val_loss: 0.2701\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2699\n",
      "Epoch 4: val_loss improved from 0.27013 to 0.26358, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 0.2699 - val_loss: 0.2636\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2655\n",
      "Epoch 5: val_loss improved from 0.26358 to 0.26161, saving model to best_weights.h5\n",
      "29/29 [==============================] - 2s 62ms/step - loss: 0.2655 - val_loss: 0.2616\n",
      "finished training\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  196\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_980 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_392 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_981 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_393 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_982 (Conv2D)         (None, 8, 16, 32)         64032     \n",
      "                                                                 \n",
      " up_sampling2d_392 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_983 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_393 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_984 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,077\n",
      "Trainable params: 89,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2054\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 134ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2052\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2053\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 3s 109ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2065\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2044\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 4s 127ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  197\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 2, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_985 (Conv2D)         (None, 32, 64, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_394 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_986 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_395 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_987 (Conv2D)         (None, 8, 16, 32)         64032     \n",
      "                                                                 \n",
      " up_sampling2d_394 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_988 (Conv2D)         (None, 16, 32, 32)        4128      \n",
      "                                                                 \n",
      " up_sampling2d_395 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_989 (Conv2D)         (None, 32, 64, 1)         129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 339,577\n",
      "Trainable params: 339,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.4672\n",
      "Epoch 1: val_loss improved from inf to 1.94888, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 194ms/step - loss: 1.4672 - val_loss: 1.9489\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.7079\n",
      "Epoch 2: val_loss did not improve from 1.94888\n",
      "29/29 [==============================] - 6s 191ms/step - loss: 2.7406 - val_loss: 9.6631\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 9.7508\n",
      "Epoch 3: val_loss did not improve from 1.94888\n",
      "29/29 [==============================] - 5s 180ms/step - loss: 9.7508 - val_loss: 9.6497\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 9.6834\n",
      "Epoch 4: val_loss did not improve from 1.94888\n",
      "29/29 [==============================] - 5s 178ms/step - loss: 9.6850 - val_loss: 9.6145\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 9.6713\n",
      "Epoch 5: val_loss did not improve from 1.94888\n",
      "29/29 [==============================] - 5s 186ms/step - loss: 9.6710 - val_loss: 9.5947\n",
      "finished training\n",
      "12/12 [==============================] - 1s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  198\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_990 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_396 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_991 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_397 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_992 (Conv2D)         (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_396 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_993 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_397 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_994 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4624\n",
      "Epoch 1: val_loss improved from inf to 0.27668, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 189ms/step - loss: 0.4616 - val_loss: 0.2767\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2720\n",
      "Epoch 2: val_loss improved from 0.27668 to 0.26269, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 197ms/step - loss: 0.2720 - val_loss: 0.2627\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2622\n",
      "Epoch 3: val_loss improved from 0.26269 to 0.25575, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 180ms/step - loss: 0.2622 - val_loss: 0.2557\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2570\n",
      "Epoch 4: val_loss improved from 0.25575 to 0.25163, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 179ms/step - loss: 0.2570 - val_loss: 0.2516\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2562\n",
      "Epoch 5: val_loss improved from 0.25163 to 0.25115, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 177ms/step - loss: 0.2562 - val_loss: 0.2511\n",
      "finished training\n",
      "12/12 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  199\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_995 (Conv2D)         (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_398 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_996 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_399 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_997 (Conv2D)         (None, 8, 16, 32)         256032    \n",
      "                                                                 \n",
      " up_sampling2d_398 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_998 (Conv2D)         (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_399 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_999 (Conv2D)         (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 306,421\n",
      "Trainable params: 306,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.8938\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 11s 357ms/step - loss: 4.8938 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2076\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2063\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 9s 320ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 11s 366ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  200\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1000 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_400 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1001 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_401 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_1002 (Conv2D)        (None, 8, 16, 32)         256032    \n",
      "                                                                 \n",
      " up_sampling2d_400 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1003 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_401 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1004 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 556,921\n",
      "Trainable params: 556,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 6.1116\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 13s 398ms/step - loss: 6.1116 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 11s 379ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 10s 356ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 10s 354ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 11s 378ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 77ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  201\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1005 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_402 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1006 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_403 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1007 (Conv2D)        (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_402 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1008 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_403 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1009 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.6083\n",
      "Epoch 1: val_loss improved from inf to 0.31884, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 177ms/step - loss: 0.6071 - val_loss: 0.3188\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2840\n",
      "Epoch 2: val_loss improved from 0.31884 to 0.26674, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 174ms/step - loss: 0.2840 - val_loss: 0.2667\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2668\n",
      "Epoch 3: val_loss improved from 0.26674 to 0.26104, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.2667 - val_loss: 0.2610\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2628\n",
      "Epoch 4: val_loss did not improve from 0.26104\n",
      "29/29 [==============================] - 6s 203ms/step - loss: 0.2629 - val_loss: 0.2661\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2643\n",
      "Epoch 5: val_loss improved from 0.26104 to 0.25653, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.2643 - val_loss: 0.2565\n",
      "finished training\n",
      "12/12 [==============================] - 1s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  202\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1010 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_404 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1011 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_405 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_1012 (Conv2D)        (None, 8, 16, 32)         256032    \n",
      "                                                                 \n",
      " up_sampling2d_404 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1013 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_405 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1014 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 306,421\n",
      "Trainable params: 306,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 9.3139\n",
      "Epoch 1: val_loss improved from inf to 10.96799, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 297ms/step - loss: 9.3221 - val_loss: 10.9680\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 11.0701\n",
      "Epoch 2: val_loss improved from 10.96799 to 10.96779, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 11.0701 - val_loss: 10.9678\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 11.0196\n",
      "Epoch 3: val_loss improved from 10.96779 to 10.81993, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 11.0170 - val_loss: 10.8199\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 10.6081\n",
      "Epoch 4: val_loss improved from 10.81993 to 2.33280, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 287ms/step - loss: 10.5715 - val_loss: 2.3328\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.6646\n",
      "Epoch 5: val_loss improved from 2.33280 to 2.28588, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 2.6622 - val_loss: 2.2859\n",
      "finished training\n",
      "12/12 [==============================] - 1s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  203\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1015 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_406 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1016 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_407 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_1017 (Conv2D)        (None, 8, 16, 32)         256032    \n",
      "                                                                 \n",
      " up_sampling2d_406 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1018 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_407 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1019 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 556,921\n",
      "Trainable params: 556,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 6.3727\n",
      "Epoch 1: val_loss improved from inf to 3.58133, saving model to best_weights.h5\n",
      "29/29 [==============================] - 13s 391ms/step - loss: 6.3727 - val_loss: 3.5813\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.2446\n",
      "Epoch 2: val_loss did not improve from 3.58133\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 3.2446 - val_loss: 6.6169\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.1848\n",
      "Epoch 3: val_loss improved from 3.58133 to 3.18049, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 3.1848 - val_loss: 3.1805\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.7380\n",
      "Epoch 4: val_loss improved from 3.18049 to 2.89829, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 2.7380 - val_loss: 2.8983\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.8830\n",
      "Epoch 5: val_loss did not improve from 2.89829\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 2.8830 - val_loss: 2.9102\n",
      "finished training\n",
      "12/12 [==============================] - 1s 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  204\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1020 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_408 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1021 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_409 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1022 (Conv2D)        (None, 8, 16, 32)         16416     \n",
      "                                                                 \n",
      " up_sampling2d_408 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1023 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_409 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1024 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4655\n",
      "Epoch 1: val_loss improved from inf to 0.29014, saving model to best_weights.h5\n",
      "29/29 [==============================] - 6s 164ms/step - loss: 0.4648 - val_loss: 0.2901\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2800\n",
      "Epoch 2: val_loss improved from 0.29014 to 0.26760, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 165ms/step - loss: 0.2801 - val_loss: 0.2676\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2658\n",
      "Epoch 3: val_loss improved from 0.26760 to 0.25878, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 162ms/step - loss: 0.2658 - val_loss: 0.2588\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2596\n",
      "Epoch 4: val_loss improved from 0.25878 to 0.25397, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 162ms/step - loss: 0.2596 - val_loss: 0.2540\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2553\n",
      "Epoch 5: val_loss improved from 0.25397 to 0.25025, saving model to best_weights.h5\n",
      "29/29 [==============================] - 5s 163ms/step - loss: 0.2554 - val_loss: 0.2502\n",
      "finished training\n",
      "12/12 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  205\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1025 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_410 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1026 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_411 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_1027 (Conv2D)        (None, 8, 16, 32)         256032    \n",
      "                                                                 \n",
      " up_sampling2d_410 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1028 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_411 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1029 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 306,421\n",
      "Trainable params: 306,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.9865\n",
      "Epoch 1: val_loss improved from inf to 2.12277, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 293ms/step - loss: 3.9865 - val_loss: 2.1228\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.5185\n",
      "Epoch 2: val_loss did not improve from 2.12277\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 2.5161 - val_loss: 2.2331\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 7.0935\n",
      "Epoch 3: val_loss did not improve from 2.12277\n",
      "29/29 [==============================] - 8s 278ms/step - loss: 7.1073 - val_loss: 10.1325\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.9179\n",
      "Epoch 4: val_loss did not improve from 2.12277\n",
      "29/29 [==============================] - 8s 278ms/step - loss: 4.9128 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.2049\n",
      "Epoch 5: val_loss did not improve from 2.12277\n",
      "29/29 [==============================] - 8s 275ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  206\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 4, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1030 (Conv2D)        (None, 32, 64, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_412 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1031 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_413 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_1032 (Conv2D)        (None, 8, 16, 32)         256032    \n",
      "                                                                 \n",
      " up_sampling2d_412 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1033 (Conv2D)        (None, 16, 32, 32)        16416     \n",
      "                                                                 \n",
      " up_sampling2d_413 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1034 (Conv2D)        (None, 32, 64, 1)         513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 556,921\n",
      "Trainable params: 556,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.6583\n",
      "Epoch 1: val_loss improved from inf to 2.89689, saving model to best_weights.h5\n",
      "29/29 [==============================] - 12s 356ms/step - loss: 2.6583 - val_loss: 2.8969\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.2410\n",
      "Epoch 2: val_loss improved from 2.89689 to 2.11246, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 322ms/step - loss: 2.2411 - val_loss: 2.1125\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 2.1193\n",
      "Epoch 3: val_loss did not improve from 2.11246\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 2.1187 - val_loss: 2.1200\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.1565\n",
      "Epoch 4: val_loss did not improve from 2.11246\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 2.1565 - val_loss: 3.2377\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 4.1321\n",
      "Epoch 5: val_loss did not improve from 2.11246\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 4.1341 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  207\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1035 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_414 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1036 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_415 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1037 (Conv2D)        (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_414 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1038 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_415 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1039 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4428\n",
      "Epoch 1: val_loss improved from inf to 0.29027, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 250ms/step - loss: 0.4421 - val_loss: 0.2903\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2811\n",
      "Epoch 2: val_loss improved from 0.29027 to 0.26828, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 0.2810 - val_loss: 0.2683\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2688\n",
      "Epoch 3: val_loss improved from 0.26828 to 0.26521, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 260ms/step - loss: 0.2687 - val_loss: 0.2652\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2649\n",
      "Epoch 4: val_loss improved from 0.26521 to 0.25988, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 249ms/step - loss: 0.2649 - val_loss: 0.2599\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2610\n",
      "Epoch 5: val_loss improved from 0.25988 to 0.25550, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 250ms/step - loss: 0.2610 - val_loss: 0.2555\n",
      "finished training\n",
      "12/12 [==============================] - 1s 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  208\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1040 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_416 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1041 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_417 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_1042 (Conv2D)        (None, 8, 16, 32)         576032    \n",
      "                                                                 \n",
      " up_sampling2d_416 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1043 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_417 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1044 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 668,661\n",
      "Trainable params: 668,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 10.4044\n",
      "Epoch 1: val_loss improved from inf to 10.98171, saving model to best_weights.h5\n",
      "29/29 [==============================] - 14s 454ms/step - loss: 10.4044 - val_loss: 10.9817\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 11.0843\n",
      "Epoch 2: val_loss did not improve from 10.98171\n",
      "29/29 [==============================] - 13s 438ms/step - loss: 11.0843 - val_loss: 10.9817\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 11.0843\n",
      "Epoch 3: val_loss did not improve from 10.98171\n",
      "29/29 [==============================] - 13s 443ms/step - loss: 11.0843 - val_loss: 10.9817\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 11.0843\n",
      "Epoch 4: val_loss did not improve from 10.98171\n",
      "29/29 [==============================] - 13s 438ms/step - loss: 11.0843 - val_loss: 10.9817\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 11.0843\n",
      "Epoch 5: val_loss did not improve from 10.98171\n",
      "29/29 [==============================] - 13s 440ms/step - loss: 11.0843 - val_loss: 10.9817\n",
      "finished training\n",
      "12/12 [==============================] - 1s 84ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  209\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 1e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1045 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_418 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1046 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_419 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_1047 (Conv2D)        (None, 8, 16, 32)         576032    \n",
      "                                                                 \n",
      " up_sampling2d_418 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1048 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_419 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1049 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 919,161\n",
      "Trainable params: 919,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 7.5939\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 15s 489ms/step - loss: 7.5939 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 14s 481ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 14s 471ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 13s 458ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 1s 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  210\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1050 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_420 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_210 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1051 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_421 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1052 (Conv2D)        (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_420 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1053 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_421 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1054 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4108\n",
      "Epoch 1: val_loss improved from inf to 0.30087, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 0.4103 - val_loss: 0.3009\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2863\n",
      "Epoch 2: val_loss improved from 0.30087 to 0.27286, saving model to best_weights.h5\n",
      "29/29 [==============================] - 8s 271ms/step - loss: 0.2862 - val_loss: 0.2729\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2683\n",
      "Epoch 3: val_loss improved from 0.27286 to 0.25989, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 242ms/step - loss: 0.2683 - val_loss: 0.2599\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2610\n",
      "Epoch 4: val_loss improved from 0.25989 to 0.25604, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 244ms/step - loss: 0.2610 - val_loss: 0.2560\n",
      "Epoch 5/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2573\n",
      "Epoch 5: val_loss improved from 0.25604 to 0.25211, saving model to best_weights.h5\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 0.2573 - val_loss: 0.2521\n",
      "finished training\n",
      "12/12 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  211\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1055 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_422 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_211 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1056 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_423 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_1057 (Conv2D)        (None, 8, 16, 32)         576032    \n",
      "                                                                 \n",
      " up_sampling2d_422 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1058 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_423 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1059 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 668,661\n",
      "Trainable params: 668,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 5.9357\n",
      "Epoch 1: val_loss improved from inf to 3.55225, saving model to best_weights.h5\n",
      "29/29 [==============================] - 15s 485ms/step - loss: 5.9357 - val_loss: 3.5522\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.5625\n",
      "Epoch 2: val_loss improved from 3.55225 to 2.08635, saving model to best_weights.h5\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 2.5625 - val_loss: 2.0863\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3115\n",
      "Epoch 3: val_loss did not improve from 2.08635\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 2.3115 - val_loss: 2.6836\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3275\n",
      "Epoch 4: val_loss did not improve from 2.08635\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 2.3275 - val_loss: 2.2871\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3809\n",
      "Epoch 5: val_loss did not improve from 2.08635\n",
      "29/29 [==============================] - 12s 397ms/step - loss: 2.3809 - val_loss: 2.4388\n",
      "finished training\n",
      "12/12 [==============================] - 1s 68ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  212\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1060 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_424 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_212 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1061 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_425 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_1062 (Conv2D)        (None, 8, 16, 32)         576032    \n",
      "                                                                 \n",
      " up_sampling2d_424 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1063 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_425 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1064 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 919,161\n",
      "Trainable params: 919,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.6640\n",
      "Epoch 1: val_loss improved from inf to 2.40090, saving model to best_weights.h5\n",
      "29/29 [==============================] - 20s 631ms/step - loss: 2.6640 - val_loss: 2.4009\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 6.3449\n",
      "Epoch 2: val_loss did not improve from 2.40090\n",
      "29/29 [==============================] - 23s 783ms/step - loss: 6.3449 - val_loss: 9.9171\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.4061\n",
      "Epoch 3: val_loss did not improve from 2.40090\n",
      "29/29 [==============================] - 22s 747ms/step - loss: 4.4061 - val_loss: 4.0673\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.1233\n",
      "Epoch 4: val_loss did not improve from 2.40090\n",
      "29/29 [==============================] - 22s 751ms/step - loss: 4.1233 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 5: val_loss did not improve from 2.40090\n",
      "29/29 [==============================] - 22s 753ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 2s 155ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  213\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 0}\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1065 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_426 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_213 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1066 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_427 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1067 (Conv2D)        (None, 8, 16, 32)         36896     \n",
      "                                                                 \n",
      " up_sampling2d_426 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1068 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_427 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1069 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,025\n",
      "Trainable params: 113,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.4996\n",
      "Epoch 1: val_loss improved from inf to 0.28421, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 318ms/step - loss: 0.4986 - val_loss: 0.2842\n",
      "Epoch 2/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2785\n",
      "Epoch 2: val_loss improved from 0.28421 to 0.26477, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2785 - val_loss: 0.2648\n",
      "Epoch 3/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2642\n",
      "Epoch 3: val_loss improved from 0.26477 to 0.25688, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 334ms/step - loss: 0.2642 - val_loss: 0.2569\n",
      "Epoch 4/5\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.2579\n",
      "Epoch 4: val_loss improved from 0.25688 to 0.25205, saving model to best_weights.h5\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2579 - val_loss: 0.2521\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2544\n",
      "Epoch 5: val_loss improved from 0.25205 to 0.24900, saving model to best_weights.h5\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.2544 - val_loss: 0.2490\n",
      "finished training\n",
      "12/12 [==============================] - 1s 68ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  214\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 1}\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1070 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_428 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_214 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1071 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_429 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " conv2d_1072 (Conv2D)        (None, 8, 16, 32)         576032    \n",
      "                                                                 \n",
      " up_sampling2d_428 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1073 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_429 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1074 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 668,661\n",
      "Trainable params: 668,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2599\n",
      "Epoch 1: val_loss improved from inf to 4.30918, saving model to best_weights.h5\n",
      "29/29 [==============================] - 20s 657ms/step - loss: 4.2599 - val_loss: 4.3092\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 2: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 19s 660ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 3: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 20s 693ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 4: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 18s 638ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 4.2054\n",
      "Epoch 5: val_loss did not improve from 4.30918\n",
      "29/29 [==============================] - 20s 706ms/step - loss: 4.2054 - val_loss: 4.3092\n",
      "finished training\n",
      "12/12 [==============================] - 2s 140ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on param set  215\n",
      "{'conv_depth': 32, 'hidden_size': 500, 'kernel_size': 6, 'lr': 0.0001, 'n_hidden_layers': 2}\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1075 (Conv2D)        (None, 32, 64, 32)        1184      \n",
      "                                                                 \n",
      " max_pooling2d_430 (MaxPooli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_215 (Dropout)       (None, 16, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1076 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_431 (MaxPooli  (None, 8, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 8, 16, 500)        16500     \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 8, 16, 500)        250500    \n",
      "                                                                 \n",
      " conv2d_1077 (Conv2D)        (None, 8, 16, 32)         576032    \n",
      "                                                                 \n",
      " up_sampling2d_430 (UpSampli  (None, 16, 32, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1078 (Conv2D)        (None, 16, 32, 32)        36896     \n",
      "                                                                 \n",
      " up_sampling2d_431 (UpSampli  (None, 32, 64, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1079 (Conv2D)        (None, 32, 64, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 919,161\n",
      "Trainable params: 919,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "start training\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 7.6481\n",
      "Epoch 1: val_loss improved from inf to 4.25510, saving model to best_weights.h5\n",
      "29/29 [==============================] - 23s 762ms/step - loss: 7.6481 - val_loss: 4.2551\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.4452\n",
      "Epoch 2: val_loss did not improve from 4.25510\n",
      "29/29 [==============================] - 20s 701ms/step - loss: 3.4452 - val_loss: 6.8578\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.2394\n",
      "Epoch 3: val_loss improved from 4.25510 to 2.67437, saving model to best_weights.h5\n",
      "29/29 [==============================] - 21s 740ms/step - loss: 3.2394 - val_loss: 2.6744\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3878\n",
      "Epoch 4: val_loss improved from 2.67437 to 2.21683, saving model to best_weights.h5\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 2.3878 - val_loss: 2.2168\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.1331\n",
      "Epoch 5: val_loss improved from 2.21683 to 2.04573, saving model to best_weights.h5\n",
      "29/29 [==============================] - 21s 727ms/step - loss: 2.1331 - val_loss: 2.0457\n",
      "finished training\n",
      "12/12 [==============================] - 2s 155ms/step\n"
     ]
    }
   ],
   "source": [
    "# All possible parameter configurations are iterated over. Scikit can be used for this.\n",
    "\n",
    "param_grid = list(ParameterGrid(tunable_params))\n",
    "n_param_combis = len(param_grid)\n",
    "print('trying ',n_param_combis,' combinations')\n",
    "\n",
    "res = []\n",
    "for i,params in enumerate(param_grid):\n",
    "    print('training on param set ',i)\n",
    "    print(params)\n",
    "    \n",
    "   \n",
    "    model = build_model(**params)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "\n",
    "    print('start training')\n",
    "    hist = model.fit(X_tune, y_tune,\n",
    "                       batch_size = batch_size,\n",
    "             verbose=1, \n",
    "             epochs = num_epochs,\n",
    "             validation_data=(X_dev,y_dev),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                        min_delta=0,\n",
    "                                        patience=5, # To ensure a great deal of patience before ending\n",
    "                                        verbose=0, mode='auto'),\n",
    "                       keras.callbacks.ModelCheckpoint('best_weights.h5', monitor='val_loss', \n",
    "                                                    verbose=1, save_best_only=True, \n",
    "                                                    save_weights_only=True, mode='auto', period=1)]\n",
    "             )\n",
    "    \n",
    "    print('finished training')\n",
    "    \n",
    "    # To ensure the best model performance from the training based on learning curve,\n",
    "    # Because the early stopping callback saves the model's \"patience\" epochs after the best one, this is required.\n",
    "    model.load_weights('best_weights.h5')\n",
    "    \n",
    "    # delete the file generated by Model Checkppoint\n",
    "    os.system('rm best_weights.h5')\n",
    "    \n",
    "\n",
    "    model.save_weights(outdir+'weights_'+param_string+'_tuning_paramset'+str(i)+'.h5')\n",
    "    \n",
    "    \n",
    "    # reformat history\n",
    "    \n",
    "    hist =  hist.history\n",
    "\n",
    "    y_dev_predicted = model.predict(X_dev)\n",
    "    \n",
    "    # compute accuracy\n",
    "    rmse = np.sqrt(np.mean((y_dev_predicted - y_dev)**2))\n",
    "    acc = acc_score(y_dev_predicted, y_dev)\n",
    "\n",
    "    res.append(dict(hist=hist,params=params, scores=[rmse,acc]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(hist['val_loss'], label='val_loss')\n",
    "    plt.plot(hist['loss'], label='train loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig(outdir+'cnn_history'+param_string+'_tuning_paramset'+str(i)+'.png')\n",
    "    \n",
    "    pd.DataFrame(hist).to_csv(outdir+'history_'+param_string+'_tuning_paramset'+str(i)+'.csv')\n",
    "    \n",
    "\n",
    "\n",
    "pickle.dump(res,open(outdir+'tuning_result'+param_string+'.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df2e0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hist': {'loss': [0.47095590829849243, 0.2765541970729828, 0.26354387402534485, 0.25893470644950867, 0.25303205847740173], 'val_loss': [0.28442299365997314, 0.26581400632858276, 0.2591252326965332, 0.2510022222995758, 0.2478446066379547]}, 'params': {'conv_depth': 32, 'hidden_size': 100, 'kernel_size': 6, 'lr': 3e-05, 'n_hidden_layers': 0}, 'scores': [0.19067526, 0.9176578572244036]}\n"
     ]
    }
   ],
   "source": [
    "##Read the accuracy\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "res = pickle.load(open(outdir+'tuning_result0_1_32_5_2_0.pkl','rb'))\n",
    "\n",
    "# get each run's final validating loss\n",
    "\n",
    "final_val_losses = [e['hist']['val_loss'][-1] for e in res]\n",
    "\n",
    "# convert to array\n",
    "final_val_losses = np.array(final_val_losses)\n",
    "\n",
    "# find the smallest index.\n",
    "idx_smallest = np.argmin(final_val_losses)\n",
    "res_best = res[idx_smallest]\n",
    "print(res_best)\n",
    "\n",
    "with open('tuning_best_result.txt','w') as f :\n",
    "    f.write(str(res_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef77e5b3",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oceanenv",
   "language": "python",
   "name": "oceanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
